
\documentclass[10pt]{article} \usepackage[accepted]{tmlr}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[algo2e]{algorithm2e} 
\usepackage{algorithm}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{arydshln}
\usepackage{subfigure}
\usepackage{bm}

\usepackage{pifont}
\usepackage{wrapfig,lipsum,booktabs}
\newcommand{\cmark}{\ding{51}}\newcommand{\xmark}{\ding{55}}\DeclarePairedDelimiter{\norm}{\lVert}{\rVert} 
\usepackage{color, colortbl}
\usepackage[title]{appendix}
\usepackage{enumitem}
\definecolor{LightGray}{rgb}{0.92,0.92,0.92}
\definecolor{Red}{rgb}{1.0, 0.13, 0.32}
\definecolor{mygreen}{rgb}{0.0, 0.5, 0.0}
\usepackage{listings}
\newcommand{\mycc}{\cellcolor{LightGray}}






\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
 
\usepackage{hyperref}
\usepackage{url}




\title{BIGRoC: Boosting Image Generation via a Robust Classifier}



\author{\name Roy Ganz \email ganz@campus.technion.ac.il \\
      \addr Electrical Engineering Department\\
      Technion
      \AND
      \name Michael Elad \email elad@cs.technion.ac.il \\
      \addr Computer Science Department \\
      Technion
      }



\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\def\month{01}  \def\year{2023} \def\openreview{\url{https://openreview.net/forum?id=y7RGNXhGSR}} 


\begin{document}
\maketitle
\begin{abstract}
The interest of the machine learning community in image synthesis has grown significantly in recent years, with the introduction of a wide range of deep generative models and means for training them.
In this work, we propose a general model-agnostic technique for improving the image quality and the distribution fidelity of generated images obtained by any generative model.
Our method, termed BIGRoC (Boosting Image Generation via a Robust Classifier), is based on a post-processing procedure via the guidance of a given robust classifier and without a need for additional training of the generative model.
Given a synthesized image, we propose to update it through projected gradient steps over the robust classifier to refine its recognition.
We demonstrate this post-processing algorithm on various image synthesis methods and show a significant quantitative and qualitative improvement on CIFAR-10 and ImageNet.
Surprisingly, although BIGRoC is the first model agnostic among refinement approaches and requires much less information, it outperforms competitive methods.
Specifically, BIGRoC improves the image synthesis best performing diffusion model on ImageNet  by 14.81\%, attaining an FID score of 2.53 and on  by 7.87\%, achieving an FID of 3.63.
Moreover, we conduct an opinion survey, according to which humans significantly prefer our method's outputs.
\end{abstract}

\section{Introduction}
\label{intro}
Deep generative models are a class of deep neural networks trained to model complicated high-dimensional data \citep{bondtaylor2021deep}. 
Such models receive a large number of samples that follow a certain data distribution, , and aim to produce new ones from the same statistics. 
One of the most fascinating generative tasks is image synthesis, which is notoriously hard due to the complexity of the natural images' manifold.
Nevertheless, deep generative models for image synthesis have gained tremendous popularity in recent years, revolutionized the field, and became state-of-the-art in various tasks \citep{cyclegan, zhu2020unpaired, progan,stylegan, brock2019large, karras2020analyzing}.
Energy-based models, variational autoencoders (VAEs), generative adversarial networks (GANs), autoregressive likelihood models, normalization flows, diffusion-based algorithms, and more, all aim to synthesize natural-looking images, ranging from relatively simple to highly complicated generators \citep{kingma2014autoencoding, goodfellow2014generative, rezende2016variational, oord2016pixel, ho2020denoising}.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{images/teaser.pdf}
    \caption{\textbf{Qualitative demonstration of BIGRoC}. Top: Images generated by guided diffusion trained on ImageNet . Bottom: Refined images by applying BIGRoC.}
    \label{fig:teaser}
\end{figure}


When operating on a multiclass labeled dataset, as considered in this paper, image synthesis can be either conditional or unconditional.
In the unconditional setup, the generative model aims to produce samples from the target data distribution without receiving any information regarding the target class of the synthesized images, i.e., a sample from .
In contrast, in the conditional case, the generator goal is to synthesize images from a target class, i.e., a sample from  where  is the label. 
As such, conditional generative models receive additional class-related information.

Most of the work in the deep generative models' field focused on improving the quality and the variety of the images produced by such models, tackled by seeking novel architectures and training procedures.
In this work, while still aiming to improve the performance of trained generative models, we place a different emphasis than in most of these studies and propose a method for refining the outputs of such models.
More specifically, our model-agnostic method improves the perceptual quality of the images synthesized by any given model via an iterative post-processing procedure driven by a \emph{robust classifier}.

With the introduction of learning-based machines into ``real-world'' applications, the interest in the robustness of such models has become a central concern.
While there are abundant definitions for robustness, the most common and studied is the adversarial one. 
This definition upholds if a classifier is robust to a small perturbation of its input, made by an adversary to fool it. 
Previous work \citep{szegedy2014intriguing, goodfellow2015explaining, kurakin2017adversarial} has demonstrated that deep neural networks are not robust at all and can be easily fooled by an adversary.
In light of this observation, many robustification methods were proposed, but the most popular among these is adversarial training \citep{goodfellow2015explaining, madry2019deep}.
According to this method, to train a robust classifier, one should generate adversarial examples and incorporate them into the training process.
While examining the properties of such classifiers, researchers have revealed a fascinating phenomenon called \emph{perceptually aligned gradients} \citep{tsipras2019robustness}. 
This trait implies that modifying an image to sharpen such a classifier's decision yields visual features perceptually aligned with the target class. In other words, when drifting an image content to be better classified, the changes obtained are visually pleasing and faithful to natural image content.

In this work, we harness and utilize the above-described phenomenon -- we propose to iteratively modify the images created by a trained generative model so as to maximize the conditional probability of a target class approximated by a given robust classifier. 
This modification can potentially improve the quality of the synthesized images since it emphasizes visual features aligned with the target class, thus boosting the generation process both in terms of perceptual quality and distribution faithfulness.
Due to the fundamental differences between classification and generation, we hypothesize that the robust classifier could capture different semantic features than the generative model. Thus, incorporating the two for image refinement can improve sample quality, as can be seen in Figure~\ref{fig:teaser}.
We term this method ``BIGRoC'' --  \textbf{B}oosting \textbf{I}mage \textbf{G}eneration via a \textbf{Ro}bust \textbf{C}lassifier.

Contrary to other refinement methods, BIGRoC is general and model-agnostic that can be applied to any image generator, both conditional or unconditional, without requiring access to its weights, given an adversarially trained classifier.
The marked performance improvement achieved by our proposed method is demonstrated in a series of experiments on a wide range of image generators on CIFAR-10 and ImageNet datasets.
We show that this approach enables us to significantly improve the quality of images synthesized by relatively simple models, boosting them to a level of more sophisticated and complex ones.
Furthermore, we show the ability of our method to enhance the performance of generative architectures of the highest quality, both qualitatively and quantitatively.
Specifically, applying BIGRoC on the outputs of guided diffusion, \citep{dhariwal2021diffusion} significantly improves its performance on ImageNet  and  -- achieving FIDs of 2.53 and 3.63, an improvement of 14.81\% and 7.87\%, respectively. Moreover, to truly validate that BIGRoC perceptually refines samples, we present an opinion survey, which finds that human evaluators significantly prefer the outputs of our method. As such, our work exposes the striking generative capabilities of adversarially trained classifiers. These abilities were yet to be fully discovered and utilized in previous work.
To summarize, our contributions are as follow:
\begin{itemize}[leftmargin=*]
    \item We introduce BIGRoC, the first model-agnostic approach for image generation refinement by harnessing the Perceptually Aligned Gradients phenomenon.
    \item Extensive experiments on CIFAR-10 and ImageNet (both  and ) show significant quantitative and qualitative improvements across a wide range of generative models.
    \item We reveal the exceptional generative power of Adversarially Robust classifiers, as the same model is capable of refining both low-quality and State-Of-The-Art image synthesizers. 
\end{itemize}

\section{Background}

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{images/perceptually_aligned_grad_comp.png}
    \caption{\textbf{PAG visualization}.
    Demonstration of large -based adversarial examples on robust (top) and non robust (bottom) ResNet50 classifiers \citep{he2015deep} trained on CIFAR-10. The classifier's certainty and the effective  norm of the perturbation   are denoted as P and , respectively. As can be seen, robust models with PAG guides the attack towards semantically meaningful features, whereas non-robust do not.
    }
    \label{fig:perceptually_aligned_gradients}
\end{figure}

\subsection{Adversarial Examples}
Adversarial examples are instances intentionally designed by an attacker to cause a false prediction by a machine learning-based classifier \citep{szegedy2014intriguing, goodfellow2015explaining, kurakin2017adversarial}.
The generation procedure of such examples relies on applying modifications to given training examples while restricting the allowed perturbations .
Ideally, the “threat model”  should include all the possible unnoticeable perturbations to a human observer.
As it is impossible to rigorously define such a set, in practice a simple subset of the ideal threat model is used, where the most common choices are the  and the  balls: .
Given , the attacker receives an instance  and generates , while aiming to fool the classifier.
Adversarial attacks can be both untargeted or targeted: An untargeted attack perturbs the input in a way that minimizes  with respect to . 
In contrast, a targeted attack receives in addition the target class , and perturbs  to maximize .
There are diverse techniques for generating adversarial examples, yet, in this work, we focus on targeted attacks using the Projected Gradient Descent (PGD) \citep{madry2019deep}-- an iterative method for creating adversarial examples that operates as shown in Algorithm \ref{Alg:PGD}.
The operation  is the projection operator onto , and  is the classification loss.

\begin{algorithm}[ht]
\SetAlgoLined
    \textbf{Input}: classifier , input , target class , , step size , number of iterations \\
    \\
    \For{t from 0 to T}{
    ;\
    }
     \\
    \textbf{Output}: 
    \caption{Targeted Projected Gradient Descent (PGD)}
    \label{Alg:PGD}
\end{algorithm}


\subsection{Adversarial Robustness}
Adversarial robustness is a property of classifiers, according to which applying a small perturbation on a classifier's input in order to fool it does not affect its prediction \citep{goodfellow2015explaining}.
To attain such classifiers, one should solve the following optimization problem:

Namely, train the classifier to accurately predict the class labels of the "toughest" perturbed images, allowed by the threat model . 
In practice, solving this optimization problem is challenging, and there are several ways to attain an approximated solution.
The most simple yet effective method is based on approximating the solution of the inner-maximization via adversarial attacks, such as PGD \citep{madry2019deep}.
According to this strategy, the above optimization is performed iteratively, fixing the classifier's parameters  and optimizing the perturbation  for each example via PGD, and then fixing these and updating .
Repeating these steps results in a robust classifier, as we use in this work.

\subsection{Perceptually Aligned Gradients}
Perceptually aligned gradients (PAG)~\citep{tsipras2019robustness,general_property,Aggarwal2020OnTB,pag_rob} is a trait of adversarially trained models, best demonstrated when modifying an image to maximize the probability assigned to a target class.
\citep{tsipras2019robustness} show that performing the above process on such models yields meaningful features aligned with the target class. 
It is important to note that this phenomenon does not occur in non-robust models.
The perceptually aligned gradients property indicates that the features learned by robust models are more aligned with human perception.
Figure \ref{fig:perceptually_aligned_gradients} presents a visual demonstration of this fascinating phenomenon.

\section{Boosting Image Generation via a Robust Classifier}
\label{sec:method}

\begin{figure}
    \centering
    \subfigure[CIFAR-10]{\label{fig:cifar_qualitative}\includegraphics[height=8.1cm]{images/Qualitative_boost2.png}}
    \subfigure[ImageNet]{\label{fig:IN_qualitative}\includegraphics[height=6.68cm]{images/IN_qualitative_fig3.png}}
    \caption{\textbf{BIGRoC qualitative results}. We present pairs of images where the left columns contain generated images and the right ones the boosted results. Figures \ref{fig:cifar_qualitative} and \ref{fig:IN_qualitative} show such results on CIFAR-10 and ImageNet , respectively.
    }
    \label{fig:qualitative_boost}
\end{figure}

We propose a method for improving the quality of images synthesized by trained generative models, named BIGRoC: Boosting Image Generation via a Robust Classifier.
Our method is model agnostic and does not require additional training or fine-tuning of the generative model that can be viewed as a post-processing step performed on the synthesized images.
Thus, BIGRoC can be easily applied to any generative model, both conditional or unconditional.
This mechanism harnesses the perceptually aligned gradients phenomenon to modify the generated images to improve their visual quality.
To do so, we perform an iterative process of modifying the generated image  to maximize the posterior probability of a given target class , , where  is modeled by an adversarially trained classifier.
This can be achieved by performing a PGD-like process that instead of adversarially changing an image  of class  to a different class , modifies it in a way that maximizes the probability that  belongs to class .
Therefore, our method requires a trained robust classifier that operates on the same data source as the images we aim to improve.

In the conditional generation process, the generator  receives the class label , from which it suppose to draw samples. 
Hence, in this setup, we have information regarding the class affiliation of the image, and we can maximize the corresponding conditional probability.
In the unconditional generation process, the generator does not receive class labels at all, and its goal is to draw samples from .
Thus, in this case, we cannot directly maximize the desired posterior probability, as our method suggests.
To bridge this gap, we propose to estimate the most likely class via our robust classifier  and afterward modify the image via the suggested method to maximize its probability.
The proposed image generation boosting is described in Algorithm \ref{Alg:adversarial_boosting} for both setups.

While the above-described approach for unconditional sampling works well, it could be further improved. We have noticed that in this case, estimating the target classes  of  via  might lead to unbalanced labels.
For example, in the CIFAR-10, when generating 50,000 samples, we expect approximately 5,000 images per each of the ten classes, and yet the labels' estimation does not distribute uniformly at all.
This imbalance stems from the incompetence of the generative model to capture the data distribution, which leads to a bias in the target labels estimation of the boosting algorithm, affecting the visual content of . Since quantitative evaluation is impaired by such class imbalances, this bias limits the quantitative improvement attained by BIGRoC.
We emphasize that this issue is manifested only in the quantitative metrics, and when qualitatively evaluating the boosted images, the improvement is significant, as can be seen in the supplementary material.

To further enhance the quantitative results of our algorithm in the unconditional case, we propose to de-bias the target class estimation of  and attain close to uniform class estimations.
A naive solution to this can be achieved by generating more samples and extracting a subset of these images with a labels-balance.
This approach is computationally heavy and does not use the generated images as-is, raising questions regarding the fairness of the quantitative comparison.
Thus, we propose a different debiasing technique -- we modify the classifier's class estimation to become more balanced by calibrating its logits.
More specifically, we shift the classifier's logits by adding a per-class pre-calculated value, , that induces equality of the mean logits value across all classes.
We define  as a vector containing all  values:
 where  is the number of classes.
For simplicity, we denote  as the logit of class  corresponding to a generated sample .
We approximate  for each class , using a validation set of generated images, and calculate a per-class debiasing factor:  (WLOG, ), where  is a mean estimator.
After calculating , given a generated image , we calculate its logits and add  to it to obtain debiased logits (), from which we derive the unbiased class estimation via softmax.
The following equation shows that, given a correct estimation of the per-class logits' mean, the per-class means of the debiased logits are equal:



\noindent We present in Appendix \ref{sec:debiasing} an empirical demonstration that verifies the validity of this method and shows its qualitative effects on unconditional generation boosting.


\begin{algorithm}[ht]
\SetAlgoLined
\textbf{Input}: Robust classifier , , , , step size , number of iterations , debiasing vector \\
\If{ is None}{
    \\
}
 \\
\textbf{Output}: 
\caption{BIGRoC}
\label{Alg:adversarial_boosting}
\end{algorithm}

As can be seen in Algorithm \ref{Alg:adversarial_boosting}, it receives as input the generated images and their designated labels (if exist) and returns an improved version of them.
As such, this method can be applied at the inference phase of generative models to enhance their performance in a complete separation from their training.
Furthermore, BIGRoC does not require access to the generative models at all and thus can be applied to standalone images, regardless of their origin.
As can be seen from the algorithm's description, it has several hyperparameters that determine the modification process of the image:  sets the maximal size of the perturbation allowed by the threat model ,  controls the step size at each update step, and  is the number of updates. Another choice is the norm used to define the threat model .

The hyperparameter  is central in our scheme - when  is too large, the method overrides the input and modifies the original content in an unrecognizable way, as can be seen in Figure \ref{fig:perceptually_aligned_gradients}.
On the other hand, when  is too small, the boosted images remain very similar to the input ones, leading to a minor enhancement.
As our goal is to obtain a significant enhancement to the synthesized images, a careful choice of  should be practiced, which restricts the allowed perturbations in the threat model.

\begin{figure}[t]
\centering
    \includegraphics[width=\textwidth]{images/norm_comp.png}
    \caption{\textbf{Threat-model effect demonstration}. Generated images via a conditional GAN (left) perturbed via a targeted PGD to maximize the probability of their target classes (\textsf{planes}, \textsf{cars} and \textsf{birds}) using either  or  threat models.
    While the boosted outputs attained by the  entirely change the structure of the images and lead to unnatural results, the  threat model leads to better results.
    }
    \label{fig:attack_norm}
\end{figure}

Another important choice is the threat model  itself.
Two of the most common choices of  for adversarial attacks are the  and the  balls.
Due to the desired behavior of our method, using the  ball is less preferable: it allows a change of  to every pixel, and as such, it will not focus on meaningful specific locations, and might not preserve the existing structure of the synthesized input image.
Thus, we choose the  ball as our threat model, with relatively small . 
Such a choice restricts the allowed perturbations and leads to changes that may concentrate on specific locations while preserving most of the existing content in the generated images.
A visual demonstration of these considerations is given in Figure \ref{fig:attack_norm}.


\section{Related Work}
\label{sec:related_work}

\subsection{Image Generation Refinement}
There are two main lines of work that aim to improve the quality of generated images.
One is based on rejection sampling -- improving the generation quality of GANs by discarding low-quality images identified by the GAN's discriminator \citep{turner2019metropolishastings, azadi2019discriminator}. Contrary to such work that does not enhance the generated images but rather acts as a selector, BIGRoC does not discard any synthesized images and improves their quality by modifying them.

The second line of work \citep{tanaka2019discriminator, che2021gan, ansari2021refining}, which is closely related to ours, addresses the task of sample refinement -- modifying the generated images to attain improved perceptual quality.
These papers propose methods for improving synthesized images using the guidance of the GAN's discriminator.
More precisely, given a latent code of a generated image, their strategy is to modify it to maximize the score given by the GAN's discriminator.
Therefore, to enhance the perceptual quality of a set of generated images, these approaches require access to both the generator and the discriminator weights and the corresponding latent code of the generated images. Thus, such methods rely on the existence of a discriminator, making them not model-agnostic.
Moreover, as image refinement is an applicative task, this constraint prevents such methods from operating directly on images without additional information, making their configuration less realistic.
In contrast to these, our work offers a much simpler and different way of boosting generated images by an external pretrained robust classifier in a completely model-agnostic way. Our method can operate without requiring access to the latent vectors generating the images or the weights of the generative model that produces them. Thus, BIGRoC can be applied to standalone images -- a realistic setup where none of the existing methods can operate.
Moreover, while competitive methods couple the generator with its discriminator, we show that a single robust classifier is capable of improving a wide variety of sample qualities from the same dataset, making our configuration even more realistically appealing, as it requires only one model per dataset.
In addition, while \citep{tanaka2019discriminator, che2021gan} are limited to GANs only, our method is model-agnostic and capable of improving generated images of any source, e.g., diffusion models.
In Section \ref{sec:comp_methods}, we empirically demonstrate that although the existing methods have much stricter requirements than ours, it leads to improved performance. Moreover, our approach is the first to be successfully applied to ImageNet , proving its scalability.

\subsection{Perceptually Aligned Gradients in Computer Vision}
PAG phenomenon was previously utilized for solving various computer vision tasks, such as inpainting, image translation, super-resolution, and image generation \citep{santurkar2019image}. 
However, in image synthesis, the obtained performance is relatively disappointing, \textit{i.e.}, Inception Score (IS) of  on CIFAR-10, far from state-of-the-art (SOTA) performance. 
Moreover, the qualitative results demonstrated are far from pleasing.
Thus, it raises the question if this is the generative capabilities performance limit of robust image classifiers.
In our work, we provide a definite answer to this question by harnessing PAG to a different task -- sample refinement.
To this end, we build upon any existing generative model, including high-performing ones, and empirically show that a robust classifier can boost the performance of SOTA image generators. In particular, we demonstrate that robust classifier guidance can improve Diff BigGAN~\citep{zhao2020differentiable} from IS of  to , well beyond the  obtained in \citep{santurkar2019image}.
As such, our work exposes a much stronger force that does exist in adversarially robust classifiers in capturing high perceptual quality features.

\section{Experimental Results}

In this section, we present experiments that demonstrate the effectiveness of our method on the most common datasets for image synthesis -- CIFAR-10 \citep{Krizhevsky09learningmultiple} and ImageNet \citep{deng2009imagenet}.
Given a generative model, we use it to synthesize a set of images  and apply our method to generate , according to Algorithm \ref{Alg:adversarial_boosting}.
Since BIGRoC is model-agnostic, it can be easily applied to any generative model, given a robust classifier trained on the same data source.
We utilize the model-agnostic property to examine the effects of applying the proposed boosting over a wide variety of image generators of different qualities: from relatively simple  to sophisticated and complex ones.
We test our method on both conditional and unconditional generative models to validate that the proposed scheme can enhance different synthesis procedures.
An application of our method without the ground truth labels is termed  BIGRoC\textsubscript{PL}, as it generates pseudo labels (PL) using our robust classifier.
In contrast, BIGRoC\textsubscript{GT} refers to the case where ground truth (GT) labels are available (in the conditional image synthesis).

In all the experiments, for each dataset, we use the same adversarial robust classifier to refine all the generated images of different sources.
The only needed adjustment is at tuning , which defines the allowed size of the visual modifications done by BIGRoC.
The striking fact that a single robust classifier improves both low and high-quality images strongly demonstrates the versatility of our approach and the surprising refinement capabilities possessed by such a model.
We analyze BIGRoC performance both quantitatively and qualitatively, using Fréchet Inception Distance (FID, \citep{heusel2018gans}, lower is better), and Inception Score (IS, \citep{salimans2016improved}, higher is better). Moreover, we conduct an opinion survey to validate that human observers find BIGRoCs outputs more pleasing.
In addition, we compare our approach with other image refinement SOTA methods mentioned in Section \ref{sec:related_work}.

\subsection{CIFAR-10}

In this section, we evaluate the performance of the proposed BIGRoC on the CIFAR-10 dataset, using a single publicly-available adversarially trained ResNet-50 on CIFAR-10 as the robust classifier \citep{robustness}. We experiment with a wide range of generative models, both conditional and unconditional.

\begin{table}[t]
\caption{\label{tab:results}BIGRoC quantitative results on CIFAR-10 for both conditional and unconditional generators.}
      \centering
        \begin{tabular}{lc|cc}
            \toprule
            Architecture & Cond. & FID  & IS  \\
            \midrule
            \rowcolor{LightGray}VAE~\citep{kingma2014autoencoding} & \ding{55} &  &  \\ 
            w/ BIGRoC\textsubscript{PL} & &  &  \\
             & & \color{mygreen}\textbf{-63.36} & \color{mygreen}\textbf{+3.22} \\
            \hline
            \rowcolor{LightGray}DCGAN~\citep{radford2016unsupervised} & \ding{55} &  &  \\ 
            w/ BIGRoC\textsubscript{PL} & &  &  \\
             & & \color{mygreen}\textbf{-8.41} & \color{mygreen}\textbf{+1.18} \\
            \hline
            \rowcolor{LightGray}WGAN-GP~\citep{salimans2016improved} & \ding{55} &  &  \\
            w/ BIGRoC\textsubscript{PL} & &  &  \\ 
             & & \color{mygreen}\textbf{-6.32} & \color{mygreen}\textbf{+0.66} \\
            \hline
            \rowcolor{LightGray}SNGAN~\citep{miyato2018spectral} & \ding{55} &  &  \\
            w/ BIGRoC\textsubscript{PL} & &  &  \\
             & & \color{mygreen}\textbf{-3.94} & \color{mygreen}\textbf{+0.57} \\
            \hline
            \rowcolor{LightGray}InfoMaxGAN~\citep{Lee_2021_WACV} & \ding{55} &  & \\
            w/ BIGRoC\textsubscript{PL} & &  & \\
             & & \color{mygreen}\textbf{-4.14} & \color{mygreen}\textbf{+0.39} \\
            \hline
            \rowcolor{LightGray}SSGAN~\citep{chen2019selfsupervised} & \ding{55} &  & \\
            w/ BIGRoC\textsubscript{PL} & &  & \\
             & & \color{mygreen}\textbf{-4.28} & \color{mygreen}\textbf{+0.41} \\
            \hline
            \rowcolor{LightGray} cGAN~\citep{mirza2014conditional} & \checkmark &  &  \\
            w/ BIGRoC\textsubscript{GT} & &  &  \\
             & & \color{mygreen}\textbf{-20.37} & \color{mygreen}\textbf{+1.62} \\
            \hline
            \rowcolor{LightGray} cGAN-PD~\citep{mirza2014conditional} & \checkmark &  &  \\
            w/ BIGRoC\textsubscript{GT} & &  &  \\
             & & \color{mygreen}\textbf{-2.77} & \color{mygreen}\textbf{+0.22} \\
            \hline
            \rowcolor{LightGray}BigGAN~\citep{brock2019large} & \checkmark &  &  \\
            w/ BIGRoC\textsubscript{GT} & &  &  \\
             & & \color{mygreen}\textbf{-0.66} & \color{mygreen}\textbf{+0.09} \\
            \hline
            \rowcolor{LightGray}Diff BigGAN~\citep{zhao2020differentiable} & \checkmark &  & \\
            w/ BIGRoC\textsubscript{GT} & &  & \\
             & & \color{mygreen}\textbf{-0.42} & \color{mygreen}\textbf{+0.13} \\
            \bottomrule
            \end{tabular}
\end{table}

\noindent \textbf{Quantitative Results} Table \ref{tab:results} contains BIGRoC\textsubscript{PL} and BIGRoC\textsubscript{GT} quantitative results for both unconditional and conditional image synthesis refinement, respectively.
These results indicate that BIGRoC achieves a substantial improvement across a wide range of generator architectures, both conditional and unconditional, demonstrating the method's versatility and validity.
Interestingly, the fact that the same robust classifier can enhance both low-quality models (that require focus on high-level features) and top-performing models (that require emphasis on low-level features) strongly attests to its generative powers.


\noindent \textbf{Qualitative Results} To strengthen the quantitative results, we show in Figure \ref{fig:cifar_qualitative} and in the supplementary material qualitative results that verify that the ``boosted'' results indeed look better perceptually.


\subsection{ImageNet}
\begin{wrapfigure}{R}{0.45\textwidth}
    \vspace{-0.8cm}
    \centering
    \includegraphics[width=\linewidth]{images/IN_256.pdf}
    \caption{\textbf{Qualitative comparison on ImageNet }. Top: Images generated by guided diffusion. Middle: Images boosted by BIGRoC. Bottom: contrast stretched differences.
    }
    \label{fig:qualitative_boost_IN}
    \vspace{-0.8cm}
\end{wrapfigure}
We turn to evaluate the performance of the proposed BIGRoC on the ImageNet  and  datasets, using a single publicly available adversarially trained ResNet-50 on ImageNet as the robust classifier \citep{robustness} for both of the resolutions.


\noindent \textbf{Quantitative Results} 
Table \ref{tab:results_IN} summarize our quantitative results on ImageNet  and .
These results strongly indicate that BIGRoC is also highly beneficial for higher-resolution images from richer datasets.
Specifically, BIGRoC improves the best-performing diffusion model \citep{dhariwal2021diffusion} on ImageNet  by 14.81\%, leading to FID of 2.53, and on  by 7.87\%, leading to FID of 3.63. The obtained results show a similarly marked improvement in IS.
Interestingly, our approach (BIGRoC\textsubscript{PL}) is capable of refining the outputs of top-performing generative models even with the absence of the ground truth labels.

\begin{table}[ht]
\caption{\label{tab:results_IN}Quantitative results on ImageNet .}
\centering
\begin{tabular}{lc|cc}
\toprule
Architecture & Resolution & FID  & IS  \\
\midrule
\rowcolor{LightGray}SNGAN~\citep{miyato2018spectral} &  & 62.28 & 13.05 \\ 
w/ BIGRoC\textsubscript{PL} && 40.40 & 71.67 \\ 
 & & \color{mygreen}\textbf{-21.88} & \color{mygreen}\textbf{+58.62} \\
\hline
\rowcolor{LightGray}SSGAN~\citep{chen2019selfsupervised} &  & 63.60 & 13.75 \\ 
w/ BIGRoC\textsubscript{PL} && 38.93 & 73.94 \\
 & & \color{mygreen}\textbf{-24.67} & \color{mygreen}\textbf{+60.19} \\
\hline
\rowcolor{LightGray}InfoMaxGAN~\citep{Lee_2021_WACV} &  & 60.61 & 13.79 \\ 
w/ BIGRoC\textsubscript{PL} && 37.70 & 75.49 \\
 & & \color{mygreen}\textbf{-22.91} & \color{mygreen}\textbf{+61.7} \\
\hline
\rowcolor{LightGray}BigGAN-deep~\citep{brock2019large} &  & 6.02 & 145.83 \\ 
w/ BIGRoC\textsubscript{PL} && 5.69 & 176.42 \\
w/ BIGRoC\textsubscript{GT} && 5.71 & 226.17 \\
 & & \color{mygreen}\textbf{-0.31} & \color{mygreen}\textbf{+80.34} \\
\hline
\rowcolor{LightGray}Guided Diffusion~\citep{dhariwal2021diffusion} &  & 2.97 & 141.37 \\
w/ BIGRoC\textsubscript{PL} && 2.77 & 150.43 \\
w/ BIGRoC\textsubscript{GT} && 2.53 & 169.73 \\
 & & \color{mygreen}\textbf{-0.44} & \color{mygreen}\textbf{+28.36} \\
\hline
\rowcolor{LightGray}BigGAN-deep~\citep{brock2019large} &  & 7.03 & 202.65 \\ 
w/ BIGRoC\textsubscript{PL} && 6.93 & 221.78 \\
w/ BIGRoC\textsubscript{GT} && 6.84 & 228.23 \\
 & & \color{mygreen}\textbf{-0.19} & \color{mygreen}\textbf{+25.58} \\
\hline
\rowcolor{LightGray}Guided Diffusion~\citep{dhariwal2021diffusion} &  & 3.94 & 215.84 \\
w/ BIGRoC\textsubscript{PL} && 3.69 & 249.91 \\
w/ BIGRoC\textsubscript{GT} && 3.63 & 260.02 \\
 & & \color{mygreen}\textbf{-0.31} & \color{mygreen}\textbf{+44.18} \\
\bottomrule
\end{tabular}
\end{table}



\noindent \textbf{Qualitative Results} To verify that our method indeed leads to better perceptual quality, we show visual results on ImageNet  in Figure \ref{fig:IN_qualitative} and in Figure~\ref{fig:teaser}. Moreover, we present in Figure \ref{fig:qualitative_boost_IN} a qualitative comparison between images generated by a guided-diffusion trained on ImageNet  and the outputs of BIGRoC applied to them. We also show the images' differences (after contrast stretching) to better grasp the perceptual modifications applied by our method. As can be seen, BIGRoC focuses on the edges and textures and leads to sharper and more high-contrast images, which are more pleasing to a human observer.



\subsection{Opinion survey with human evaluators}
As current quantitative metrics are limited proxies for human perception, we conduct an opinion survey with human evaluators to better validate that our proposed method leads to better visual quality.
We randomly sampled  images from a guided diffusion, trained on ImageNet , and applied BIGRoC on them.
Human evaluators were shown pairs of such images in a random order, and the question: \textit{``Which image looks better?''}. They were asked to choose an option between ``Left'', ``Right'', and ``Same''.
The image pairs were in a random order for each evaluator.
We collected  individual answers in total, where  of the votes opted for BIGRoC's outputs,  the generated ones, and the rest chose the ``same'' option.
When aggregating the votes per each image pair, in  of the pairs, human evaluators were in favor of our algorithm's outputs, while only in  of them, they prefer the generated ones. In the remaining , the ``same'' option obtained the most votes.
These results indicate that human evaluators considerably prefer our method outputs, with a significance level of . We provide additional details regarding the conducted survey in Appendix \ref{app:survey}.

\subsection{Comparison with other methods}
\label{sec:comp_methods}
Previous works, such as DOT \citep{tanaka2019discriminator}, DDLS \citep{che2021gan} and DG-\textit{f}low \citep{ansari2021refining}, address image generation refinement, as we do. As mentioned in Section \ref{sec:related_work}, we propose a much simpler approach than our competitors and require much less information since BIGRoC can operate without access to the image generator, the discriminator, and without knowing the latent codes corresponding with the generated images.
Moreover, BIGRoC is the first model-agnostic refinement method that can operate on any generative model's output.
Besides these advantages, we demonstrate that although our method utilizes less information than other methods and can operate in setups that competitive approaches can not, BIGRoC performs on par and even better. 
To this end, we compare our method with current SOTA image refinement methods on CIFAR-10 and ImageNet .
For both these setups, we adopt the same publicly available pretrained models of SN-ResNet-GAN as used in \citep{tanaka2019discriminator, che2021gan, ansari2021refining} and apply our algorithm to the generated images and evaluate its performance quantitatively (see the supplementary material for additional implementation details). 
In Table \ref{tab:comp_results}, we compare the quantitative results of the DOT, DDLS, and DG-\textit{f}low with BIGRoC using IS, as this is the common metric reported in these papers. Our findings show that our approach significantly outperforms the other methods on the challenging ImageNet dataset while obtaining comparable results to DG-\textit{f}low on CIFAR-10.

\begin{table}[h]
\caption{Quantitative comparison with competitive methods.}
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{l|cc}
\toprule
\multirow{2}{*}{Architecture} & \multicolumn{2}{c}{Inception Score } \\
& CIFAR-10 & ImageNet\\
\midrule
\rowcolor{LightGray}SN-ResNet-GAN & 8.38 & 36.8\\
w/ DOT & -- & 37.29 \\
w/ DDLS & 9.09 & 40.2\\
w/ DG-\textit{f}low & \textbf{9.35} & -- \\
w/ BIGRoC & 9.33 & \textbf{44.68}\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\label{tab:comp_results}
\end{table}


\section{Ablation Study}
We conduct experiments to better understand the performance improvements obtained and analyze the effects of the central hyperparameters in our algorithm.

\subsection{The effect of \texorpdfstring{}{TEXT}}
\begin{wrapfigure}{R}{0.5\textwidth}
    \vspace{-0.3cm}
    \centering
    \includegraphics[width=0.5\textwidth]{images/epsilon_tradeoff.pdf}
    \caption{\textbf{Trade-off effects of \bm{}}. Demonstrated on Guided-Diffusion trained on ImageNet .
    }
    \label{fig:trade_off_eps}
    \vspace{-0.8cm}
\end{wrapfigure}
As stated in Section \ref{sec:method}, the value of  defines the allowed perturbation.
In Figure \ref{fig:trade_off_eps}, we demonstrate the effect of different values of  when applying BIGRoC\textsubscript{GT} to images generated by guided diffusion, trained on ImageNet .
As can be seen, it affects the trade-off between diversity and fidelity, demonstrated by IS versus FID values.
Our method attains lower FID scores in a range of tested values of  while achieving better IS, leading to better trade-offs. We present additional ablations in the supplementary materials.
This study shows that although its importance, BIGRoC is not highly sensitive to the choice of .

\subsection{The effect of the guiding classifier}
In this work, we propose a method for perceptually improving generated images by using a robust classifier. 
However, there are a few other choices of models that can be used for guiding the refinement process.
The simplest choice is using a standard non-robust classifier trained on the same dataset as the generative model. 
Another applicable option when refining the outputs of guided diffusion models is to use the inherent guiding classifier of the diffusion.
To validate that indeed robust classifiers have the best refining capabilities, we apply Algorithm~\ref{Alg:adversarial_boosting} on 50,000 ImageNet  images generated by a guided diffusion~\citep{dhariwal2021diffusion}, using a ResNet50 (``Vanilla clf''), a guiding classifier (``Guiding clf'') proposed in~\citep{dhariwal2021diffusion} and a robust classifier (``RoC'').
We summarize our positive findings in Table~\ref{tab:guiding_clf_ablataion}, which show that a robust classifier provides the best guidance among the tested alternatives.

\begin{table}[ht]
\caption{FID scores of Algorithm~\ref{Alg:adversarial_boosting} using different classifiers.}
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccc}
\toprule
\multirow{2}{*}{w/o Alg.~\ref{Alg:adversarial_boosting}} & \multicolumn{3}{c}{w/ Alg.~\ref{Alg:adversarial_boosting}} \\
& Vanilla clf & Guiding clf & RoC\\
\midrule
2.97 & 3.19 & 2.77 & 2.53 \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\label{tab:guiding_clf_ablataion}
\end{table}

\subsection{The effect of the threat model}
In all of our experiments, we use an adversarially trained (AT) robust classifier with a threat model  based on  norm with a predefined  value. In this section, we study the effect of  in the training of the AT robust classifier on BIGRoC's performance. In Table \ref{tab:ablation_threat_model} we compare the influence of using a non-adversarial classifier (i.e. ) and adversarial classifiers trained with different threat models' sizes on our proposed method, while the rest of the hyperparameters are fixed.
As can be seen, using AT classifiers in BIGRoC enhances the results significantly.

\begin{table}[ht]
\caption{Illustration of the robust classifier's threat model effect on BIGRoC's performance, measured in FID, using WGAN-GP trained on CIFAR-10 dataset.}
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lcccc}
\toprule
\multirow{2}{*}{w/o BIGRoC} & \multicolumn{4}{c}{w/ BIGRoC} \\
&  &  & & \\
\midrule
22.32 & 19.71 & 18.79 & 16.28 & 15.87 \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\label{tab:ablation_threat_model}
\end{table}


\section{Discussion and Conclusions}
In this work, we propose a novel method that leverages the perceptually aligned gradients phenomenon for refining synthesized images.
Due to the core ability of such a robust classifier to better capture significant visual features, it is capable of effectively improving the output of generative models.
Our approach does not require additional training of the generative model, and it is completely model agnostic, contrary to other methods.
In a line of experiments, we show that our method is highly effective and capable of substantially enhancing the qualitative and quantitative results of various generative models over multiple datasets. Moreover, we conduct an opinion survey that validates that the outputs of BIGRoC are indeed more perceptually pleasing. Interestingly, our work reveals the surprising generative capabilities of robust classifiers, as a single such model can refine the outputs of both simple and SOTA generators.

\bibliography{main}
\bibliographystyle{tmlr}

\clearpage
\newpage
\appendix
\onecolumn

\section{Additional Ablations and Demonstrations}
\label{sec:additional_ablations}
\subsection{The effect of BIGRoC's number of steps}
\label{sec:abl_num_steps}
When  is fixed, increasing the number of steps leads to smaller steps. Fine-grained steps can lead to better performance, but with a computational cost. In Table \ref{tab:ablation_num_steps}, we summarize the effect of the number of steps w.r.t a fixed . As can be concluded,  is a plausible value since it is a good trade-off between refinement performance and computational cost.

\begin{table}[ht]
\caption{The effect of the number of steps in BIGRoC's algorithm, measured in FID, using WGAN-GP trained on CIFAR-10 dataset.}
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lcccc}
\toprule
\multirow{2}{*}{w/o BIGRoC} & \multicolumn{4}{c}{w/ BIGRoC} \\
& 1 step & 7 steps & 20 steps & 30 steps\\
\midrule
22.32 & 17.48 & 16.28 & 16.15 & 16.27 \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\label{tab:ablation_num_steps}
\end{table}


\subsection{Visual demonstration of BIGRoC's iterations}
BIGRoC is an iterative boosting algorithm, and as such, it performs several update steps. In Figure \ref{fig:vis_through_time}, we visualize the optimization algorithm performed by our method. As can be seen, the perceptual quality of the images obtained by BIGRoC gradually improves during its application. More specifically, at first, BIGRoC focuses on the coarse shape and details of the image and then on the fine details.

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{images/Boosting_dynamics.png}
    \caption{\textbf{BIGRoC's steps visualization}, demonstrated using VAE trained on CIFAR-10: On the left column we show the generated images of the model. The righmost column corresponds with the final output of BIGRoC. The middle 9 columns are the results obtained after each intermediate step of our algorithm.}
    \label{fig:vis_through_time}
\end{figure*}

\subsection{Qualitative comparison with non-robust models}
As explained in the experimental part of the paper, we study the effects of applying BIGRoC with non-robust classifiers.
More specifically, we do so with a non-robust ResNet-50.
In Figure \ref{fig:inception_vs_robust}, we show that applying our algorithm with such a non-robust network does not refine the image as a robust network that has PAG does.
We use exactly the same hyperparameters in these experiments.

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{images/inception_vs_at.pdf}
    \caption{\textbf{Guiding classifier effect}. Qualitative comparison between the refinement obtained by BIGRoC with robust and non-robust models guidance.}
    \label{fig:inception_vs_robust}
\end{figure*}



\section{Opinion Survey Details}
\label{app:survey}
\begin{figure}[H]
    \centering
    \fbox{\includegraphics[width=0.5\linewidth]{images/survey_screenshot.jpeg}}
    \caption{\textbf{Opinion survey}. An example of a question from the human-observer survey.}
    \label{fig:survey_screenshot}
\end{figure}
As mentioned in the paper, we conduct an opinion survey in which we ask human evaluators to choose their preferred image from a pair of two -- a generated one and BIGRoC's output. In addition, the evaluators were allowed to choose that they have no preference.
We randomly generate  images using guided-diffusion~\citep{dhariwal2021diffusion} trained on ImageNet  and applied BIGRoC on them.
We create pairs of original-boosted images in random order and shuffled the order of them for each evaluator.  
An example of the screen shown to evaluators is displayed in Figure \ref{fig:survey_screenshot}.
We provide all  pairs in the supplementary material.


\section{Implementation Details}

In this work, except for three basic generative models (see description in \ref{sec:imp_det_cifar}), we did not train models and used only available pretrained ones from verified sources. For quantitative evaluation, we use common implementations of IS and FID metrics. In all of our experiments, we use the same robust classifier to boost all the generative models that operate on the same dataset. 
We use the pretrained generators to synthesize sets of images and BIGRoC to refine them.
The specific details regarding the experimental results are listed in the sections below.

\subsection{CIFAR-10}
\label{sec:imp_det_cifar}
\noindent \textbf{Adversarial Robust Classifier}
We use a pretrained robust ResNet-50 on CIFAR-10, provided in \citep{robustness}. This model is adversarially trained with a threat model  with step size  of .
\\
\noindent \textbf{Image Generators} Besides VAE, DCGAN, and cGAN that we trained from scratch, using the relevant available codebases, we did not train any other generator and used only publicly available ones. For cGAN-PD, WGAN-GP, SNGAN, InfoMaxGAN, and SSGAN, we use the ones from mimicry repository\footnote{\url{https://github.com/kwotsin/mimicry}}. We use the pretrained versions of BigGAN and Differential Augmentation CR BigGAN (Diff BigGAN) from the data-efficient GANs repository\footnote{\url{https://github.com/mit-han-lab/data-efficient-gans/tree/master/DiffAugment-biggan-cifar}}.

\noindent \textbf{BIGRoC hyperparameters}
As stated above, we use the same robust classifier in all our experiments.
Thus, the remaining hyperparameters to tune are , step size, and the number of steps.
We empirically find out that the number of steps is relatively marginal (see Section \ref{sec:abl_num_steps}), and thus we opt to use .
In all the experiments, we fix the step size to be .
Since we test various image generators of different qualities, each requires a particular amount of visual enhancement, defined by the value of .
Low-quality generators require substantial improvement and therefore benefit from high  values, while better ones benefit from smaller values.
In the below table, we summarize the value of  for each tested architecture.

\begin{table}[ht]
\caption{BIGRoC's  values in CIFAR-10 experiments}
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lcc}
\toprule
Architecture &  & normalization\\
\midrule
VAE & 25 & \cmark\\
DCGAN & 5 & \cmark\\
WGAN-GP & 5 & \cmark\\
SNGAN & 3 & \cmark\\
SSGAN & 3 & \cmark\\
\hline
cGAN & 5 & \cmark\\
cGAN-PD & 2 & \cmark\\
BigGAN & 1 & \cmark\\
Diff BigGAN & 1 & \cmark\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\label{tab:eps_values}
\end{table}

\noindent Where normalization is referred to images in [-1, 1].
To better interpret the meaning of  in terms of pixels modification, the average change of a pixel value is expressed by .
For example, in DCGAN,  is equivalent to an average change of .
We note that in this example, the pixels are in a range between -1 to 1 and therefore, the mean change is 

\subsection{ImageNet}
\label{sec:imp_det_IN}
\noindent \textbf{Adversarial Robust Classifier} We use a pretrained robust ResNet-50 on ImageNet, provided in \citep{robustness}, on both  and . This model is adversarially trained with a threat model  with step size of .

\noindent \textbf{Image Generators} We did not train any generator and utilize the publicly available ones. For SNGAN, SSGAN, and InfoMaxGAN, we use the ones from the mimicry repository. As for BigGAN-deep (truncation) and guided diffusion, we utilize the fact that BIGRoC can operate on standalone images and utilize the sets of generated images, published in guided diffusion's repository\footnote{\url{https://github.com/openai/guided-diffusion}}, and we apply our method upon these.
We test our method using the aforementioned sets of generated images using two setups -- with and without the ground truth labels.
When operating without the labels, we produce pseudo labels using our robust classifier and then apply BIGRoC.

\noindent \textbf{BIGRoC hyperparameters} As in CIFAR-10, we only tune the value of . In the below table, we report the used values for our tested architectures.

\begin{table}[ht]
\caption{BIGRoC's  values in ImageNet experiments}
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{clcc}
\toprule
Resolution & Architecture &  & normalization\\
\midrule
\parbox[t]{2mm}{\multirow{5}{*}{\rotatebox[origin=c]{90}{128}}} & SNGAN & 40 & \cmark\\
 & SSGAN & 40 & \cmark\\
 & InfoMaxGAN & 40 & \cmark\\
 & BigGAN-deep & 5 & \xmark\\
 & Guided Diffusion & 1.5 & \xmark\\
 \hline
 \parbox[t]{2mm}{\multirow{2}{*}{\rotatebox[origin=c]{90}{256}}} & BigGAN-deep & 1 & \xmark\\
 & Guided Diffusion & 1.5 & \xmark\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\label{tab:eps_values_IN}
\end{table}

\subsection{Comparison with other methods}
\label{sec:comp_other_methods}
\noindent \textbf{Adversarial Robust Classifier} For CIFAR-10 we use the same robust classifier as described in Appendix \ref{sec:imp_det_cifar} and for ImageNet we use the same model as in Appendix \ref{sec:imp_det_IN}.


\noindent \textbf{Image Generators}
To fairly compare BIGRoC and the competitive methods, we use BIGRoC to refine the outputs of the same pretrained model as in DOT, DDLS, and DG-\textit{f}low -- SN-ResNet-GAN\footnote{\url{https://github.com/pfnet-research/sngan_projection}}.
We experiment in both CIFAR-10 and ImageNet and compare our results with the reported ones of the other methods.
The missing values in Table \ref{tab:comp_results} stem from the fact that DOT did not report its results on SN-ResNet-GAN on CIFAR-10, and DG-\textit{f}low was not tested on ImageNet or any other high-resolution dataset.

\noindent \textbf{BIGRoC hyperparameters}
We report in the table below the value of epsilon used to attain the results in Table \ref{tab:comp_results}.

\begin{table}[ht]
\caption{BIGRoC's  values in Table \ref{tab:comp_results} experiments}
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lcc}
\toprule
Dataset &  & normalization\\
\midrule
CIFAR-10 & 1.8 & \xmark\\
ImageNet & 15 & \xmark\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\label{tab:eps_values_comp}
\end{table}


\section{Fidelity-Diversity Analysis}
In image synthesis, fidelity and diversity measure the photorealism and distribution faithfulness of the generated images.
In the main paper, we considered FID and Inception Score as our quantitative metrics for evaluating the quality of the generated and boosted images. While IS mainly focuses on fidelity, FID accounts for both. However, to better understand BIGRoC's contribution in terms of fidelity and diversity, we report in Table \ref{tab:precision_recall} the precision and recall scores~\cite{naeem2020reliable} of applying our method to different generative models, trained on ImageNet .
Theoretically, using too large  values when applying our method can improve the samples' fidelity but potentially sacrifice the diversity. However, we abstain from this by choosing proper  values. This way, we improve the overall generation quality, expressed by better FID scores. We demonstrate the effect of  in Figure \ref{fig:trade_off_eps} -- using too large  values boosts the fidelity (expressed via IS) but harms the diversity (reflected in FID).
However, as can be seen from the table, a proper choice of  enables us to improve the overall quality, expressed by the FID score, without trading off diversity for fidelity.

\begin{table}[ht]
\caption{\label{tab:precision_recall}Precision-Recall results on ImageNet .}
\centering
\begin{tabular}{lc|cc|c}
\toprule
Architecture & Resolution & Precision  & Recall  & FID \\
\midrule
\rowcolor{LightGray}SNGAN~\citep{miyato2018spectral} &  & 0.25 & 0.43 & 62.28 \\ 
w/ BIGRoC\textsubscript{PL} && 0.32 & 0.52 & 40.40 \\ 
 & & \color{mygreen}\textbf{+0.07} & \color{mygreen}\textbf{+0.09} & \color{mygreen}\textbf{-21.88} \\
\hline
\rowcolor{LightGray}SSGAN~\citep{chen2019selfsupervised} &  & 0.27 & 0.43 & 63.60 \\ 
w/ BIGRoC\textsubscript{PL} && 0.33 & 0.51 & 38.93\\
 & & \color{mygreen}\textbf{+0.06} & \color{mygreen}\textbf{+0.08} & \color{mygreen}\textbf{-24.67} \\
\hline
\rowcolor{LightGray}InfoMaxGAN~\citep{Lee_2021_WACV} &  & 0.27 & 0.46 & 60.61 \\ 
w/ BIGRoC\textsubscript{PL} && 0.33 & 0.52 & 37.70 \\
 & & \color{mygreen}\textbf{+0.06} & \color{mygreen}\textbf{+0.06} & \color{mygreen}\textbf{-22.91} \\
\hline
\rowcolor{LightGray}ADM~\citep{dhariwal2021diffusion} &  & 0.70 & 0.65 & 5.91 \\ 
w/ BIGRoC\textsubscript{GT} && 0.72 & 0.64 & 4.41 \\
 & & \color{mygreen}\textbf{+0.02} & \color{red}\textbf{-0.01} & \color{mygreen}\textbf{-1.5} \\
\hline
\rowcolor{LightGray}Guided Diffusion~\citep{dhariwal2021diffusion} &  & 0.78 & 0.59 & 2.97\\
w/ BIGRoC\textsubscript{GT} && 0.79 & 0.59 & 2.75 \\
 & & \color{mygreen}\textbf{+0.01} & \textbf{-} & \color{mygreen}\textbf{-0.22} \\
\bottomrule
\end{tabular}
\end{table}


\section{Qualitative Results}
\label{sec:qualitative_res}
In this section, we show additional qualitative results to further demonstrate the qualitative enhancement attained by our method.
We use image generators of different qualities, both conditional and unconditional, and show the generated images and the boosted ones in Figures \ref{fig:bigGANqualitative}, \ref{fig:VAEqualitative}, \ref{fig:WGAN-GPqualitative} and \ref{fig:SSGANqualitative}.
The images below are simply the 100 first synthesized images from each class.

\begin{figure}[ht]
\centering
\subfigure[A comparison between BigGAN generated images of class \textsf{automobile} and the corresponding boosted ones.]{\label{fig:Ng1}\includegraphics[width=0.9\textwidth]{images/bigGAN_car.jpeg}}

\subfigure[A comparison between BigGAN generated images of class \textsf{bird} and the corresponding boosted ones.]{\label{fig:Ng2}\includegraphics[width=0.9\textwidth]{images/bigGAN_bird.jpeg}}

\subfigure[A comparison between BigGAN generated images of class \textsf{dog} and the corresponding boosted ones.]{\label{fig:Ng3}\includegraphics[width=0.9\textwidth]{images/bigGAN_dog.jpeg}}

\caption{\textbf{BIGRoC refinement of BigGAN}. A qualitative comparison between BigGAN generated images of CIFAR-10 samples and the refined ones by BIGRoC algorithm.}
\label{fig:bigGANqualitative}
\end{figure}

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.9\textwidth]{images/VAEboost.jpeg}
    \caption{\textbf{BIGRoC refinement of VAE}. A qualitative comparison between an unconditional VAE generated images of CIFAR-10 samples and the refined ones by BIGRoC algorithm.
    }
    \label{fig:VAEqualitative}
\end{figure}

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.9\textwidth]{images/WGAN_boost.jpeg}
    \caption{\textbf{BIGRoC refinement of WGAN-GP}. A qualitative comparison between an unconditional WGAN-GP generated images of CIFAR-10 samples and refined ones by BIGRoC algorithm.
    }
    \label{fig:WGAN-GPqualitative}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{images/SSGAN_boost.jpeg}
    \caption{\textbf{BIGRoC refinement of SSGAN}. A qualitative comparison between an unconditional SSGAN generated images of CIFAR-10 samples and refined ones by BIGRoC algorithm..
    }
    \label{fig:SSGANqualitative}
\end{figure}

\section{Debiasing}
\label{sec:debiasing}
In Section \ref{sec:method} we describe our debiasing algorithm, which aims to induce uniform class distribution over the outputs of BIGRoC.
The rationale behind this procedure is expressed in Equation \ref{eq:debiasing}.
To better understand the outcome of our debiasing, we present in Figure \ref{fig:debiasing} its effect visually. 
We compare the results of applying BIGRoC in the unconditional case, with and without debiasing.
One can clearly see that it reduces the amount of the majority class and leads to a more uniform class distribution, by modifying the images accordingly.


\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{images/debiasing_qualitative.png}
    \caption{\textbf{Demonstration of the debiasing technique}. We show 100 generated images by an unconditional SNGAN and the results of the BIGRoC algorithm, with and without the proposed debiasing.
    As can be seen, the outputs of the boosting algorithms are perceptually superior, while the histograms expose the fact that the suggested debiasing algorithm induces a more uniform labels distribution.
    In the "Boosting without Debiasing" experiment, 36 out of 100 images are classified as \textsf{deers}, and only 3 are \textsf{horses}.
    The most prominent \textsf{deer} images are marked in red.
    However, when applying the debiased boosting, the number of \textsf{deers} is reduced to 9, and the number of \textsf{horses} is increased to 15.
    We mark the boosted images that remain \textsf{deer} in red, and images that are modified to other minority classes in green.
    As can be seen, many of the \textsf{deers} were changed to be \textsf{horses}, a perceptually similar class.}
    \label{fig:debiasing}
\end{figure*}














\section{Computational Resources}

In this work, we do not train generative models (when possible) and use publicly available pretrained ones to generate images and apply BIGRoC on their outputs.
This way, we decouple the generative model's complexity from our algorithm since it is applied to the generated images themselves.
In all of our experiments, we use the Google COLAB service with a single GPU.

\end{document}
