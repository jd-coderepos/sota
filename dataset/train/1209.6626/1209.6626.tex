\maketitle
\renewcommand{\algorithmicrequire}{{\textbf{Input:}}}
\renewcommand{\algorithmicensure}{{\textbf{Output:}}}
\makeatletter
\newcommand{\IFTHEN}[3][default]{\ALC@it\algorithmicif\ #2\
  \algorithmicthen\ #3\
  \ifthenelse{\boolean{ALC@noend}}{}{\algorithmicendif\ } \ALC@com{#1}}
\makeatother
\newcommand{\bigO}[1]{\ensuremath{\mathcal{O}\left(#1\right)}\xspace}
\newcommand{\LOGAND}{~\&\,}
\newcommand{\LOGANDIN}{~\&=\,}
\newcommand{\LOGORIN}{~|=\,}
\newcommand{\MULIN}{~*=\,}
\newcommand{\MOD}{~\%\,}
\newcommand{\MODIN}{~\%=\,}
\newcommand{\SUBIN}{~-=\,}
\newcommand{\ADDIN}{~+=\,}


\begin{abstract} 
  We study algorithms for the fast computation of modular inverses.
  Newton-Raphson iteration over -adic numbers gives a recurrence relation computing modular inverse modulo , that is logarithmic in . 
  We solve the recurrence to obtain an explicit formula for the inverse. 
  Then we study different implementation variants of this iteration and show that our explicit formula is interesting for small exponent values but slower for large exponent, say of more than  bits.
  Overall we thus propose a hybrid combination of our explicit formula and the best asymptotic variants. This hybrid combination yields then a constant factor improvement, also for large exponents. 
\end{abstract}
\section{Introduction}
The multiplicative inverse modulo a prime power is fundamental for the
arithmetic of finite rings, for instance at the initialization phase of
Montgomery's integer multiplication (see, e.g.,
\cite{Dusse:1990:eurocrypt,Arazi:2008:CMI} and references therein). 
It is also used, e.g., to compute homology groups in algebraic topology for
image pattern recognition \cite{jgd:2003:GAP}, mainly to improve the running
time of algorithms working modulo prime powers. Those can be used for the
computation of the local Smith normal
form~\cite{jgd:2001:JSC,Elsheikh:2012:ISSAC}, for instance in the context of
algebraic topology: there linear algebra
modulo  can reveal torsion coefficients and inverses are required for
pivoting in Gaussian elimination or minimal polynomial synthesis (see, e.g.,
\cite[algorithm LRE]{jgd:2003:GAP} or \cite{Reeds:1985:SRS}). 


Classical algorithms to compute a modular inverse uses the
extended Euclidean algorithm and Newton-Raphson iteration over p-adic fields, namely Hensel lifting \cite{Krishnamurthy:1983:padic}.
Arazi and Qi in \cite{Arazi:2008:CMI} lists also some variants adapted to the binary characteristic case that cut the result in lower and higher bits.

In the following, we give another proof of Arazi and Qi's logarithmic formula
using Hensel lifting. 
Then we derive an explicit formula for the inverse that generalizes to any prime
power. Finally, we study the respective performance of the different algorithms
both asymptotically and in practice and introduce a hybrid algorithm combining
the best approaches. 

\section{Hensel's lemma modulo \texorpdfstring{}{p{\textasciicircum}m}}
For the sake of completeness, we first give here Hensel's lemma and
its proof from Newton-Raphson's iteration (see
e.g. \cite[Theorem 7.7.1]{Bach:1996:ANTEA} or \cite[\S 4.2]{Brent:2011:MCA} and
references therein). 
\begin{lemma}[Hensel]\label{lem:hensel} 
Let  be a prime number, ,  and 
such that . If  and  then
 satisfies .
\end{lemma}
\begin{proof}
Taylor expansion gives that
. Thus if
, 
the above equation becomes .
\end{proof}

\section{Inverse modulo \texorpdfstring{}{2{\textasciicircum}m}}
Now, in the spirit of \cite{Xenophontos:2010:fixed}, we apply this lemma to the
inverse function 


\subsection{Arazi and Qi's formula}
We denote by an under-script  (resp. ) the lower (resp. higher)
part in binary format for an integer.
From Equation~(\ref{eq:invfun}) and Lemma~\ref{lem:hensel} modulo ,
if , then we immediately get

In other words 
. Now let  so that we
also have  and hence  with
. Thus

which shows that 

The latter is exactly \cite[Theorem~1]{Arazi:2008:CMI} and yields the
following Algorithm~\ref{alg:arazi}, where the lower and higher parts of
integers are obtained via masking and shifting. 
\begin{algorithm}[htbp]
\caption{Arazi\&Qi Quadratic Modular inverse modulo }
\label{alg:arazi}
\begin{algorithmic}[1]
\REQUIRE  odd and .
\ENSURE .
\STATE ;
\FOR{(; ; )}
\STATE ;\hfill\COMMENT{}
\STATE ; ;\hfill\COMMENT{}
\STATE ;\hfill\COMMENT{}
\STATE ;\hfill\COMMENT{}
\STATE ;
\STATE ; ;\hfill\COMMENT{}
\STATE ;\hfill\COMMENT{}
\STATE ;\hfill\COMMENT{}
\STATE ;\hfill\COMMENT{}
\ENDFOR
\STATE ;\hfill\COMMENT{}
\RETURN ;
\end{algorithmic}
\end{algorithm}

\begin{lemma}\label{lem:ara} Algorithm~\ref{alg:arazi} requires  arithmetic operations.
\end{lemma}






\subsection{Recurrence formula}
Another view of Newton-Raphson's iteration is to create a recurrence. 
Equation~(\ref{eq:invfun}) gives 


This yields the loop of Algorithm~\ref{alg:hensel}, for the
computation of the inverse, 
see e.g. \cite{Krishnamurthy:1983:padic} or \cite[\S 2.4]{Brent:2011:MCA}.

\begin{algorithm}[htbp]
\caption{Hensel Quadratic Modular inverse}
\label{alg:hensel}
\begin{algorithmic}[1]
\REQUIRE  a prime,  coprime to ,  and .
\ENSURE .
\STATE ;\hfill\COMMENT{extended gcd}
\FOR{(; ; )}
\STATE\label{lin:sqr} ;\hfill\COMMENT{} 
\STATE ;\hfill\COMMENT{} 
\STATE\label{lin:mod1} ;\hfill\COMMENT{}
\STATE ;\hfill\COMMENT{}
\STATE ;\hfill\COMMENT{}
\ENDFOR 
\STATE ;\hfill\COMMENT{} 
\STATE ;\hfill\COMMENT{} 
\STATE\label{lin:mod2} ;\hfill\COMMENT{}
\STATE ;\hfill\COMMENT{}
\STATE ;\hfill\COMMENT{}
\STATE ;\hfill\COMMENT{}

\RETURN ;
\end{algorithmic}
\end{algorithm}

\begin{lemma}\label{lem:rec} Algorithm~\ref{alg:hensel} is correct and requires 
 arithmetic operations.
\end{lemma}
\begin{proof} The proof of correctness is natural in view of the Hensel
lifting. First . Second, by induction, suppose 
. Then  and . Finally .
\end{proof}

\begin{remark} We present this algorithm for computations modulo  but its
optimization modulo a power of  is straightforward: replace the modular
operations of for instance lines~\ref{lin:mod1},~\ref{lin:mod2} etc. by a
binary masking: . 
\end{remark}

\begin{remark} It is important to use a squaring in line~\ref{lin:sqr}.
Indeed squaring can be faster than multiplication, in particular in the
arbitrary precision setting \cite{Zuras:1994:square}. 
In the case of Algorithm~\ref{alg:hensel}, the improvement over an algorithm of the
form  is of about .
\end{remark}

\begin{remark}
Note that for Algorithms~\ref{alg:arazi} and~\ref{alg:hensel}, a large part of
the computation occur during the last iteration of the loop when  is
closest to . Therefore, a recursive version cutting in halves will be more
efficient in practice since the latter will be exactly done at 
instead of at the largest power of  lower than . Moreover this
improvement will take place at each recursion level. 
We thus give in the following the recursive version for Formula~(\ref{eq:rec}),
the one for a recursive version of Arazi\&Qi is in the same spirit. 

\begin{algorithm}[htbp]
\newcounter{prevalgorithm}
\setcounter{prevalgorithm}{\thealgorithm}
\renewcommand\thealgorithm{\theprevalgorithm'}
\addtocounter{algorithm}{-1}
\caption{Recursive Hensel}
\label{alg:rec}
\begin{algorithmic}[1]
\REQUIRE  a prime,  coprime to , and .
\ENSURE .
\IFTHEN{}{\algorithmicreturn~;}\hfill\COMMENT{ext. gcd}
\STATE 
\STATE\label{lin:modph} ;\hfill\COMMENT{}
\STATE RecursiveHensel;
\STATE ;\hfill\COMMENT{} 
\STATE ;\hfill\COMMENT{} 
\STATE\label{lin:modpm} ;\hfill\COMMENT{}
\STATE ;\hfill\COMMENT{}
\STATE ;\hfill\COMMENT{}
\STATE ;\hfill\COMMENT{}
\RETURN ;
\end{algorithmic}
\end{algorithm}
\end{remark}

\subsection{Factorized formula}
We now give an explicit formula for the inverse by solving the
preceding recurrence relation, first in even characteristic.\\

We denote by  a new sequence, that
satisfies .
With  we get ,
by induction, supposing that , we get

Using the remarkable identity, this in turn yields:
 therefore, with
 and  we have that  


The latter equation gives immediately rise to the following Algorithm~\ref{alg:expl}. 

\begin{algorithm}[htbp]
\caption{Explicit Quadratic Modular inverse modulo }
\label{alg:expl}
\begin{algorithmic}[1]
\REQUIRE  odd and .
\ENSURE .
\STATE Let  and  be such that  is odd and ;
\STATE ;
\STATE ;
\FOR{(; ; )}
\STATE ; \hfill\COMMENT{square: }
\STATE ;\hfill\COMMENT{}
\STATE ; 
\STATE ;\hfill\COMMENT{}
\ENDFOR
\RETURN ;
\end{algorithmic}
\end{algorithm}

\begin{lemma} Algorithm~\ref{alg:expl} is correct and 
requires  arithmetic operations.
\end{lemma}
\begin{proof}
Modulo ,  is invertible if and only if  is odd, so that
 and therefore, using Formula~(\ref{eq:expl}), we get

Thus,

\end{proof}

There are two major points to remark with this variant:
\begin{enumerate}
\item It performs fewer operations than previous algorithms.
\item It must compute with the full -adic development (modulo operations are
  made modulo  and not .
\end{enumerate}
Therefore we will see that this algorithm has a worse asymptotic complexity
but is very efficient in practice for small exponents.

\subsection{Generalization modulo any prime power}
The formula generalizes directly for any prime power:
\begin{theorem}
Let  be a prime number,  coprime to  and  is the
inverse of  modulo .
Let also  be the following sequence:

Then .
\end{theorem}
\begin{proof}
The proof is similar to that of Lemma~\ref{alg:expl} and follows also from
Hensel's lemma.
From the analogue of Equation~(\ref{eq:expl}), we have . 
Now as , by the definition of  we have 
. 
\end{proof}

\section{Complexity analysis over arbitrary precision}\label{sec:ana}
We provide here the equivalents of the complexity results of the previous
section but now for arbitrary precision: the associated binary
complexity bounds for the different algorithms are given here with classical
arithmetic operations on integer (i.e. without fast variants like Karatsuba or
DFT). 
We thus now suppose that masking and shifting as well as addition are linear
and that multiplication is quadratic (\bigO{2m^2} operations to multiply to
elements of size ).
\begin{lemma}\label{lem:arazi} 
Using classical arithmetic, Algorithm~\ref{alg:arazi} requires

\end{lemma}
\begin{proof} Following the algorithm, the complexity bound becomes 

\end{proof}
\smallskip
\begin{lemma}\label{lem:henarb} 
Using classical arithmetic in even characteristic modulo , Algorithm~\ref{alg:hensel} requires 
\end{lemma}
\begin{proof} Following the algorithm, the complexity bound becomes
  
\end{proof}
\smallskip
\begin{lemma}\label{lem:explarb} 
Using classical arithmetic, Algorithm~\ref{alg:expl} requires

\end{lemma}
\begin{proof} Similarly, here we have 
\end{proof}


\section{Experimental comparisons}
The point of the classical Newton-Raphson algorithms (as well as Arazi and Qi's
variant) is that it works with modular computations of increasing sizes, whereas
the explicit formula requires to work modulo the highest size from the
beginning. 
On the one hand we show next that this gives an asymptotic advantage the recurring relations. On the other hand, in practice, the explicit formula enables
much faster performance for say cryptographic sizes.
All experiments have been done on an Intel Xeon W3530, 2.8 GHz, running linux
debian\footnote{The source code for the experiments is available on
  \url{http://ljk.imag.fr/membres/Jean-Guillaume.Dumas/Software/InvModTwoK}. It
  uses GMP version 5.0.5 (\url{http://gmplib.org}), with givaro-3.7.2 C++
  wrappers (\url{http://givaro.forge.imag.fr})}
\subsection{Over word-size integers}
Using word-size integers, the many masking and shifting required by recurring
relations do penalize the performance, where the simpler Algorithm~\ref{alg:expl} is on average  faster on a
standard desktop PC, as shown on Figure~\ref{fig:uint}. Differently, Arazi and
Qi's variant suffers from the manipulations required to extract the low and high
parts of integers.
\begin{figure}[htb]\center\vspace{-2pt}
\includegraphics[width=\columnwidth]{resinvext64}
\caption{Modular inverse on 64 bits machine words}\label{fig:uint}\vspace{-2pt}
\end{figure}

\subsection{Over arbitrary precision arithmetic}
From Lemma~\ref{lem:explarb}, we see that the explicit formula adds a logarithmic factor, asymptotically. 
In practice, Figure~\ref{fig:gmp} shows that using
GMP\footnotemark[1], the asymptotic behavior of Algorithm~\ref{alg:arazi} becomes predominant only for integers with more than  bits. 
For the Newton-Raphson iteration the asymptotic behavior of Algorithm~\ref{alg:hensel} becomes predominant even sooner, for integers with about 
 bits. 
Below that size, Algorithm~\ref{alg:expl} is better.
\begin{figure}[htb]\center\vspace{-2pt}
\includegraphics[width=\columnwidth]{resinvextGIV}
\caption{Modular inverse on arbitrary precision integers}\label{fig:gmp}\vspace{-2pt}
\end{figure}

\begin{remark} 
  Now, in \cite{Krishnamurthy:1983:padic,Xenophontos:2010:fixed},
  the recurrence relation from~(\ref{eq:rec}), is extended\footnote{this is to
    be compared with explicit Formula~(\ref{eq:expl}), , where the computation is done with the first inverse  (recall that ), where in the classical setting the
    computation is done with the inverse so far: }
  to  for a fixed . 
  This allows a faster convergence, by a factor of . 

  Unfortunately the price to pay
  is to compute a -th power at each iteration (instead of a single square),
  which could be done, say by recursive binary squaring, but at a price of
   squarings and between  and  multiplications. Overall
  there would be no improvement in the running time.
\end{remark}


\subsection{Hybrid algorithm}




With the thresholds of Figure~\ref{fig:gmp} and from the previous algorithms, 
we can then use a classical hybrid strategy which is better than
all of them everywhere:
for small exponents it uses the explicit formula of Algorithm~\ref{alg:expl};
then for larger exponents:
\begin{enumerate}
\item it starts to compute the inverse recursively at half the initial exponent;
\item then, to lift the inverse modulo the double exponent, it uses the classical Hensel formula of Equation~(\ref{eq:rec}), and
  switches to Arazi\&Qi formula of Equation~(\ref{eq:arazi}), only for exponents
  larger than  bits. 
\end{enumerate}
Actually, the lift switches back to Hensel formula after  bits: indeed on
the used computer quasi linear multiplication via FFT comes into play in GMP and
the analysis of Section~\ref{sec:ana} is not relevant anymore.
The obtained algorithm is on average  times faster than any
other direct lifting alone as shown with the curve (4) of
Figure~\ref{fig:gmp} (recall that on Figure~\ref{fig:gmp} ordinates are
presented in a logarithmic scale) and also on the ratios of
Figure~\ref{fig:ratio}.
\begin{figure}[htb]\center\vspace{-2pt}
\includegraphics[width=\columnwidth]{resinvextLARGE}
\caption{Ratios of modular inverse lifting algorithms over the hybrid method}\label{fig:ratio}\vspace{-2pt}
\end{figure}


\section{Conclusion}
We have studied different variants of Newton-Raphson's iteration over
p-adic numbers to compute the inverse modulo a prime power.
We have shown that a new explicit formula can be up  times faster in
practice than the recursive variants for small exponents.
Asymptotically, though, the latter formula suffers from a supplementary
logarithmicfactor in the power (or a doubly logarithmic factor in the prime
power) that makes it slower for large arbitrary precision integers. 
However, using each one of the best two algorithms in their respective regions
of efficiency, we were able to use a hybrid strategy with improved performance
of  on average at any precision.  

More studies are to be made for the respective behavior of the algorithms in odd
characteristic. Indeed there bit masking is replaced by extended euclidean
algorithms variants and their respective performance could be different.

\section*{Acknowledgment} 
Many thanks to Christoph Walther, who found two typographic mistakes 
in the published version of Algorithm~\ref{alg:rec} ( where  was
correct, line~\ref{lin:modph} and  where  was correct,
line~\ref{lin:modpm})~\cite{Walther:2018:cav}.




