\documentclass[ letterpaper, 11pt]{article}
\usepackage{amsmath,amssymb,amsfonts,mathrsfs,amsthm}
\usepackage[all]{xy}
\usepackage{url}
\usepackage{float}
\usepackage{framed}
\usepackage{enumerate}
\usepackage{color}
\usepackage[normalem]{ulem}
\usepackage{algorithmic}
\usepackage{tikz}
\usetikzlibrary{petri}
\usepackage{xspace}
\usepackage[hang,small,bf]{caption}
\usepackage{fmtcount}
\definecolor{DarkBlue}{rgb}{0.1,0.1,0.5}
\usepackage[colorlinks=true,linkcolor=black,citecolor=DarkBlue]{hyperref}

\usepackage{geometry}
\geometry{tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\renewcommand{\baselinestretch}{1.065}

\widowpenalty=8000
\clubpenalty=10000



\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}{Conjecture}
\newtheorem{assumption}{Assumption}



\newcommand{\set}[1]{\left \{#1\right \}}
\newcommand{\Set}[2]{\left\{ #1 :\, #2\right\}}
\newcommand{\eps}{\varepsilon}
\newcommand{\T}{{\cal T}}
\newcommand{\A}{{\cal A}}
\renewcommand{\d}{d}
\newcommand{\gametree}{\textsf{GameTree}\xspace}
\newcommand{\statetree}{{\textsf{StateTree}}\xspace}
\newcommand{\randomtree}{{\textsf{RandomnessTree}}\xspace}
\newcommand{\potent}{potent\xspace}
\newcommand{\Sim}{{\mathsf{Sim}_\pi}}
\newcommand{\RTBC}{\textsf{RTC}\xspace}
\newcommand{\KTC}{\textsf{SBTC}\xspace}
\newcommand{\tree}{{\cal R}}






\newcommand{\comment}[1]{{\sf [#1]}}
\newcommand{\ran}[1]{{\color{blue}#1}}
\newcommand{\ranc}[1]{\ran{\comment{Ran: #1}}}


\newcommand{\del}[1]{\sout{#1}}



\begin{document}


\title{\textbf{Potent Tree Codes and their applications}: \\
Coding for Interactive Communication, revisited}
\author{Ran Gelles  \;\;\; Amit Sahai
 \\ \\ Department of Computer Science, UCLA, Los angeles
\\ \texttt{\{gelles, sahai\}@cs.ucla.edu}}
\date{}
\maketitle



\newcommand{\sectionline}{\nointerlineskip \vspace{\baselineskip}\hspace{\fill}\rule{0.5\linewidth}{.7pt}\hspace{\fill}\par\nointerlineskip \vspace{\baselineskip}
}



\begin{abstract}

In this work, we study the fundamental problem of reliable
\emph{interactive} communication over a noisy channel.  In a
breakthrough sequence of papers published in 1992 and
1993~\cite{schulman92,schulman93}, Schulman gave
\emph{non-constructive} proofs of the existence of general methods
to emulate any two-party interactive protocol such that: (1) the
emulation protocol only takes a constant-factor longer than the
original protocol, and (2) if the emulation protocol is executed
over a noisy channel (BSC), then the probability that the emulation
protocol fails to perfectly emulate the original protocol 
is exponentially small in the total length of the
protocol. Unfortunately, Schulman's emulation procedures either
only work in a model with a large amount of shared
randomness~\cite{schulman92}, or are non-constructive in that they
rely on the existence of \emph{good tree codes}~\cite{schulman93}.
The only known proofs of the existence of good tree codes are
non-constructive, and finding an explicit construction remains an
important open problem. Indeed, randomly generated tree codes are
\emph{not} good tree codes with overwhelming probability.

In this work, we revisit the problem of reliable interactive
communication, and obtain the following results:

\begin{itemize}
\item
We introduce a new notion of goodness for a tree code, and define the notion of a
\emph{\potent tree code}.  We believe that this notion is of
independent interest.
\item
We prove the correctness of an explicit emulation procedure based on
any \potent tree code.  (This replaces the need for good tree codes
in the work of Schulman~\cite{schulman93}.)
\item
We show that a randomly generated tree code (with suitable constant
alphabet size) is a \potent tree code with overwhelming probability.  Furthermore we are able to partially derandomize this result
using only  random bits, where  is the depth of the tree.
\end{itemize}

These (derandomized) results allow us to obtain the first fully
\emph{explicit} emulation procedure for reliable interactive
communication over noisy channels with a constant communication
overhead,  with failure probability that is exponentially small in
the length of the original communication protocol.

Our results also extend to the case of interactive multi-party communication among a constant number of parties.
\end{abstract}


\thispagestyle{empty}   \newpage
\setcounter{page}{1}









\section{Introduction}


In this work, we study the fundamental problem of reliable
\emph{interactive} communication over a noisy channel.  The famous
coding theorem of Shannon~\cite{shannon48} from 1948 shows how to
transmit any message over a noisy channel with optimal rate such
that the probability of error is exponentially small in the length
of the message.  However, if we consider an interactive protocol
where individual messages may be very short (say, just a single
bit), even if the entire protocol itself is very long, Shannon's
theorem does not suffice.

In a breakthrough sequence of papers published in 1992 and
1993~\cite{schulman92,schulman93}, Schulman attacked this problem
and gave a \emph{non-constructive} proof of the existence of a
general method to emulate any two-party interactive protocol such
that: (1) the emulation protocol only takes a constant-factor longer
than the original protocol, and (2) if the emulation protocol is
executed over a noisy channel (specifically a Binary Symmetric
Channel\footnote{The Binary Symmetric Channel with crossover
probability  is one that faithfully transmits a bit with
probability , and toggles the bit with probability .  Note
that Schulman's results as quoted here extend to the case of any
discrete memoryless channel with constant capacity, as do all of our
results.} with some constant crossover probability less than
), then the probability that the emulation protocol fails
to perfectly emulate the original protocol 
is exponentially small in the total length of the protocol.
Unfortunately, Schulman's 1992 emulation procedure~\cite{schulman92}
either required a nonstandard model in which parties already share a
large amount of randomness before they communicate, where the amount
of shared randomness is quadratic in the length of the protocol to
be emulated, or required inefficient encoding and decoding. On the
other hand, Schulman's 1993 emulation procedure~\cite{schulman93}
 is non-constructive in that it
relies on the existence of \emph{good tree codes}\footnote{ We note,
with apology, that what we are calling a ``good tree code'' is what
Schulman calls a ``tree code.''  We make this change of terminology
because we will introduce an alternative relaxed notion of goodness
for a tree code that will lead to our notion of a ``\potent tree
code.'' }.  The only known proofs of the existence of good tree
codes are non-constructive, and finding an explicit construction
remains an important open problem.  Indeed randomly generated tree
codes are \emph{not} good tree codes with overwhelming probability.


In this work, we revisit the problem of reliable interactive
communication, and give the first fully \emph{explicit} emulation
procedure for reliable interactive communication over noisy channels
with a constant communication overhead,  with failure probability
that is exponentially small in the length of the original
communication protocol\footnote{Here we assume that we know the
length of the protocol in advance.}.  To obtain this result, we do
the following:

\begin{itemize}\addtolength{\itemsep}{-0.5em}
\item
We introduce a new notion of goodness for a tree code, and define
the notion of a \emph{\potent tree code}.  We believe that this
notion is of independent interest.
\item
We prove the correctness of an explicit emulation procedure based on
any \potent tree code.  (This replaces the need for good tree codes
in the work of Schulman~\cite{schulman93}.)  This procedure is
efficient given a black box for efficiently decoding the \potent
tree code.
\item
We show that a randomly generated tree code (with suitable constant
alphabet size) is a \potent tree code with overwhelming probability.
Furthermore, we show that a randomly generated tree code (when
combined with a good ordinary error-correcting code) can be
efficiently decoded with respect to a BSC with overwhelming
probability.

\item
Finally, we are able to partially derandomize the above result using
only  random bits, where  is the depth of the tree, while
maintaining the efficiency of decoding.
\end{itemize}

With the above work done, our result is immediate: Since only 
random bits are needed, they can be chosen once and for all, encoded
using an ordinary block error-correcting code, and sent to the other
party.  Then a deterministic procedure can be used to finish the
protocol.

Our result extends to the case of any constant number of parties.
For the case of a super-constant number of parties, however, our
explicit emulation procedure will have a  slowdown for 
parties (regardless of the length of the protocol).  A
(non-explicit) emulation procedure based on good tree codes was
given by Rajagopalan and Schulman~\cite{RS94} that achieved a
 slowdown in the general case.

Also, another result we obtain relates to the recent work of
Braverman and Rao~\cite{BR10}. They consider whether good tree codes
can be used to improve the result of Schulman for \emph{adversarial}
errors --- which only works if the fraction of errors is below
. They obtain a very significant improvement: as long as the
fraction of errors is at most , any protocol can be
simulated with only a constant slowdown, using a good tree code over
a constant-size alphabet (the simulation tolerates a 
error fraction when using a binary alphabet). We show that a similar
result can be obtained replacing the good tree code with a \potent
tree, showing our notion is useful even for the case of arbitrary
(adversarial) errors. However, in this case, like all previous work
on the adversarial error case, we do not know how to obtain
efficient decoding against adversarial errors.


\paragraph{Our approach.}
We begin our investigation by asking the question: What properties
does a tree code need in order to be useful for emulating protocols
over noisy channels?  (Without loss of generality, assume that
protocols only exchange one bit at a time from each party.) For the
purpose of this paper, a tree code is simply any deterministic
on-line encoding procedure in which each symbol from the input
alphabet  is (immediately) encoded with a single symbol from
the output alphabet , but the encoding of future input symbols
can depend on all the input symbols seen so far.  As such, any such
deterministic encoding can be seen as a complete -ary tree
with each edge labeled with a single symbol of the output alphabet
.

\begin{figure}[htb]
\begin{center}
\begin{tikzpicture}
\coordinate (top) at (4,5);

\draw[thick,dashed] (top) -- (1,1);
\draw[thick,dashed] (top) -- (7,1);
\draw[thick] (top) -- (4.5,1) node [right] {P}
  node (1) [pos=0.3] {}
  node (2) [pos=0.45,token] {1}
  node (3) [pos=0.6] {}
  node (4) [pos=0.75] {}
  node (5) [pos=0.9] {};


  \draw[-,thick] (2) -- (3.5,1) node [left] {P'} ;

\draw (0,0) rectangle (8,6);

\end{tikzpicture}
\end{center}
\caption{A very bad tree code}
\label{fig:verybad}
\end{figure}
The usefulness of some kind of tree code for protocol emulation
seems immediate, since each party must encode the bit it needs to
send, before knowing what other bits it needs to send later (which
it will not know until it receives messages from the other party).
Let us associate every path from the root to a node in the tree code
with the concatenation of output symbols along that path.  Then, at
first glance, it may appear that all we need from the tree code is
for ``long-enough'' divergent paths to have large relative Hamming
distance.  That is, suppose that the tree code illustrated in
Figure~\ref{fig:verybad} has the property that the relative Hamming
distance between the path from node 1 to P and the path from node 1
to P' is very small, even though each of those paths is long.  This
would certainly be problematic since the protocol execution
corresponding to each path could be confused for the other.  As long
as all long divergent paths had high Hamming distance, however, it
seems plausible that eventually the protocol emulation should be
able to avoid the wrong paths.  Also, it is important to note that
with suitable parameters, a randomly generated tree code would
guarantee that all long divergent paths have high relative Hamming distance with overwhelming probability.

However, this intuition does not seem to suffice, because while the protocol emulation is proceeding down an \emph{incorrect} path, one party is sending the \emph{wrong} messages -- based on wrong interpretations of the other party's communication.  After a party realizes that it has made a mistake, it must then be able to ``backtrack'' and correct the record going forward.  The problem is that even short divergent paths with small relative Hamming distance can cause problems.  Consider the tree code illustrated in Figure~\ref{fig:bad}.  In this figure suppose the path along the nodes 1, 2, and 3 is the ``correct'' path, but that the short divergent paths from 1 to A, 2 to B, and 3 to C all have small relative Hamming distance to the corresponding portions of the correct path.  Then in the protocol emulation, because of the bad Hamming distance properties, the emulation may initially incorrectly proceed to node A, and then realize it made a mistake.  But instead of correctin!
 g to a node on the correct path, it might correct to the node A' and proceed down the path to B.  Then it may correct to B', and so on.  Because the protocol emulation keeps making mistakes, it may never be able to successfully backtrack and communicate the messages that correspond to the actual protocol execution.
\begin{figure}[htb]
\begin{center}
\begin{tikzpicture}
\coordinate (top) at (4,5);

\draw[thick,dashed] (top) -- (1,1);
\draw[thick,dashed] (top) -- (7,1);
\draw[thick] (top) -- (4.5,1)
  node (1) [pos=0.3,token] {1}
  node (2) [pos=0.45,token] {2}
  node (3) [pos=0.6,token] {3}
  node (4) [pos=0.75,token] {}
  node (5) [pos=0.9,token] {};


  \draw[-,thick] (1) -- ++(-50:1.2cm) node (a) [token,fill=gray,label=right:A]{};
  \draw[-,thick] (2) -- ++(-120:1.2cm) node (b) [token,fill=gray,label=left:B] {};
   \draw[-,thick] (3) -- ++(-50:1.2cm) node[token,fill=gray,label=right:C]{};

   \draw[-,dashed] (a) -- +(-0.9,0) node [token,fill=red,label=left:A'] {};
   \draw[-,dashed] (b) -- +(1.1,0)  node [token,fill=red,label=right:B'] {};

   \draw[-, thick] (4) -- ++(-120:1.1cm);
   \draw[-, thick] (5) -- ++(-50:0.5cm);


\draw (0,0) rectangle (8,6);


\end{tikzpicture}

\end{center}
\caption{A bad tree code}
\label{fig:bad}
\end{figure}

Schulman~\cite{schulman93} dealt with this problem by simply insisting that \emph{all} divergent paths have large relative Hamming distance in his definition of a good tree code.  This would prevent all such problems, and guarantee that errors in emulation could only be caused by actual channel errors.  The downside of this approach is that randomly generated tree codes would have short divergent paths with small (even zero) relative Hamming distance with overwhelming probability, and thus would not be good tree codes.

Our main observation is that this requirement goes too far.  If a tree code has the property that for every path from root to leaf, there are only a few small divergent branches with low relative Hamming distance (as illustrated in Figure~\ref{fig:potent}), then the emulation protocol will be able to recover from these few errors without any problems.  We call such tree codes \emph{\potent tree codes} since they are sufficiently powerful to enable efficient and reliable interactive communication over a noisy channel.

More precisely, let  and  be two parameters from the interval .
Define a path from node  to a descendant node  (of length
) to be \emph{-bad} if there exists a path from  to
another descendant node  (also of length ) such that the
Hamming distance between the - path and the - path is less
than .
Then an \emph{-potent tree code} of depth  is such that for every path  from root to leaf, the number of nodes in the union of all -bad subpaths of  is at most
.



\begin{figure}[htb]
\begin{center}
\begin{tikzpicture}
\coordinate (top) at (4,5);

\draw[thick,dashed] (top) -- (1,1);
\draw[thick,dashed] (top) -- (7,1);
\draw[thick] (top) -- (4.5,1)
  node (1) [pos=0.3] {}
  node (2) [pos=0.45] {}
  node (3) [pos=0.6] {}
  node (4) [pos=0.65] {}
  node (5) [pos=0.9] {};


  \draw[-,thick] (1.center) -- ++(-50:0.5cm) ;
  \draw[-,thick] (3.center) -- ++(-120:0.5cm);
     \draw[thick] (4.center) -- ++(-50:0.5cm);

   \draw[thick] (5.center) -- ++(-50:0.5cm);

\draw (0,0) rectangle (8,6);


\end{tikzpicture}
\end{center}
\caption{A potent tree code}
\label{fig:potent}
\end{figure}



We show that randomly generated tree codes (with suitable constant
alphabet sizes) are potent tree codes with overwhelming probability.
As hinted above, because every root-leaf path has good properties, a
potent tree code will work for emulating \emph{any} (adversarially
chosen) interactive protocol.  With some additional randomization,
we show that within such emulations, decoding of a randomly
generated potent tree code can be done efficiently even for an
adversarially chosen protocol.


\paragraph{Naturalness of our definition.}
We argue that our notion of bad subpaths in a \potent tree code
captures the level of local ``confusion'' that is possible in a tree
code, in a manner that we see as analogous to how ordinary symbol
overlap (Hamming ``closeness'') captures such confusion in the
context of ordinary error-correcting codes, which are much less
structured objects.  In this analogy, \potent tree codes with
 (which correspond to Schulman's good tree codes) are
analogous to maximum distance separable (MDS) codes in the context
of ordinary error-correcting codes.  Just as MDS codes are powerful
and useful objects, but not necessary for most applications of
error-correcting codes, we think of Schulman's good tree codes as
being powerful and useful objects, but not necessary for important
applications like reliable interactive communication where \potent
tree codes suffice.


\paragraph{Other Related Work.}
In 2006, Peczarski~\cite{peczarski06} provides a randomized way for
constructing good tree codes. The construction succeeds with
probability  using alphabet with size proportional to
. Therefore, using Peczarski's method to construct a
good tree code with exponentially small failure probability
, yields a polynomial slowdown; or a sub-linear but
super-logarithmic slowdown if   is negligible (in the
length of the simulated protocol). Other methods for constructing a
good tree code are reported by Schulman~\cite{schulman-email}, yet
they require polynomial-size alphabet (in the depth of the tree),
resulting in a logarithmic slowdown using Schulman's
emulation~\cite{schulman93}. Schulman~\cite{schulman-email} also
provides methods for constructing tree codes with weaker properties
such as satisfying the Hamming distance property for only a
logarithmic depth (which yields a failure probability that is
inverse-polynomial). Ostrovsky, Rabani, and Schulman~\cite{ORS05}
consider a relaxed problem of communication for control of
polynomially bounded systems, and gave explicit constructions of
codes suitable for that setting.

In work concurrent and independent to ours, Moitra~\cite{Moitra11}
introduced a relaxation of good tree codes that he calls local tree
codes, which allows him to obtain a fully explicit and deterministic
emulation protocol, but which obtains error probability that is a
fixed inverse polynomial in the length of the protocol.  In
contrast, our work obtains a fully explicit randomized emulation
protocol, but achieves error probability that is exponentially small
in the length of the protocol.





\section{Preliminaries}\label{sec:pre}


We begin with several definitions that we use later.
Unless otherwise mentioned, we use base 2 for all logarithms.
\begin{definition}
We say that a function  is negligible in , and denote 
if for any polynomial , and sufficiently large  ,
.
\end{definition}
Our model of communication is based on a binary channel that flips each
bit with probability , independently of other bits.
\begin{definition}
A binary symmetric channel (BSC) with error probability 
is a binary channel  such that for every inputed bit
outputs the same bit with probability  or the complementary bit
with probability , independently of previous transmissions (memoryless).
\end{definition}

One can use codes in order
to send messages which can be recovered except with arbitrary small probability.
This is done by adding redundancy to each message, according to the desired
error probability.
Shannon's coding theorem asserts the existence of an error-correcting code that reduces the
error probability (for a single message) to be exponentially small,
while increasing the amount of transmitted information
by only a constant factor.

\begin{lemma}[Shannon Coding Theorem~\cite{shannon48}]\label{lem:shannon}
For a BSC channel with capacity , an alphabet  and any , there exists a code
 and  with  such that

\end{lemma}
\noindent
Although throughout this paper we assume the channel is a BSC with symbol error of at most  (using an error correction code), our result applies for any memoryless noisy channel with maximal symbol error probability .


The main structure we use is a \emph{tree code}, introduced by Schulman~\cite{schulman93,schulman96}.
Each edge in a tree code is assigned with a label (from a given alphabet ),
such that strings obtained by concatenation of these labels
form a code, that is, have a large Hamming distance.

\begin{definition}
The Hamming distance of two strings  and
 of the same length over an alphabet ,
is the number of positions  such that .
The Hamming distance is denoted by .
\end{definition}

As said earlier, we re-define the term \emph{tree code} to be any tree, such that
every arc  in the tree has a label  over some fixed alphabet .
Denote with  the label of the arc between
 and its parent and  the concatenation of the labels along the
route from the root to the node . Using our new terminology,
the tree codes introduced by Schulman~\cite{schulman96}
are denoted as \emph{good tree codes}.
\begin{definition}[Tree Codes~\cite{schulman96}] \label{def:TreeCode}
A  \textbf{good -ary tree code} over an alphabet , of distance parameter  and depth ,
is a -ary tree code of depth  such that
for every two nodes  and  at the same depth,

where  is the distance from  and  to their least common ancestor.
\end{definition}
Tree codes can be used to communicate a node  between the users, by sending the labels
. Decoding a transmission means recovering the node at the end of
the route defined by the received string of labels.
In order to reduce the error probability of the label
transmission, each label is separately coded using a standard error-correcting code.
It is shown in~\cite{schulman96} that for every distance parameter , there exists a good -ary tree code of infinite depth, labeled using   symbols.
However, although it is known to exist, its explicit efficient construction
remains an open question.




\section{Potent Tree Codes}\label{sec:potent} 


\subsection{Potent Tree Codes and Their Properties}\label{sec:potent}


We now formally define the set of \emph{\potent trees} and its complement,
the set of \emph{bad trees}. The latter contains trees that are not useful for our purpose:
at least one of their paths is composed of
``too many'' sub-paths that do not satisfy the distance condition, i.e.,
the total length of these sub-paths
is at least  fraction of the tree depth , for some fixed constant . Formally,
\begin{definition}\label{def:badNode}
Let  be some nodes at the same depth  of a tree-code, and let
 be their least common ancestor, located at depth .
The nodes  and  are
-\textbf{bad nodes} (of length )
if .
In this case, the path (of length ) between  and  is called an -\textbf{bad path} (similarly, the path between  and  would also be a bad path).
Define the imposed -\textbf{bad interval} (of length )
as the interval .
\end{definition}



\begin{definition}\label{def:badTree}
An \textbf{-bad tree}
is a tree of depth 
that has a path containing -bad subpaths, such that their
union is of total length at least .
\end{definition}
\begin{definition}
An  \textbf{-\potent tree code}  is a tree of depth ,
such that for every path  from root to leaf,
the union of all bad subpaths of  is of length less than .
In other words,  the tree is \emph{not} an -bad tree.
\end{definition}
\noindent We stress that a bad tree is not necessarily bad in \emph{all} of its paths,
since the existence of a single bad path is sufficient.

Conveniently, it is rather simple to construct a \potent tree,
which makes it a feasible
tool for plenty of applications.
In the following we give two methods for constructing \potent trees.
The straightforward method is to randomly pick each label of the tree.
The obtained Random Tree Code (\RTBC) is a potent tree except with probability
exponentially small in the depth of the tree.
The drawback of the first construction, is that its description is exponential.
However, we observe that our proof does not require the entire tree to be random,
but rather makes a use of the fact that any two paths along the tree are \emph{independent}.
Using the method of Alon, Goldreich, H{\aa}stad and Peralta~\cite{AGHP92}
we are able to construct a  tree in which any two paths are \emph{almost independent}.
Moreover, such a tree has an efficient description.



\subsection{Random Tree Codes as Potent Trees}


\begin{definition}
Let  be a finite alphabet.
A {\bf random tree code} (\RTBC) is a -ary tree,
where each arc  has a label ,
randomly and independently chosen.
\end{definition}

\noindent
\textbf{Intuition.}
It is important to note that a \RTBC might {\em not} be a good tree code
according to Definition~\ref{def:TreeCode}.
However, with high probability, the \RTBC can be used to replace a tree code, without significantly
damaging the probability of success.
Informally speaking, we can think of a \RTBC as using a good tree code, but increasing
the channel error rate. Indeed, the only difference is that with a probability of
 two edges in the \RTBC are assigned with the same label
(and as a consequence some paths might not satisfy the distance condition).
An equivalent result is obtained by taking a good tree code and ``forcing'' the channel
to make an error during the transmissions related to those edges.
This leads to an expected increase of  in the channel's error rate.



\begin{theorem}\label{thm:RTCisPotent}
Suppose .
Except with probability ,
a \RTBC with alphabet 
is -\potent.
\end{theorem}
\noindent The proof is given in Appendix~\ref{app:RTBC}.
\bigskip



\subsection{Small-Biased Random Trees as Potent Trees}


In order to agree on a \RTBC with alphabet , the users need to communicate
(or pre-share)  random bits. Surprisingly, we can reduce the description size to
 and still have a \potent code with overwhelming probability.
This is allowed due to Alon et al.'s construction of  a sample space with an efficient description
that is -biased~\cite{AGHP92}.

\begin{definition}[-biased sample space~\cite{NN90, AGHP92}]
A sample space  on  bits is said to be -biased with respect to linear tests
if for every sample  and every string , the random variable  satisfies
.
\end{definition}
We use~\cite[Construction 2]{AGHP92} to achieve a sample space 
which is -biased with respect to linear tests.
Let  be an odd prime such that ,
and let  be the quadratic character of { (mod~)}.
Let  be the sample space described by the following construction.
A point in the sample space is described by a number ,
which corresponds to the -bit string 
where .
\begin{proposition}[\cite{AGHP92}, Proposition~2]
The sample space  is -biased with respect to linear tests.
\end{proposition}
We use the above to construct
a -ary tree code of depth  with labels over an alphabet .
Without loss of generality we assume that  is a power of 2, and
describe the tree as the -bit string constructed by concatenating of all
the tree's labels in some fixed ordering.
Since each -bit sample describes a tree-code,
we are sometimes negligent with the distinction between these two objects.

\begin{definition}\label{def:SBTC}
A -ary \emph{Small-Biased Tree Code} (\KTC) of depth , is a tree described by some sample
from the sample space  with ,  for some constant  that we can choose later.
\end{definition}


We note that small-bias trees have several properties which are very useful for our needs.
Specifically, every set of labels are almost independent.
\begin{definition}[almost -wise independence~\cite{AGHP92}]\label{def:independent}
A sample space on  bits is \textbf{-independent} if for any
 positions  and -bit string ,

\end{definition}
Due to a lemma by Vazirani~\cite{Vazirani86} (see also corollary~1 in~\cite{AGHP92}),
if a sample space is -biased with respect to linear tests, then for every , the sample space is -independent. Thus,  is -independent, for any .
\begin{corollary}\label{cor:k-independence}
Let  be a -ary \KTC of depth , then any  labels of  are almost independent,
that is, any  bits of 's description
are -independent.
\end{corollary}


Finally, let us argue that such a construction is efficient.
Let  and assume a constant alphabet .
Each sample  takes  bits, and each  can be computed by  operations.




\bigskip
We now show that the properties shown in Appendix~\ref{app:RTBC} for a \RTBC,
hold for a \KTC as well.
\begin{proposition}\label{prop:KTCisPotent}
Suppose .
Except with probability ,
a \KTC of depth  over alphabet 
is -\potent.
\end{proposition}
\begin{proof}
We show that the probability of a \KTC to be
-bad is exponentially small.
We begin by fixing a leaf , and later use a union bound
to bound the probability over the entire tree.
Assume that the tree is bad, that is,
there exist bad intervals of total length .
Due to Lemma~\ref{lem:intervals}
there must exist \emph{disjoint}
bad intervals of total length at least .


There are at most 
ways to distribute these disjoint
intervals along the path from  root to .
In a similar way to Lemma~\ref{lem:prob4smallHamming},
we can bound the probability of  having
a node  at the same depth as  which imposes a bad interval of length .
Since the tree is -independent,
the suffixes (of length ) of the label sequences  and  are almost independent.
For  and a node   denote by  the last  symbols of .
\begin{lemma}\label{lem:ktcHD}
For any two nodes at the same level  with a common ancestor  levels
away,

\end{lemma}
\begin{proof}
Note that  and  are identical except for their suffix of length .

Choosing  completes the proof.
For the ease of notation, in the following we use  as an upper bound of the above probability.
\end{proof}
The above lemma leads to the following bound on the probability that two nodes are -bad.
\begin{corollary}\label{cor:defect}

\end{corollary}
\noindent Using a union bound, the probability that there exist a node
 with common ancestor  level away, such that
 and  do not satisfy the distance requirement is bounded by


Consider again the path from root to , and the disjoint
bad intervals of total length at least  along it.
There are at most  labels involved (along both the path to  and the colliding paths).
Since the intervals are disjoint, their probabilities are almost independent as well, and
the probability that a specific pattern of interval happens is bounded by the
multiplication of the probabilities of each interval.


According to the above, 
the probability for a \KTC to be -bad is bounded by

which is exponentially small in  for .
\end{proof}


\section{Applications - Simulation with Adversarial Errors}\label{sec:appBR}
In a recent paper~\cite{BR10} Braverman and Rao show how to simulate
any 2-party protocol over a noisy channel, that is able to withstand an error
rate of up to , for any constant .
Their simulation uses good tree codes to communicate
the process of the simulated protocol over the noisy channel.

We show that the analysis of Braverman and Rao
can be repeated using a -potent tree instead of a good tree code,
and withstand error rate of up to .
Intuitively, for every node which is not -bad, the potent tree code behaves
exactly like a good tree code (i.e., many channel errors are required for having a decoding error).
On the other hand, for every possible path along the potent tree,
there are at most  nodes which are -bad, that is,
at most additional  times in which the scheme differs from a good tree code (in each one of the directions of communication).
This gives an algorithm that withstand up to 
fraction of (adversarial) errors.

\begin{theorem}\label{thm:BR}
For any 2-party binary protocol  and any constant  there exist a
protocol  that simulates  over a noisy channel using \potent tree-codes,
imposes a constant slowdown
and succeeds except with negligible probability.
\end{theorem}
\noindent See proof in Appendix~\ref{app:BR}.

\section{Applications - Efficient Simulation with   Random Errors }\label{sec:app}



We provide an efficient randomized algorithm that succeeds to simulate
any interactive protocol over noisy channel with overwhelming probability.
In 1992 Schulman proposed an efficient randomized scheme that solves this
problem~\cite{schulman92} which requires quadratic communication\footnote{The simulation itself impose a constant slowdown, however the users must share a parity-checking matrix of quadratic size.}.
By using potent trees (realized via \KTC{}s), we improve the result of Schulman and obtain
a linear communication (i.e., a constant dilation) which includes the communication required to agree on the same \KTC.
The scheme we obtain is efficient and constructive.
We then extend our proof to any multiparty protocol following the analysis of Rajagopalan and Schulman~\cite{RS94}, again, by replacing the good tree code with a potent tree.


\subsection{Interactive Protocol Over Noisy Channels}
Our setting considers a distributed computation of a fixed function , performed by several
users who (separately) hold the inputs. We begin by considering only two users and later
extend our result to any number of users.
Let  be a 2-party distributed protocol
which on inputs , both parties output the value .
In each round,  and  send a single message to each other, based on their input and
messages previously received. The protocol  assumes an ideal communication channel which
contains no errors. Under these assumptions,  takes  rounds of communication to output the correct answer, where one round means both users simultaneously send each other a message.

In a more realistic model, the channel between  and  may be noisy, so that each message
needs to be encoded in order to identify and correct possible errors.
Shannon's \emph{Coding Theorem}~\cite{shannon48} (see Lemma~\ref{lem:shannon})
shows that an exponentially small decoding error in the length of the message 
can be achieved, if the message is encoded into a code word of length ,
for some constant 
determined by the channel \emph{capacity}.
However, if we use a standard Shannon code to encode multiple messages,
then the probability of having at least a single decoding error
is proportional to the number of messages sent, rather than arbitrarily small.
In this paper we explore the worst case scenario of the above tradeoff between the
number of messages and their size.
Namely, we assume that a total amount of  bits of information  is divided into
 messages of a single bit each. Our aim is to send  bits over the channel
and obtain an exponentially small failure probability.


Let us formulate the computation process of the protocol .
During each round, each user  sends one bit according to
its input  and the messages received so far. Let 
denote the  first bit sent by user , and let  be the
two bits transmitted in the first round by A and B respectively, where .
Generally, let  be the first  (2 bit-)messages exchanged during the protocol, then the information sent in round 
is defined by .

\begin{figure}[htb]
\begin{framed}
\begin{tikzpicture}
\node (root) [above] {\gametree} ;
\coordinate
  child {    edge from parent node [near end,right] {00} }
  child {    edge from parent node [near end,right] {01} }
  child  {
    child {    edge from parent node [near end,right] {00} }
    child {    edge from parent node [near end,right] {01} }
    child {    edge from parent node [near end,right] {10} }
    child {    edge from parent node [near end,right] {11} }
    edge from parent node[near end,right] {10} }
  child {    edge from parent node [near end,right] {11} }
  ;
\end{tikzpicture}
\begin{tikzpicture}
[level/.style={sibling distance=9mm}]   \node (root) [above] {\statetree} ;
\coordinate
  child {node {00x0}}
  child {node {00x1}}
  child {node {01x0}}
  child {node {01x1}}
  child {node {10x0}
      child child child {edge  from parent [draw=white] node {}}  child child}
  child {node {10x1}}
  child {node {11x0}}
  child {node {11x1}}
  child {node {Hx0}}
  child {node {Hx1}}
  child {node {Bx0}}
  child {node {Bx1}}
  ;
\end{tikzpicture}
\end{framed}
\caption{The \gametree and the \statetree}
\label{fig:trees}
\end{figure}
The computation (over a noiseless channel) can be described as a single route 
along the \gametree,
a 4-ary tree of depth  (see Figure~\ref{fig:trees}). The path  begins
at the root of the tree
and the  edge is determined by the 2 bits exchanged in the  round,
i.e., the first edge in the path is , the second
is , etc.






\subsection{Simulating  Over a Noisy Channel}



\subsubsection{The basic scheme}\label{sec:basicScheme}
Our goal is to calculate a protocol  over a noisy channel. In order to do so, we use the method
of Schulman~\cite{schulman96} described in Figure~\ref{alg:protocol}.
[The protocol is described for user . The protocol for  is identical.]
The idea behind the simulation is the following.
Each user keeps a record of  (his belief of) the  current progress of ,
described as a pebble on one of the \gametree nodes.


\begin{figure}[htb]
\begin{framed}
\small
Begin with own pebble at the root of \gametree\ and own state  at the \statetree root's child labeled
.
Repeat the following  times\footnotemark:
\begin{enumerate}
\item Send  to user B.
\item Given the sequence of messages Z received so far from user B, guess the
current state  of B as the node that minimizes .
From the guess , infer
B's pebble movements and compute the (alleged) current position pebble of B's pebble and the bit  outputted by B for this round.
\item Set your pebble movement and new state according to the current position  of your pebble  and the following:
    \begin{enumerate}
    \item If pebble then move own pebble according to the pair of bits
     to a state .
    The new state is 's child labeled with the arc .
    \item If  is a strict ancestor of pebble: own movement is , and the
    next state is along the arc .
    \item Otherwise, move own pebble backwards. New state is along the arc 
    where  is the parent of .
    \end{enumerate}
\end{enumerate}
\end{framed}
\caption{Interactive protocol  for noisy channels~\cite{schulman96}}
\label{alg:protocol}
\end{figure}
\footnotetext{For the simulation to be well defined,
    we must extend  to  rounds.
    We assume that in each of the   spare rounds,
     outputs 0 for each user and every input.}

Each round, according to the transmissions received so far,
the user makes a guess for the position of the other user's pebble,
and infers how his own pebble should  move.
The user sends a message that describes
how he moves his pebble (out of the six possible movements matching the
4 child nodes, `H' to keep the pebble in the same place or `B' to back up to the parent node) and
the bit outputted by him, assuming the protocol is
described by the new position of his pebble.
Each one of these  12 options represents a child in a 12-ary
tree denoted as the \statetree (Figure~\ref{fig:trees}).
The user communicates\footnote
{We imply here using a (standard) error-correcting code in order to send the label over the
noisy channel, with constant slowdown (as given by Lemma~\ref{lem:shannon}).
Throughout the paper, any transmission of a label is to be understood in this manner.}
the label
assigned to the edge in the \statetree that describes his move. The \emph{state} of the user
is the current node on the \statetree, starting from its root,
and changing according to the edge communicated.


Informally speaking, the simulation works since the least common ancestor  of
both the user's pebbles always lie along the path . If both users take the
correct guess for the other user's pebble position, they simulate  correctly and their pebbles move along .
Otherwise, their pebbles diverge, yet the common ancestor remains on .
On the following rounds, when the users acknowledge an inconsistency in the pebbles' positions,
they move their pebbles backwards until the pebbles reach their common ancestor, and
the protocol continues.  The users will simulate  as long as the number of
divergences is small enough.
It is shown in~\cite{schulman96} that repeating the above process for
 rounds is sufficient for simulating
 with exponentially small error probability (over the
channel errors).
We refer the reader to~\cite{schulman96}
for a detailed description of the protocol and its analysis.



In order to be able to construct such
a simulation, we replace the (non-constructive)
good 12-ary tree code with  originally used by Schulman, by a
\potent tree.
Surprisingly, this simple change is enough to obtain a constructible scheme
for simulating interactive protocols over noisy channels.
We note that in Section~\ref{sec:multiparty} we show that the same can be done using a ternary tree
instead of a 12-ary tree, using the methods of~\cite{RS94}. However, for the clarity of the
presentation, we first analyze the scheme using  a 12-ary tree
and only later optimize the result.



\begin{theorem}\label{thm:mainA}
Given a -\potent tree code with a constant-size alphabet 
(which depends on the constant )
and an oracle for a decoding procedure of that tree code,
the protocol  (Figure~\ref{alg:protocol})
is an efficient simulation of the protocol  (that has  rounds).
It takes  rounds and succeeds with probability  over the channel errors,
assuming the use of an error correcting code with (label) error probability .
\end{theorem}

Moreover,
if we are given an oracle to a tree code decoding procedure, the obtained protocol
is efficient. In Section~\ref{sec:eff} we show a decoding procedure
that is efficient  on average, given that the tree is \KTC. This immediately
leads to the following (main) Theorem.

\begin{theorem}[Main]\label{thm:main}
There exists an efficient simulation that computes any distributed 2-party protocol  of length ,
using a BSC for communication and a pre-shared \KTC. The simulation imposes a constant slowdown,
and succeeds with probability  over the channel errors and the choice of the \KTC.
\end{theorem}

We now give the proof idea  for Theorem~\ref{thm:mainA} and later complete the formal proof.
We begin by defining a good move: a move that advances the simulation of  in one step,
and a bad move: an erroneous step in the simulation that requires us to back up and re-simulate
that step. We show that any bad move is associated with a decoding error,
i.e., recovering a wrong node , due to channel errors or tree defects.
Thus, we can bound the number of bad moves by bounding the probability for
channel errors and tree defects.
Using (Shannon's) error correcting codes, the probability of a channel error is arbitrarily small,
and so is the probability of having many channel errors.
Furthermore, we use a \potent tree code, to guarantee
a small number of tree defects, except with an exponentially small probability.



\vspace{1em}




Recall the following properties of the simulation .
\begin{lemma}[\cite{schulman96}] \label{lem:lcaOnTrack}
The least common ancestor of the two pebbles lies on .
\end{lemma}
\begin{lemma}[\cite{schulman96}]\label{lem:moves}
Let  and  be the positions of the two pebbles in the \gametree at some time ,
and let  denote the least common ancestor of  and .
Define the {\em mark} of the protocol as the depth of  minus the
distance from  to the further of  and .

If during a specific round, both users guess the other's state correctly
(a {\em good} move), the mark increases by 1.
Otherwise (a {\em bad} move), the mark decreases by at most 3.
\end{lemma}
\noindent A proof for  both of the above lemmas is given in~\cite{schulman96}.

Our goal is to show that the probability of having more than  bad rounds
is exponentially small. By setting  and  we guarantee
that  at the end of the calculation the mark will be (at least) .
Since the common ancestor of the pebbles always lies along the path ,
a mark of value   indicates that the common ancestor has reached depth ,
and  was successfully simulated.

For a bad round at time , we assume that (at least) one of the users takes a wrong
guess of the (other user's) current state.
Suppose that
the least common ancestor of the right state and
the wrongly guessed state in the \statetree, is distanced  levels away (i.e., an error of magnitude ).
Define the {\em error interval} (of length ) corresponding to the erroneous guess
as  .


We now show that given a \potent tree,
  simulates  over a noisy channel with overwhelming probability.


\begin{proof} \textbf{(Theorem~\ref{thm:mainA})}.
Suppose the parties share a -\potent tree code\footnote{
    Proposition~\ref{prop:KTCisPotent} guarantees  that
    as long as ,
    only a negligible fraction of the \KTC{}s are -bad. Therefore,
     for obtaining a \potent tree with overwhelming probability, we require .},
for some .
Assume that a specific run of a simulation failed, and thus
it must be that more than  errors have occurred.

Note that the simulation defines a path along the \statetree, from the root
to one of the leaves. Since the \statetree is -\potent, the
specific path contains bad intervals of total length
at most . We assume a worst case scenario in which
each -bad node causes a bad move in the simulation.
We show that
the probability of having  additional  bad moves
(in the remaining nodes, which are not -bad)
is exponentially small.

Consider a specific bad move caused by erroneously decoding a node which is not -bad,
at time . Namely, the user guesses a wrong node  instead of the real transmitted node .
For an error of magnitude ,  and  are identical from the root
to the least common ancestor of  and  at level .
Since the decoding is done by minimizing the Hamming distance,
making this wrong guess is independent of transmissions prior to round .
It follows that such an error (of magnitude ) can happen only if at least 
channel errors have occurred during the last  rounds.
Due to the same reason, it is easy to see that decoding errors of which the
error intervals are disjoint, are independent.

We consider again the bad moves which are associated with
a decoding error of  nodes which are not -bad. Each such a bad move (i.e., a decoding error)
impose an error interval of length , and the union of these intervals must be
of length at least .
Each such an error happens with probability at most
.
Due to Lemma~\ref{lem:intervals} we can find a set of disjoint intervals
of length at least . Due to the discussion above, these errors are independent, and their
probability to jointly occur is bounded by




We conclude the proof by bounding the probability
for having any possible error pattern of total length at least 
along the bad moves associated with nodes which are not -bad,
by using the union bound
over all possible error patterns (there are
at most  such patterns),
for each one of the users. The probability is bounded by

which is  for  .
\end{proof}


\subsubsection{Performing decoding in an efficient way}\label{sec:eff}


A decoding process outputs the node  (at depth ) that minimizes the Hamming distance
between  and the received string of labels .
Although the above Theorem~\ref{thm:mainA} is proven assuming an oracle to
tree-code decoding procedure, this requirement is too strong for our needs.
Since we count any node which is -bad as an error (even when no error have occurred),
it suffices to have an oracle that decodes correctly given that the (transmitted) node
is not -bad.

We follow the techniques
employed by Schulman~\cite{schulman96}
(which are based on ideas from~\cite{wozencraft57, reiffen60, fano63}),
and show an efficient decoding that succeeds if the node is
not -bad.
While the decoding process of~\cite{schulman96} is based on the fact that
the underlying tree is a good tree code,
in our case the tree code is a \KTC.\footnote{A similar proof works also for a \RTBC.}


The decoding procedure is the following.
For a fixed time , let  be the current guess of the other user's state,
and denote the node along the path from the root to  as .
Also, recall that   are the labels received so far. If there exists a child of 
whose edge is labeled , choose that child (break ties arbitrarily),
otherwise, arbitrarily choose one of 's child nodes.
Denote with  the new guess.

Recall that  denotes the -suffix of , i.e., the last  symbols along the path from the tree's root to the node .
We look at the earliest time  such that .
For that specific , exhaustively search the subtree of  and set
the new guess  as the node 
(at depth ) that minimizes the Hamming distance .


Note that when  is an -bad node of maximal length ,
any path from the root to some other node ,
where the least common ancestor of  and  is located  levels away,
must have
a Hamming distance .
Therefore, if all the suffixes of length  satisfy
,
it is guaranteed that the
node minimizing the Hamming distance is within the subtree of .
However, if  is an -bad node of length ,
the decoding process might yield a wrong guess,
i.e., a node in the subtree of  that does not minimize the Hamming distance.

The following proposition bounds the probability for a decoding error of magnitude .
\begin{proposition}\label{pro:errorProb}
Assume a \KTC is used to communicate the string  over a BSC.
Using the efficient decoding procedure (with some constant ),
the probability for a specific user to make
a decoding error of magnitude 
is  bounded by ,
if an error correction code with (label)
error probability less than  is used.
\end{proposition}

\begin{proof}
A decoding error of magnitude  occurs if the decoding process outputs a node
 , such that the common ancestor of  is  levels away.
Such an error can happen due to one of the following reasons:
\begin{enumerate}
\renewcommand{\labelenumi}{(\roman{enumi})}
\setlength{\itemsep}{1pt}
\vspace{-0.3em}
\item For the received string  it holds that
. This happens when
the Hamming distance  is  and more than  channel errors  occurred.
\item The decoding process did not return the node that minimizes the Hamming distance.
\end{enumerate}
Note that we only need to consider the paths from root to  and to  and thus use the -wise independence of the tree's labels.
Recall that the probability to have specific set of  labels is  away from uniform, with , and the probability for a given Haming distance between  and  is bounded by Lemma~\ref{lem:ktcHD}.
Let  be the maximal label error of the channel.
Using a union bound for every possible node ,
the probability of part (i) is bounded by

which is exponentially small in  as long as .


For part (ii),
note that the decoding process does not return the node that minimizes the Hamming
distance if
 is larger than , for the suffix determined by the decoding procedure
(using the notations described above for the efficient decoding procedure).
This implies that for the outputted node , .
Since  is not the node that minimizes the Hamming distance,
there must exist a node 
of distance at most ,
such that .
By the triangle inequality, the Hamming distance between the paths from
  and   to
 their least common ancestor
must be at most .
Using the union bound for any possible such  and any possible Hamming distance up to ,
we bound the probability of this event by

A union bound on the two cases completes this proof.
\end{proof}

We stress that the above decoding process always outputs the correct
node (i.e., the node which minimizes the Hamming distance), if the transmitted
node is not -bad. For that reason, the analysis performed
in the proof of  Theorem~\ref{thm:mainA} is still valid, since it
only requires the decoding procedure to succeed when the node is not -bad
(and assumes that the simulation has a bad move
in each node which is a bad node).



We now show that this procedure is efficient in expectation.
Let  be the depth of the subtree explored at time .
The decoding process takes   steps
(this dominates terms of   required to maintain the guess, etc).

For time , if  then 
yet for , . Assume that the
sequence of labels transmitted is  for some node  of depth .
The above requirements imply that the suffixes (of length )
of  and  have Hamming distances \emph{exactly} .
This happens with probability at most

assuming .

With a sufficiently large yet constant alphabet, e.g.,  ,
we bound
the probability that  equals  to be .
The expected running time is then given by

Since we repeat the simulation step for   times,
the computation is efficient in expectation.
To complete the proof, we mention that~\cite{schulman96} presents  a data structure
which allows us to perform the above decoding with overhead .



\subsubsection{Simulating an adaptively chosen protocol}\label{sec:adaptive}




For a given protocol,   fails with exponentially small probability that
depends on the choice of the \KTC and the BSC errors.
Assume that the we first pick a \potent tree
and then the protocol  is (adversarially) chosen.
Due to Theorem~\ref{thm:mainA}, as long as the tree code is  \potent,
the simulation succeeds with overwhelming probability, over the
BSC errors alone. However, the decoding process described in
Section~\ref{sec:eff} above, might no longer be efficient,
since the adversary might force the simulation
to travel through the ``bad'' regions in the tree that require exploring large subtrees.

An interesting remedy to the above
can be achieved by
by introducing more randomness,
which prevents the adversary from fixing the path along the \statetree the simulation takes.
We now extend  the basic scheme 
to the stronger notion
of adversarially chosen protocol (Section~\ref{sec:adaptive}), and prove the following theorem.
\begin{theorem}\label{thm:mainAdaptive}
Except for probability  over the choice of the \KTC, there exists
an efficient scheme to simulate any 2-party protocol 
of length , with success probability at least  over the channel errors.
\end{theorem}

As said above,
the expected runtime for the decoding process described in Section~\ref{sec:eff}
is no longer efficient in this case. The adversary can choose
the simulated protocol  and  ``fix'' a path along the
\statetree (up to channel errors). As the decoding process is efficient in expectation,
the path fixed by the adversary might be a path that is inefficient to decode.
However, by adding randomness, we are able to change  such that
for any protocol , the actual traversed path in the \statetree is fully random.
This is done by permuting the nodes of the \statetree
separately for each level. The users need to communicate which permutation
is used for each level, which is done by sending the specific permutation in use via
additional (\potent) tree code, which we denoted as the \randomtree.


Define the \randomtree to be a \KTC of degree  (for our case ).
For a specific node, each one of  the  children
denotes one of the possible permutations on  values.
Each round, the user chooses a random permutation by randomly selecting
one of the children of his current position in the \randomtree (starting from the root).
Recall that, in the \statetree, each node has 12 children where each represents one of
, , . We can assume a fixed order, that is, the first child always
represents , the second represents , etc.
For a time , assume the chosen permutation is .
In our randomized simulation, the  child in the
\statetree has the meaning  . For instance, the first node represents
one of the meanings , , , determined by .

The adapted scheme, Randomized-, is described in Figure~\ref{alg:protocolAdaptive}.
For Theorem~\ref{thm:mainAdaptive}, we assume that
both the \statetree and the \randomtree are -\potent trees,
which can be achieved (with overwhelming probability)
by having a large enough (yet a constant) alphabet size.
As before, we assume each label is sent using an error correcting code, such that
the error probability per transmission is less then .
Such an error correcting rate imposes
a constant slowdown, according to Lemma~\ref{lem:shannon}.

\begin{figure}[htb]
\begin{framed}
\small
Begin with own pebble at the root of \gametree\ and own state  at the \statetree root's child labeled
. Let the \emph{randomness-state}  be the root of the \randomtree.
Repeat the following  times:
\begin{enumerate}
\item Send  to user B.
\item Randomly choose one of the children of . Set the randomness-state  to be
the chosen child and send .
\item Given the sequence of messages Z received so far from user B, guess the
current state  of B and the current randomness-state  of B.
From the guesses, infer B's pebble movements and compute the
(alleged) current position pebble of B's pebble and the bit  outputted by B for this round.
\item Set your pebble movement and new state
according to the current position  of your pebble  and the following:
    \begin{enumerate}
    \item if pebble then move own pebble according to the pair of bits
     to a state .
    The new state is 's child labeled with the arc .
    \item If  is a strict ancestor of pebble: own movement is , and the
    next state is along the arc .
    \item Otherwise, move own pebble backwards. New state is along the arc 
    where  is the parent of .
    \end{enumerate}
\end{enumerate}
\end{framed}
\caption{Interactive protocol Randomized- for
  simulating an adversarially chosen protocol  over noisy channels}
\label{alg:protocolAdaptive}
\end{figure}

\vspace{0.5em plus 0.5em minus 0.2em}
Theorem~\ref{thm:mainAdaptive} immediately follows from the following theorems,
\begin{theorem}\label{thm:mainB}
Assume \randomtree and \statetree are -\potent
trees for some , and assume an oracle for tree-code decoding process,
then Randomized- (Figure~\ref{alg:protocolAdaptive}) is an efficient simulation
of any protocol  (that has  rounds).
If any label is sent using a error correcting code with (label) error probability
, then Randomized-
succeeds except with probability
 over the channel errors.
\end{theorem}
\begin{theorem}\label{thm:adaptiveEff}
For a given , suppose that
the \randomtree and the \statetree are \RTBC{s} with
large enough (yet constant) alphabet size,  
and that ,
then the decoding procedure (Section~\ref{sec:eff}) is
(i) efficient in expectation, and (ii) correctly decodes a node which is not -bad.
\end{theorem}

We now show that the simulation succeeds except with an exponentially small probability.
Note that when both the \statetree and \randomtree are correctly decoded,
the user recovers the position of the other user's pebble and the move
is successful (in the notion of Lemma~\ref{lem:moves}).
However, if for a time  there is an error either in the \statetree or in the \randomtree,
the move is a bad move.


\begin{proof}\textbf{(Theorem~\ref{thm:mainB})}.
Assume that a simulation failed, which means more than  bad moves have occurred.
We fix the path traveled in both trees,
and show the probability of having this many errors is exponentially small.
Since our trees are -\potent, each path includes bad intervals of total length
at most , which can contribute
towards at most  bad moves, for both trees.

The rest of the errors have occurred in nodes which are not -bad, and for at least
one of the trees, the number of such errors is at least . Consider that specific tree.
Each such an error is associated with error interval of length , such that
the length of the union of the intervals is at least .
Using Lemma~\ref{lem:intervals}, we know there exist disjoint intervals of total length
at least  along the same path.
Each error interval of length  corresponds to an error of magnitude , and
since the transmitted node is not -bad, these errors can only be caused by channel errors.
As explained above (see proof of Theorem~\ref{thm:mainA}),
the errors which correspond to these disjoint intervals are independent,
and the probability that a fixed specific pattern of disjoint intervals
of total length  jointly occur
is at most , where  is the label error probability.

The probability
of having any error pattern of total length at least 
is given by the union bound, summing over
all possible error patterns in both tree, and over each one of the users. There are
at most  such combinations, and
the probability is bounded by , which is exponentially small for
.
\end{proof}

We now show that the decoding procedure described in Section~\ref{sec:eff} is efficient in expectation, for both the trees.
\begin{proof} \textbf{(Theorem~\ref{thm:adaptiveEff})}.
The Randomized- scheme makes a random walk\footnote{
    To be more accurate,
    it is a random walk from the root to a leaf, where the depth can only increase.}
on the \randomtree.
Following the analysis of Section~\ref{sec:eff},
we can choose a constant-size  such that
the probability of exploring at time  a subtree of depth 
is bounded by 
(when decoding a \randomtree node,
using the decoding procedure described in Section~\ref{sec:eff}).
Specifically, let
,
and require .
The expected time for decoding
the \randomtree during the simulation is given by


For a fixed protocol , each path of the \randomtree
defines a corresponding path in the \statetree. Since the \randomtree contains all
possible permutations
for the \statetree nodes, choosing a random path in the \randomtree yields a random walk on the
\statetree. In the same manner as above,
the expected time for decoding the \statetree is efficient.

Property (ii) has been proven in Section~\ref{sec:eff}, and holds for this case as well.
\end{proof}





\subsection{Simulating -Party Protocols}\label{sec:multiparty}


In this section we extend our result to support a simulation
of a protocol  with any number  of users.
This is done by incorporating the tools described in the previous sections
with the method of simulating an -party protocol over a disturbed channel
developed by Rajagopalan and Schulman~\cite{RS94}.
The paper~\cite{RS94} shows that a scheme for simulating multiparty protocol
over a disturbed channel
{\em exists},
yet the question of its efficient implementation has been open since 1994.
The Scheme presented in~\cite{RS94}
obtains a communication dilation of  where  is the maximal connectivity degree,
that is, the maximal number of parties connected to a specific user.

Rajagopalan and Schulman, in their work~\cite{RS94},
describe how to adapt the 2-party simulation of~\cite{schulman96}
to an arbitrary number of users. The key idea is to replace the 12-ary \statetree
with a ternary tree (that is, ),
where each node has three child nodes marked with .
The values  and  indicate the output bit of the user in the simulated round,
and  indicates that the last simulated round is suspected to be invalid
and should be  deleted and re-simulated.
The simulation (described here for a specific user )
is completely defined by the following process. Each round, the user uses all the previous communications to infer the current simulated round of  and sends his output bit to user  (by communicating the label assigned with arc to child   or  respectively,
in the ternary \statetree shared between users  and ).
If the user finds an inconsistency, he transmits
 which denotes deleting the last received (undeleted) bit and rolling the protocol  one step back. The user shares such a ternary tree with each of the  parties connected to him, and is allowed
to output a different bit to each party. Yet, when the user decides to roll back he outputs
 on each of the outgoing links. Inconsistency is defined as one of the two following cases:
(1) the current decoded transcript of the \statetree disagrees with the bits sent so far, or (2)
the user received  from one of his neighbors.
We refer the reader to~\cite{RS94} for a complete description and analysis of this scheme.


One can easily check that the bulk of the analysis performed in~\cite{RS94} applies
for the case of replacing the good ternary tree code with a ternary \KTC (or \RTBC).
The analysis is composed of two parts. The first part shows that if after
 rounds the scheme simulates step  of  then at least
 errors have occurred in decoding the correct tree-node during
the \emph{history cone} of the user at time  (i.e., all the transmissions
that affect the user state at time ). The other part
bounds the probability of having a constant fraction of errors (out of the number of rounds).
While the first part is completely independent of the
fact that we replace the good tree code with a \KTC,
in order to complete the proof, we must adapt the second part to the usage of \KTC. This is done by
Lemma~\ref{lem:raja} below.

Let us formally describe these two parts.
We begin by defining the notion of the history cone~\cite{RS94}.
Let  denote a user  at time .
\begin{definition}[\cite{RS94}]
 and  are \textbf{time-like} if messages sent by user  at time  has an affect on
the computation of user  at time  (or vice versa).
\end{definition}
That is,  and  are always time-like,
and  and  are time-like if  and  are neighbors.
\begin{definition}[\cite{RS94}]
A \textbf{ time-like path} is a sequence 
such that  any two elements in the path are time-like
(i.e., for every ,  and  are either neighbors or the same party).
\end{definition}

The proof of~\cite{RS94} follows from the next two lemmas
\begin{lemma}[Lemma (5.1.1) of~\cite{RS94}]\label{lem:rsOne}
If a user  at time  has successfully simulated only the first  rounds of ,
then there is a  time-like sequence that ends at  and
includes at least  tree-decoding errors.
\end{lemma}
\begin{lemma}[Lemma (5.1.2) of~\cite{RS94}]\label{lem:rsTwo}
Using error correcting codes with dilation ,
the probability that any fixed t time-like path has more than
 tree-decoding errors, is less than
.
\end{lemma}
The proof of the multiparty case is given by setting .
The first lemma states that if the simulation failed
(the first  rounds of  are not valid for some user)
then there must exist one user who has  errors along one of his  time-like sequences.
The probability of this event is bounded by the Lemma~\ref{lem:rsTwo} to be
less than  summed over
all the  possible time sequences, which is bounded by .


While the above Lemma~\ref{lem:rsOne} holds regardless of the tree in use,
we prove a variant of the above Lemma~\ref{lem:rsTwo}
for the case of using a \potent tree.
Moreover, although Lemma~\ref{lem:rsTwo} holds for any time , only  is required
for completing the proof for the multiparty case, which we prove in the following lemma.


\begin{lemma}\label{lem:raja}
Suppose each two users share a -\potent tree, for some
 . If an error correcting code with  label error probability  is used,
then for any fixed  time-like path, the probability that there are more than
 tree-decoding errors
is bounded by ,
over the errors of the channel.
\end{lemma}
\begin{proof}
We assume an oracle for the decoding process, which can easily be replaced
by the \emph{efficient decoding} procedure
given in Section~\ref{sec:eff}, if we use a \KTC.
Assume that at least  errors have occurred in a specific  time-like path.
Fix a specific user  and assume that the errors of this user
are included in error intervals of total length .
By Lemma~\ref{lem:intervals}, there exist disjoint error intervals of total length at least .
Recall that each error interval of length  corresponds to an error of magnitude ,
and recall that in each tree, at most  of the nodes are -bad.
Thus, at least  of the errors of user  in the  time-like path
occur in nodes which are not -bad.
These errors can only be originated due to channel errors\footnote{This claim also applies
    to the efficient decoding procedure, as it
    always returns the node that minimized the Hamming distance,
    if it is not -bad.
    See the proof of Theorem~\ref{thm:mainA}
    and discussion in Section~\ref{sec:eff}.},
and since the intervals are disjoint, they are independent.
As above (see proof of Theorem~\ref{thm:mainA}),
the probability of having errors that correspond to these (fixed) disjoint error intervals
is bounded by .
Clearly, tree-decoding errors of a specific user are independent
of the communication (and channel errors) of other users.
It follows that the probability for all the users to have
a total amount of 
errors matching the fixed intervals pattern is bounded by
.
With  and at most  users,
this probability is bounded by .


Using a union bound we sum the probability over any number  of errors  and
over any one of the  
different ways to distribute  errors along the fixed time-like path.
The probability that there are at least 
errors in this fixed  time-like path is bounded by

\end{proof}
\noindent For  ,
this probability is at most .
\begin{corollary}
Suppose each two users\footnote{The same tree can be used by all the users.} share a \KTC
with  for some ,
and use an error correcting code with
(label) error probability less than .
Then, except with probability  over the choice of the \KTC,
for any fixed  time-like path,
the probability that there are more than  tree-decoding errors
is less than 
over the the errors of the channel.
\end{corollary}
That is, with  the \KTC is -\potent, with
overwhelming probability, due to Proposition~\ref{prop:KTCisPotent}.
Each label in an alphabet of size  requires  bits.
Due to Lemma~\ref{lem:shannon}, we can use an error correcting code
such that each transmission is  and the label error probability is
less than the required . Specifically,
for efficient decoding we require ,
which can be done with code of length
 as well.
The above lemma replaces
Lemma 5.1.2 of~\cite{RS94}, and
leads to  the following theorem.
\begin{theorem}\label{thm:multiparty}
There exists a constructible and efficient  simulation
that computes any -party protocol  of length 
using a BSC for communication and a pre-shared \KTC.
The simulation succeeds with probability ,
and impose a dilation of .
\end{theorem}
\noindent An efficient version of the above scheme,
using the efficient decoding methods described in Section~\ref{sec:eff},
has an expected time complexity of .


\section*{Acknowledgments}
We would like to thank Leonard Schulman and Anant Sahai for many useful discussions at a very early stage of this research. We also thank Madhu Sudan, David Zuckerman, and Venkatesan Guruswami for several helpful conversations.  We would like to thank Alan Roytman for miscellaneous remarks.








\bibliographystyle{alpha}
\bibliography{coding}






\appendix
\section*{Appendix}


\section{Random Tree Codes And Their Properties}\label{app:RTBC}
In this section we analyze several of the properties of Random Tree Codes (\RTBC), and show that
a \RTBC is potent, except with high probability.

Observe that any two paths in a \RTBC have large enough Hamming distance, except for  a
negligible probability over the choice of the labels. This property makes the \RTBC a useful code.
\begin{lemma}\label{lem:prob4smallHamming}
Let  be a -ary \RTBC over ,
and let  and  be any two nodes at some common depth  in ,
with least common ancestor  at depth , then for every ,

\end{lemma}
\begin{proof}
We sum the probability for any possible Hamming distance . A direct calculation gives\\

\end{proof}\vspace{-0.5em}
Assume that  are at some depth ,
and that their least common ancestor is at depth ;
we say that  and  have a distance  in that case.
Assume that the labels  were transmitted.
If a good tree code is used, then the probability of decoding a different node, , is
exponentially small in the distance , where the probability is
over the channel errors. We denote this event as a
decoding error of \emph{magnitude} .
In the following lemma we obtain a similar
result for a random tree code,
where in this case the probability is over both the channel errors and the choice of the \RTBC.



Finally, we prove Theorem~\ref{thm:RTCisPotent} by showing that
the set of all -bad \RTBC
for constants , is exponentially small.
\begin{proposition}\label{lem:probBadRTBC}
Suppose .
The probability for a \RTBC of depth 
with alphabet 
to be -bad,
is at most 
\end{proposition}
\begin{proof}
We begin by fixing a leaf , and later we use a union bound
to bound the probability over the entire tree.
Assume that there exist bad intervals of total length at least ,
then there must exist \emph{disjoint}
bad intervals of total length at least ,
as stated by the following lemma~\cite{schulman96}.


\begin{lemma}[\cite{schulman96}]\label{lem:intervals}
Let  be intervals on , of total length .
Then there exists a set of indices  such that
the intervals indexed by  are disjoint, and their
total length is at least . That is, for any , , and
.
\end{lemma}
\noindent The proof is given in~\cite{schulman96}.


There are at most  ways to distribute these disjoint
intervals along the path from the \RTBC's root to .
Using Lemma~\ref{lem:prob4smallHamming} and a union bound
we are assured that the probability of having
(any) node  at the same depth as  which imposes a bad interval of length  is
 less than .
The probability for a specific pattern of disjoint bad intervals
to jointly occur is the multiplication of the probability for each interval to occur
(the intervals are independent since they are disjoint).
According to the above, for large enough ,
the probability for a \RTBC to be -bad is bounded by

which is exponentially small in  for .
\end{proof}

\subsection{Construction of a Pseudo-\RTBC Using Cryptographic Assumptions}


Using conventional cryptographic assumptions
and settings one can easily build a pseudo-\RTBC which can not be
distinguished from a truly random \RTBC.
In order to construct a pseudo -ary \RTBC of depth ,
we assume the existence of a
family of pseudo-random functions (PRF)~\cite{GGM86}, ,
which can be computed efficiently.
The user randomly chooses a seed 
of length ,
and labels the arc  with the label .
When a pseudo-\RTBC is used to communicate between several
users, they all share the same seed .

\begin{lemma}
Let RT be a truly random \RTBC and let PRT be a pseudo-\RTBC, then for
any  algorithm  which is polynomial in ,

\end{lemma}
\begin{proof}
Otherwise,  is a method to distinguish the
pseudo-random function  used to label the
\RTBC from a truly random function, in contradiction to it
being a pseudo-random function.
\end{proof}
A memoryless BSC channel can be considered as a (very restricted) polynomial-time algorithm.
The seed  for the PRF can be chosen by one party,
encoded using any good error-correcting code, and sent to the
other party at the start of the protocol.  Note that since all parties
are honest, and the channel is efficiently simulatable, there is no
need to hide the PRF's seed.
It follows that we can replace any use of \RTBC
with a pseudo-\RTBC, affecting the probabilities with only a negligible factor.




\section{Details of Theorem~\ref{thm:BR}}\label{app:BR}
We now prove Theorem~\ref{thm:BR}.
The proof follows the analysis of Braverman and Rao~\cite{BR10} in a straightforward way,
assuming the tree code in use is -potent (that is, ).



In~\cite{BR10} the users consider  as a binary tree . Each path in the tree describes a possible transcript of , where  odd levels describe party A's outputs and even levels describe B's outputs. The users use a good tree code to communicate the vertices of  according to their inputs.

Assume that at time  user  sends  and let  be the label received at B's side
(similarly, User B sends , etc.).
Upon receiving , user B decodes the received string  and obtains a possible transcript of , from which he can compute his next step in . This process is repeated for  times.

Let  denote a set of vertices in  described by decoding the received string. We denote with  the largest number such that the first  symbols of  are equal to  and the first  symbols of  are equal to .

Define  to be the number of transmission errors in the  interval of the simulation (for both users). In the analysis of~\cite{BR10}, a lower bound on the number of error in case that the simulation fails. We now show that using a -\potent tree, the lower bound
changes by at most .

The analysis of~\cite{BR10} begins by considering a simpler simulation in which the alphabet
size might be polynomial, and then extends the result to a constant alphabet size in a straightforward way. In order to ease the proof, we show that the theorem holds for the simple protocol with polynomial alphabet. Extending the result to the constant-alphabet protocol is immediate.

\begin{proof} (\textbf{Theorem~\ref{thm:BR}}.)
We redefine the quantity  to allow us consider possible errors caused by the tree in addition to   channel errors. Let   be the number of communication errors between rounds  and , assuming that the total length of bad intervals along the paths  and  in the potent tree, is at most .


\begin{lemma}[replacing lemma 4 of \cite{BR10}]\label{lem:4}

\end{lemma}
\begin{proof}
Without loss of generality, we assume that the  symbol in  differs from . Consider two cases. If the node  is not -bad,
then the only way to get a decoding error of magnitude  is if at least
 communication errors have happened (this is identical to~\cite{BR10}).

In the second case, the node  is -bad.
If  the lemma is trivial.
Otherwise,  must be an -bad node of maximal length at most .
 and again such a decoding error
implies at least  communication errors.
\end{proof}

The quantity  is defined by~\cite{BR10} as the smallest round  such that both users announced 
the first  edges of  within their transmisssions. The following Lemma is stated in~\cite{BR10}.
\begin{lemma}[Lemma~5 of~\cite{BR10}]\label{lem:5}
For , if , then 
\end{lemma}
\noindent The proof of this lemma is independent of the tree code in use, and thus it is valid for simulation with potent tree as well.

Last, we show the following lower bound on the number of errors.
\begin{lemma}[replacing lemma 6 of \cite{BR10}]\label{lem:6}
For , if , then 
\end{lemma}

\begin{proof}
We prove by induction. 
assuming that the total length of the imposed bad-intervals between
rounds  and  (that is, along the paths  and )
is exactly , .
Lemma~\ref{lem:4} guarantees that .
By Lemma~\ref{lem:5},  and we can use the induction hypothesis on the first part, which gives
. Summing these two bounds proves the lemma.
\end{proof}
\noindent Note that the in the case of a good tree code, , which gives exactly Lemma~6 of~\cite{BR10}. With a \potent tree,  which reduces the maximal error rate by .

In a similar way Lemma~8 of~\cite{BR10} can be adapted to potent trees, which completes the proof of Theorem~\ref{thm:BR}, by setting .

\end{proof}




\end{document}
