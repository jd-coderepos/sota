\documentclass{LMCS}

\def\dOi{11(3:8)2015}
\lmcsheading {\dOi}
{1--29}
{}
{}
{Nov.~12, 2014}
{Sep.~\phantom04, 2015}
{}

\ACMCCS{[{\bf Mathematics of computing}]: Probability and
  statistics---Stochastic processes---Markov processes;  Probability
  and statistics---Distribution functions} 

\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{dsfont}

\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{longtable}

\usepackage{epsfig}
\usepackage[usenames,dvipsnames]{pstricks}

\newcommand{\myred}[1] {{\color{red}#1}}
\newcommand{\myblue}[1] {{\color{blue}#1}}

\usepackage{xspace}
\def\eg{{\em e.g.}\xspace}
\def\cf{{\em cf.}\xspace}
\def\ie{{\em i.e.}\xspace}

\begin{document}

\title[Formal Abstractions of Continuous-Space Markov Processes]{
Quantitative Approximation of the\\ Probability Distribution
of a Markov Process\\ by Formal Abstractions\rsuper*
}

\author[S.~Esmaeil Zadeh Soudjani]{Sadegh Esmaeil Zadeh Soudjani}
\address{Department of Computer Science, University of Oxford, United Kingdom}
\email{\{Sadegh.Soudjani,Alessandro.Abate\}@cs.ox.ac.uk}

\author[A.~Abate]{Alessandro Abate}
\address{\vspace{-18 pt}}\titlecomment{{\lsuper*}This article generalises and completes the results presented
  in \cite{SA14} and specifically benefits from extensions first
  discussed in \cite{SAH12}.}
\thanks{This work has been supported by the European Commission via STREP project MoVeS 257005 and IAPP project AMBI 324432, 
and by the John Fell Oxford University Press Research Fund.}

\keywords{Continuous-Space Markov Processes, 
Discrete-time Stochastic Systems, 
Formal Abstractions, 
PCTL Verification, 
Probabilistic Invariance, 
Higher-Order Approximations}



\begin{abstract}
\label{sec:abstract}
\noindent The goal of this work is to formally abstract a Markov process evolving in discrete time over a general state space as a finite-state Markov chain, 
with the objective of precisely approximating its state probability distribution 
in time, 
which allows for its approximate, faster computation by that of the Markov chain. 
The approach is based on formal abstractions and employs an arbitrary finite partition of the state space of the Markov process, 
and the computation of average transition probabilities between partition sets.
The abstraction technique is formal, 
in that it comes with guarantees on the introduced approximation that depend on the diameters of the partitions:  
as such, they can be tuned at will.  
Further in the case of Markov processes with unbounded state spaces, 
a procedure for precisely truncating the state space within a compact set is provided, 
together with an error bound that depends on the asymptotic properties of the transition kernel of the original process. 
The overall abstraction algorithm, 
which practically hinges on piecewise constant approximations of the density functions of the Markov process, 
is extended to higher-order function approximations:  
these can lead to improved error bounds and associated lower computational requirements.     
The approach is practically tested to compute probabilistic invariance of the Markov process under study, 
and is compared to a known alternative approach from the literature. 
\end{abstract}

\maketitle

\section{Introduction}
\label{sec:intro}
Verification techniques and tools for deterministic, discrete time, finite-state systems have been available for many years \cite{Kur94}. 
Formal methods in the stochastic context are typically limited to finite-state structures, 
either in continuous or in discrete time \cite{BKH99,KNSS00}.
Stochastic processes evolving over continuous (uncountable) spaces are often related to undecidable problems (the exception being when they admit analytical solutions).
It is thus of interest to resort to formal approximation techniques that allow solving decidably corresponding problems over finite discretisations of the original models.
In order to formally relate the computable approximate solutions to the original problems,  
it is of interest to come up with explicit bounds on the error introduced by the approximations. 
The use of formal approximations techniques over complex models can be looked at from the perspective of research on abstractions, 
which are of wide use in formal verification. 

Successful numerical schemes based on Markov chain approximations of 
general stochastic systems in continuous time have been introduced in the literature \cite{KD01}.
However, the finite abstractions are only related to the original models asymptotically (at the limit, that is weakly), with no explicit error bounds. 
This approach has been applied to the approximate study of probabilistic reachability or safety of stochastic hybrid models in \cite{KR06,PH06}.
An alternative line of work on approximations of continuous-space, discrete-time Markov processes is pursued in \cite{DDP04,DGJP03}, 
where the discussed approximation scheme generates a finite-state model.
In \cite{DDP03} the idea of approximating by averaging is introduced,
where the conditional expectation is used to compute the approximation,
and is later extended in \cite{CDPP14}.
The weak point of these contributions is the fact that the approximation errors that are essential in assessing the quality of the approximation are not computed.
 
As an alternative to qualitative approximations, 
in \cite{APKL10} a technique has been introduced to provide formal abstractions of discrete-time, continuous-space Markov models \cite{APLS08}, 
with the objective of investigating their probabilistic invariance (safety) via model checking procedures over a finite Markov chain.
In view of computational scalability, the approach has been improved and optimised in \cite{SA11,SA13}, 
extended to a wider class of processes \cite{SA12,SATAC12}, and practically implemented as a software tool \cite{FAUST15}.  
These abstraction techniques hinge on piecewise-constant approximations of the kernels of the Markov process. 
Linear projection operators are employed in \cite{SAH12} to generalise these techniques via higher-order interpolations that provide improved error bounds on the approximation level.

In this work we show that the approach in \cite{APKL10,SA13} can be successfully employed to approximately compute the statistics in time of a stochastic process over a continuous state space. 
We first provide a forward recursion for the approximate computation of the state distribution in time of the Markov process. 
This computation is based on a partitioning of the state space, 
and on the abstraction of the Markov process as a finite-state Markov chain. 
Further, a higher-order approximation method is presented, as a generalisation of the approach above, 
and an upper bound on the error related to the new approximation is formally derived.
Based on the information gained from the state distribution in time, 
we show that the method can be used as an alternative to \cite{APKL10,SAH12,SA12,SA13} to approximately compute 
probabilistic invariance (safety) for discrete-time stochastic systems over general state spaces.
Probabilistic invariance (safety) is the dual problem to probabilistic reachability. 
Over deterministic models reachability and safety have been vastly studied in the literature, 
and computational algorithms and tools have been developed based on both forward and backward recursions.
Similarly, for the probabilistic models under study, 
we compare the presented approach (based on forward computations) with existing approaches in the literature \cite{APKL10,SAH12,SA12,SA13} (which hinge on backward computations), 
particularly in terms of the introduced approximation error.

The Markov chain abstraction applied to the forward/backward computation of probabilistic invariance can be generalised to other specifications expressed as non-nested PCTL formulae or to reward-based criteria characterised via value function recursions. 
Moreover, the constructed Markov chain can be shown to represent an \emph{approximate probabilistic bisimulation} of the original process \cite{A12,TA13,AKNP14}.

The article is structured as follows. 
Section~\ref{sec:prelim} introduces the model under study and discusses some structural assumptions needed for the abstraction procedure. 
The procedure comprises two separate parts:
Section~\ref{sec:trunc} describes the truncation of the dynamics of the model, 
whereas Section~\ref{sec:partition} details the abstraction of the dynamics (approximation of the transition kernel) -- 
both parts contribute to the associated approximation error. 
Section \ref{sec:approx&error} considers higher-order approximation schemes and quantifies
the introduced approximation error. Section \ref{sec:proj} specialises 
these higher-order schemes to explicit algorithms for low-dimensional models using known interpolation bases. 
Section~\ref{sec:safety} discusses the application of the procedure to the computation of probabilistic invariance, 
and compares it against an alternative approach in the literature.

\smallskip

In this article we use  to denote the natural numbers,
 and 
for any .

\section{Models, Preliminaries, and Goals of this work}
\label{sec:prelim}

We consider a discrete time Markov process  defined over a general state space, 
which is characterised by a pair ,
where  is a continuous state space that we assume endowed with a metric and be separable\footnote{A metric space  is called separable if it has a countable dense subset.}.
We denote by  the probability structure on ,
with  being the Borel -algebra\footnote{The Borel -algebra  is the smallest -algebra in  that contains all open subsets of . For a separable metric space ,  equals the -algebra generated by the open (or closed) balls of .} 
in  and  a probability measure to be characterised shortly.  
 is a stochastic kernel that assigns to each point  a probability measure , 
so that for any measurable set , 
. 
We assume that the stochastic kernel  admits a density function ,
namely .  

Given the measurable space , we set up the product space 
containing elements , where the bold typeset is used in the sequel to indicate vector quantities.
Suppose that the initial state of the Markov process  is distributed according to the density function . Then the multi-variate density function 
is a probability measure  on the product space .
On the other hand the state distribution of  at time  is characterised by a density function ,
which fully describes the statistics of the process at time  and is in particular such that, 
for all , 

where the symbol  is used to indicate the probability associated to events over the product space 
(note that the event  is equivalent to  on their corresponding probability spaces).

The state density functions  can be characterised recursively, as follows: 

In practice the forward recursion in \eqref{eq:recurs} rarely yields a closed form for .  
A special instance where this is the case is represented by a linear dynamical system perturbed by a Gaussian process noise: 
due to the closure property of Gaussian distributions over addition and multiplication by a constant,  
it is possible to explicitly write recursive formulae for the mean and the variance of the distribution, 
and thus express in a closed form the distribution in time of the solution process.  
In more general cases, it is necessary to numerically (hence, approximately) compute this density function in time.    

\medskip

This article provides a numerical approximation of the density function of  in time 
as the probability mass function (pmf) of a finite-state Markov chain .  
The Markov chain  is obtained as an abstraction of the concrete Markov process . 
The abstraction is associated with a guaranteed and tunable error bound,
and algorithmically it leverages a state-space partitioning procedure.  
The procedure is comprised of two steps: 
\begin{enumerate} 
\item 
since the state space  is generally unbounded, 
it is first properly truncated; 
\item 
subsequently,  
a partition of the truncated dynamics is introduced. 
\end{enumerate} 

Section~\ref{sec:trunc} discusses the error generated by the state-space truncation, 
whereas Section~\ref{sec:partition} describes the construction of the Markov chain by state-space partitioning.
The discussed Markov chain abstraction is based on a piecewise-constant approximation of the density functions. 
In order to improve the efficiency and the precision of the approximation, 
we generalise the abstraction method in Section~\ref{sec:approx&error} utilizing higher-order approximations of the density functions.
We employ the following example throughout the article as a running case study. 
\begin{exa}
\label{ex:linear_1d}
Consider the one-dimensional stochastic dynamical system

where the parameters , whereas , 
and  is a process comprised of independent, identically distributed random variables with a standard normal distribution. 
The initial state of the process is selected uniformly within the bounded interval . 
The solution of the model is a Markov process, 
evolving over the state space , 
and fully characterised by the conditional density function 

\end{exa}

We raise the following assumptions in order to
relate the state density function of  to the probability mass function of .
More precisely, 
these assumptions are employed for the computation of the approximation error, 
but the abstraction approach proposed in this article can be applied without raising them.
\begin{asm}
\label{ass:marg_conv}
For given sets  and ,
there exist positive constants  and , such that 
 and  satisfy the following conditions: 

\end{asm}
\begin{asm}
\label{ass:Lip_cont_bounded}
The density functions  and  are (globally) Lipschitz continuous,  
namely there exist finite constants , 
such that the following Lipschitz continuity conditions hold: 

Moreover, there exists a finite constant  such that

\end{asm}
The Lipschitz constants  are practically computed by taking partial derivatives of the density functions  and maximising their norm.
The sets  and  will be used to truncate the support of the density functions 
 and , respectively. 
Assumption~\ref{ass:marg_conv} enables the precise study of the behaviour of density functions 
over the truncated state space. 
Furthermore, 
the Lipschitz continuity conditions in Assumption~\ref{ass:Lip_cont_bounded} are essential to derive error bounds related to the abstraction of the Markov process over the truncated state space. 
In order to compute these error bounds, 
we assign the infinity norm to the space of bounded measurable functions over the state space , namely 
 
In the sequel the function  denotes the indicator function of a set , 
namely , if ; else . 

\medskip

\textbf{Example \ref{ex:linear_1d} (Continued).}
Select the interval  and define the set  by the linear inequality

The initial density function  of the process can be represented by the function 

Then Assumption~\ref{ass:marg_conv} is valid with constants  and .
The constant  in Assumption~\ref{ass:Lip_cont_bounded} is equal to .
Lipschitz continuity, as per \eqref{eq:cond_init_dens} and \eqref{eq:cond_kern},
holds for the constants  and . 
\hfill \qed

\section{State-Space Truncation Procedure}
\label{sec:trunc}

We limit the support of the density functions  to the sets  respectively, 
and recursively compute support sets , as in \eqref{eq:recur_supp}, 
that are associated to the density functions . 
Then we employ the quantities  in Assumption~\ref{ass:marg_conv} 
to compute bounds , as in \eqref{eq:trunc_error}, 
on the error incurring in disregarding the value of the density functions  outside the sets . 
Finally we truncate the original, unbounded state space to the set .  

As intuitive, the error related to the spatial truncation depends on the behaviour of the conditional density function  over the eliminated regions of the state space. 
Suppose that sets  are selected such that Assumption~\ref{ass:marg_conv} is satisfied with constants :  
then Theorem~\ref{thm:error_trunc} provides an upper bound on the error obtained from manipulating the density functions in time  exclusively over the truncated regions of the state space. 
\begin{thm}
\label{thm:bound_behaviour}
Under Assumption~\ref{ass:marg_conv}
the functions  satisfy the bound

where the quantities  are defined recursively by

whereas the support sets  are computed as 

where  denotes the projection map along the second set of coordinates\footnote{Recall that both  and  are defined over .}.
\end{thm}

\begin{rem}
Notice that if the shape of the sets  and  is computationally manageable (\eg, if these sets are polytopes),  
then it is possible to precisely implement the computation of the recursion in \eqref{eq:recur_supp} by available software tools, 
such as the MPT toolbox \cite{mpt}. 
Further, 
if for some , , then for all , . 
Similarly, we have that 
\begin{itemize}
\item if for some , , then for all , .
\item if for some , , then for all , . 
\end{itemize}  
In order to clarify the role of  in the computation of , 
we emphasize that , 
where  depends only on  and is defined by the set-valued map

Figure~\ref{fig:graph_Lambda} provides a visual illustration of the recursion in \eqref{eq:recur_supp}. \qed
\end{rem}

Let us introduce the quantity , which plays a role in the solution of \eqref{eq:trunc_error} and will be frequently used shortly:


The following theorem provides a truncation procedure, 
valid over a finite time horizon , 
which reduces the state space  to the set . 
The theorem also formally quantifies the associated truncation error. 

\begin{thm}
\label{thm:error_trunc}
Suppose that the state space of the process  has been truncated to the set . 
Let us introduce the following recursion to compute functions  as an approximation of the density functions : 

Then the introduced approximation error is
,
for all .
\end{thm}
Recapitulating,  
Theorem~\ref{thm:error_trunc} leads to the following procedure to approximate the density functions  of  over an unbounded state space : 
\begin{enumerate}
\item truncate  in such a way that  has a bounded support ; 
\item truncate the conditional density function  over
a bounded set for all , 
then quantify  as the support of the truncated density function;
\item leverage the recursion in \eqref{eq:recur_supp} to compute the support sets ; 
\item use the recursion in \eqref{eq:rec_trunc} to compute the approximate density functions  over the set .
Note that the recursion in \eqref{eq:rec_trunc} is effectively computed over the set , since  for all .  
\end{enumerate}

\noindent Note that we could as well handle the support of  over the time-varying sets , 
by adapting the recursion in \eqref{eq:rec_trunc} with  instead of .  
However, 
while employing the (larger) set  may lead to an increase in memory requirements at each stage,  
it will considerably simplify the computations of the state-space partitioning and of the Markov chain abstraction:   
indeed, employing time-varying sets  would render the partitioning procedure also time-dependent, 
and the obtained Markov chain would be time-inhomogeneous.
We therefore opt to work directly with set  in order to avoid these difficulties.  

\medskip 

\noindent\textbf{Example \ref{ex:linear_1d} (Continued).}
We easily obtain a closed form for the sets , via 

Set  is the union of intervals . 
The error of the state-space truncation over  is 

\hfill \qed

\begin{figure}
\centering
\scalebox{0.8}
{
\begin{pspicture}(-0.5,-3.6)(8,3.6)
\pspolygon[linewidth=0.0020,linecolor=white,fillstyle=vlines,hatchwidth=0.04,hatchangle=0.0,hatchcolor=green](0,-0.6)(6.5,3.8)(7.8,1.2)(0,-3.9)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(0,0.13)(7.8,0.13)
\psline[linewidth=0.04cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(3.8,-3.7)(3.8,3.7)
\rput(3.8,3.9){}
\rput(7.95,0.13){}
\psline[linewidth=0.06cm](0,-0.6)(6.5,3.8)
\psline[linewidth=0.06cm](0,-3.9)(7.8,1.2)
\rput(4.4,-1.5){}
\rput(3.15,2){}
\rput(7.7,2.63){}
\rput(3.5,-0.27){}
\psline[linewidth=0.04cm,linecolor=red,linestyle=dashed,dash=0.16cm 0.16cm](3,-1.95)(3,1.45)
\psline[linewidth=0.04cm,linecolor=red,linestyle=dashed,dash=0.16cm 0.16cm](4.7,-0.85)(4.7,2.6)
\psline[linewidth=0.04cm,linecolor=red,linestyle=dashed,dash=0.16cm 0.16cm](4.7,2.6)(1.3,2.6)
\psline[linewidth=0.04cm,linecolor=red,linestyle=dashed,dash=0.16cm 0.16cm](4.7,-1.95)(1.3,-1.95)
\psline[linewidth=0.04cm,linecolor=blue,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{<->}(1.5,-1.95)(1.5,2.6)
\rput{90.0}(1.9,-0.3){\rput(1.1914062,0.71){\textcolor{blue}{}}}
\psline[linewidth=0.04cm,linecolor=blue,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{<->}(3,0)(4.7,0)
\end{pspicture} 
}
\caption{Graphical representation of the recursion in \eqref{eq:recur_supp} for sets .}
\label{fig:graph_Lambda}
\end{figure}

The recursion in \eqref{eq:rec_trunc} indicates that the support of functions  are always contained in the set  (namely, they are equal to zero over the complement of ). 
We are thus only interested in computing these functions over the set ,  
which allows
simplifying the recursion in \eqref{eq:rec_trunc} as follows:  


\section{Markov Chain abstraction via State-Space Partitioning}
\label{sec:partition}
In this section we assume that sets  have been properly selected so that  is bounded.
In order to formally abstract process  as a finite Markov chain  and to approximate its state density functions,
we select a finite partition of the bounded set  as , 
where sets  have non-trivial measure.   
We then complete the partition over the whole state space  
by additionally including set .  
This results in a finite Markov chain  with  discrete abstract states in the set , 
and characterised by the transition probability matrix ,
where the probability of jumping from any pair of states  to  () is computed as 

for all , 
and where  is the Kronecker delta function (the abstract state  of  is absorbing), 
and  denotes the Lebesgue measure of a set (i.e., its volume).    
The quantities in \eqref{eq:trans_elem} are well-defined since the set  is bounded and the measures , 
are finite and non-trivial. 
Notice that matrix  for the Markov chain  is stochastic, namely

The initial distribution of  is the pmf , 
and it is obtained from  as
.
Then the pmf associated to the state distribution of  at time  can be computed as .

It is intuitive that the discrete pmf  of the Markov chain  approximates the continuous density function  of the Markov process . 
In the rest of the section we show how to formalise this relationship: 
 is used to construct an approximate function, denoted by , 
of the density . 
Theorem~\ref{thm:Error} shows that  is a piecewise constant approximation 
(with values in its codomain that are the entries of the pmf , normalised by the Lebesgue measure of the associated partition set) 
of the original density function . 
Moreover, 
under the continuity assumption in \eqref{eq:cond_kern} (ref. Lemma~\ref{lmm:lip_cont}) we can establish the Lipschitz continuity of , 
which enables the quantification (in Theorem~\ref{thm:Error}) of the error related to its piecewise constant approximation .    

\begin{lem}
\label{lmm:lip_cont}
Suppose that the inequality in \eqref{eq:cond_kern} holds. 
Then the state density functions  are globally Lipschitz continuous with constant  for all : 

\end{lem}
\begin{thm}
\label{thm:Error}
Under Assumptions~\ref{ass:marg_conv} and \ref{ass:Lip_cont_bounded}, 
the functions  can be approximated by piecewise constant functions , defined as

where  is the indicator function of a set .
The approximation error is upper-bounded by the quantity

where  can be recursively computed as 

and  is an upper bound on the diameters of the partition sets , namely
.
\end{thm}
Note that the functions  are defined over the whole state space , 
but \eqref{eq:approx_marg} implies that they are equal to zero outside the set .
\begin{cor}
The recursion in \eqref{eq:part_error_rec} admits the explicit solution 

where  is introduced in \eqref{eq:kappa}.  
\end{cor}

Underlying Theorem~\ref{thm:Error} is the fact that  are in general sub-stochastic density functions:  
 
This is clearly due to the fact that we are operating on the dynamics of  truncated over the set .  
It is thus intuitive that the approximation procedure and the derived error bounds are also valid for the case of sub-stochastic density functions \cite{AKNP14}, 
namely 

the only difference being that the obtained Markov chain  is as well sub-stochastic.  
 
Further, 
whenever the Lipschitz continuity requirement on the initial density function, as per \eqref{eq:cond_init_dens} in Assumption~\ref{ass:Lip_cont_bounded}, does not hold, 
(for instance, this is the case when the initial state of the process is deterministic)
we can relax this continuity assumption on the initial distribution of the process by starting the discrete computation from the time step . 
In this case we define the pmf ,
where

and derive  for all . 
Theorem~\ref{thm:Error} follows along similar lines, 
except for equation \eqref{eq:part_error_rec}, where the initial error is set to  
and the time-dependent terms  can be derived as 
.

It is important to emphasise the practical computability of the derived errors, 
and the fact that they can be tuned by selecting a finer partition of set  that relates to a smaller global parameter . 
Further,
in order to attain abstractions that are practically useful, it imperative to seek improvements on the derived error bounds: 
in particular, the approximation errors can be computed locally (under corresponding local Lipschitz continuity assumptions), 
following the procedures discussed in \cite{SA13}.

\medskip

\noindent\textbf{Example \ref{ex:linear_1d} (Continued).}
The error of the Markov chain abstraction can be expressed as

The error can be tuned in two distinct ways: 
\begin{enumerate}
\item 
by selecting larger values for , 
which on the one hand leads to a less narrow truncation, 
but on the other requires the partition of a larger interval;  
\item 
by reducing partitions diameter , which of course results in a larger cardinality of the partition sets.   
\end{enumerate}
Let us select values , and time horizon . 
For  we need to partition the interval , 
which results in the error  for all .
For  we need to partition the smaller interval
, 
which results in the error  for all . 
Notice that in the case of , 
we partition a larger interval and obtain a smaller error, 
while for  we partition a smaller interval with correspondingly a larger error. 
It is obvious that the parameters  can be chosen properly to ensure that a certain error precision is met.
This simple model admits a solution in closed form, 
and its state density functions can be obtained as the convolution of a uniform distribution (the contribution of initial state) and a zero-mean Gaussian distribution with time-dependent variance (the contributions of the process noise). 
This leads to the plots in Figure~\ref{fig:1d_density}, 
which display the original and the approximated state density functions for the set of parameters . 
\hfill \qed
\begin{figure}
\centering
\includegraphics[scale = 0.5]{density_a12}
\includegraphics[scale = 0.5]{density_a08}
\caption{Piecewise constant approximation  of the state density function  (derived analytically), 
for parameters  (left) and  (right).} 
\label{fig:1d_density}
\end{figure}

\section{Higher-Order Approximation Schemes}
\label{sec:approx&error}
In the previous section we have shown that a Markov chain abstraction can be employed to formally approximate the density function of a Markov process in time. 
This abstraction is interpreted as a piecewise-constant approximation of the density function of the Markov model. 
In this section we argue that this procedure can be extended to approximation techniques based on higher-order interpolations. 

With focus on the truncated region of the state space, 
let us denote with  the space of bounded and measurable functions ,
equipped with the infinity norm
, 
for all . 
The linear operator , defined over  by 

characterises the solution of the recursion in \eqref{eq:recursive_RA2} as
, for any .
While in Section~\ref{sec:partition} we have proposed approximations of functions  by piecewise-constant 
functions  with an explicit quantification of the associated error, 
in this section we are interested in considering approximations via higher-order interpolations.

\subsection{Quantification of the Error of a Projection Over a Function Space}

Consider a set of basis functions , ,
the function space  generated by this set as a subset of , 
and a linear operator , 
which projects any function  onto the function space .
Theorem~\ref{thm:error_dynamic} provides a theoretical result for approximating the solution of \eqref{eq:recursive_RA2}: 
the following section provides details on turning this result into a useful tool for approximations.
\begin{thm}\label{thm:error_dynamic}
Assume that a linear projection operator  satisfies the inequality

and that there exists a finite constant , 
such that

Define the functions  as approximations of  (cf. \,\eqref{eq:operator}), by

Then it holds that 

where the error  satisfies the difference equation

\end{thm}
\begin{cor}
\label{thm:dir_error}
Under the assumptions raised in \eqref{eq:Gener_opr}-\eqref{eq:constant_M}, 
the error  can be alternatively expressed explicitly as .
\end{cor}
The error  formulated in Theorem \ref{thm:error_dynamic} is comparable with the quantity  computed in Theorem \ref{thm:Error}. 
Both  represent bounds on the approximation error introduced by , 
the density function obtained after state space truncation. 
The difference is in the initialisation of the corresponding recursions, 
where we have  because , 
but  since  is a piecewise constant approximation of  in \eqref{eq:approx_marg}. 
As we mentioned before, the quantities in \eqref{eq:relax_cont} can be alternatively employed as the starting values of the computation to relax the continuity assumption on , which results in an initial error , thus providing a complete similarity between  and .

\subsection{Construction of the Projection Operator}

In the ensuing sections we focus, for the sake of simplicity, on a Euclidean domain,   
namely , 
where  denotes a finite dimension.
We discuss a general form for an interpolation operator related to the discussed projection operation. 
Let  be independent functions 
defined over a generic set . 
The interpolation operator  is defined
as a projection map onto the function space , 
which projects any function 
to a unique function ,
using a finite set of data  and 
such that .  
The projection coefficients  satisfy the linear equation ,
where  and  are --dimensional column vectors, 
and  is the associated --dimensional interpolation matrix.

\medskip

Let us now shift the focus to the recursion in \eqref{eq:recursive_RA2} discussed in the previous section and tailor the operators above accordingly. 
Let us select a partition  for the set , 
with finite cardinality . 
Selecting a basis  for each partition, 
let us introduce the interpolation operators  
for the projection over each partition set ,  
which is done as described above by replacing the domain  with . 
Finally, let us introduce the (global) linear operator , 
acting on a function  by 

where  represents the restriction of the domain of function  to the partition set .

\subsection{Approximation Algorithm}
An advantage of the interpolation operator in \eqref{eq:operator_partition} is that  
is fully characterised by the interpolation coefficients , since 
 
The set of interpolation coefficients  is computable by matrix multiplication 
based on the data set .
More precisely, we have  with the interpolation matrices .
These matrices depend solely on the interpolation points  and on the basis functions  evaluated at these points 
and can be computed off-line (see step~\ref{alg:comp} in Algorithm~\ref{algo:app_val}, to be discussed shortly).
Moreover, values of the function  only at the interpolation points  are sufficient for the computation of . 

Let us now focus on the recursion in \eqref{eq:dis_val_fun}, 
namely , 
given the initialisation , 
for the approximate computation of the value functions. 
This recursion indicates that the approximate functions  belong to the image of the operator , 
and as such can be expressed as 

where  denote the interpolation coefficients referring to function  (at step ).  
This suggests that we need to store and update the coefficients  for each iteration in \eqref{eq:dis_val_fun}.   
Writing the recursion in the form  indicates that the function  is in the range of the projection .
Therefore, it is sufficient to evaluate the function  over the interpolation points in order to compute the coefficients .  
In the following expressions, 
the pair  indicates the indices of related partition sets, 
namely ,
whereas the pair of indices  show the ordering positions within partition sets. 
For an arbitrary interpolation point  we have:

Introducing the following quantities

we can succinctly express 

Algorithm~\ref{algo:app_val} provides a general procedure for the discrete computation of the interpolation coefficients and of the approximate value functions.
\begin{algorithm}
\caption{Approximate computation of the functions }
\label{algo:app_val}
\begin{center}
\begin{algorithmic}[1]
\REQUIRE 
Density function , 
set  
\STATE
Select a finite -dimensional partition of the set 
( are non-overlapping)
\STATE
For each , select interpolation basis functions 
and points , where 
\STATE \label{alg:marginals}
Compute , where  and 
\STATE \label{alg:comp}
Compute a matrix representation for the operators , namely 
\STATE \label{alg:init_marginals}
 Set  and , for all 
\IF{}
\STATE \label{alg:comp_1} 
Compute interpolation coefficients  based on equation
,
given  and matrices  in step~\ref{alg:comp}
\STATE \label{alg:comp_2}
Compute values  as , for all 
\STATE

\ENDIF
\ENSURE
Approximate functions 
\end{algorithmic}
\end{center}
\end{algorithm}

It is possible to simplify Algorithm~\ref{algo:app_val} when the interpolation matrices  are nonsingular.
Let us transform the basis  to its equivalent basis using matrix . The interpolation matrices corresponding to the new basis will be the identity matrix. In other words, the new basis functions admit  and thus
step~\ref{alg:comp} can be skipped, 
and that the main update (steps~\ref{alg:comp_1} and \ref{alg:comp_2}) can be simplified as follows: 


In Algorithm~\ref{algo:app_val}, 
the interpolation points  are in general pair-wise distinct. 
By extending the domain of interpolation  to its closure , 
it is legitimate to use boundary points as interpolation points, 
which can lead to a reduction of the number of integrations required in Algorithm~\ref{algo:app_val}.
In the ensuing sections, we will exploit this feature by specifically selecting equally spaced interpolation points.

\section{Special Forms of the Projection Operator} 
\label{sec:proj}

In this section we leverage known interpolation theorems for the construction of the projection operator : 
this should both yield useful schemes for a number of standard models, 
and further help with the understanding of the details discussed in the previous section.

\subsection{Piecewise Constant Approximations}
\label{subsec:PWC}

We focus on the special case of the approximation of a function by a piecewise constant one, 
which has inspired Section~\ref{sec:partition}.
Let us select the basis functions  for all  -- 
the cardinality of these sets of basis functions is simply equal to   
(we eliminate the corresponding indices when appropriate).  
In this case the matrix operators  (\cf step~\ref{alg:comp} in Algorithm~\ref{algo:app_val}) correspond to the identity matrix, 
and the projection operator  becomes 

where the quantities  (\cf step~\ref{alg:marginals} in Algorithm~\ref{algo:app_val}) form a square matrix 
(see step~\ref{alg:marginals_1} in Algorithm~\ref{algo:app_val_abs}).   
The procedure is detailed in Algorithm~\ref{algo:app_val_abs},
while the associated error is formally quantified in Theorem~\ref{thm:zero_abs}.
\begin{algorithm}
\caption{Piecewise constant computation of the functions }  
\label{algo:app_val_abs}
\begin{center}
\begin{algorithmic}[1]
\REQUIRE 
Density function , set 
\STATE
Select a finite -dimensional partition of the set 
( are non-overlapping)
\STATE
For each , select one representative point 
\STATE \label{alg:marginals_1}
Compute matrix  with entries , where 
\STATE Set  and , for all 
\IF{}
\STATE
Compute the row vector  based on 
\STATE

\ENDIF
\ENSURE
Approximate functions 
\end{algorithmic}
\end{center}
\end{algorithm}

\begin{thm}
\label{thm:zero_abs} 
Suppose the density function  satisfies the Lipschitz continuity assumption \eqref{eq:cond_kern} with constant . Then the projection operator \eqref{eq:proj_piecewise_constant} satisfies the inequality 

where  is the partition diameter of ,
with .
Theorem~\ref{thm:error_dynamic} ensures that the approximation error of Algorithm~\ref{algo:app_val_abs} is upper bounded by the quantity

with the constant  defined in Assumption~\ref{ass:Lip_cont_bounded}. 
\end{thm}
Notice that the error  of Theorem~\ref{thm:zero_abs} reduces to  in Theorem~\ref{thm:Error} when employing the quantities in \eqref{eq:relax_cont} to relax the continuity assumption on . 

Let us compare Algorithms~\ref{algo:app_val} and \ref{algo:app_val_abs} in terms of their computational complexity. 
Algorithm~\ref{algo:app_val} requires  integrations in the marginalisation steps (\ref{alg:marginals} and \ref{alg:init_marginals}),
whereas  integrations are required in Algorithm~\ref{algo:app_val_abs}.  
Furthermore, steps~\ref{alg:comp} and \ref{alg:comp_1} in Algorithm~\ref{algo:app_val} can be skipped by using proper equivalent basis functions, 
whereas these steps are not needed at all in Algorithm~\ref{algo:app_val_abs}. 
As a bottom line, 
higher interpolation orders increase the computational complexity of the approximation procedure, 
however this can as well lead to a lower global approximation error.   
From a different perspective, since the global approximation error depends on the local partitioning sets (their diameter and the local continuity of the density function), 
for a given error higher interpolation procedures may require less partitions sets.

As a final note, comparing the transition probabilities of \eqref{eq:trans_elem} with quantities  in step~\ref{alg:marginals_1} of Algorithm~\ref{algo:app_val_abs} reveals that the Markov chain abstraction presented in Section~\ref{sec:partition} is a special case of Algorithm~\ref{algo:app_val_abs}.
More precisely, the \emph{mean value theorem} for integration ensures the existence of representative points  such that   of Algorithm~\ref{algo:app_val_abs} is equal to  in \eqref{eq:trans_elem}.

\subsection{Higher-order Approximations for One-Dimensional Systems}

We study higher-order interpolations over the real axis, 
where the partition sets  are real-valued intervals. 
We use this simple setting to quantify the error related to the approximate computation of the functions .
We select equally spaced points as the interpolation points and employ polynomial basis functions within each interval.

Consider a one dimensional Markov process, , with a partitioning of  which is such that . 
Define the interpolation operator  of \eqref{eq:operator_partition} over the polynomial basis functions ,  (or their equivalent Lagrange polynomials \cite{Mastroianni:2008:IPB:1502750})
using equally spaced interpolation points 

The following result can be adapted from \cite{Mastroianni:2008:IPB:1502750}. 
\begin{thm}
\label{thm:high_1d}
Assume that the density function  is -times differentiable and define the constant 

The interpolation operator , constructed with polynomial basis functions and equally spaced interpolation points, satisfies the inequality

where , 
with 
and where  is the cardinality of the set of basis functions.
\end{thm}
Theorem~\ref{thm:high_1d} provides the necessary ingredients for Theorem~\ref{thm:error_dynamic}, 
leading to the quantification of the approximation error: 
employing Algorithm~\ref{algo:app_val} with equally spaced points and
polynomial basis functions of degree less than ,
the approximation error is upper bounded by the quantity

with the constant  defined in \eqref{eq:constant_M} and computed for this particular choice of basis functions and points.

It is worth highlighting that, 
unlike the piecewise constant case of Section~\ref{sec:partition}, 
with higher-order approximation approaches the global error is a nonlinear function of the partition size , 
namely it depends on a power of the partition size contingent on the order of the selected interpolation operator. 
As such, its convergence speed, as  is decreased, increases over that of the piecewise constant case. 

\medskip

\noindent\textbf{Example \ref{ex:linear_1d} (Continued).} 
We partition the set  for the one dimensional system of Example \ref{ex:linear_1d} with the intervals .
We select interpolation points  with polynomial basis functions , 
leading to piecewise affine approximations (namely, first-order interpolation with ) of the density functions . 
This set of basis functions can be equivalently transformed to 

to obtain . 
The constant  has the same value as  and the quantity  in Theorem \ref{thm:high_1d} is . The error related to this first-order approximation can be upper bounded as

Notice that the first part of the error in \eqref{eq:error_example_2}, 
which specifically relates to the first-order approximation,  
is proportional to  -- this improves the error bound computed in \eqref{eq:error_example_1}.
Algorithm \ref{algo:app_val} is implemented for this linear system with the aforementioned parameters
 and the time horizon . 
The errors corresponding to the values  and  are analytically upper-bounded, 
for any , as 

and as ,
respectively.  
The plots in Figure \ref{fig:higher_order_density} display the first- and zero-order approximations of the density function  and compare it with the analytic solution for two different values  (left) and  (right). 
The partition size  and parameter  have been selected in order to illustrate the differences of the two approximation methods in Figure \ref{fig:higher_order_density},
but may be increased at will in order to decrease the related error bound to match a desired value. 

\begin{figure}
\centering
\includegraphics[scale = 0.5]{higher_order_12}
\includegraphics[scale = 0.5]{higher_order_08}
\caption{Comparison of the first-order (affine) approximation  
versus the Markov chain abstraction (zero-order approximation, constant)  of the state density function  (derived analytically), 
for  and parameters  (left) and  (right).} 
\label{fig:higher_order_density}
\end{figure}

\subsection{Bilinear Interpolation for Two-Dimensional Systems}

We directly tailor the results of Section \ref{sec:approx&error} to a general two-dimensional Markov process, 
where . 
Assume that set  is replaced by a superset that is comprised of a finite union of rectangles: 
this replacement does not violate the bound on the truncation error formulated in Section \ref{sec:trunc}.   
Consider a uniform partition (using squared partition sets of size ) for the set .  
We employ a bilinear interpolation within each partition set

with basis

(or their equivalent Lagrange polynomials \cite{SAH12}).
Assume that the density function  is partially differentiable and define the following bounds on its derivatives

The operator  in \eqref{eq:operator_partition}, 
constructed with bilinear interpolation within each partition set, 
satisfies the inequality

where , 
with 
We implement Algorithm~\ref{algo:app_val} for two-dimensional processes using bilinear interpolation: 
the approximation error is upper-bounded by the quantity

with the constant  defined in \eqref{eq:constant_M} and computed for this particular choice of basis functions and points.
It can be proved that for bilinear interpolation basis functions,
the constant  of \eqref{eq:constant_M} is upper bounded by  of Assumption \ref{ass:Lip_cont_bounded}, and thus can be replaced by this quantity in the error computation.

\subsection{Trilinear Interpolation for Three-Dimensional Systems}

We now apply the results of Section \ref{sec:approx&error} to a general three-dimensional Markov process, 
where  
Again we replace the set  by a superset that is comprised of a finite union of boxes, 
without violating the bound on the truncation error formulated in Section \ref{sec:trunc}. 
Consider a uniform partition (using cubic sets of size ) for the set .  
We employ a trilinear interpolation within each partition set with basis functions

Assume that the density function  is partially differentiable and define the following bounds on its derivatives

We implement Algorithm~\ref{algo:app_val} for three-dimensional processes using trilinear interpolation in the operator  \eqref{eq:operator_partition}.
The approximation error is then upper bounded by the quantity

with the constant

Similar to the bilinear interpolation case, the constant 
can be replaced by  of Assumption \ref{ass:Lip_cont_bounded} in the error computation.

\section{Application of the Formal Approximation Procedure\\ to the Probabilistic Invariance Problem}
\label{sec:safety}
The problem of probabilistic invariance (or, equivalently, safety) for general Markov processes has been theoretically characterised in \cite{APLS08}  
and further investigated computationally in \cite{APKL10,SA11,SAH12,SA12}. 
With reference to a discrete-time Markov process  over a continuous state space , 
and to a safe set , 
the goal is to quantify the probability

More generally, it is of interest to quantify the probability , 
where the initial condition of the process  is a random variable characterised by the density function .
In Section~\ref{subsec:safety_forward} we present a forward computation of probabilistic invariance by application of the approximation procedure above,  
then review results on backward computation \cite{APKL10,SA11,SAH12,SA12} in Section~\ref{subsec:safety_backward}. 
We conclude in Section~\ref{subsec:compare} with a comparison of the two approaches. 

\subsection{Forward Computation of Probabilistic Invariance}
\label{subsec:safety_forward}
The technique for approximating the density function of a process in time can be easily employed for the approximate computation of probabilistic invariance.
Define
functions , 
characterised as 

Then the solution of the problem is obtained as .
A comparison of the recursions in \eqref{eq:frwd_recursion} and in \eqref{eq:rec_trunc} reveals how probabilistic invariance can be computed as a special case of the general approximation procedure in this work.
In applying the procedure, 
the only difference consists in replacing set  by the safe set , 
and in restricting Assumption~\ref{ass:Lip_cont_bounded} to hold over the safe set -- the solution over the complement of this set is trivially known, 
as such the error related to the truncation of the state space can be disregarded.  
The procedure consists in partitioning the safe set, 
in constructing the Markov chain  as per \eqref{eq:trans_elem}, 
and in computing  as an approximation of  based on \eqref{eq:approx_marg}. 
The error of this approximation is , which results in the following:

Note that the sub-density functions satisfy the inequalities


\subsection{Backward Computation of Probabilistic Invariance}
\label{subsec:safety_backward}

The contributions in \cite{APKL10,SA11,SAH12,SA12} have characterised specifications in PCTL with an alternative formulation based on backward recursions.  
In particular, the computation of probabilistic invariance can be obtained via the value functions , 
which are characterised as 

The desired probabilistic invariance is expressed as 

The value functions always map the state space to the interval  and they are non-increasing, 
namely  for any fixed .  
The contributions in \cite{APKL10,SA11,SAH12,SA12} discuss efficient algorithms for the approximate computation of the quantity ,   
relying on different assumptions on the model under study. 
The easiest and most straightforward procedure is based on the following assumption \cite{APKL10}. 
\begin{asm}
\label{ass:back_cond_kernel}
The conditional density function of the process is globally Lipschitz continuous with respect to the conditional state within the safe set.   
Namely, there exists a finite constant , such that

A finite constant  is introduced as 
.
\end{asm}

The procedure introduces a partition of the safe set  and extends it to , 
with .
Then it selects arbitrary representative points 
and constructs a finite-state Markov chain  over the finite state space , 
endowed with transition probabilities

for all . The error of such an approximation is \cite{SAH12}:
 
where  is the max partitions diameter, 
and  is the Lebesgue measure of set . 

\subsection{Comparison of the Two Approaches}
\label{subsec:compare}

We first compare the two constructed Markov chains.
The Markov chain  obtained with the abstraction from the forward approach is a special case of the Markov chain  from the backward approach: in the latter case in fact the representative points can be selected intelligently to determine the average probability of jumping from one partition set to another. 
More specifically, the quantities \eqref{eq:trans_elem} are a special case of those in \eqref{eq:trans_elem_rep} (based on the mean value theorem for integration).
We will show that this leads to a less conservative (smaller) error bound for the approximation. 

The forward computation is in general more informative than the backward computation since it provides not only the solution of the safety problem in time, but also the state distribution over the safe set.
Further the forward approach may provide some insight to the solution of the infinite-horizon safety problem \cite{ta2011,TA14} for a given initial distribution. 
As discussed in \cite{TA14},
solution of the infinite-horizon safety problem depends on the existence of absorbing subsets of the safe set. 
The outcome of the forward approach can provide evidence on the non existence of such subsets.
Finally, the forward approach presented in Sections \ref{sec:trunc}-\ref{sec:proj} for approximating density functions can be used to approximate the value functions in the recursion \eqref{eq:frwd_recursion} over \emph{unbounded} safe sets since we do not require the state space (thus also the safe set) to be bounded, 
while boundedness of the safe set is required in all the results in the literature that are based on backward computations. 

Next, we compare errors and related assumptions. 
The error computations
rely on two different assumptions: 
the Lipschitz continuity of the conditional density function with respect to the current state or to the next state, respectively.  
Further, 
the constants  and  are generally different and play an important role in the form of the error. 
 represents the maximum probability of remaining within a given set, 
while  is an indication of the maximum concentration of the process evolution towards one state, over a single time-step. 
 is always less than or equal to one, while  could be any finite positive number.

\medskip

\noindent\textbf{\textbf{Example \ref{ex:linear_1d} (Continued).}}
The constants  and  for the one dimensional dynamical system of Example \ref{ex:linear_1d} are

If , 
the system trajectories converge to an equilibrium point (in expected value). 
In this case the model solution has higher chances of ending up in a neighbourhood of the equilibrium in time, 
and the backward recursion provides a better error bound. 
If , 
the system trajectories tend to diverge with time. 
In this case the forward recursion provides a much better error bound, 
compared to the backward recursion. 

For the numerical simulation we select a safety set , 
a noise level , 
and a time horizon . 
The solution of the safety problem for the two cases  and  is plotted in Figure~\ref{fig:1d_example}.
We have computed constants  (in both cases), 
while  for the first case  
and  for the second case. 
We have selected the center of the partition sets (distributed uniformly over the set ) as representative points for the Markov chain .
In order to compare the two approaches, we have assumed the same computational effort (related to the same partition size of ),
and have obtained an error  for  and  for .
The simulations show that the forward approach works better for , 
while the backward approach is better suitable for .
Note that the approximate solutions provided by the two approaches are very close: 
the difference of the transition probabilities computed via the Markov chains  are in the order of , 
and the difference in the approximate solutions (black curve in Figure~\ref{fig:1d_example}) is in the order of . 
This has been due to the selection of very fine partition sets that have resulted in small abstraction errors. \hfill\qed
\begin{figure}
\centering
\includegraphics[scale = 0.5]{a12_errorbar}
\includegraphics[scale = 0.5]{a08_errorbar}
\caption{Approximate solution of the probabilistic invariance problem (thin black line), 
together with error intervals of forward (\textcolor{blue}{blue} band) and backward (\textcolor{red}{red} band) approaches, for  (left) and  (right).}
\label{fig:1d_example}
\end{figure}

\begin{rem}
Over deterministic models,
\cite{IM07HSCC} compares forward and backward reachability analysis and provides insights on their differences:
the claim is that for systems with significant contraction, forward reachability is more effective than backward reachability because of numerical stability issues.
On the other hand, 
for the probabilistic models under study, 
the result indicates that under Lipschitz continuity of the transition kernel the backward approach is more effective in systems with convergence in the state distribution. 
If we treat deterministic systems as special (limiting) instances of stochastic systems, 
our result is not contradicting with \cite{IM07HSCC} since the Lipschitz continuity assumption on the transition kernels of probabilistic models does not hold over deterministic ones. \hfill\qed
\end{rem}
Motivated by the previous example, 
we study how the convergence properties of a Markov process are related to the constant .
 
\begin{thm}
\label{thm:exp_conv}
Assume that the initial density function  is bounded and that
the constant  is finite and . 
If the state space is unbounded, the sequence of density functions  uniformly exponentially converges to zero. 
The sequence of probabilities  and the corresponding solution of the safety problem for any compact safe set  exponentially converge to zero. 
\end{thm}
Theorem~\ref{thm:exp_conv} indicates that under the invoked assumptions the probability ``spreads out'' over the unbounded state space as time progresses.  
Moreover, the theorem ensures the absence of absorbing sets \cite{ta2011,TA14}, 
which are indeed known to characterise the solution of infinite-horizon properties.
Example~\ref{ex:linear_stab} studies the relationship between constant  and the stability of linear stochastic difference equations.
\begin{exa}
\label{ex:linear_stab}
Consider the stochastic linear difference equations

where  are i.i.d. random vectors with known distributions.
For such systems , then the condition  implies instability of the system in expected value.
Equivalently, mean-stability of the system implies . 
Note that for this class of systems  does not generally imply stability, since  is only the product of the eigenvalues of the system. \hfill\qed
\end{exa}
The Lipschitz constants  and  have a different nature, as clarified in Example~\ref{ex:non_linear}. 
\begin{exa}
\label{ex:non_linear}
Consider the dynamical system 

where  are i.i.d. with known distribution . 
Suppose that the vector field  is continuously differentiable and that the matrix  is invertible. 
Then the \emph{implicit function theorem} guarantees the existence and uniqueness of a function  such that . 
The conditional density function of the system in this case is \cite{Papoulis91}:

The Lipschitz constants  are specified by the dependence of function  from the variables , respectively.
As a special case the invertibility of  is guaranteed for systems with additive process noise, namely
. Then ,
 is the Lipschitz constant of ,
while  is the multiplication of the Lipschitz constant of  and of . \hfill\qed
\end{exa}

\section{Conclusions} 
\label{sec:concl}

This contribution has put forward new algorithms, 
based on Markov chain abstractions, 
for the efficient computation of approximate solutions of the state distribution function in time of Markov processes evolving over continuous state spaces. 
A higher-order function approximation method has also been presented, with a formal derivation of an upper bound on the associated error.  
The approach has been applied to the verification of a particular non-nested PCTL formula (expressing probabilistic safety or invariance), 
and compared with an alternative computational approach from the literature.

The authors plan to integrate the presented procedures within the software tool \textsf{FAUST}, 
which is developed for the formal abstraction and verification of uncountable-state stochastic processes \cite{FAUST15}. 
The software enables the user to automatically export the finite-state abstracted model to existing probabilistic model checking tools,  
such as PRISM and MRMC \cite{HKNP06,KKZ05}, for further quantitative analysis, verification, and synthesis objectives.
  

\bibliographystyle{plain}
\bibliography{biblio}

\vspace{2cm}\appendix
\section{Proof of Statements}
\begin{proof}[Proof of Theorem \ref{thm:bound_behaviour}]
We prove the theorem inductively.
The statement is trivial for  based on Assumption \ref{ass:marg_conv}.
Suppose it is true for , then we prove it for .
Take , then

The first integral is upper bounded by .
The domain of the second integral implies that . Combining this with the definition \eqref{eq:recur_supp} of  and  results in . Then 

Then we obtain , 
for all .
\end{proof}

\proof[Proof of Theorem \ref{thm:error_trunc}]
The initial density function  satisfies the following inequality:

Suppose  satisfies the inequality. We prove that it is also true for .
Take any ,

Take any , we have


\proof[Proof of Lemma \ref{lmm:lip_cont}] 
For any  and ,



\begin{proof}[Proof of Theorem \ref{thm:Error}]
We use the triangle inequality as 

Define the set of Lebesgue integrable functions  and its subset :

and the operators

Then  is formulated as times application of the operator  to the initial function ,

Define functions  by the recursive equation:

initialised with .
Notice that the functions  are all piecewise constant due to their recursive definition. We restrict our attention to the set  since the supports of both functions  are included in . 
The goal is to
prove that  satisfies \eqref{eq:approx_marg} and .
We achieve this goal using induction. The initial function  is of the form

Suppose the statement is true for . Then for any , ,

We have proved \eqref{eq:approx_marg}.
The approximation error for  is computed using \eqref{eq:cond_init_dens} in Assumption \ref{ass:Lip_cont_bounded}. Take any state , :

For  we can write

The error has two terms. The first term is upper bounded as follows

Let us focus on the second term: 
for any arbitrary state , , we have 

The summation of the two upper bounds leads to that in \eqref{eq:part_error_rec}.
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:error_dynamic}]
The definition of  implies that , 
with . 
Then \eqref{eq:Main_inequality} is true for  with . 
Assume that ; 
then for any , 

The first term can be upper bounded based on the linearity of the operator  as 

On the other hand, the second term is upper bounded as follows: 

The addition of the two bounds leads to the statement. 
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:exp_conv}]
Based on the recursion over the density functions, we have that 

Then  converges to zero uniformly exponentially, with a rate . 
With focus on the safety problem we have , where

Note that if 

then the state-space cannot be bounded under the assumptions. 
\end{proof}


\newpage
\section{List of Symbols}
\begin{longtable}{lp{10.5cm}}
& the set of natural numbers\\
& the finite set of natural numbers\\
& the finite set of non-negative numbers\\
 &  discrete-time Markov process\\
 & state space of the Markov process\\
 & Borel -algebra on the space \\
 & stochastic kernel\\
 & probability measure on  for one-step transition of the process\\
& conditional density function of the process\\
& density function of the initial state\\
& density function of \\
& probability measure on the product space \\
& bold typeset is employed for vectors\\
& Markov chain for forward computation of the density function\\
& parameters of the example\\
& process noise\\
& support of the initial density function  in the example\\
& Gaussian density function with zero mean and standard deviation \\
& sets used in the truncation procedure\\
 & threshold on truncation part of :  for all \\
 & threshold on truncation part of :  for all \\
 & threshold on truncation part of : 
 for all \\
& Lipschitz constants of \\
& Lipschitz constants of  with respect to \\ 
 & upper bound for the quantities \\
 & infinity norm\\
 & indicator function of set \\
 & support set of  obtained via a recursive procedure\\
 & truncated state space\\
 & set-valued map \\
 & constant equal to  for  and to  for \\
 & approximate density function after state space truncation\\
 & support set of  in the example\\
 & selected partition\\
 & partition size\\
 & partition diameter\\
 & partition set associated with absorbing state of Markov chain\\
 & transition probability matrix of the Markov chain\\
 & Kronecker delta function, equal to one for  and zero otherwise\\
 & Lebesgue measure of a set\\
 & pmf of a Markov chain at \\
 & pmf of a Markov chain at time \\
 & approximation of the density function  after abstraction\\
 & abstraction error related to partitioning\\
 &  space of bounded and measurable functions on \\
 & space of bounded and measurable functions on \\
 & linear operator on  defined as   for all \\
 & set of basis functions \\
 & function space generated by \\
 & projection operator\\
&  upper bound for \\
&  upper bound for , for all \\
 & approximation of  computed via higher-order methods\\
 & error of higher-order approximation\\
 & dimension of the state space\\
 & interpolation operator 
projecting any function 
to a unique function of  such that \\
 & -dim. column vector containing values of  at the interpolation points\\
 & -dim. column vector containing interpolation coefficients\\
 & -dimensional interpolation matrix corresponding to \\
 & set of basis functions for partition set \\
 & set of interpolation points in the partition set \\
 & set of interpolation coefficients in the partition set \\
& matrix representation of interpolation inside partition set \\
& -dimensional identity matrix\\
& function  with domain restricted to set \\
 & interpolation coefficients for  used in Algorithm~\ref{algo:app_val}\\
 & defined as  and used in Algorithm~\ref{algo:app_val}\\
 & defined as  and used in Algorithm~\ref{algo:app_val}\\
 & matrix with entries  used for piecewise constant approximation of the density functions in Algorithm~\ref{algo:app_val_abs}\\
& a row vector used in Algorithm~\ref{algo:app_val_abs} for values of  \\
& diameter of the partition set , \\
& partition set  for one-dimensional systems\\
& an upper bound for the quantity , for all \\
& partition set  for two-dimensional systems \\
& upper bounds on partial derivatives of  in 2-dim. systems\\
&  upper bounds on partial derivatives of  in 3-dim. systems\\
 & safety probability over the set  with time horizon  and initial state \\
 & safety probability over the set  with the initial state admitting the density function \\
 & sub-density functions for forward computation of the safety probability\\
 & value functions for backward computation of the safety probability\\
 & error of forward computation of the safety probability\\
 & error of backward computation of the safety probability\\
 & Lipschitz constant of  with respect to \\
 & upper bound for , for all \\
 & finite-state Markov chain obtained via the backward abstraction approach\\
 & transition probabilities of the Markov chain 
\end{longtable}

\end{document}
