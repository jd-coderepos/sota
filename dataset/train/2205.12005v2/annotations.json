[{'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-dev', 'Metric': 'Accuracy', 'Score': '82.43'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-std', 'Metric': 'overall', 'Score': '83.62'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-std', 'Metric': 'yes/no', 'Score': '94.83'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-std', 'Metric': 'number', 'Score': '69.82'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-std', 'Metric': 'other', 'Score': '77.02'}}, {'LEADERBOARD': {'Task': 'Image Captioning', 'Dataset': 'COCO Captions', 'Metric': 'BLEU-4', 'Score': '46.5'}}, {'LEADERBOARD': {'Task': 'Image Captioning', 'Dataset': 'COCO Captions', 'Metric': 'METEOR', 'Score': '32.0'}}, {'LEADERBOARD': {'Task': 'Image Captioning', 'Dataset': 'COCO Captions', 'Metric': 'CIDER', 'Score': '155.1'}}, {'LEADERBOARD': {'Task': 'Image Captioning', 'Dataset': 'COCO Captions', 'Metric': 'SPICE', 'Score': '26.0'}}]
