\def\year{2018}\relax
\documentclass[letterpaper]{article} \usepackage{aaai18}  \usepackage{times}  \usepackage{helvet}  \usepackage{courier}  \usepackage{url}  \usepackage{graphicx}  \frenchspacing  \usepackage{multirow}
\usepackage{pgfplotstable}
\usepackage{capt-of}
\usepackage{amsmath}
\usepackage{amssymb}

\frenchspacing  

\setlength{\pdfpagewidth}{8.5in}  \setlength{\pdfpageheight}{11in}  \pdfinfo{
/Title (Generative Adversarial Network for Abstractive Text Summarization)
/Author (Linqing Liu, Yao Lu, Min Yang, Qiang Qu, Jia Zhu, Hongyan Li)}
\setcounter{secnumdepth}{0}  



 \begin{document}
\title{Generative Adversarial Network for Abstractive Text Summarization\thanks{The work was partially supported by CAS Pioneer Hundred Talents Program and the MOE Key Laboratory of Machine Perception at Peking University under grant number K-2017-02. Q. Qu is the corresponding author.}}
\author{Linqing Liu \hspace{0.3cm}  Yao Lu \hspace{0.3cm} Min Yang \hspace{0.3cm} Qiang Qu \hspace{0.3cm} Jia Zhu \hspace{0.3cm} Hongyan Li\\
	Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences\\ 
	Alberta Machine Intelligence Institute \space
	School of Computer Science, South China Normal University\\ 
    MOE Key Laboratory of Machine Perception, Peking University\\ 
{\tt \{likicode, 95luyao, min.yang1129\}@gmail.com} \hspace{0.3cm} {\tt qiang@siat.ac.cn} \\{\tt jzhu@m.scnu.edu.cn} \hspace{0.3cm} {\tt lihy@cis.pku.edu.cn}
}


\maketitle
\begin{abstract}
In this paper, we propose an adversarial process for abstractive text summarization, in which we simultaneously train a generative model  and  a discriminative model .  In particular,  we build the generator  as an agent of reinforcement learning, which takes the raw text as input and predicts the abstractive summarization.  We also build a discriminator which attempts to distinguish the generated summary from the ground truth summary.  Extensive experiments demonstrate that our model achieves competitive ROUGE scores with the state-of-the-art methods on CNN/Daily Mail dataset.  Qualitatively, we show that our model is able to generate more abstractive, readable and diverse summaries\footnote{Supplemental material: http://likicode.com/textsum/}. 
\end{abstract}

\section{Introduction}
Abstractive text summarization is the task of generating a short and concise summary that captures the salient ideas of the source text.  The generated summaries potentially contain new phrases and sentences that may not appear in the source text. 
In the past decades, a flurry of studies have been conducted on abstractive text summarization \cite{nallapati2016abstractive,see2017get,paulus2017deep}. Despite the remarkable progress of previous studies, abstractive summarization is still challenged by (i) Neural sequence-to-sequence models tend to generate trivial and generic summary, often involving high-frequency phrases; (ii) The generated summaries have limited grammaticality and readability; (iii) In most previous work the standard sequence-to-sequence models are trained to predict the next word in summary using the maximum-likelihood estimation (MLE) objective function. However, this strategy has two major shortcomings. First, the evaluation metric is different from the training loss. Second, the input of the decoder in each time step is often from the true summary during the training. Nevertheless, in the testing phase, the input of the next time step is the previous word generated by the decoder. This exposure bias leads to error accumulation at test time.

To address the above challenge, in this paper, we propose an adversarial framework to jointly train a generative model  and a discriminative model .  Specifically, the generator  takes the original text as input and generate the summary. We use reinforcement learning (i.e., policy gradient) to optimize  for a highly rewarded summary. Thus, it effectively bypasses exposure bias and non-differentiable task metrics issues.  We implement the discriminator  as a text classifier that learns to classify the generated summaries as machine or human generated. The generator  and the discriminator  are optimized with a minimax two-player game. The discriminator  tries to distinguish the ground truth summaries from the generated summaries by the generator , while the training procedure of generator  is to maximize the probability of  making a mistake. Thus, this adversarial process can eventually adjust  to generate plausible and high-quality abstractive summaries.


\section{Our model}
Similar to the standard training strategy \cite{goodfellow2014generative}, we simultaneously train two models in an adversarial manner: a generative model  and a discriminative model .  We first pre-train the generative model by generating summaries given the source text. Then we pre-train the discriminator by providing positive examples from the human-generated summaries and the negative examples produced from the pre-trained generator. After the pre-training, the generator and discriminator are trained alternatively.

\subsection{Generative Model}
The generator takes the source text  as input and predicts the summary . Here, the  is the length of the source text  and  is the length of the predicted summary. We use a bi-directional LSTM encoder to convert the input text  into a sequence of hidden states .  Following \cite{see2017get}, on time step , an attention-based LSTM decoder is then used to compute the hidden state  of the decoder and a context vector .  The reader can refer to the supplement of this paper (or  \cite{see2017get}) for the implementation details. The parameters of the generator  are collectively represented by .  The context vector  is concatenated with the decoder state  and fed through a fully connected layer and a softmax layer to produce the  probability of predicting word from target vocabulary at each time step :
{\footnotesize

	
    
}
where ,  , ,  are learnable parameters.  Similar to the work of \cite{see2017get}, we incorporate a switching pointer-generator network to use either word generator from fixed vocabulary or pointer copying rare or unseen from the input sequence. Finally, we can get the final probability  of each token  in the summary. 

\subsection{Discriminative Model}

The discriminator is a binary classifier and aims at distinguishing the input sequence as originally generated by humans or synthesized by machines. We encode the input sequence with a CNN as it shows great effectiveness in text classification \cite{kim2014convolutional}. We use multiple filters with varying window sizes to obtain different features and then apply a max-over-time pooling operation over the features. These pooled features are passed to a fully connected softmax layer whose output is the probability of being “original”. 

\subsection{Updating model parameters}
In the adversarial process, using the discriminator as a reward function can further improve the generator iteratively by dynamically updating the discriminator. Once we obtain more realistic and high-quality summaries generated by generator , we re-train the discriminator as:  
{\scriptsize
	
}
When the discriminator  is obtained and fixed, we are ready to update the generator . The loss function of our generator  consists two parts: the loss computed by policy gradient (denoted by ) and the maximum-likelihood loss (denoted by ). 
Formally, the objective function of  is , where  is the scaling factor to balance the magnitude difference between  and .  According to the policy gradient theorem \cite{sutton2000policy},  we compute the gradient of   w.r.t. the parameters :

{\scriptsize
	
}
where  is the action-value function, and we have ,  is the length of the text. We update the parameters using stochastic gradient descent,  is the generated summary up to time step ,   is the source text to be condensed. 

\section{Experiments}

\textbf{Dataset - CNN/Daily Mail Corpus.} The dataset \cite{nallapati2016abstractive} is widely used in abstractive summarization. It comprises news stories in CNN and Daily Mail websites paired with multi-sentence human generated abstractive summaries. It contains 287,226 training pairs, 13,368 validation pairs and 11,490 test pairs. 


\begin{table}[]
	\footnotesize
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		Methods & ROUGE-1 & ROUGE-2 & ROUGE-L & Human\\ \hline
		ABS &   35.46   & 13.30 & 32.65  & 2.07\\ \hline
		PGC &   39.53   & 17.28 &  36.38 & 3.81\\ \hline
		DeepRL  &   39.87   & 15.82 &  \textbf{36.90}&3.04\\ \hline
		Pretrain & 38.82 & 16.81 & 35.71 & 3.70 \\ \hline
		Ours   &   \textbf{39.92} & \textbf{17.65} & 36.71 & \textbf{4.01} \\ \hline
	\end{tabular}
	\caption{Quantitative evaluation results}
	\label{my-label}
\end{table}


\textbf{Experimental Results.} We compare our approach with three methods, including the abstractive model (ABS) \cite{nallapati2016abstractive}, the pointer-generator coverage networks (PGC) \cite{see2017get}, and the abstractive deep reinforced model (DeepRL) \cite{paulus2017deep} (ML+RL version).

We firstly compare our model with the pre-trained generator. After adversarial training, ROUGE-1, ROUGE-2, ROUGE-L increase by 1.10, 0.84 and 1.00 absolute points respectively. In addition, our model exhibits competitive ROUGE scores with the state-of-the-art methods. Specifically, our approach achieves the best ROUGE-1 and ROUGE-2 scores. 

We also perform human evaluation to evaluate the readability and quality of summaries. We randomly select 50 test examples from the dataset. For each example, two human evaluators are asked to rank each summary generated by all 5 models based on their readability, where 1 indicates the lowest level of readability while 5 indicates the highest level. As we can observe from Table 1,  our model contributes significantly to improving the readability of summaries.

To evaluate the proposed model qualitatively, we also report the generated summaries in supplementary files.

\section{Conclusion}
In this paper, we proposed an adversarial process for abstractive text summarization. Experimental results showed that our model could generate more abstractive, readable and diverse summaries.


\bibliography{sample}
\bibliographystyle{aaai}

\end{document}
