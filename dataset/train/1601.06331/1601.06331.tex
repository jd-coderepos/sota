\documentclass[prodmode,acmtompecs]{acmsmall} 




\usepackage{graphicx}
\usepackage[cmex10]{amsmath}	\usepackage{amssymb}	\usepackage{multirow}

\DeclareMathOperator*{\argmin}{arg\,min} \DeclareMathOperator*{\argmax}{arg\,max} \DeclareMathOperator*{\expectation}{\mathrm{E}} 

\newcommand{\reqvec}{\mathbf{q}}
\newcommand{\reqscalar}{q}
\newcommand{\ribvec}{\boldsymbol{\alpha}}
\newcommand{\ribscalar}{\alpha}

\newcommand{\priorityImplication}{monotonicity in individual expected payoff}
\newcommand{\modelSatisfyPriorityImplication}{a system satisfies monotonicity in payoffs}

\newcommand{\concaveHull}{R}
\newcommand{\feasibilityRegion}{F}
\newcommand{\fullUserSet}{N}

\newcommand{\succS}[1]{\succ_{#1}}
\newcommand{\succeqS}[1]{\succeq_{#1}}
\newcommand{\precS}[1]{\prec_{#1}}
\newcommand{\preceqS}[1]{\preceq_{#1}}

\newcommand{\myComments}[1]{}	

\newif\ifinfocom
\infocomfalse

\newif\ifextended
\extendedtrue

\newif\ifdissertation
\dissertationfalse

\newif\ifhuawei
\huaweifalse

\newcommand{\infocomStart}{\ifinfocom \myComments{Infocom: }}
\newcommand{\extendedStart}{\ifextended  \myComments{Extended version: }}
\newcommand{\dissertationStart}{\ifdissertation  \myComments{Dissertation version: }}
\newcommand{\huaweiStart}{\ifhuawei  \myComments{Huawei version: }}

\newcommand{\commentEnd}{\myComments{End}}

\newcommand{\add}[1]{#1}



\begin{document}

\markboth{Y. Du and G. de Veciana}{Efficiency and Optimality of Largest Deficit First Prioritization}

\title{Efficiency and Optimality of Largest Deficit First Prioritization: Resource Allocation for Real-Time Applications}
\author{YUHUAN DU and GUSTAVO DE VECIANA
\affil{The  University of Texas at Austin}
}

\begin{abstract}
An increasing number of real-time applications with compute and/or communication deadlines
are being supported on shared infrastructure.  Such applications can often tolerate 
occasional deadline violations without substantially impacting their Quality of Service (QoS).
A fundamental problem in such systems is deciding how
to allocate shared resources so as to meet applications' QoS requirements.
A simple framework to address this problem is to, (1) dynamically prioritize users as a possibly complex function of their deficits (difference of achieved vs required QoS), and (2) allocate resources so to expedite users with higher priority.
This paper focuses on a general class of systems using such priority-based resource allocation.
We first characterize the set of feasible QoS requirements and show the optimality of max weight-like prioritization.
We then consider simple weighted Largest Deficit First (-LDF)
prioritization policies, where users with higher weighted QoS deficits are given higher priority.
The paper gives an inner bound for the feasible set under -LDF policies, and,
under an additional monotonicity assumption, characterizes its geometry leading to a sufficient condition for optimality.
Additional insights on the efficiency ratio of -LDF policies, the 
optimality of hierarchical-LDF and characterization of clustering of failures are also discussed.
\end{abstract}

\keywords{Soft real-time applications, cloud-computing, largest deficit first prioritization, feasibility region, feasibility optimal, geometry of inner bound, class-based hierarchical prioritization}

\begin{bottomstuff}
\add{
This research was supported by Huawei Technologies Co. Ltd.}

\add{A conference version of this paper has been accepted to INFOCOM 2016. 
}
\end{bottomstuff}

\maketitle

\section{Introduction}
\label{sec_introduction}
A growing number of real-time applications with compute and/or communication deadlines
are being moved onto shared infrastructure, e.g., ranging from embedded systems to efficient cloud infrastructure.
Such applications include control, multimedia processing, and/or machine learning components associated
with enabling various types of user services as well as wireless, intelligent transportation and energy systems.
In many cases such applications can tolerate occasional deadline violations, i.e., have soft 
constraints,  without impacting the application Quality of Service (QoS). For example, 
applications with feedback can quickly compensate for errors, or humans may tolerate occasional 
failures in video processing since they can be partially concealed, or wireless base stations can
tolerate occasional frame losses, since these can be retransmitted.
More generally real-time applications' long-term QoS may depend in a complex manner 
on what was accomplished on time, e.g., partial completion of a set of tasks, or notions of video quality. 

Enabling efficient sharing of compute/communication resources is a challenging problem. 
On the one hand, even for a single resource, tying the sharing model, e.g., 
round robin, priority schemes, to QoS metrics is generally hard due
to the uncertainty in applications' workloads and possible variations in processing speeds.
On the other hand, today's applications leverage complex networks of heterogeneous compute/communication resources, 
e.g., multi-core computers, embedded network system, or combinations of computation on mobile devices 
and the cloud. 
Consider the example in Figure~{\ref{fig_complex_network_resources}}. 
User 1 periodically generates a task that needs to be processed sequentially on Resources A, B, C, D in each 
period while User 2 generates tasks to be processed on Resource B then C. 
How should one go about designing resource sharing policies 
across multiple heterogeneous resources, where parallelism, task preemption and migration are allowed?
Furthermore, how can one address heterogeneous QoS requirements associated  
with real-time applications? For example, User 1's QoS may still benefit from partial completions while User 2 
only benefits if all processing is completed. 
This general class of problems involving both heterogeneous resources and user QoS requirements
is the focus of this paper. 

\infocomStart
\begin{figure}[htp]
  \centering
  \includegraphics[width=0.23\textwidth]{Figures/example_complex_network_resources.pdf}
  \caption{An example for a network of resources. A, B, C and D represent compute/communication resources. }
  \label{fig_complex_network_resources}
\end{figure}
\commentEnd\fi

\extendedStart
\begin{figure}[htp]
  \centering
  \includegraphics[width=0.32\textwidth]{Figures/example_complex_network_resources.pdf}
  \caption{An example for a network of resources. A, B, C and D represent compute/communication resources. Tasks from User 1 need to be processed on A, B, C, D while tasks from User 2 require processing on B, C. }
  \label{fig_complex_network_resources}
\end{figure}
\commentEnd\fi



The design space of possible solutions to this problem is huge and has been
explored in many research communities. In this paper we study an approach to
resource allocation based on a decomposition of concerns:
\begin{enumerate}
\item user priorities are dynamically set based on the history outcomes; 
\item and, resources are allocated so as to favor users with higher priority.
\end{enumerate}
In such a framework there is quite a bit of latitude in choosing how priorities are set, and
in turn how these affect the allocation of resources. 
For example, users' priorities could be set based on measured deficits, the ``difference'' of the required and achieved QoS, 
i.e., Largest Deficit First (LDF) prioritization. 
In turn, for complex systems such as that in Figure~{\ref{fig_complex_network_resources}}, resources
could be allocated greedily giving preemptive access to tasks associated with higher-priority users.

In general an optimal user prioritization strategy could leverage detailed
information regarding how these priorities will impact the allocation of resources and completion outcomes to achieve
the best possible user QoS. 
Such strategies require excessive amounts of information regarding the underlying compute/communication resources and resource allocation mechanism, and thus are generally hard to implement. 
By contrast, LDF-based prioritization is quite intuitive. 
It requires only tracking of users' possibly heterogeneous QoS deficits, in this
sense it is truly decoupling user prioritization from the underlying priority-based resource allocation. 
Unfortunately, it is known to be suboptimal in certain settings \cite{DiW06,JLS07,KWJ13}.

A theoretical study of the efficiency and, possibly optimality, of LDF-based prioritization 
systems supporting real-time users with heterogeneous QoS requirements 
is the main focus of this paper. We note, however, that we do not directly address the design
of the underlying priority-based resource allocation, although we consider some natural
characteristics it could have to ensure optimality when combined with LDF user prioritization.




{\bf \em Related Work. }
There have been much work studying dynamic prioritization policies in the context of diverse resource, workload and/or QoS models. 

The authors in \cite{HoK12,HoK13b} propose a framework to model a wireless access point serving a set of clients that in each period generate packets which need to be transmitted by the end of the period. 
In their model only one client can transmit at a time and thus the access point can be viewed as a single resource. Each client transmits its packets over an unreliable channel which has a fixed probability of success, and thus, the time to successfully transmit a packet can be modeled as a geometric random variable. In this setting the authors show that the LDF policy is ``optimal.'' 
However, the results are restricted to a single resource shared by users with geometric workloads. In this paper we study the performance of LDF in a more general setting which includes this prior work as a special case. 
This initial set of papers motivated follow-up work in wireless context, see e.g., \cite{HoK14,MLH10,JaS11}. 


The performance of LDF and similar policies has also been studied in \cite{MCK95,DiW06,JLS07,KWJ13}. The authors in \cite{DiW06} consider the generalized switch model and were the first to propose the notion of ``local pooling'' as a sufficient condition for the Longest Queue First (LQF) policy to be throughput optimal. 
Subsequently, the work in \cite{JLS07} considers a multi-hop wireless network under a node-exclusive interference model and shows that the efficiency ratio of the greedy maximal matching policy, which is essentially LQF, equals to the ``local pooling'' factor of the network graph. More recently, the authors in \cite{KWJ13} consider real-time traffic in ad hoc wireless networks under a link-interference model and also characterize the efficiency ratio of the LDF policy. 

The results in \cite{DiW06,JLS07,KWJ13} depend on the constant service rate model and the specific interference model, i.e., where the set of links/queues that can be scheduled simultaneously is restricted. 
These models may be appropriate in some wireless/queueing networks but do not necessarily hold in our broader context, e.g., soft real-time applications with stochastic workloads. Also, \cite{DiW06} lacks a performance analysis of LQF when it is not optimal and the works in \cite{JLS07,KWJ13} focus on the efficiency ratio of LDF-like policies but lack a characterization of the full capacity region of these policies. 
Moreover, when the system can deliver more than the requirements, either the QoS requirements for real-time traffic or the throughput requirements for queueing systems, there is no discussion of how to manage the allocation of the ``excess capacity'' across users. 

The authors in \cite{TaE92,TaE93,MMA99,DaP00,Sto04} propose max weight 
scheduling policies for different types of queueing systems and show them to be throughput optimal 
via the approaches summarized in \cite{DoM94,DoM97,MeT08}. 
\extendedStart
The authors in \cite{Nee09} and \cite{VBY13} further 
characterize the delay of the max weight policy, and study its inefficiency in spatial wireless networks, respectively. 
\commentEnd\fi
As we will see in the sequel we too discuss a max weight-like scheduling policy, but it suffers from the usual complexity problems when the decision space
is large and it requires excessive amounts of information, motivating us to consider simpler policies. 

Additional related work includes work on modeling and scheduling of real-time tasks, see e.g., \cite{SAA04,DaB11,LiI08,ShS02}. 

{\bf \em Our Contributions. }
In this paper, we contribute to the theoretical understanding and performance characterization of the Largest Deficit First (LDF) policy with applications to resource allocation to support real-time services. We make three key contributions. 

First, we propose a novel general model for a class of systems supporting priority-based resource allocation 
and study different dynamic prioritization policies. This model is general in terms of the ``impact'' the priority decisions can have on the QoS payoffs. Specifically, in each period the payoffs under a priority decision are modeled by a random vector, which includes as special cases the single resource model, the geometric/constant workload and/or specific interference model adopted in prior work. 
For this general model, we propose a general inner bound  for the QoS feasibility region of LDF prioritization policy. 

Second, with an additional property, {\em monotonicity in payoffs}, we characterize the geometry of the inner bound . 
Based on this, we further propose a sufficient condition for the optimality of the LDF policy and characterize the efficiency ratio of LDF. 
In practice, understanding the geometry of  enables us to understand and identify possible bottlenecks in the priority-based resource allocation infrastructure. 
We also show that the LDF policies (as well as a hierarchical-LDF version) are optimal when there are two classes of exchangeable users. 

Finally, we also consider the class of weighted LDF policies, which enable us to explore the allocation of ``excess payoffs'' when the system has ``excess'' capacity. Simulation results are exhibited to show the impact of weights and to characterize the clustering of failures. 

{\bf \em Paper Organization. }
The paper is organized as follows: Section 2 introduces our general model for systems supporting priority-based resource allocation. Section 3 develops theoretical results and characterizes the performance of the weighted LDF policies while Section 4 presents some examples for the optimality of the weighted LDF/hierarchical-LDF policies. Section 5 discusses some practical issues while the impact of weights is exhibited via simulation in Section 6. Section 7 concludes the paper and points to future work. Some of the proofs are provided in the Appendix.

\section{System Model}
\label{sec_system_model}
We consider applications which periodically generate random workloads with the same period and specify long-term QoS requirements. In the sequel we let a user denote a specific instance of such an application. 

We begin by introducing a general model for systems that allocate resources in each period based on the following decomposition: 
(1) users are assigned priorities dynamically, e.g., at runtime, according to a function of the past history, and (2) the system allocates resources based on these priorities. 

For the most part in this paper, the manner in which (2) is carried out will not be our concern. Instead our focus will be on how to perform dynamic user prioritization to achieve optimal (or near-optimal) system performance when combined with a given underlying mechanism for (2). 
\extendedStart
In our follow-up work \cite{DuD16S}, we consider a specific system model and study the combined design of (1) and (2). 
\commentEnd\fi

\subsection{General Model for Systems Supporting Priority-Based Resource Allocation} 
\label{subsection_general_payoff_model}
We consider an abstract system that serves  users indexed from  to . Let  be the user set. The system operates in discrete time, over periods . In each period, it picks a user {\em priority decision}  where  is the index of the user with  highest priority. We let  denote the set of all possible priority decisions and let  represent the number of possible decisions, thus,  

In each period, given the priority decision  passed to the underlying resources, since there are intrinsic uncertainties in users' workloads, 
each user  achieves a non-negative random QoS payoff, denoted by . We let . 
We assume the payoffs are independent across periods. 
The distribution of  depends on the selected priority decision  and the expected payoff vector given  is denoted by . We assume all possible payoff vectors form a finite rational set. 
\extendedStart
Moreover, we naturally assume that for each user , there exists a decision  such that . 
\commentEnd\fi

Each user requires a long-term average QoS payoff  as the QoS requirement. We let  and assume 's are rational\footnote{All the results in this paper can be generalized to models with irrational values. For simplicity in the proof we do not consider that level of generality. }. We denote by  the priority decision at period . To keep track of the deficits between required and achieved QoS payoffs, for each user  and period , we define\footnote{We truncate the deficit at  for the convenience of defining feasibility in the sequel. Removing the truncation won't change the results in the paper. }

where . 

The goal is thus to devise user prioritization policies which will meet users' long-term payoff requirements. 

\begin{definition}
A {\bf user prioritization policy} is a stationary policy that picks a priority decision  at period  based on the following:
\begin{longitem}
\item[-] users' payoff requirement vector ; 
\item[-] expected payoff vectors ; 
\item[-] and, the deficits . 
\end{longitem}
\end{definition}

The process  is a Markov chain under any such policy. We assume the initial state , the requirements , the set of all possible payoff vectors and the user prioritization policy make  an irreducible Markov chain. 

\begin{definition}
\label{defn_feasibility_pr}
A payoff requirement vector  is said to be {\bf feasible} if there exists a user prioritization policy  under which the Markov chain  is positive recurrent. We also say this policy fulfills this requirement vector. 
\end{definition}

The expected payoff vectors  could in principle be statistically inferred from the history events or by repeated experiments. 
However, in a practical setting this can be challenging and it is of interest to find a policy that performs well and uses little a-priori information regarding the exponential set of expected payoff vectors . 

Note that this model is general in the sense that the ``impact'' of priority decisions  on the QoS payoff vectors  is at this point general, whereas the specific resource and workload models in prior work, e.g., \cite{DiW06,JLS07,KWJ13}, implicitly impose properties on  and therefore restrict the results significantly. 

\subsection{Example: Centralized Computing System for Real-Time Applications}
\label{subsection_SRT_model}
Our model can for example capture a centralized computing infrastructure supporting Soft Real-Time (SRT) applications where the  users share compute resources. In a cloud-based collaborative video conferencing context, a user might correspond to an individual end user and the period length might correspond to the length of a group of video frames. 

The users generate streams of tasks periodically. Specifically in each period a user generates several tasks. A task may further consist of a graph of possibly dependent sub-tasks with (possibly) random processing requirements, i.e., workloads. These tasks/sub-tasks need to be fully completed before the end of the period. 
For real-time services, it is generally useless to process a task after its deadline. For example, in the video conferencing context it is not desirable to present an out-of-date frame.  Therefore, we assume tasks/sub-tasks not completed on time are dropped. 

In each period , the user prioritization policy picks a user priority decision , based on which compute resources are allocated to process tasks. 
Given the task processing results, a payoff  is achieved for each user  based on whether the tasks were successfully processed, or how much of the task graphs were completed. 
In general,  may represent any user-specific QoS payoff per period, that can be averaged over time, e.g., the quality/resolution of video frame processing, or the number of task completions. Accordingly the vector  represents the long-term average QoS requirements. 

\dissertationStart
Note that these payoff vectors depend heavily on the internal design of the system and in this paper we assume the internal design is fixed and has been carefully optimized by the computing system architect. 
In practice, it may be challenging to jointly optimize the internal design and the stationary priority scheduling policy to provide the best QoS to users. 
A discussion of different internal designs in a specific computing system model is provided in [?]. 
\commentEnd\fi

\subsection{Example: Complex Networks and Flexible Modeling of Application Execution Payoffs}
As indicated in the introduction, our model also applies to a complex network of heterogeneous compute and communication resources, as long as users periodically and synchronously generate tasks that require timely processing on diverse resources and moving around in the network, e.g., as shown in Figure~\ref{fig_complex_network_resources}. 

Given the priority decision in each period, the network of resources coordinate according to some priority-based resource allocation mechanism to accelerate the processing of tasks with high priorities, by reducing the communication/queueing delays, processing with higher processor speed, allocating more shared resources, etc. 

Again, different users can define their payoffs in different ways and specify their QoS requirements accordingly. 

\dissertationStart
\myComments{In dissertaion, we have to re-organize this section. }
\subsection{Other Interpretations of General Payoff Model}
Our general payoff model applies beyond the soft real-time context. For example, for each user , by viewing  as expected arrival rates and  as the service rate given priority decision  is selected in period , the general payoff model captures the queueing system, e.g., the generalized switch model or the wireless networks considered in prior work \cite{DiW06,JLS07,KWJ13}. 

However, our general payoff model is general in the sense that the ``impact'' of priority decisions  on the payoff vectors  is left unspecified, while the interference model in these prior work implicitly imply properties on P. 

In the next section, we first derive results in the general payoff model and then add further properties on  to get cleaner results. 
\commentEnd\fi


\section{Performance Analysis}

In this section we shall develop theoretical results for such systems. 
\infocomStart
To save space we have deferred proofs of these results to the extended version of this paper available at \cite{EXT2}. 
\commentEnd\fi
Some of these results are similar to prior work but in the more general model while other results are completely new. 
For completeness we shall develop a self-contained theoretical framework. 
\dissertationStart
In the sequel we provide examples to help understand these results in the context of SRT applications. 
\commentEnd\fi

\subsection{System Feasibility Region and Feasibility Optimal Policy}
\label{subsection_feasibility_region_and_optimal_scheduling}

The set of all feasible long-term payoff requirement vectors will be referred to as the {\em system feasibility region} . 
We let  denote the feasibility region of a user prioritization policy . 
To characterize  we introduce some further notation. 

A vector  is said to be {\em dominated} by a vector  if  for all  and is denoted by . We define ,  and  in a similar manner. 

Given the set of priority decisions  and the expected payoff vectors , we let  be the set of requirement vectors  which are dominated by a vector in the convex hull of  denoted Conv(), i.e., 


Figure~{\ref{fig_feasible_region}} exhibits  for a two-user (left figure) and three-user (right figure) setting. 
In the two-user setting, the points labeled  and  are the expected payoff vectors of two priority decisions, i.e., where User 1 or User 2 has higher priority, respectively. The shadowed area represents . 
\dissertationStart
Clearly these two expected payoff vectors are always on a line. 
\commentEnd\fi
In the three-user setting, the circles represent the  possible expected payoff vectors, and the region dominated by their convex hull is . 
Note that in a -user scenario where , as displayed the expected payoff vectors need not be on a hyperplane in the -dimensional space. 
As we will see this is essentially the source of complexity in studying such systems. 

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.65\textwidth]{Figures/figure_feasible_region_infocom.pdf}
  \caption{Examples of set  when  and . }
  \label{fig_feasible_region}
\end{figure}

Clearly, for any requirement vector  in the interior of , denoted by , one can achieve  if one is allowed to do probabilistic time sharing among priority decisions by picking decisions according to a pre-computed probability distribution whose mean payoff dominates . Therefore, . We can also show the following result. 

\begin{lemma}
\label{lemma_R_in_close_C}
The system feasibility region  is such that

where  is the closure of . 
\end{lemma}

Intuitively, if  is feasible, it is fulfilled by some user prioritization policy that in the long-term picks each priority decision some fraction of the time and thus,  is dominated by some point in the convex hull of . This is similar to prior work, e.g., \cite{TaE92}. 
\infocomStart
See the extended version of this paper \cite{EXT2} for the proof. 
\commentEnd\fi
\extendedStart
See the appendix for a detailed proof. 
\commentEnd\fi
In other words,  is different from  by at most a boundary, and therefore, characterizes  for practical purposes. Thus, in the sequel we will also refer to  as the system feasibility region. 

Ideally, it is desirable to devise an ``optimal'' policy that can fulfill all feasible requirements. 
More formally, a user prioritization policy  is said to be {\em feasibility optimal} if . 
Similar to prior work \cite{TaE92,TaE93}, the following max weight-like policy is one such feasibility optimal policy. 

\begin{definition}
The {\bf deficit-based max weight (MW)} prioritization policy is such that, at period , given the deficit vector  computed by (\ref{align_deficit_in_general_payoff}), it picks a priority decision  that satisfies

where  is the inner product of two vectors. 
\end{definition}


\begin{theorem}
\label{theorem_MW_feasibility_optimal}
\infocomStart
The feasibility region of the MW policy  is such that 

and therefore, the MW policy is feasibility optimal. 
\commentEnd\fi
\extendedStart
The system feasibility region  and the feasibility region of the MW policy  are related to  as follows, 

and therefore, the MW policy is feasibility optimal. 
\commentEnd\fi
\end{theorem}

\noindent See Appendix \ref{appendix_pf_thm_MW_feasibility_optimal} for the proof.

However, the MW policy and time sharing policies require full knowledge of  which is challenging in complex practical systems. Moreover, these policies are hard to implement since they involve solving fairly complex optimization problems, i.e., Eq (\ref{align_max_weight}). Changes in the user set or payoff requirement vector  will also impact the realization of these policies. 
In summary, the requirements in terms of a-priori knowledge, the computational complexity and lack of flexibility to changes make them hard to use in practice. This motivates the policies considered in the next subsection. 

For ease of reference, Table \ref{tab_notation} provides a summary of the notation used to denote various regions used in the rest of the paper\textemdash some of these are introduced in the sequel. 

\begin{table}[h]
\normalsize
    \tbl{Notation of regions. \label{tab_notation}}{
    \centering
    \begin{tabular}{| c || l |}
    \hline
    {\bf Regions} & {\bf Description}\\
    \hline
    \hline
     & System Feasibility Region. \\
    \hline
    Conv & Convex hull of the expected payoff vectors.     \\
    \hline
     & Region dominated by Conv. \\ \hline
     & Feasibility region of the -LDF policy. \\
    \hline
     & An inner bound for \\
    \hline
     & Dominant of the convex hull. \\
    \hline
     & Region characterizing the geometry of . \\
    \hline
    \end{tabular}
    }
\end{table}

\subsection{Weighted LDF Policies and Associated Feasibility Regions}
\label{subsection_LDF}
The LDF user prioritization policies require no a-priori knowledge of the system, are simple to implement and adapt easily to changes in  or the user set. In particular we shall characterize the feasibility regions of these policies by providing an inner bound. 

\begin{definition}
\label{defn_w_LDF}
Given a vector , the {\bf weighted Largest Deficit First (-LDF)} user prioritization policy is such that, at period , given the deficit vector , it picks a priority decision  that satisfies

with ties broken arbitrarily (possibly randomly). In other words, it sorts the weighted deficits of users and assigns priorities accordingly. 
Let . 
We refer to the policy with  the {\bf Largest Deficit First (LDF)} policy. 
\end{definition}

\dissertationStart
The LDF policy has been explored before \cite{DiW06, JLS07, KWJ13} in the context of specific resource, workload and payoff models. We also generalize it to a class of policies with different weight vectors and provide better geometric characterization of the feasibility region. 
\commentEnd\fi

Clearly, the -LDF prioritization policies do not require knowledge of the expected payoff vectors .
Note that we still use deficit feedback to stabilize the system. 
In terms of computational complexity, solving (\ref{align_max_weight}) is  while sorting weighted deficits only requires . 
It also allows us to further differentiate the performance across users by assigning different weights. The impact of weights is discussed in Section \ref{sec_simulations}. 

Prior work has established that the LDF policy need not be feasibility optimal. Therefore, a key question is whether the feasibility regions for the -LDF policies are acceptable and to characterize the gap between their feasibility regions and the system feasibility region . 
To that end, we first provide an inner bound, denoted by , for the feasibility region of any -LDF policy. 

\begin{theorem}
\label{thm_R_IB}
For any , an inner bound for the feasibility region of the -LDF policy  is given by
 
where

where  denotes the set of all priority decisions that assign the highest  priorities to users in . 
\end{theorem}

In other words, if , it is feasible under all -LDF policies except perhaps boundary points. 
The underlying intuition for this bound is as follows. A vector  is in  if
there is a weight vector  such that for any subset of users , and decisions giving users in  the highest priorities, the weighted sum of payoff requirement  will not exceed the least sum weighted payoff . 
Based on , we can construct an appropriate Lyapunov function to show feasibility for  and each . 
\infocomStart
See the extended version of this paper \cite{EXT2} for the proof. 
\commentEnd\fi
\extendedStart
See Appendix \ref{appendix_pf_thm_R_IB_chap2} for the proof. 
\commentEnd\fi

\dissertationStart
In other words,  and is feasible under the -LDF policy if there is a weight vector  such that for any subset of users , by giving users in  the highest priorities, the weighted sum of payoff requirement  will not exceed the least sum weighted payoff . 
\commentEnd\fi

Understanding the geometry of  enables us to characterize the performance gap between -LDF and feasibility optimal policies. 
Let us informally consider the geometry of  for the two special cases in Figure~{\ref{fig_feasible_region}}. 
In the two-user case in Figure~{\ref{fig_feasible_region}},  is the same as  and thus, the -LDF policies are feasibility optimal. 
However, in the three-user case in Figure~{\ref{fig_feasible_region}}, this need not be true. 
Indeed, in this setting, the region  corresponds to  minus the convex hull of , modulo some boundary points. 
This is exhibited in Figure~{\ref{fig_three_user_R_IB}}. 
In the next subsection, we will formalize these observations and show under what conditions they hold true. 

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.8\textwidth]{Figures/three_user_R_IB.pdf}
  \caption{Visualizing  for the three-user scenario in Figure~{\ref{fig_feasible_region}}. \add{In this example, the expected payoff vectors  are not on the same hyperplane} and . }
  \label{fig_three_user_R_IB}
\end{figure}

\subsection{Geometry of  under Monotonicity in Payoffs}
\label{subsection_characterizing_R_IB}

In order to formally characterize the geometry of  we will add a further natural requirement to the general model. 


We define  to be the set of users that have higher priorities than user  under decision . 

\begin{definition}
The system with expected payoff vectors  is said to satisfy {\bf \priorityImplication} if, for any two priority decisions  and  and any user  such that , it is true that . We call this {\bf monotonicity in payoffs} for short. 
\end{definition}

In other words, a user  can expect to get a higher payoff if some users with higher priority are re-assigned lower priorities. 
\dissertationStart
Note we are not comparing the expected payoffs of different users since payoffs can be defined in different ways for different users and may not be comparable. 
\commentEnd\fi
This property characterizes in a broad sense how priorities impact the expected payoffs when the underlying system allocates resources. 
It is a natural condition but need not hold in general. 

We shall define  to be the set of payoff requirement vectors  which dominate a vector in the convex hull of , i.e., 

We call  the {\em dominant of the convex hull}. Contrast this to the definition of  in (\ref{align_C}). 

For the special cases in Figure~{\ref{fig_feasible_region}} and \ref{fig_three_user_R_IB},  equals to , but in general it can be larger than . Figure~{\ref{fig_eg_for_B_intersect_C}} shows a conceptual picture of what could happen. The three circles represent three possible expected payoff vectors. Here, the whole shadowed area  is larger than the region Conv which is the triangle formed by the three circles. 
Note that this is only a conceptual example to help visualize  in higher dimensions. In reality for two dimensions, i.e., systems with two users, we know there are only  expected payoff vectors as shown in Figure~{\ref{fig_feasible_region}}. 

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.3\textwidth]{Figures/example_B_intersect_C.pdf}
  \caption{An example where  is larger than Conv. }
  \label{fig_eg_for_B_intersect_C}
\end{figure} 

In the sequel we will see that given monotonicity in payoffs,  is obtained by ``removing'' , rather than just  from . 
To develop this result we need some further notation associated with each subset of users . 

The projection of a vector  on the subspace of  is denoted by , i.e., 




We let  represent the projections of expected payoff vectors corresponding to decisions in , i.e., which assign the highest priorities to users in . 

Given a subset  and , we define the feasibility region  and the dominant of the convex hull  as follows. 



Note that  and  are not necessarily the same as projecting  and  on the subspace of , respectively. This is because in the definitions of  and , 
we only focus on a subset of decisions  rather that the full decision set . 
\dissertationStart
we only focus on priority decisions  rather that the full decision set . 
\commentEnd\fi

Let us now define a region  which will help characterize the geometry of the inner bound . 

\begin{definition}
\label{defn_concave_hull}
Let  be defined as follows:

where . 
In other words, any  satisfies that for any user subset , its projection on the subspace of  belongs to the set , which is the feasibility region  minus the dominant of the convex hull . 
\end{definition}

One can visualize obtaining the set  as a process of removing  from  in all subspaces corresponding to all subsets . The geometry of  is then captured as follows. 
\begin{theorem}
\label{thm_visualize_R_IB}
If the system satisfies monotonicity in payoffs, then the inner bound region  is such that

\end{theorem}

\infocomStart
See the extended version of this paper \cite{EXT2} for this somewhat technical proof. 
\commentEnd\fi
\extendedStart
\noindent See Appendix \ref{appendix_pf_thm_visualize_R_IB} for this somewhat intricate argument. 
\commentEnd\fi

\subsection{Sufficient Condition for -LDF's Optimality}

By Theorem \ref{thm_R_IB} and Theorem \ref{thm_visualize_R_IB}, we immediately get

Since  is obtained by removing  from  for each , if what is removed is nothing more than a boundary, the difference between  and  is at most a boundary and thus -LDF policies are feasibility optimal. It is easy to see this happens when vectors in  lie on a hyperplane for each subset of users . This can be formalized as follows. 

\begin{definition}
\label{defn_subset_payoff_equivalence}
The system with expected payoff vectors  is said to satisfy {\bf subset payoff equivalence} if for each subset of users  the vectors in  lie on a hyperplane, i.e., there exists a nonzero  such that for all , 

\end{definition}

\begin{theorem}
\label{thm_sufficient_condition_for_LDF_optimality}
If the system satisfies monotonicity in payoffs and subset payoff equivalence, then 

and therefore, the -LDF policies are feasibility optimal. 
\end{theorem}
\extendedStart
\noindent Please refer to Appendix \ref{appendix_pf_thm_sufficient_condition_for_LDF_optimality} for detailed proof. 
\commentEnd\fi

The conditions for this theorem are akin but not equivalent to the conditions introduced in \cite{DiW06} for the generalized switch model. 
Specifically, we require the system to satisfy monotonicity in payoffs and subset payoff equivalence. The work in \cite{DiW06} requires local pooling in the generalized switch model. 
In the model in \cite{DiW06}, given a priority decision  where  is the index of the queue with the the  highest priority, the queue service rate vector can be denoted by , where  represents the units of work that can be removed from queue  in one time slot under priority decision .  is akin to  in our context. However, the generalized switch model in \cite{DiW06} implies properties on the service rate vectors . For example, it implies that for all , we have  for all , and  for all  satisfying , etc. These implicit requirements do not necessarily hold in systems which satisfy the conditions in Theorem \ref{thm_sufficient_condition_for_LDF_optimality}. 

If the system has only two users, then clearly subset payoff equivalence is satisfied since the two expected payoff vectors are always on a line. Therefore, we get the following corollary. 
\begin{corollary}
\label{corollary_two_user_optimality}
If the system has two users and satisfies monotonicity in payoffs, then -LDF policies are feasibility optimal. 
\end{corollary}

Note that in a two-user scenario, the property of monotonicity in payoffs simply means a user gets higher payoff under the higher priority than its payoff under the lower priority. 
In Section \ref{subsection_multiple_classes_of_users} we will consider systems serving two classes of exchangeable users and use this corollary to show the optimality of LDF-like policies. 

\subsection{Efficiency Ratio Analysis}

When the conditions in Theorem \ref{thm_sufficient_condition_for_LDF_optimality} do not hold, one can still study the efficiency ratio, see e.g., \cite{JLS07}, to evaluate the performance of -LDF policies. 
\begin{definition}
The {\bf efficiency ratio} of the -LDF policy is defined as

\end{definition}
Clearly  equals to  if and only if the -LDF policy is feasibility optimal. 




If a system does not satisfy subset payoff equivalence, i.e., for some subset of users  the vectors in  are not on the same hyperplane, we can characterize the ``heterogeneity'' of these vectors based on the following notion. 

\begin{definition}
Given a subset of users , the {\bf subset payoff ratio}  for  is defined as

\end{definition}
The optimal  is such that the projections of the vectors in  on  are as close to each other as possible. 

Clearly if the vectors in  are on the same hyperplane, then  and the optimal  is the normal vector to the hyperplane. Intuitively,  characterizes the degree to which the vectors in  deviate from being on the same hyperplane. 

This notion enables us to characterize the efficiency ratio of -LDF for a given system. 

\begin{theorem}
\label{thm_efficiency_ratio}
If the system satisfies monotonicity in payoffs, the efficiency ratio of the -LDF policy is such that

\end{theorem}

\infocomStart
See the extended version of this paper \cite{EXT2} for the proof. 
\commentEnd\fi
\extendedStart
\noindent See Appendix \ref{appendix_pf_thm_efficiency_ratio} for the proof. 
\commentEnd\fi
Intuitively, the bottleneck of the efficiency ratio is the subset  where  is the smallest. 

Note that by picking any , we can get lower bounds on  for all subsets  by placing its projection  into (\ref{align_subset_payoff_ratio}). Thus, any  enables us to construct a lower bound on . A trivial option is , where for each subset  the value of  represents the sum payoff of users in  under decision . 
\dissertationStart
In the sequel we will consider specific resource and user models in SRT context and explore other options of  to evaluate -LDF's efficiency. 
\commentEnd\fi

We have shown that the efficiency and optimality of the -LDF policies is related to . 
Understanding and analyzing the geometry of  can in principle enable us to provide feedback to the designers of priority-based resource allocation mechanisms regarding which specific priority decision or set of priority decisions are problematic and bottlenecks for the system so that the designers can focus on improving the resource allocation for these problematic decisions. 
For example, in the conceptual setting shown in Figure~{\ref{fig_eg_for_B_intersect_C}}, the priority decision corresponding to the lower left circle is the ``bottleneck'' of the system and should be targeted to make the dominant of the convex hull as small as possible. 
This is of particular interest for some practical systems where it is possible to get explicit knowledge of  which reflect the underlying priority-based resource allocation, e.g., by collecting data over a long time. 


A priority decision is problematic if the associated underlying resource allocation suffers from resource contention, blocking among users/applications, or even deadlocks on compute resources, etc. 
Based on feedback regarding the bottlenecks, the designer could improve the associated resource allocation schemes, e.g., by increasing the processing speed of the certain computing resources, spending more energy, reducing the contention, and/or resolving the blocking/deadlock, and thus, improve the efficiency of the overall system under the -LDF prioritization policies.  

\section{Examples for -LDF's Optimality}
Theorem \ref{thm_sufficient_condition_for_LDF_optimality} gives a sufficient condition for -LDF to be feasibility optimal. 
One example system that satisfies these conditions is the model considered in prior work \cite{HoK12} which, as mentioned in Section \ref{sec_introduction}, can be viewed as a single-resource geometric-workload model. 
In this section we consider more system settings and show how our results provide useful insights in practice. 
\dissertationStart
Theorem \ref{thm_sufficient_condition_for_LDF_optimality} gives us a sufficient condition for -LDF policies to be feasibility optimal. In this section we consider the soft real-time setting and discuss several examples that satisfy those conditions. 

Recall that in SRT setting users are periodically generating streams of tasks that need to complete before deadline and  represents the expected number of tasks/sub-tasks completed on time, or the expected quality of task processing results per period under priority decision . To verify the conditions in Theorem \ref{thm_sufficient_condition_for_LDF_optimality}, we verify the subset payoff equivalence property. 
\commentEnd\fi

\subsection{Exchangeable Expected Payoffs}

We shall start by showing that for systems that are ``symmetric'', -LDF policies are feasibility optimal. 

\begin{definition}
A subset of users  is said to have {\bf exchangeable expected payoffs} if, for all priority decisions  and all , if we switch the priorities of user  and  and use  to represent the resulting new priority decision, then

\end{definition}
In other words, exchanging the priorities of two users in  will simply exchange their expected payoffs without impacting that of other users. 
This would be true if the priority-based resource allocation were symmetric for users in  and the users generate tasks with identically distributed or exchangeable workloads. 

If the users in  have exchangeable expected payoffs, we can verify the property of subset payoff equivalence by picking  for each subset of users .
Therefore, by Theorem \ref{thm_sufficient_condition_for_LDF_optimality} we get the following corollary. 

\begin{corollary}
\label{corollary_exchangeable expected_workloads}
If the set of users  have exchangeable expected payoffs and the system satisfies monotonicity in payoffs, then the -LDF policies are feasibility optimal. 
\end{corollary}

\noindent See Appendix \ref{appendix_pf_corollary_exchangeable expected_workloads} for the proof. 

\subsection{Multiple Classes of Exchangeable Users and Hierarchical-LDF}
\label{subsection_multiple_classes_of_users}
In this subsection, we first consider a system supporting two classes of exchangeable users. 
Formally, a class of users is {\em exchangeable} if they have exchangeable expected payoffs and the same QoS requirement. 
The users in different classes may have distinct payoffs and QoS requirements. 
In some contexts it is of practical interest to first prioritize the classes and then prioritize users in each class, respectively. We refer to such schemes as using {\em class-based hierarchical prioritization}. 

In practice, depending on whether the priorities of classes can change dynamically, there are two types of class-based hierarchical prioritization: Type  where the class priorities are fixed, and Type  where one can dynamically prioritize classes of users, and then users within each class. 

The first type of hierarchical prioritization might correspond to a setting where the users/applications are separated into human-interactive/high-QoS and background-processing/low-QoS categories \cite{PCO}, and it is always desirable to first process high-QoS users. In this setting, the problem is reduced to a collection of independent user prioritization problems similar to the one considered in this paper. By Corollary \ref{corollary_exchangeable expected_workloads}, -LDF is feasibility optimal to prioritize users in each class. 

The second type of dynamic hierarchical prioritization might be of interest in systems where switching between processing different user classes involves overheads, and/or where it is inefficient to mix the processing of different user classes, probably because of resource contention or deadlocks. 

In this setting, we propose a class-based {\em hierarchical-LDF} policy that in each period works in two steps by (1) prioritizing classes by LDF based on the aggregate deficits, i.e., the sum of deficits for users in the same class, and (2) prioritizing users in each class according to LDF based on individual users' deficits. 
The framework of hierarchical-LDF is exhibited in Figure{~\ref{fig_hierarchical_LDF}}. 
Note that here LDF can be replaced by -LDF for any  and the following result would hold. 

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.55\textwidth]{Figures/hierarchical_LDF.pdf}
  \caption{The framework for class-based hierarchical-LDF policy. }
  \label{fig_hierarchical_LDF}
\end{figure} 

\begin{theorem}
\label{thm_optimality_hierarchical_LDF}
In a system with two classes of exchangeable users, if the property of monotonicity in payoffs is satisfied, the hierarchical-LDF policy is feasibility optimal among all possible class-based hierarchical prioritization policies. 
\end{theorem}

The proof follows directly from Corollary \ref{corollary_two_user_optimality} and \ref{corollary_exchangeable expected_workloads}. By Corollary \ref{corollary_two_user_optimality} we know the class-based LDF policy is optimal to set priorities amongst the two classes and by Corollary \ref{corollary_exchangeable expected_workloads} we know the LDF-based user prioritization is also optimal for the exchangeable users in each class. 

More generally, for systems serving multiple (more than two) classes of exchangeable users, 
one can view each class as a ``super user'', and define the aggregate payoff and QoS requirement for a super user to be the sum of payoffs and QoS requirements for users in that class, respectively. 
Then the dynamic prioritization of super users can be viewed as the problem considered in this paper. Therefore, by Theorem \ref{thm_sufficient_condition_for_LDF_optimality}, if the system with the super users' expected aggregate payoffs satisfies monotonicity in payoffs and subset payoff equivalence, the LDF policy is a feasibility optimal choice for prioritizing super users and thus, the hierarchical-LDF policy is feasibility optimal among all class-based hierarchical prioritization policies. 
Indeed, all the results we have introduced, e.g., Theorem \ref{theorem_MW_feasibility_optimal}-\ref{thm_efficiency_ratio}, still hold for the prioritization of these super users. 

\dissertationStart
\subsection{Single-Resource Memoryless-Workload (SRMW) Model}

In the exchangeable expected payoff scenario, we verified subset payoff equivalence by picking  as the normal vector of the hyperplane for each subset of users , i.e., the sum service rate  is a constant for decisions . In this subsection we discuss an example that still satisfies subset payoff equivalence but where the sum service rate is not necessarily a constant. 

We consider a special case of the model described in \ref{subsection_SRT_model}. Suppose the system has only one resource, i.e., only one task is processed at a time. Each user generates exactly one task at each period with release time and deadline being the beginning and end of the period, respectively. Again tasks not completed by the deadline are dropped.
We let  be the expected number of timely completed tasks per period under priority decision  and suppose each user  requires  as the long-term average number of completed tasks per period. 
In this setting the workload of a task refers to the required core time to fully complete the task. Note that a task's workload can be large in which case it may not complete on time. 
Suppose in each period, the workload of the task from user  is a memoryless random variable with parameter . (By memoryless random variable we refer to the exponential random variable with  being the rate parameter in the continuous-time scenario and the geometric random variable with  being the success probability in the discrete-time scenario. ) We assume the workloads are independent across users and periods. At each period given priority decision , the system processes the tasks sequentially from highest to lowest priority. Such a model is called {\em single-resource memoryless-workload model with parameters }, or SRMW for short. 

As we have argued in Section \ref{sec_introduction}, the model in prior work \cite{HoK12} can be viewed as a single-resource geometric-workload model, and thus is the discrete version of the SRMW model. In \cite{HoK12} they show that LDF is feasibility optimal, and here in SRMW model we generalize the optimality to the class of -LDF policies

\begin{corollary}
\label{corollary_SCMW}
In the SRMW model, the class of -LDF policies are feasibility optimal. 
\end{corollary}

See the appendix for the proof. 
\commentEnd\fi

\dissertationStart
This subsection should also go to dissertation, probably with the following paragraph. 

This SRMW model is a generalized version of the system model in \cite{HoK12}. The work in \cite{HoK12} studies a discrete-time wireless model where  users are competing to transmit a packet to the server at each period of length  time slots. The deadlines of the packets are the end of the period. If user  is scheduled at a time slot, it successfully transmits the packet with probability  and will re-transmit if it fails until the period ends. Therefore, the workload, i.e., the time to successfully transmit a packet from user  is a geometric random variable with success parameter . In \cite{HoK12} they show that LDF is feasibility optimal.
\commentEnd\fi


\section{Some Practical Issues}
In practice, besides meeting minimum payoff requirements, users may be willing to pay for additional payoffs, e.g., better video quality in the video conferencing setting, albeit at possibly different prices. 
Given the requirements  and the achieved average payoffs , we call  the {\em excess payoff} for each user . While using -LDF policies to fulfill users' payoff requirements, we also want to manage the allocation of excess payoffs across users, perhaps with the aim of maximizing the benefits to the system or users. 

However, the non-negative definition of deficit (\ref{align_deficit_in_general_payoff}) makes it hard to track excess payoffs. For example, consider a model with  users and suppose the payoff is always  for the high priority user and  for the low priority user. 
Suppose the payoff requirement vector is . Since , we know  is feasible and the system can deliver  excess payoff. 
Suppose we use the LDF policy, starting from  it is easy to verify\footnote{Since the payoffs are deterministic, we can verify this by evaluating the deficits for the first few periods and we will observe that the process  evolves in a periodic pattern. } that the system will switch giving high priority to these two users, and thus the achieved average payoff vector is . Clearly User  gets  excess payoff while User  gets nothing. 
This happens because  and  are frequently forced to  from different negative values, which causes the ``unfairness'' between these two users. 

To solve this problem, we modify the deficit definition for each user  and period  as follows, 

i.e., we allow  to be negative. 

Now for the simple example above, if we adopt LDF but based on the possibly negative deficits , we can get achieved average payoff vector . We observe that the two users equally split the excess payoff. 

Intuitively, for each user  the modified deficit  changes roughly linearly as  increases with the slope being . Since -LDF policy aims to balance weighted deficit , we know  is roughly the same for all users.
We will verify this observation in the simulation section and based on this we can manage the excess payoffs across users by picking the appropriate weight vector . 

\dissertationStart
In this section, we will cover some additional practical issues associated with -LDF policies.  

Besides meeting minimum long-term payoff requirements, users in practice may also be willing to pay for additional payoffs, i.e., better QoS, albeit at possibly different prices. 
For example, in the video conferencing setting, users may be willing to pay for better video quality if possible. 
For users that require average payoffs  but actually achieve average payoffs , we call  the {\em excess payoff} for each user . While using -LDF policies to fulfill users' payoff requirements, we also want to manage the allocation of excess payoffs across users, perhaps with the aim of maximizing the relative benefits to the system or users. 

However, the non-negative definition of deficit (\ref{align_deficit_in_general_payoff}) makes it hard to track excess payoffs. For example, consider a model with  users and suppose the payoff is always  for the high priority user and always  for the low priority user. 
Suppose the payoff requirement vector is . Since , we know this payoff requirement is feasible and the system can deliver  excess payoff. 
Suppose we use the LDF policy, starting from  it is easy to verify\footnote{Since the payoffs are deterministic, we can verify this by evaluating the deficits for the first few periods and we will observe that the process  evolves in a periodic pattern. } that the system will switch giving high priority to these two users from period to period, giving the achieved average payoff vector . Clearly User  gets  excess payoff while User  gets nothing. 
This happens because  and  are frequently forced to  from different negative values, which causes the ``unfairness'' between these two users. 

To solve this problem, we modify the deficit definition for each user  and period  as follows, 

i.e., we allow  to be negative. 

Now for the simple example above, if we adopt LDF but based on the possibly negative deficits , we can get achieved average payoff vector . We observe that the two users equally split the excess payoffs. 

Intuitively, for each user  the modified deficit  changes roughly linearly as  increases with the slope being . Since -LDF policy aims to balance weighted deficit , we know  is roughly the same for all users, unless some  cannot be increased/decreased any more which means user  is already always assigned the highest/lowest priority. We will verify this observation in the simulation section and based on this we can manage the excess payoffs for all users  by picking the appropriate weight vector . 
\commentEnd\fi

\add{
Note that for completeness we will need to modify the feasibility definition since the process  is no longer positive recurrent as it may keep decreasing or increasing. 
\infocomStart
Refer to the extended version of this paper \cite{EXT2} for details. 
\commentEnd\fi
\extendedStart
Now we call a payoff requirement vector  feasible if, under some user prioritization policy, for each user  the time-averaged payoff per period is at least . Formally, recall that  is the random payoff for user  in period . As the payoff requirement, each user  requires that

Note that this definition and Definition \ref{defn_feasibility_pr} are just two ways to define the feasibility. With the theorem in \cite{Bla56} we can show that for any user prioritization policy, the sets of feasible QoS requirements under these two different feasibility definitions differ by at most a boundary and thus are equivalent for practical purposes. Therefore, all the results we discuss in this paper hold under both feasibility definitions. 
\commentEnd\fi
}


\section{Simulations}
\label{sec_simulations}
In this section we explore via simulation the impact of weights of -LDF policies. 

Consider an illustrative system with single computing resource serving  soft real-time users. In each period of length , each user generates one task that need to complete by end of the period. We let the non-negative workload, i.e., task service time, distributions for three users be Gamma, Gamma and Gamma, respectively. We pick these workload distributions to make them general and heterogeneous. 
In each period, the payoff for user  is  if user 's task completes and is  otherwise. Accordingly, user 's QoS requirement  represents the long-term task completion ratio. 

We start with initial deficit . In each period, we independently generate task workloads for users and simulate the -LDF policy based on  to pick a priority decision. The single resource sequentially processes users' tasks from highest to lowest priority. 
Tasks not completed on time are dropped. 
All simulations are run for  periods.  
A requirement vector  is feasible if it is dominated by the achieved task completion ratio vector  over the  periods. The vectors  and  are specified in various settings in the sequel. 

Note that in this setting monotonicity in payoffs is satisfied while subset payoff equivalence is not. 

\subsection{Impact of Weights on Long-Term Completion Ratios}
\label{subsection_effect_weights_long_term}

In Table \ref{tab_q_and_q_prime} we consider a requirement vector  that is feasible under the -LDF policies and display the achieved 
 under two different weight vectors . For each weight vector , we verify that  is the same for all three users. 
Contrasting the two lines in Table \ref{tab_q_and_q_prime}, we can see that for a system which can deliver more than required, changing the weight vector reallocates the excess payoffs and gives more excess payoffs to users with smaller weights. 

\begin{table}[h]
\normalsize
	\tbl{Achieved completion ratio vectors under two weight vectors. \label{tab_q_and_q_prime}}{
    \centering
	\begin{tabular}{|c|c|c|c|}
	 \hline
	  &  & Achieved  & 	\\
	 \hline
	 \hline
	 \multirow{2}{*}{} &  &  & 	\\
	 \cline{2-4}
	  &  &  & 	\\
	 \hline
	\end{tabular}
	}
\end{table}

\dissertationStart
\subsection{Impact of Weights on Long-Term Achieved Completion Ratios}
\label{subsection_effect_weights_long_term}
\myComments{This needs further improvement. }
We denote by  the actually achieved long-term time-averaged task completion ratio vector. 
In scenarios where each user has a positive time fraction of being assigned the highest priority under -LDF policy\footnote{In some scenarios, this may not be true. For example, in a two-user scenario, if the requirement of user  is much larger than user  the -LDF policy may end up always assigning user  with the higher priority. But we claim most real-time applications in practice requires a reasonable QoS requirement, making the requirements similar to each other, and therefore, these scenarios are not of great interest. }, we observe that  is the same for each user , where  and  represent the required and achieved completion ratio for user , respectively. 
This is because deficit  roughly\footnote{Because of the randomness, it is not exactly linear change. } changes linearly over periods with slope being , as shown in Figure~\ref{figure_example_deficit}, and -LDF policy aims to balance weighted deficit . 
This is true for both feasible and infeasible requirements. 

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.45\textwidth]{Figures/example_deficit.pdf}
  \caption{An example of the deficits of users in a three-user scenario with a feasible vector of requirements. }
  \label{figure_example_deficit}
\end{figure}

For example one can verify this statement in Table \ref{tab_q_and_q_prime} where we display the achieved completion ratio vectors for a feasible and an infeasible vector of requirements under two different weight vectors. As can be seen, increasing the weight of user  drives the achieved completion ratio  to the 
required  even if the requirement vector  is infeasible, but with the risk of penalizing other users. Conversely, a user with a smaller weight will likely experience a larger deficit or additional completions, depending on the feasibility of the requirements. 





\begin{table}[h]
\normalsize
    \centering
	\begin{tabular}{|c|c|c|c|}
	 \hline
	  &  & Achieved  & 	\\
	 \hline
	 \multirow{4}{*}{} &
	 \multirow{2}{*}{} & \multirow{2}{*}{} & \multirow{2}{*}{}	\\
	 Feasible: &  &  &	\\
	 \cline{2-4}
	  & \multirow{2}{*}{} & \multirow{2}{*}{} & \multirow{2}{*}{}	\\
	  &  &  &	\\
	 \hline
	 \multirow{4}{*}{} &
	 \multirow{2}{*}{} & \multirow{2}{*}{} & \multirow{2}{*}{}	\\
	 Infeasible: &  &  &	\\
	 \cline{2-4}
	  & \multirow{2}{*}{} & \multirow{2}{*}{} & \multirow{2}{*}{}	\\
	  &  &  &	\\
	 \hline
	\end{tabular}
    \caption{Actually achieved completion ratio vectors and the value of  for two QoS requirement vectors under two weight vectors. }
    \label{tab_q_and_q_prime}
\end{table}



Thus, in practice when it is not clear whether a vector of QoS requirements is feasible, one can assign different weights to users based on how the users behave to the gaps between QoS requirements and the achieved completion ratios. 

\commentEnd\fi

\subsection{Characterization of Clustering of Failures and Impact of Weights}
\label{subsection_characterization_of_failure_clustering}
If a user's task is not completed in a period, we call it a failure event. The requirement vector  focuses on long-term task completion ratio, but it would likely be undesirable for a user to experience consecutive or clustered failure events. 
Figure~\ref{figure_clustering_of_failures} gives an example of failure events. 
In this subsection we consider the same  used above and explore the clustering of failures under two -LDF policies. 

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.6\textwidth]{Figures/clustering_of_failures.pdf}
  \caption{Characteristics of clustering of failures. }
  \label{figure_clustering_of_failures}
\end{figure}

We consider Inter-Failure Intervals (IFIs) between typical failures. 
IFI is supported on the set . To quantitatively evaluate the clustering of the failures, we focus on the standard deviation (SD) of the IFIs for each user. 
One extreme case is that failures happen strictly periodically and therefore, the SD is . 
Intuitively, a user with a smaller IFI SD implies that the user experiences less clustered failures. 

Next we introduce an evaluation benchmark. 
For each user , we know  represents the time-averaged failure ratio. 
If the failure happens in each period independently with probability , the IFI can be modeled by a geometric random variable supported on the set  with the parameter being . We use the SD of such a geometric random variable as a benchmark.  

Under some -LDF policy, we define {\em SD ratio} of user  to be the ratio of user 's IFI SD to the SD of the geometric random variable with parameter . 
Table \ref{tab_sd_ifi} shows the SD ratios of three users under two different weight vectors . 
Under , the ratios are less than , indicating that the failures under the LDF policy are less clustered compared to the scheme where failure event happens i.i.d. in each period. 
The last two columns in Table \ref{tab_sd_ifi} indicates that increasing the weight of user  reduces the degree of failure clustering for user  but at the price of other users' more clustered failures. Thus, the users' sensitivities to clustered failures is another factor to consider when one assigns weights to users. 


\begin{table}[h]
\normalsize
    \tbl{Characterization of clustering of failures. \label{tab_sd_ifi}}{
    \centering
    \begin{tabular}{| c || c | c |}
    \hline
    ~ & {\bf SD ratio under} & {\bf SD ratio under}\\
    ~ &  & 	\\
    \hline
    \hline
    {\bf User 1} & 88\% & 39\%	\\
    \hline
    {\bf User 2} & 77\% & 97\%	\\
    \hline
    {\bf User 3} & 92\% & 107\%	\\
    \hline
    \end{tabular}
    }
\end{table}

\dissertationStart
\subsection{Characterization of Clustering of Failures and Impact of Weights}
\label{subsection_characterization_of_failure_clustering}
If a user's task is not completed in a period, we call it a failure event. The QoS requirement focuses on time-averaged task completion ratio, but it would likely be undesirable for a user to experience consecutive or clustered failure events. Here we explore via simulation the clustering of failures.
We first consider LDF policy, i.e., , and the feasible QoS requirement vector  used in \ref{subsection_effect_weights_long_term}. Figure~ \ref{figure_clustering_of_failures} gives an example of failure events. 

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.45\textwidth]{Figures/clustering_of_failures.pdf}
  \caption{Characteristics of clustering of failures. }
  \label{figure_clustering_of_failures}
\end{figure}

We first consider sequences of consecutive failures (including a single failure event) and display the distributions of consecutive failures for our three users in Figure~{\ref{figure_consecutive_failures}}. Clearly isolated failure instances are the most likely (i.e., with probability , ,  for three users, respectively) but there is a chance (albeit small) of seeing  or  consecutive failures. 

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.4\textwidth]{Figures/consecutive_failures.pdf}
  \caption{The distribution of consecutive failures. }
  \label{figure_consecutive_failures}
\end{figure}

Next we consider Inter-Failure Intervals (IFIs) between typical failures. 
IFI is supported on the set . To quantitatively evaluate the clustering of the failures, we focus on the standard deviation of the IFIs. 
One extreme case is that failures happen periodically and therefore, the standard deviation is . 
We consider a benchmark called i.i.d. randomly distributed failures scheme (IID-F) where failure happens in each period independently with the same probability. 
In this benchmark IFI is a geometrically distributed random variable. 
To make it a fair comparison, we set the parameter of the benchmark to be the actual time-averaged failure probability under LDF. 
We further define {\em relative degree of failure clustering} for a user  to be the ratio of the standard deviation of user 's IFIs under LDF to that in IID-F.
The standard deviations of IFIs under LDF and IID-F and their ratios are shown in Table \ref{tab_sd_ifi}. 
The results exhibit that under LDF policy the failures are less clustered compared to the IID-F benchmark and the three users have similar relative degree of failure clustering. 

\begin{table}[h]
\normalsize
    \centering
    \begin{tabular}{| c | c | c | c |}
    \hline
    ~ & {\bf LDF Policy} & {\bf IID-F} & {\bf LDF/IID-F}\\
    \hline
    {\bf User 1} & 5.83 & 6.77 & 86\%	\\
    \hline
    {\bf User 2} & 4.90 & 5.84 & 84\%	\\
    \hline
    {\bf User 3} & 4.40 & 5.12 & 86\%	\\
    \hline
    \end{tabular}
    \caption{Standard deviations of inter failure intervals with . }
    \label{tab_sd_ifi}
\end{table}

Changing the weights also impacts the clustering of failures. 

We consider the same requirement  but with a different weight vector . We conduct the same analysis for IFIs and exhibit the results in Table \ref{tab_sd_ifi_different_weights}. 
The standard deviations in IID-F are different from those in Table \ref{tab_sd_ifi} because of the different achieved completion ratios driven by the weight vectors. 
The ratios in the last columns of Table \ref{tab_sd_ifi} and \ref{tab_sd_ifi_different_weights} indicate that increasing the weight of user  induces a smaller relative degree of failure clustering for user  but at the price of other users' more clustered failures. Thus, the users' sensitivities to clustered failures is another factor to consider when one assigns weights to users. 

\begin{table}[h]
\normalsize
    \centering
    \begin{tabular}{| c | c | c | c |}
    \hline
    ~ & {\bf -LDF Policy} & {\bf IID-F} & {\bf -LDF/IID-F}\\
    \hline
    {\bf User 1} & 4.43 & 5.85 & 76\%	\\
    \hline
    {\bf User 2} & 7.27 & 6.21 & 117\%	\\
    \hline
    {\bf User 3} & 5.93 & 5.41 & 110\%	\\
    \hline
    \end{tabular}
    \caption{Standard deviations of inter failure intervals with . }
    \label{tab_sd_ifi_different_weights}
\end{table}
\commentEnd\fi


\section{Conclusion}
Resource allocation in complex systems supporting real-time users with general QoS requirements can be relatively ``easy''. One can in principle design the system to allow priority-based resource allocation and adopt simple -LDF policies to dynamically prioritize users/applications. 
Our theory provides guidance towards understanding the suboptimality and even optimality of such solutions and how to improve the system design. 
For future work, it would be interesting to explore the management of real-time users across systems and/or sharing with non real-time traffic. 





\huaweiStart
\section*{Acknowledgment}
This research was supported by Huawei Technologies Co. Ltd. 
The authors would like to thank Alan Gatherer, Zheng Lu, Haishan Zhu and Mattan Erez for their comments and feedbacks on this work. 
\commentEnd\fi

\bibliography{diss_myown}{}
\bibliographystyle{ACM-Reference-Format-Journals}

\section{Appendix}

\subsection{Proof of Lemma \ref{lemma_R_in_close_C}}
\label{appendix_pf_lemma_F_in_close_C}
Given , since it is feasible there exists a user prioritization policy  that fulfills , i.e., the Markov chain  is positive recurrent, which implies there exists a stationary distribution over the state space. Since  is a stationary policy that picks  based on , by Ergodic Theorem each priority decision  is selected with some time fraction  such that  . If we consider  as a queue, the average arrival   should not be bigger than the average departure which is given by  since otherwise  goes a.s. to infinity and the chain cannot be positive recurrent. 

Therefore, 

which implies . 

\subsection{Proof of Theorem \ref{theorem_MW_feasibility_optimal}}
\label{appendix_pf_thm_MW_feasibility_optimal}
We start by introducing a lemma. 

\begin{lemma}
\label{lemma_feasibility_region_projection_understanding}
A payoff requirement vector  is in  if and only if, for any non-negative vector , there exists a priority decision , such that


Equivalently,  is in  if and only if, for any , 

\end{lemma}

To understand this lemma, since any vector in  is dominated by some , we consider for simplicity a . Such a vector can be expressed as a convex combination of expected payoff vectors, i.e., , where 
 and 


Now we have


This actually proves the necessity of the condition. The formal proof is shown below. 

\begin{proof}[Proof of Lemma \ref{lemma_feasibility_region_projection_understanding}]
Given a payoff requirement vector , by definition of , we know that  lying in set  is equivalent to the {\em feasibility} of the following set of linear equations and inequalities, 



The condition in Lemma \ref{lemma_feasibility_region_projection_understanding} is equivalent to the {\em infeasibility} of 


By strong duality \cite{BoV09} it is easy to prove that set (\ref{align_feasible_set}) being feasible is equivalent to set (\ref{align_infeasible_set}) being infeasible and this concludes the proof. 
\end{proof}

\begin{proof}[Proof of Theorem \ref{theorem_MW_feasibility_optimal}]
By Lemma \ref{lemma_R_in_close_C} we know  and by definition we know . To prove the theorem it suffices to show . We show this by constructing a Lyapunov function and using Foster's theorem. 

Given , the goal is to show  can be fulfilled by the MW policy. 

By definition of interior there exists  such that  where . We define a Lyapunov function as 


In period , we have


Under the MW policy, by (\ref{align_max_weight}) we know that


Since , we get that 

where the last step is true by Lemma \ref{lemma_feasibility_region_projection_understanding}. 

Also since there are finite payoff vectors, we use  to represent an upper bound on all possible payoff values and payoff requirements. 
Therefore, by (\ref{align_drift}) we get that

for  satisfying . 

It is not hard to show\footnote{This is true because given our assumption that requirement  and the payoff vectors are rational valued and have finite options, the state space of process  is in a lattice, see e.g., \cite{CoS13b}.} there are finite states  with . Therefore, by Foster's theorem,  is positive recurrent and  is fulfilled by the MW policy. 
Thus, this shows that . 
\end{proof}

\subsection{Proof of Theorem \ref{thm_R_IB}}
\label{appendix_pf_thm_R_IB_chap2}
We first introduce some further notation. Given two vectors  and , we denote by  the entrywise product. 

For any  and , the goal is to show that  can be fulfilled by the -LDF policy. 

Let . 
By definition of interior there exists an  such that . 
By definition of , there exists a vector  such that  and  satisfy the conditions (\ref{align_R_IB_defn}). 

Consider the following candidate Lyapunov function: 


Note that we consider a process  that is driven by the -LDF policy. In period , by similar analysis as in (\ref{align_drift}) we have that


Let  denote the priority decision selected according to -LDF policy. Thus, We have that

By reordering users according to priorities, we get


By -LDF policy we know . By (\ref{align_R_IB_defn}) we have  for . Therefore, 



Suppose  is an upper bound on all  and , by (\ref{align_LDF_drift_chap2}), we get that

for  satisfying . 

Again, since there are finite states  with , by Foster's Theorem  is positive recurrent and  is fulfilled by the -LDF policy. 

Therefore, for any , we have that


\subsection{Proof of Theorem \ref{thm_visualize_R_IB}}
\label{appendix_pf_thm_visualize_R_IB}
The proof of Theorem \ref{thm_visualize_R_IB} is complicated and we apologize for that. Part of the complication comes from understanding how the property of monotonicity in payoffs characterizes the geometry of the region . Further, a feasible payoff requirement implies feasibilities for all user subsets, and thus we need to look at the projections in all subspaces. 

Figure~\ref{fig_outline_pf_thm_3} gives the high-level outline for the proof of Theorem \ref{thm_visualize_R_IB}. There are two parts which involve the technical results Lemma \ref{lemma_q_S_in_C_S} and \ref{lemma_finding_nonnegative_beta}, which we will state in the proof. In order to allow the reader follow the proof, we defer their own proof to later. 

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.85\textwidth]{Figures/outline_pf_thm_3.pdf}
  \caption{Outline for the proof of Theorem \ref{thm_visualize_R_IB}. }
  \label{fig_outline_pf_thm_3}
\end{figure}

\begin{lemma}
\label{lemma_q_S_in_C_S}
If a system satisfies monotonicity in payoffs, then for all  and all subsets of users , . 
\end{lemma}

We have argued in Section \ref{subsection_characterizing_R_IB} that  does not necessarily equal to the projection of region  on the subspace of  in general, but the statement is true if the system satisfies monotonicity in payoffs. Please refer to Appendix \ref{pf_lemma_q_S_in_C_S} for detailed proof of this lemma. 

Given a subset of users , for two vectors  and , we say  if  for any . 
We define the subspace of  as . 

For a region  which lies in the subspace of , we denote by  the relative interior of , i.e., the interior of , relative to the subspace of . 
Similarly we use ,  to represent the relative closure and boundary of  in the subspace of , respectively. 

Following the definition of region  in Definition \ref{defn_concave_hull}, we can express int and cl as below, 

By definition, we know  and  are closed sets. We can also show\footnote{This is clear from the definition of  and . We omit the proof to save space. }


Next we prove Theorem \ref{thm_visualize_R_IB} in two parts:  and . 

{\bf Part I of the proof: }

We start with the easy part and first show .

Given , by definition, there exists  such that for all subsets of users , 

i.e., 




To show , by (\ref{align_cl_R}) we need to show for all subsets of users  that . 

Since , by Lemma \ref{lemma_q_S_in_C_S} we have . 

Now suppose for some subset of users , . By definition of  and interior, there exists  such that  and , which implies that


\newcommand*{\cvxCombPar}{c}

Since , there exists  such that  and . Therefore, 

which is contradicted to (\ref{equ_alpha_S_q_S}). Therefore,  and thus , implying that . 

{\bf Part II of the proof: }

For the second part we show .

Given , by (\ref{align_int_R}), we know for all , . The goal is to show , i.e., to find an  such that for all subsets of users , 


We start with the following lemma which is proved in Appendix \ref{pf_lemma_finding_nonnegative_beta} in the sequel. 

\begin{lemma}
\label{lemma_finding_nonnegative_beta}
If \modelSatisfyPriorityImplication, given , for each subset of users , there exists nonzero , such that for all  where ,  

\end{lemma}

Given Lemma \ref{lemma_finding_nonnegative_beta}, by letting  we find  that is very similar to the  we are looking for, except for two differences: (1)  may not be strictly positive, and (2) it is strictly ``less than'' in (\ref{align_beta_strict_smaller_than_condition}). 
The idea is to add a small perturbation to  to construct a strictly positive vector. 

Formally, given Lemma \ref{lemma_finding_nonnegative_beta}, to show  we shall prove the following even stronger statement by induction. 

{\bf Claim 1:} If \modelSatisfyPriorityImplication, given , for each subset of users , there exists  such that for all , 


By Claim 1, let , we can find  satisfying (\ref{align_alpha_S_q_S}) which implies . Therefore, it suffices to prove Claim 1. We prove this by induction on the cardinality  of user set . 

If , clearly Claim 1 is correct. 

Suppose Claim 1 is correct for all  with  where . Given an  with , by Lemma \ref{lemma_finding_nonnegative_beta}, we can find nonzero  satisfying the conditions in Lemma \ref{lemma_finding_nonnegative_beta}. We separate the set  into two sets  and  where


Since , . By induction of Claim 1 on , there exists  such that for any , 


We claim that for small enough , 

satisfies condition (\ref{align_alpha_S_prime_q_S_prime}) for all . 

Any  falls into one of the following two cases:  and . It suffices to show (\ref{align_alpha_S_prime_q_S_prime}) in each case. 

If , then . By (\ref{align_condition_for_S_2}), we know (\ref{align_alpha_S_prime_q_S_prime}) is correct. 

If , then . Let . We know


By Lemma \ref{lemma_finding_nonnegative_beta}, . Since there are finite subsets , for small enough , 


i.e., (\ref{align_alpha_S_prime_q_S_prime}) holds true. 

In summary, this proves Claim 1 and thus . Therefore, . 

\subsection{Proof of Lemma \ref{lemma_q_S_in_C_S}}
\label{pf_lemma_q_S_in_C_S}
First we introduce a further notation. Given a decision  and a user set , we let  represent the decision that satisfies
\begin{longitem}
\item . 
\item For users  or , if  has higher priority than  in , then  also has higher priority than  in decision . 
\end{longitem}
In other words,  is the priority decision obtained by modifying decision  to assign highest priorities to users in  without changing the relative orders in and out of , respectively. 

Given that the system satisfies monotonicity in payoffs, for all , we have that


Given , the goal is to show  for all subsets of users . 
By definition of , there exists a convex combination of vectors in  that dominates , i.e., there exists  such that 

and . 

Therefore, for any subset of users , 

which by (\ref{align_m_d_S}) gives


We let . Since , we know  , and by definition of , 


\subsection{Proof of Lemma \ref{lemma_finding_nonnegative_beta}}
\label{pf_lemma_finding_nonnegative_beta}
Given , by (\ref{align_int_R}) we know that for all subsets of users , . 
Given a subset of users , the goal is to find  which satisfies the requirements in Lemma \ref{lemma_finding_nonnegative_beta}. 
In this proof, we focus on the subspace of . 

Since , there exists  such that . Since  and , we know that connecting  and  intersects  at some point denoted by . By the closure property of ,  and thus, . 
Since , we get that  lies on a supporting hyperplane \cite{BoV09} of , and by definition of , there exists nonzero normal vector  of this supporting hyperplane such that


Figure~\ref{fig_finding_beta_in_pf_Lemma_4} conceptually shows the process of constructing . The circles represent the expected payoff vectors. For simplicity we suppress the superscript  in the figure. 
We shall show this  satisfies the requirements in Lemma \ref{lemma_finding_nonnegative_beta}. 

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.65\textwidth]{Figures/finding_beta_in_pf_Lemma_4.pdf}
  \caption{The process of constructing  when  equals to  (left figure), and when  is larger than  (right figure). }
  \label{fig_finding_beta_in_pf_Lemma_4}
\end{figure}

Since , there exists  such that , and by (\ref{align_v_is_minimum}), we get that

The vector  is also shown in Figure{~\ref{fig_finding_beta_in_pf_Lemma_4}}. 

On the other hand, since , by similar analysis as in (\ref{align_cvx_greater_than_min}) we know that


Thus, 

which implies  if . Since , for all subset  where , we have that


Therefore, to show (\ref{align_beta_strict_smaller_than_condition}) it suffices to show for all  where  that


Given , we write  where  and . 

For all  where , we can rewrite  as follows,


To show (\ref{align_beta_S_prime_u_S_prime}), it suffices to show that


Suppose  and  are the optimal solutions for (\ref{align_sum_S_minus_S_prime}) and (\ref{align_sum_S_prime}), respectively. Formally, 



We consider the unique decision  that satisfies the following: 
First, , i.e.,  assigns highest priority to users in . 
Second, the priority ordering for user subset  in  are the same as those in . 
Third, the priority ordering for user subset  in  are the same as those in . 

Since , we know  and therefore, 


Now it suffices to show that


This is true because given that the system satisfies monotonicity in payoffs, we can get that

and


In summary, this proves (\ref{align_beta_S_prime_u_S_prime}) and thus  satisfies the conditions in Lemma \ref{lemma_finding_nonnegative_beta}. 

\subsection{Proof of Theorem \ref{thm_sufficient_condition_for_LDF_optimality}}
\label{appendix_pf_thm_sufficient_condition_for_LDF_optimality}

Clearly . 
To show , by (\ref{align_A_vs_R_LDF}) it suffices to show . 

Given , the goal is to show , i.e., for all user subsets , 


Given a user subset , by Lemma \ref{lemma_q_S_in_C_S} we know . Further we can show  since otherwise . By definition of interior and , there exists  such that .  

Suppose , by definition there exists  such that . Now we get two vectors  and . Since vectors in  lie on a hyperplane and , there exists nonzero  such that

which contradicts with . 

Therefore,  and thus . 

\subsection{Proof of Theorem \ref{thm_efficiency_ratio}}
\label{appendix_pf_thm_efficiency_ratio}

Given monotonicity in payoffs, by (\ref{align_A_vs_R_LDF}) we know  and  differs from  by at most a boundary. By the definition of the efficiency ratio, we know


To show , it suffices to show , i.e., for each , we have , which is equivalent to showing that for each , there exists a subset of users , such that . 

Given a , we define  which represents how far the vector  can extend before it goes beyond the region  and let . We claim there exists a user subset  such that  since otherwise we can increase  while guaranteeing  is still in . 
Next we shall show , i.e., . 

Since , there exists  such that . Since , by Lemma \ref{lemma_q_S_in_C_S} we know  and thus, there exists  such that . 

Given that , for any nonzero , we have that


By  and , we get that


Since , by similar analysis as in (\ref{align_cvx_greater_than_min}) we know . Similarly we can show . Thus, 

Clearly,  for any nonzero . 

Since (\ref{align_min_projection_leq_ratio_max_projection}) is true for any nonzero , we get that


Therefore, for each , there exists a subset of users  such that , and thus,
. 

\subsection{Proof of Corollary \ref{corollary_exchangeable expected_workloads}}
\label{appendix_pf_corollary_exchangeable expected_workloads}
By Theorem \ref{thm_sufficient_condition_for_LDF_optimality}, to show -LDF policies are feasibility optimal, it suffices to show the system satisfies subset payoff equivalence. To show this, it suffices to show for all user subsets  and all priority decisions  that 


This is true because we can convert  to  by repeatedly switching a pair of users in  at each step such that at step  both decisions assign the highest  priorities to the same users, respectively. By the definition of exchangeable expected payoffs, the sum of the expected payoffs for users in  remains the same at each step. 





\dissertationStart
\appendix
\section{Some Further Explanations}
\subsection{TODO for this paper}
\begin{enumerate}
\item Make the shadowed areas in the figures thicker. 
\item Can I use package multirow? Change looking for tables. 
\item Work on defn of feasibility, i.r., p.r.. 
\item Finish proof of corollary 1. Refer to 6.28 - 7.3 page 43. 
\item We should explain that LDF is not optimal. Maybe give the example that we use in the group presentation. 
\item stand on the reader's point of view: is it clear? 
\item What we discuss in the beginning has to be super clear and convincing. 
\item If we discuss something in the sequel, mention that! E.g., the simulation setup if it is incomplete. 
\item Re-go over comments for sigmetrics review. 
\item Are we missing any simple generalization? E.g., energy consumption. 
\item Improve system model using ``lattice''. 
\item generalization of payoff model: considering iid and Markovian arrivals, and the scheduler knows about the arrival for current period. 
\item consider to generalize general payoff model to  not just . 
\item Re-go over comments for sigmetrics review. 
\end{enumerate}

\subsection{TODO for dissertation}
\begin{enumerate}
\item Give examples to illustrate the difference between our sufficient condition and Walrand's work. 
\end{enumerate}
\commentEnd\fi

\end{document}
