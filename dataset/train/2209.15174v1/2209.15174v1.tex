\subsection{Effect of Band Split Bandwidth}
\label{sec:bandwith}

The band split bandwidth  needs to be manually defined and may affect the performance. We first select seven different options for  and compare the models:
\begin{enumerate}
    \item \textit{V1}: We evenly split the entire spectrogram by a 1k Hz bandwidth (remainders are merged to the last subband). This results in 22 subbands.
    \item \textit{V2}: We split the frequency band below 16k Hz by a 1k Hz bandwidth, the frequency band between 16k Hz and 20k Hz by a 2k Hz bandwidth, and treat the rest as one subband. This results in 19 subbands.
    \item \textit{V3}: We split the frequency band below 8k Hz by a 1k Hz bandwidth, split the frequency band between 8k Hz and 16k Hz by a 2k Hz bandwidth, treat the frequency band between 16k Hz and 20k Hz as one subband, and treat the rest as another subband. This results in 14 subbands.
    \item \textit{V4}: We split the frequency band below 1k Hz by a 100 Hz bandwidth, split the frequency band between 1k Hz and 8k Hz by a 1k Hz bandwidth, split the frequency band between 8k Hz and 16k Hz by a 2k Hz bandwidth, treat the frequency band between 16k Hz and 20k Hz as one subband, and treat the rest as another subband. This results in 23 subbands.
    \item \textit{V5}: We split the frequency band below 1k Hz by a 100 Hz bandwidth, split the frequency band between 1k Hz and 16k Hz by a 1k Hz bandwidth, split the frequency band between 16k Hz and 20k Hz by a 2k Hz bandwidth, and treat the rest as one subband. This results in 28 subbands.
    \item \textit{V6}: We split the frequency band below 1k Hz by a 100 Hz bandwidth, split the frequency band between 1k Hz and 4k Hz by a 500 Hz bandwidth, split the frequency band between 4k Hz and 8k Hz by a 1k Hz bandwidth, split the frequency band between 8k Hz and 16k Hz by a 2k Hz bandwidth, treat the frequency band between 16k Hz and 20k Hz as one subband, and treat the rest as another subband. This results in 26 subbands.
    \item \textit{V7}: We split the frequency band below 1k Hz by a 100 Hz bandwidth, split the frequency band between 1k Hz and 4k Hz by a 250 Hz bandwidth, split the frequency band between 4k Hz and 8k Hz by a 500 Hz bandwidth, split the frequency band between 8k Hz and 16k Hz by a 1k Hz bandwidth, split the frequency band between 16k Hz and 20k Hz by a 2k Hz bandwidth, and treat the rest as one subband. This results in 41 subbands.
\end{enumerate}

Table~\ref{tab:bandwidth} provides the vocal extraction performance evaluated by the uSDR metric across the MUSDB18-HQ test set. We can see that the performance of \textit{V1} to \textit{V3} remain on par, but \textit{V4} provides a significant gain. Given that the main difference between \textit{V3} and \textit{V4} is the split of finer subbands below 1k Hz, it shows that lower frequency bands are important for the model to successfully estimate more accurate spectrograms, and a possible explanation is that the frequency band below 1k Hz typically covers the fundamental frequency and the first few harmonics of the vocal track, which enables the band modeling RNN to better capture the F0 information and to better estimate higher frequency components. As more subbands are split at lower frequency parts from \textit{V4} to \textit{V7}, the performance continues to improve, further showing that a fine-grained band-splitting scheme is essential for BSRNN to get better performance. Moreover, we further perform a small-scale grid search and use the following band split bandwidths for the \textit{bass}, \textit{drum} and \textit{other} tracks in MUSDB18:
\begin{enumerate}
    \item \textit{Bass}: We split the frequency band below 500 Hz by a 50 Hz bandwidth, split the frequency band between 500 Hz and 1k Hz by a 100 Hz bandwidth, split the frequency band between 1k Hz and 4k Hz by a 500 Hz bandwidth, split the frequency band between 4k Hz and 8k Hz by a 1k Hz bandwidth, split the frequency band between 8k Hz and 16k Hz by a 2k Hz bandwidth, and treat the rest as one subband. This results in 30 subbands.
    \item \textit{Drum}: We split the frequency band below 1k Hz by a 50 Hz bandwidth, split the frequency band between 1k Hz and 2k Hz by a 100 Hz bandwidth, split the frequency band between 2k Hz and 4k Hz by a 250 Hz bandwidth, split the frequency band between 4k Hz and 8k Hz by a 500 Hz bandwidth, split the frequency band between 8k Hz and 16k Hz by a 1k Hz bandwidth, and treat the rest as one subband. This results in 55 subbands.
    \item \textit{Other}: We use the same band split scheme as \textit{vocals} (i.e., \textit{V7} above).
\end{enumerate}

We empirically find that different instrument tracks may have their own superior band split schemes than that for \textit{vocals}. Given that different instruments can have different frequency ranges, harmonic patterns and mixing techniques, the observation shows that such a priori knowledge or expert knowledge may play an important role in exploring intrinsic characteristics of different musical instruments. Note that adjusting the band split bandwidths may further improve the model performance, and here we do not perform exhaustive grid search for the sake of simplicity.

\begin{table}[!htbp]
    \centering
    \small
    \caption{Performance on vocal extraction for BSRNN models with different band split bandwidths.}
    \begin{tabular}{c|c|c|c|c|c|c|c|c}
    \toprule
        Bandwidth & V1 & V2 & V3 & V4 & V5 & V6 & V7 \\
        \hline
        uSDR & 8.15 & 8.21 & 8.06 & 9.51 & 9.57 & 9.78 & \textbf{10.04} \\
    \bottomrule
    \end{tabular}
    \label{tab:bandwidth}
\end{table}

\begin{table}[!htbp]
    \centering
    \small
    \caption{Performance on vocal extraction for BSRNN models with different evaluation segment hop sizes.}
    \begin{tabular}{c|c|c|c|c}
    \toprule
        Hop size (s) & 0.5 & 1 & 1.5 & 3 \\
        \hline
        uSDR & \textbf{10.04} & 10.00 & 9.94 & 9.75 \\
    \bottomrule
    \end{tabular}
    \label{tab:hop}
\end{table}

\begingroup
\setlength{\tabcolsep}{4pt}
\begin{table*}[!ht]
    \centering
    \scriptsize
    \caption{Comparison with existing models on MUSDB18-HQ (HQ) and MUSDB18 (nHQ) dataset.}
    \begin{tabular}{c|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc}
    \toprule
        \multirow{3}{*}{Model} & \multicolumn{4}{c|}{Vocals} & \multicolumn{4}{c|}{Bass} & \multicolumn{4}{c|}{Drum} & \multicolumn{4}{c|}{Other} & \multicolumn{4}{c}{All} \\
        \cline{2-21}
         & \multicolumn{2}{c|}{uSDR} & \multicolumn{2}{c|}{cSDR} & \multicolumn{2}{c|}{uSDR} & \multicolumn{2}{c|}{cSDR} & \multicolumn{2}{c|}{uSDR} & \multicolumn{2}{c|}{cSDR} & \multicolumn{2}{c|}{uSDR} & \multicolumn{2}{c|}{cSDR} & \multicolumn{2}{c|}{uSDR} & \multicolumn{2}{c}{cSDR} \\
         \cline{2-21}
         & HQ & nHQ & HQ & nHQ & HQ & nHQ & HQ & nHQ & HQ & nHQ & HQ & nHQ & HQ & nHQ & HQ & nHQ & HQ & nHQ & HQ & nHQ \\
         \hline
         ResUNetDecouple+ \cite{kong2021decoupling} & -- & -- & -- & 8.98 & -- & -- & -- & 6.04 & -- & -- & -- & 6.62 & -- & -- & -- & 5.29 & -- & -- & -- & 6.73 \\
         CWS-PResUNet \cite{liu2021cws} & -- & -- & 8.92 & -- & -- & -- & 5.93 & -- & -- & -- & 6.38 & -- & -- & -- & 5.84 & -- & -- & -- & 6.77 & -- \\
         KUIELab-MDX-Net \cite{kim2021kuielab} & -- & -- & 8.97 & 9.00 & -- & -- & 7.83 & 7.86 & -- & -- & 7.20 & 7.33 & -- & -- & 5.90 & 5.95 & -- & -- & 7.47 & 7.54 \\
         Hybrid Demucs \cite{defossez2021hybrid} & -- & -- & 8.13 & 8.04 & -- & -- & \textbf{8.76} & \textbf{8.67} & -- & -- & 8.24 & 8.58 & -- & -- & 5.59 & 5.59 & -- & -- & 7.68 & 7.72 \\
         \hline
         BSRNN & 10.04 & 9.92 & 10.01 & 10.21 & 6.80 & 6.77 & 7.22 & 7.51 & 8.92 & 8.68 & 9.01 & 8.58 & 6.01 & 5.97 & 6.70 & 6.62 & 7.94 & 7.84 & 8.24 & 8.23 \\
         \quad\quad + finetuning & \textbf{10.47} & \textbf{10.36} & \textbf{10.47} & \textbf{10.53} & 7.20 & 7.17 & 8.16 & 8.30 & \textbf{9.66} & \textbf{9.46} & \textbf{10.15} & \textbf{9.65} & \textbf{6.33} & \textbf{6.27} & \textbf{7.08} & \textbf{7.00} & \textbf{8.42} & \textbf{8.32} & \textbf{8.97} & \textbf{8.87} \\
         \hline
    \bottomrule
    \end{tabular}
    \label{tab:all}
\end{table*}
\endgroup

\subsection{Effect of Evaluation Segment Hop Size}
\label{sec:hop}

Table~\ref{tab:bandwidth} reports model performance with the default evaluation segment hop size of  seconds. We also report the model performance with different segment hop sizes here. Table~\ref{tab:hop} shows the uSDR scores with models with four different hop sizes and a fixed segment size of  seconds. We can see that choosing any  can result in a performance improvement, and the reason can be because the overlap-add operation smooths the outputs and mitigates the noise or distortion introduced. We can also find that decreasing  from 1.5 to 0.5 does not provide significant gain while linearly increases the processing time with the extra segments. This shows that although we choose  for the experiments here, in practice one can choose  for a balance between processing speed and performance.

\subsection{Comparison with State-of-the-art Systems}

Here we compare the BSRNN model with existing state-of-the-art systems on both MUSDB18 and MUSDB18-HQ dataset. We choose the top-ranking systems in the Music Demixing (MDX) Challenge 2021 \cite{mitsufuji2021music} as the baselines. We report the results before and after the semi-supervised finetuning stage for BSRNN for all the four tracks. For the other systems, the best reported numbers found in all available literatures are reported. Table~\ref{tab:all} presents the results on both MUSDB18 and MUSDB18-HQ dataset on both uSDR and cSDR metrics. We can observe that BSRNN trained only on MUSDB18-HQ dataset outperforms all existing systems on \textit{vocal}, \textit{drum} and \textit{other} tracks on both MUSDB18 and MUSDB18-HQ dataset, and performs slightly worse on \textit{bass} track. Possible explanations for this observation are that the energy rescaling process in our data mixing procedure might not be well suited for bass as empirically bass is not as strong as other instruments in a song, and the band-split scheme needs further investigation to better capture low- and mid-frequency range information where bass lies in. Regarding the semi-supervised finetuning stage, we observe that all tracks are able to obtain a performance gain, especially for \textit{bass} and \textit{drum} tracks where we can observe an around 1 dB improvement on the cSDR metric. Compared to existing semi-supervised methods described in Section~\ref{sec:semi}, our self-boosting finetuning pipeline is evaluated on all instrument tracks instead of a vocal or speech only task, and the experiments are also conducted on 44.1k Hz sample rate signals instead of 16k Hz sample rate signals. Moreover, our pipeline does not lead to a gradually increased model size as \cite{tzinis2022remixit}, and does not need external modules that require separate training procedures as \cite{defossez2019demucs, wang2021semi}. This proves that the proposed semi-supervised finetuning stage has the potential to become a more universal pipeline for general source extraction or separation tasks.