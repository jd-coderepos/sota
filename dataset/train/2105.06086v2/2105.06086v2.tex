

\documentclass[final]{cvpr}

\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}

\usepackage{caption}
\usepackage{subcaption}


\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false]{hyperref}

\newcommand{\tablestyle}[2]{\setlength{\tabcolsep}{#1}\renewcommand{\arraystretch}{#2}\centering\footnotesize}
\makeatletter\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}
  {.5em \@plus.2ex \@minus.2ex}{-.5em}{\normalfont\normalsize\bfseries}}\makeatother
\usepackage{amssymb,booktabs,tabulary,multirow}

\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\newcolumntype{x}[1]{>{\centering\arraybackslash}p{#1pt}}
\newlength\savewidth\newcommand\shline{\noalign{\global\savewidth\arrayrulewidth
  \global\arrayrulewidth 0.2pt}\hline\noalign{\global\arrayrulewidth\savewidth}}

\def\cvprPaperID{55} \def\confYear{CVPR 2021}


\pagenumbering{gobble}
\begin{document}

\title{HINet: Half Instance Normalization Network for Image Restoration}

\author{Liangyu Chen \thanks{Equally contribution.}\hspace{20pt} Xin Lu \footnotemark[1] \hspace{20pt} Jie Zhang\hspace{20pt} Xiaojie Chu \hspace{20pt} Chengpeng Chen\\ 
{} MEGVII Technology \hspace{20pt} {} Fudan University \hspace{20pt} {} Peking University\\
{\tt\small \{chenliangyu,luxin,chenchengpeng\}@megvii.com}\\
{\tt\small j\_zhang19@fudan.edu.cn \hspace{20pt} chuxiaojie@stu.pku.edu.cn}\\
}
\maketitle


\begin{abstract}
   In this paper, we explore the role of Instance Normalization in low-level vision tasks. Specifically, we present a novel block: Half Instance Normalization Block (HIN Block), to boost the performance of image restoration networks. 
   Based on HIN Block, we design a simple and powerful multi-stage network named HINet, which consists of two subnetworks. With the help of HIN Block, HINet surpasses the state-of-the-art (SOTA) on various image restoration tasks. For image denoising, we exceed it 0.11dB and 0.28 dB in PSNR on SIDD dataset, with only 7.5\% and 30\% of its multiplier-accumulator operations (MACs),  and  speedup respectively. For image deblurring, we get comparable performance with 22.5\% of its MACs and  speedup on REDS and GoPro datasets. For image deraining, we exceed it by 0.3 dB in PSNR on the average result of multiple datasets with  speedup. With HINet, we won the 1st place on the NTIRE 2021 Image Deblurring Challenge - Track2. JPEG Artifacts, with a PSNR of 29.70. The code is available at \url{https://github.com/megvii-model/HINet}.
\end{abstract}

\vspace{-0.2cm}
\section{Introduction}
Normalization is widely used in high-level computer vision tasks: Batch Normalization~\cite{ioffe2015batch} and IBN~\cite{pan2018two} in classification~\cite{ma2018shufflenet}, Layer Normalization~\cite{ba2016layer} in DETR~\cite{carion2020end} and GroupNorm~\cite{wu2018group} in FCOS~\cite{tian2019fcos} for detection \etc. Besides, Instance Normalization~\cite{ulyanov2017improved} is used to style/domain transfer~\cite{pan2018two, huang2017arbitrary} tasks. However, the simple application of normalization to low-level computer vision problems can be suboptimal. For example, Batch Normalization can't improve the performance of the network in super-resolution~\cite{lim2017enhanced}.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.47\textwidth]{figures/visual_3.pdf}
    \vspace{-0.2cm}
    \caption{Visualized results of HINet on various image restoration tasks. Left: degraded image. Right: the predicted result of HINet. From top to bottom: image denoising, image deblurring, and image deraining task respectively.}
    \label{fig:visual_3}
    \vspace{-0.2cm}
\end{figure}

In this paper, we carefully integrate Instance Normalization as building blocks to advance the network performance in image restoration tasks. Specifically, we present a Half Instance Normalization Block (HIN Block). Based on HIN Blocks, we further propose a multi-stage network called HINet, which consists of two subnetworks. By stacking HIN Block in each subnetwork's encoder, the receptive field at each scale is expanded, and the robustness of features is also improved. In addition to the architecture of each stage, we adopt cross-stage feature fusion~\cite{zamir2021multi} and supervised attention module~\cite{zamir2021multi} between two stages to enrich the multi-scale features and facilitate achieving performance gain respectively. 




Compared with the state-of-the-art architecture MPRNet~\cite{zamir2021multi}, HINet surpasses it on various image restoration tasks. For image denoising, we exceed it 0.11 dB and 0.28 dB in PSNR on SIDD~\cite{abdelhamed2018high} dataset, with only 7.5\% and 30\% of its multiplier-accumulator operations (MACs),  and  speedup respectively. For image deblurring, we get comparable performance with 22.5\% of its MACs and  speedup on REDS~\cite{nah2019ntire} and GoPro~\cite{nah2017deep} datasets. For image deraining, we exceed it by 0.3 dB in PSNR on the average result of multiple datasets following~\cite{Zamir2021MPRNet}, with  speedup. Visualized results of various image restoration tasks are shown in Figure~\ref{fig:visual_3}. In addition, we apply HIN to various models and various datasets, the results demonstrate the generalization ability of HIN. For example, with the help of HIN, DMPHN~\cite{Zhang_2019_CVPR} increased 0.42 dB in PSNR on GoPro~\cite{nah2017deep} dataset. 



Our contributions can be summarized as follows:
\begin{itemize}
   \item We carefully integrate Instance Normalization as building blocks and proposed a Half Instance Normalization Block. To the best of our knowledge, it is the first model to adopt normalization \emph{directly} with state-of-the-art performance in image restoration tasks.
   \item Based on HIN Block, we design a multi-stage architecture, HINet, for image restoration tasks, and achieves the state-of-the-art performance with fewer MACs and inference time compares to the SOTA method~\cite{zamir2021multi}.
   \item Extensive experiments are conducted to demonstrate the effectiveness of our proposed HIN Block and HINet. With the help of HIN Block and HINet, we won 1st place on the NTIRE 2021 Image Deblurring Challenge - Track2. JPEG Artifacts~\cite{nah2021ntire}, with a PSNR of 29.70.
\end{itemize}

\section{Related Work}


\subsection{Normalization in low-level computer vision tasks:}
Normalization has become an essential component in high-level computer vision tasks (especially Batch Normalization) but is rarely used in low-level computer vision tasks. ~\cite{nah2017deep} modified the ResBlock~\cite{he2016deep} by removing batch normalization since they trained the model with a mini-batch of size 2 in deblur. ~\cite{lim2017enhanced} removed batch normalization in super-resolution, which the batch normalization get rid of range flexibility from networks.  As the disharmony between image restoration tasks and Batch Normalization (BN) discussed in ~\cite{yu2018wide}, image restoration tasks commonly use small image patches and small mini-batch size to train the network, which causes the statistics of BN unstable. Moreover, the image restoration task is a per-image dense pixel value prediction task, which is scale sensitivity. While BN is usually helpful in scale insensitive tasks. 


In addition to the above, Instance Normalization~\cite{ulyanov2016instance} is proposed to replace Batch Normalization in ~\cite{ulyanov2016texture} to improve the performance of the style transfer task. ~\cite{huang2017arbitrary} demonstrates Instance Normalization is the normalization of low-level features to some extent. They proposed adaptive instance normalization to the style transfer task by aligning the channel-wise statistics in Instance Normalization of style image to content image. Based on ~\cite{huang2017arbitrary}, ~\cite{kim2020transfer} adopts an adaptive instance normalization as a regularizer to build denoiser and transfers knowledge learned from synthetic noise data to the real-noise denoiser.
Unlike ~\cite{kim2020transfer}, we extend the Instance Normalization as a method of feature enhancement and apply it to the image restoration tasks \emph{directly} without transfer learning. 

\subsection{Architectures for Image Restoration }

The single-stage methods are widely used in image restoration tasks, and these methods generally improve the network capacity through the complex network structure~\cite{anwar2020densely, zhang2018density}. The multi-stage methods decompose the complex image restoration task into smaller easier sub-tasks, employing a lightweight subnetwork at each stage. ~\cite{fu2019lightweight} introduce the mature Gaussian-Laplacian image pyramid decomposition technology to the neural network, and uses a relatively shallow network to handle the learning problem at each pyramid level. ~\cite{ren2019progressive} proposes a progressive recurrent network by repeatedly unfolding a shallow ResNet~\cite{he2016deep}, and introduces a recurrent layer to exploit the dependencies of deep features across stages. ~\cite{zhang2019deep} proposes a deep stacked hierarchical multi-patch network. Each level focus on different scales of the blur and the finer level contributes its residual image to the coarser level. ~\cite{zamir2021multi} proposes a multi-stage progressive image restoration architecture, where there are two encoder-decoder subnetworks and one original resolution subnetwork. ~\cite{zamir2021multi} also proposes a supervised attention module (SAM) and a cross-stage feature fusion (CSFF) module between every two stages to enrich the features of the next stage. Our model also uses these two modules to facilitate achieving significant performance gain and uses two simple U-Nets ~\cite{ronneberger2015u} as the subnetworks.



\begin{figure*}
    \centering
    \includegraphics[width=0.96\textwidth]{figures/pipeline.pdf}
    \caption{Proposed Half Instance Normalization Network (HINet). The encoder of each subnetwork contains Half Instance Normalization Blocks (HIN Block). For simplicity, we only show 3 layers of HIN Block in the figure, and HINet has a total of 5 layers. We adopt CSFF and SAM modules from MPRNet~\cite{Zamir2021MPRNet}.}
    \label{fig:pipeline}
    \vspace{-0.2cm}
\end{figure*}

\section{Approach}
In this section, we provide more detailed explanations about HINet and HIN Block in the following subsections. Specifically, we introduce HINet in \ref{HINet} and HIN Block in \ref{HIN Block}.

\subsection{HINet}
\label{HINet}
The architecture of our proposed Half Instance Normalization Network (HINet) is shown in Figure~\ref{fig:pipeline}. HINet consists of two subnetworks, each of which is a U-Net ~\cite{ronneberger2015u}. 
As for U-Net in each stage, we use one  convolutional layer to extract the initial features. Then those features are input into an encoder-decoder architecture with four downsamplings and upsamplings. We use convolution with kernel size equal to 4 for downsampling, and use transposed convolution with kernel size equal to 2 for upsampling. In the encoder component, we design Half Instance Normalization Blocks to extract features in each scale, and double the channels of features when downsampling. In the decoder component, we use ResBlocks~\cite{he2016deep}  to extract high-level features, and fuse features from the encoder component to compensate for the loss of information caused by resampling. As for ResBlock, we use leaky ReLU~\cite{maas2013rectifier} with a negative slope equal to 0.2 and remove batch normalization. Finally, we get the residual output of the reconstructed image by using one  convolution.

We use cross-stage feature fusion (CSFF) module and supervised attention module (SAM) to connect two subnetworks, where these two modules come from~\cite{zamir2021multi}. As for CSFF module, we use  convolution to transform the features from one stage to the next stage for aggregation, which helps to enrich the multi-scale features of the next stage. As for SAM, we replace the  convolutions in the original module with  convolutions and add bias in each convolution. By introducing SAM, the useful features at the current stage can propagate to the next stage and the less informative ones will be suppressed by the attention masks~\cite{zamir2021multi}.

In addition to the network architecture, we use Peak Signal-to-Noise Ratio (PSNR)
as the metric of the loss function, which is PSNR loss. Let  denotes the input of subnetwork , where  is the batch size of data,  is the number of channels,  and  are spatial size.  denotes the final predict of subnetwork , and  is the ground truth in each stage. Then we optimize HINet end-to-end as follows:



\begin{figure}
    \centering
    \includegraphics[width=0.47\textwidth]{figures/HIN_Block.pdf}
    \vspace{-0.1cm}
    \caption{Proposed Half Instance Normalization Block (HIN Block) and ResBlock in details.}
    \label{fig:HIN_block}
    \vspace{-0.3cm}
\end{figure}

\subsection{Half Instance Normalization Block}
\label{HIN Block}
Because of variance of small image patches differ a lot among mini-batches and the different formulations of training and testing~\cite{yu2018wide}, BN\cite{ioffe2015batch} is not commonly used in low-level tasks~\cite{ledig2017photo,lim2017enhanced}. Instead, Instance Normalization (IN) keeps the same normalization procedure consistent in both training and inference. Further, IN re-calibrates the mean and variance of features without the influence of batch dimension, which can keep more scale information than BN. We use IN to build Half Instance Normalization Block (HIN block). By introducing HIN block, the modeling capacity of HINet is improved (as shown in Figure~\ref{fig:more_iters}). Moreover, the extra parameters and computational cost introduced by IN can be ignored.

As shown in Figure~\ref{fig:HIN_block} a. HIN block firstly takes the input features  and generates intermediate features  with  convolution, where / is the number of input/output channels for HIN block. Then, the features  are divided into two parts (). The first part  is normalized by IN with learnable affine parameters and then concatenates with  in channel dimension. HIN blocks use IN on the half of the channels and keep context information by the other half of the channels. Later experiments will also show that this design is more friendly to features in shallow layers of the network. After the concat operation, the residual features  are obtained by passing features to one  convolution layer and two leaky ReLU layers, which is shown in Figure~\ref{fig:HIN_block} a. Finally, HIN blocks output  by add  with shortcut features (obtained after  convolution).

\section{Experiments}
We evaluate our approach on multiple datasets across image restoration tasks. We report the standard metrics in image restoration including PSNR and SSIM. The datasets used for training are described next.
\subsection{Implementation Details}
\paragraph{Datasets}
As in ~\cite{Zamir2021MPRNet}, we train our models on SIDD~\cite{abdelhamed2018high} for image denoising, GoPro~\cite{nah2017deep} for image deblurring, and 13,712 clean-rain image pairs (for simplicity, denoted as Rain13k in the following) gathered from ~\cite{fu2017removing,li2016rain,yang2017deep,zhang2018density,zhang2019image} for image deraining. In addition, we use REDS~\cite{nah2019ntire} dataset for image deblurring with JPEG artifacts, and we denote it as REDS dataset for simplicity. For evaluation, we follow the setting in the NTIRE 2021 Challenge on Image Deblurring~\cite{nah2021ntire}, \ie use 300 images in the validation set of REDS, denoted as REDS-val-300 next. 


\paragraph{Training}
The networks are trained with Adam optimizer. The learning rate is set to  by default, and decreased to  with cosine annealing strategy~\cite{loshchilov2016sgdr}. We train our models on  patches with a batch size of 64 for  iterations. We apply flip and rotation as data augmentation.
Following ~\cite{zhang2018shufflenet}, we customize the network to the desired complexity by applying a scale factor  on the number of channels, \eg ``HINet '' denotes scaling the number of channels in basic HINet  times. 

\begin{table}
\centering
\tablestyle{5pt}{1.05}\setlength{\tabcolsep}{1.mm}\begin{tabular}{l|cc}
& \multicolumn{2}{|c}{SIDD~\cite{abdelhamed2018high}}\\
Method & PSNR & SSIM\\ 
\hline
DnCNN~\cite{zhang2017beyond}&23.66&0.583\\
MLP~\cite{burger2012image}&24.71&0.641\\
DM3D~\cite{dabov2007image}&25.65&0.685\\
CBDNet~\cite{guo2019toward}&30.78&0.801\\
RIDNet~\cite{anwar2019real}&38.71&0.951\\
AINDNet~\cite{kim2020transfer}&38.95&0.952\\
VDN~\cite{yue2019variational}&39.28&0.956\\
SADNet~\cite{chang2020spatial}&39.46&0.957\\
DANet+~\cite{yue2020dual}&39.47&0.957\\
CycleISP~\cite{Zamir2020CycleISP}&39.52&0.957\\
MPRNet~\cite{Zamir2021MPRNet}&39.71&0.958\\
\hline
HINet (\textbf{ours})&\underline{39.82}&0.958\\
HINet (\textbf{ours})&\textbf{39.99}&0.958\\
\end{tabular}
\vspace{-0.2cm}
\caption{Denoising comparisons on SIDD~\cite{abdelhamed2018high} dataset.  denotes the methods that use additional training data. Best and second best scores are \textbf{highlighted} and \underline{underlined}. Our HINet achieves 0.28 dB absolute improvement in PSNR over the previous best method MPRNet~\cite{Zamir2021MPRNet}.}
\label{tab.SIDD.results}
\vspace{-0.2cm}
\end{table}




\begin{table}
\centering
\tablestyle{5pt}{1.05}\setlength{\tabcolsep}{1.mm}\begin{tabular}{l|cc}
& \multicolumn{2}{|c}{GoPro~\cite{nah2017deep}}\\
Method & PSNR & SSIM\\
\hline
Xu et al.~\cite{xu2013unnatural} & 21.00 & 0.741\\
Hyun et al.~\cite{hyun2013dynamic} & 23.64 & 0.824\\
Whyte et al.~\cite{whyte2012non} & 24.60 & 0.846\\
Gong et al.~\cite{gong2017motion} & 26.40 & 0.863\\
DeblurGAN~\cite{kupyn2018deblurgan}& 28.70 & 0.858\\
Nah et al.~\cite{nah2017deep} & 29.08 & 0.914\\
Zhang et al.~\cite{zhang2018dynamic} & 29.19 & 0.931\\
DeblurGAN-v2~\cite{kupyn2019deblurgan} & 29.55 & 0.934\\
SRN~\cite{tao2018scale} & 30.26 & 0.934\\
Gao et al.~\cite{gao2019dynamic} & 30.90 & 0.935\\
DBGAN~\cite{zhang2020deblurring} & 31.10 & 0.942\\
MT-RNN~\cite{park2020multi} & 31.15 & 0.945\\
DMPHN~\cite{Zhang_2019_CVPR} & 31.20 & 0.940\\
Suin et al.~\cite{suin2020spatially} & 31.85 & 0.948\\
MPRNet~\cite{Zamir2021MPRNet} & \underline{32.66} & \textbf{0.959}\\
\hline
HINet (\textbf{ours}) & \textbf{32.77} & \textbf{0.959}\\
\end{tabular}
\vspace{-0.2cm}
\caption{Deblurring comparisons on GoPro~\cite{nah2017deep} dataset. Best and second best scores are \textbf{highlighted} and \underline{underlined}. Our HINet achieves 0.11 dB absolute improvement in PSNR over the previous best method MPRNet~\cite{Zamir2021MPRNet}.}
\label{tab.GoPro.results}
\vspace{-0.4cm}
\end{table}



\begin{table*}
\centering
\tablestyle{5pt}{1.05}\setlength{\tabcolsep}{1.mm}\begin{tabular}{l|cccccccccc|cc}
& \multicolumn{2}{c}{Test100~\cite{zhang2019image}}& \multicolumn{2}{c}{Rain100H~\cite{yang2017deep}}& \multicolumn{2}{c}{Rain100L~\cite{yang2017deep}}& \multicolumn{2}{c}{Test2800~\cite{fu2017removing}}& \multicolumn{2}{c}{Test1200~\cite{zhang2018density}}& \multicolumn{2}{|c}{Average}\\
Method&PSNR & SSIM&PSNR &SSIM &PSNR & SSIM & PSNR & SSIM & PSNR & SSIM & PSNR & SSIM\\
\hline
DerainNet~\cite{fu2017clearing}&22.77 & 0.810 & 14.92 & 0.592 & 27.03 & 0.884 & 24.31 & 0.861 & 23.38 & 0.835 & 22.48 & 0.796\\
SEMI~\cite{wei2019semi} & 22.35 & 0.788 & 16.56 & 0.486 & 25.03 & 0.842 & 24.43 & 0.782 & 26.05 & 0.822 & 22.88 & 0.744\\
DIDMDN~\cite{zhang2018density} & 22.56 & 0.818 & 17.35 & 0.524 & 25.23 & 0.741 & 28.13 & 0.867 & 29.65 & 0.901 & 24.58 & 0.770\\
UMRL~\cite{yasarla2019uncertainty} & 24.41 & 0.829 & 26.01 & 0.832 & 29.18 & 0.923 & 29.97 & 0.905 & 30.55 & 0.910 & 28.02 & 0.880\\
RESCAN~\cite{li2018recurrent}& 25.00 & 0.835 & 26.36 & 0.786 & 29.80 & 0.881 & 31.29 & 0.904 & 30.51 & 0.882 & 28.59 & 0.857\\
PreNe~\cite{ren2019progressive} & 24.81 & 0.851 & 26.77 & 0.858 & 32.44 & 0.950 & 31.75 & 0.916 & 31.36 & 0.911 & 29.42 & 0.897\\
MSPFN~\cite{jiang2020multi} & 27.50 & 0.876 & 28.66 & 0.860 & 32.40 & 0.933 & 32.82 & 0.930 & 32.39 & 0.916 & 30.75 & 0.903\\
MPRNet~\cite{Zamir2021MPRNet} & \underline{30.27} & \underline{0.897} & \underline{30.41} & \underline{0.890} & \underline{36.40} & \underline{0.965} & \underline{33.64} & \underline{0.938} & \underline{32.91} & \underline{0.916} & \underline{32.73} & \underline{0.921}\\
\hline
HINet (\textbf{ours})& \textbf{30.29}& \textbf{0.906} & \textbf{30.65} & \textbf{0.894} & \textbf{37.28} & \textbf{0.970} & \textbf{33.91} & \textbf{0.941} & \textbf{33.05} & \textbf{0.919} & \textbf{33.03} & \textbf{0.926}\\
\end{tabular}
\vspace{-.2cm}
\caption{Deraining comparisons on Test100~\cite{zhang2019image}, Rain100H~\cite{yang2017deep}, Rain100L~\cite{yang2017deep}, Test2800~\cite{fu2017removing} and Test1200~\cite{zhang2018density}. In addition, the average results over these datasets are provided. Best and second best scores are \textbf{highlighted} and \underline{underlined}. Our HINet achieves 0.3 dB absolute improvement in PSNR over the previous best method MPRNet~\cite{Zamir2021MPRNet}.}
\label{tab.Rain13k.results}
\vspace{-0.3cm}
\end{table*}






\begin{table}
\centering
\tablestyle{5pt}{1.05}\setlength{\tabcolsep}{1.mm}\begin{tabular}{l|l|c|rr|rr}
Dataset& Method & PSNR & \multicolumn{2}{c}{MACs(G)} &Time(ms)&speedup\\
\hline
\multirow{3}{4em}{SIDD~\cite{abdelhamed2018high}} & MPRNet~\cite{Zamir2021MPRNet} & 39.71 & 573.50&100\% & 78.8 & \\
&HINet &39.82&42.88&7.5\% & 11.6 & \\
&HINet &39.99&170.71&29.8\% & 27.0& \\
\hline
\multirow{2}{4em}{REDS~\cite{nah2019ntire}} & MPRNet~\cite{Zamir2021MPRNet} & 28.81 & 760.11&100\% & 90.1& \\
&HINet  &28.83&170.71&22.5\% & 27.0 & \\
\hline
\multirow{2}{4em}{GoPro~\cite{nah2017deep}} & MPRNet~\cite{Zamir2021MPRNet} & 32.66 & 760.11&100\% & 90.1 &  \\
&HINet  &32.77&170.71&22.5\% & 27.0 & \\
\hline
\multirow{2}{4em}{Rain13k} & MPRNet~\cite{Zamir2021MPRNet} & 32.73 &141.28&100\% & 37.4 & \\
&HINet  &33.03&170.71&120.8\% & 27.0 & \\
\end{tabular}
\vspace{-.2cm}
\caption{Comparing the PSNR and MACs of MPRNet~\cite{Zamir2021MPRNet} and ours. For Rain13k, we compare the average PSNR over Test100~\cite{zhang2019image}, Rain100H~\cite{yang2017deep}, Rain100L~\cite{yang2017deep}, Test2800~\cite{fu2017removing} and Test1200~\cite{zhang2018density}. MACs and Time are estimated with the input size of . The proportion of the calculations and the speedup compared to MPRNet~\cite{Zamir2021MPRNet} are also listed. Runtimes are computed with the Tesla V100 GPU.}
\label{tab.GmacsCompare}
\vspace{-.3cm}
\end{table}




\subsection{Main Results}
We show the effectiveness of HINet on different datasets in Table~\ref{tab.SIDD.results}, Table~\ref{tab.GoPro.results} and Table~\ref{tab.Rain13k.results}. In addition, we compare the MACs (\ie multiplier-accumulator operations) and inference time of MPRNet~\cite{Zamir2021MPRNet} and HINet in Table~\ref{tab.GmacsCompare}. MACs is estimated when the input is . Moreover, we conduct quality experiments to show the superiority of our method as shown in Figure~\ref{fig:visual_more}.

\paragraph{SIDD~\cite{abdelhamed2018high}} For image denoising, we train our model on the 320 high-resolution images of the SIDD dataset, and test on the 1280 patches from SIDD dataset. The results are shown in Table~\ref{tab.SIDD.results} and Table~\ref{tab.GmacsCompare}. Surprisingly, using only 7.5\% of MPRNet~\cite{Zamir2021MPRNet}'s MACs, our model exceeds it by 0.11 dB in PSNR. Moreover, our model exceeds MPRNet a big margin, 0.28 dB in PSNR under 30\% of the MACs, and is 2.9 times faster than MPRNet.


\paragraph{REDS~\cite{nah2019ntire} and GoPro~\cite{nah2017deep}} For image deblurring, we train our model on REDS~\cite{nah2019ntire} dataset with jpeg compression artifacts, and evaluate the results on REDS-val-300 as we described above. In addition, we conduct experiments on GoPro~\cite{nah2017deep} dataset for image deblurring following ~\cite{Zamir2021MPRNet,Zhang_2019_CVPR} \etc. It contains 2103 image pairs for training and 1111 pairs for evaluation. In Table~\ref{tab.GoPro.results} and Table~\ref{tab.GmacsCompare}, we compare our approach to the state-of-the-art methods. We get a comparable performance to MPRNet~\cite{Zamir2021MPRNet} with only 22.5\% MACs and  speed advantage. It indicates the efficiency of our model. 

\paragraph{Rain13k} For image deraining, we train our model on Rain13k as described above and evaluate results by Y channel in YCbCr color space following ~\cite{jiang2020multi,Zamir2021MPRNet}. It contains 13712 image pairs in the training set, and we evaluate the results on Test100~\cite{zhang2019image}, Rain100H~\cite{yang2017deep}, Rain100L~\cite{yang2017deep}, Test2800~\cite{fu2017removing}, Test1200~\cite{zhang2018density}. We show the results in Table~\ref{tab.Rain13k.results}. HINet achieves 0.3 dB absolute improvement in PSNR over the previous best method MPRNet~\cite{Zamir2021MPRNet} and  faster than it.

\subsection{Ablation}The core idea of HINet lies in HIN Block. We evaluate it from multiple perspectives in this subsection.
It should be noted that these experiments are \emph{not} to achieve the performance of the state-of-the-art, but to illustrate the superiority of HIN on various models and image restoration tasks.
Therefore we mainly use the UNet of the first stage of HINet , without skip connections between encoder and decoder for ablation experiments for fast feedback, and we denoted the UNet as ``HINet Simple'' in next. It is trained on  patches with a batch size of  for  iterations. For optimizer, we follow the settings in ~\cite{Zamir2021MPRNet} except we set the learning rate to  instead of .

\paragraph{The effectiveness of Half Instance Normalization:} 
We conduct experiments on various models and datasets, as we shown in Table~\ref{hin.effectiveness}. 

On REDS~\cite{nah2019ntire} dataset (shown in Table~\ref{hin.effectiveness.REDS}), HIN brings 0.12 dB in PSNR for HINet Simple. 
This illustrates the effectiveness of HIN on the REDS~\cite{nah2019ntire} dataset and HINet Simple model.

On GoPro~\cite{nah2017deep} dataset (shown in Table~\ref{hin.effectiveness.GoPro}), we reimplement the DMPHN(1-2-4-8)~\cite{Zhang_2019_CVPR}. We set the learning rate to  and decreased to  with cosine annealing strategy~\cite{loshchilov2016sgdr}. We train the model on  patches, with a batch size of 32 for  iterations. Flip and rotation are applied as data augmentation. HIN brings 0.42 dB boost in PSNR, it demonstrates HIN is effective on different models and different datasets.

We train PRMID~\cite{wang2020practical} and CycleISP~\cite{Zamir2020CycleISP} on SIDD~\cite{abdelhamed2018high} dataset as shown in Table~\ref{hin.effectiveness.SIDD}. For PRMID, we set the initial learning rate to  with a batch size of 16 for  iterations. For CycleISP, we set the initial learning rate to  with a batch size of 16 for  iterations. Adam optimizer, cosine annealing strategy~\cite{loshchilov2016sgdr} and flip/rotation as data augmentation are adopted in both cases. HIN brings 0.09 dB and 0.06 dB boost in PSNR on PRMID and CycleISP respectively. Since SIDD~\cite{abdelhamed2018high} and GoPro~\cite{nah2017deep}/REDS~\cite{nah2019ntire} are different image restoration task datasets, it demonstrates that HIN is effective in different image restoration tasks.

\begin{table}
    \tablestyle{5pt}{1.05}\setlength{\tabcolsep}{1.mm}\begin{subtable}[h]{0.49\textwidth}
    \centering
      \begin{tabular}{lc|cc}
      &&\multicolumn{2}{c}{REDS~\cite{nah2019ntire}}\\
      Method&HIN?&PSNR&SSIM\\
      \hline
      HINet Simple&- &28.11&0.847\\
      HINet Simple&\checkmark &28.23&0.850\\
\end{tabular}
      \vspace{.1cm}
      \caption{Comparison of the models with/without HIN on REDS~\cite{nah2019ntire} dataset for deblurring. HIN brings 0.12 dB in PSNR to HINet Simple. }
      \label{hin.effectiveness.REDS}
   \end{subtable}
   \begin{subtable}[h]{0.49\textwidth}
   \vspace{.2cm}
   \centering
   \tablestyle{5pt}{1.05}\setlength{\tabcolsep}{1.mm}\begin{tabular}{lc|cc}
      &&\multicolumn{2}{c}{GoPro~\cite{nah2017deep}}\\
      Method&HIN?&PSNR&SSIM\\
      \hline
      DMPHN(1-2-4-8)~\cite{Zhang_2019_CVPR}&- &30.98&0.943\\
      DMPHN(1-2-4-8)~\cite{Zhang_2019_CVPR}&\checkmark &31.40&0.948\\
\end{tabular}
      \vspace{.1cm}
      \caption{Comparison of the models with/without HIN on GoPro~\cite{nah2017deep} dataset for deblurring. HIN brings 0.42 dB in PSNR to DMPHN(1-2-4-8)~\cite{Zhang_2019_CVPR}. It indicates HIN's effectiveness is robust to datasets and models.}
      \label{hin.effectiveness.GoPro}
   \end{subtable}
   \vspace{.15cm}
   \begin{subtable}[h]{0.49\textwidth}
   \centering
   \vspace{.25cm}
   \tablestyle{5pt}{1.05}\setlength{\tabcolsep}{1.mm}\begin{tabular}{lc|c}
   \vspace{.1cm}
   &&\multicolumn{1}{c}{SIDD~\cite{abdelhamed2018high}}\\
      Method&HIN?&PSNR\\
      \hline
      PRMID~\cite{wang2020practical}&- &39.30\\
      PRMID~\cite{wang2020practical}&\checkmark&39.39\\
      \hline
      CycleISP~\cite{Zamir2020CycleISP}&- &39.50\\
      CycleISP~\cite{Zamir2020CycleISP}&\checkmark&39.56\\
   \end{tabular}
   \vspace{.1cm}
   \caption{Comparison of the models with/without HIN on SIDD~\cite{abdelhamed2018high} dataset for denoising. HIN brings 0.09 dB and 0.06 dB in PSNR to PRMID~\cite{wang2020practical} and CycleISP~\cite{Zamir2020CycleISP} respectively. It indicates HIN's effectiveness is robust to image restoration tasks and model size.}
   \label{hin.effectiveness.SIDD}
   \end{subtable}
\vspace{-.1cm}
\caption{To demonstrate the effectiveness of HIN, we conduct experiments on various datasets and models.}
\vspace{-.2cm}
\label{hin.effectiveness}
\end{table}

\paragraph{Comparison with other Normalizations:}
Normalization has not been fully explored in image restoration tasks. We compare HIN with other normalizations to demonstrate the superiority of our proposed HIN. We conduct experiments on REDS~\cite{nah2019ntire} dataset on HINet Simple. The results are shown in Table~\ref{tab:vs.norm}. We denote the HINet Simple w/o. Norm as the baseline in the following. BN~\cite{ioffe2015batch} results a significant performance drop compares to baseline, \ie 0.12 dB in PSNR. We conjure that is because of the inaccurate batch statistics estimation when batch size is small. It is alleviated by SyncBN~\cite{zhang2018context} in some extent, \ie HINet Simple w/. SyncBN brings 0.1 dB gain compares to HINet Simple w/. BN. However, it is still inferior to baseline (28.09 dB vs. 28.11 dB in PSNR). As we can see, with the help of IN~\cite{ulyanov2017improved}, HINet Simple w/. IN exceed baseline by 0.03 dB in PSNR. It indicates IN facilitates the training of image restoration tasks. As shown in Table~\ref{tab:vs.norm}, HIN exceeds its counterparts, and it brings 0.12 dB gain in PSNR compares to baseline. It demonstrates the superiority of our proposed HIN.

\begin{table}[h]
    \centering
    \tablestyle{5pt}{1.05}\setlength{\tabcolsep}{1.mm}\begin{tabular}{l|c}
        Method &PSNR \\
        \hline
        HINet Simple w/o. Norm & 28.11 \\
        HINet Simple w/. BN~\cite{ioffe2015batch} & 27.99\\
        HINet Simple w/. SyncBN~\cite{zhang2018context} &28.09\\
        HINet Simple w/. LN~\cite{ba2016layer} & 28.09 \\
        HINet Simple w/. IN~\cite{ulyanov2017improved} & 28.14 \\
        HINet Simple w/. IBN~\cite{pan2018two} & 28.18 \\
        HINet Simple w/. GN~\cite{wu2018group} & 28.19\\
        \hline
        HINet Simple w/. HIN(\textbf{ours}) & \textbf{28.23}\\
    \end{tabular}
\caption{Comparison of different normalization approaches on the image restoration task. Experiments are conducted on REDS~\cite{nah2019ntire} dataset. HINet Simple w/. BN means a fully normalized model with BN in the encoder.}
\label{tab:vs.norm}
\end{table}

\paragraph{More training iterations:}
We analyze the impact of increasing the number of training iterations based on HINet Simple. We train the model on REDS~\cite{nah2019ntire} dataset for 300k, 600k, and 900k iterations with/without HIN respectively. The results are shown in Figure~\ref{fig:more_iters}. The gap between HINet Simple w/. HIN and HINet Simple w/o. HIN does not decrease as the number of iterations increased. We conjure that this is because HIN increases the upper limit of the model, not just speeds up the convergence.

\begin{figure}
    \centering
    \includegraphics[width=0.48\textwidth]{figures/more_iters.pdf}
    \caption{Effectiveness of HIN when training more iterations.}
    \label{fig:more_iters}
\end{figure}

\paragraph{Guideline of add HIN layer in an existing network:}
HINet Simple consists of 5 encoder blocks and 5 decoder blocks. We further explore the appropriate add location of HIN Block. The results are shown in Table~\ref{tab:HIN.position}. It indicates that adding HIN to all encoder blocks gets the highest score. In addition, adding HIN to the encoder and decoder causes performance drop \ie 28.23 dB to 28.21 dB. It demonstrates that adding more HIN does not necessarily lead to better performance. In practice, add one HIN layer to each encoder block might be a good choice. 

\begin{table}[h]
    \centering
    \tablestyle{5pt}{1.05}\setlength{\tabcolsep}{1.mm}\begin{tabular}{l|ccccc|c|c}
    &\multicolumn{5}{c|}{Encoder}&\\
    Method&1&2&3&4&5&Decoder&PSNR\\
\hline
         \multirow{12}{6em}{HINet Simple} &-&-&-&-&-&-&28.11\\
         &\checkmark&\checkmark&-&-&-&-&28.15\\
         &-&\checkmark&\checkmark&-&-&-&28.19\\
         &-&-&\checkmark&\checkmark&-&-&28.19\\
         &-&-&-&\checkmark&\checkmark&-&28.21\\
         &\checkmark&\checkmark&\checkmark&-&-&-&28.19\\
         &-&\checkmark&\checkmark&\checkmark&-&-&28.20\\
         &-&-&\checkmark&\checkmark&\checkmark&-&28.21\\
         &\checkmark&\checkmark&\checkmark&\checkmark&-&-&28.21\\
         &-&\checkmark&\checkmark&\checkmark&\checkmark&-&28.22\\
         &\checkmark&\checkmark&\checkmark&\checkmark&\checkmark&-&\textbf{28.23}\\
         &\checkmark&\checkmark&\checkmark&\checkmark&\checkmark&\checkmark&28.21\\
    \end{tabular}
    \caption{Guideline of add HIN layer in an existing network (\eg HINet Simple): adding HIN to all encoder blocks gets highest score, while more HIN does not necessarily lead to better performance.}
\label{tab:HIN.position}
\end{table}

\subsection{Extension to HINet:}
In order to achieve better performance on NTIRE 2021 Image Deblurring Challenge Track2. JPEG artifacts~\cite{nah2021ntire}, we extend HINet, and adopt test time augmentation strategy. To further enhance the performance, we ensemble 3 similar models. In this subsection, we discuss the impact of these three methods on the results. And at the end, the results of the development phase and the test phase are provided. The results are evaluated on REDS-val-300, except the test phase result.

\paragraph{Wider, Deeper:} 
It has been demonstrated that scaling up the model from width and depth improves the model capacity~\cite{tan2019efficientnet,yu2018wide}. For width, we simply use HINet . For depth, we add two residual blocks at the end of each encoder block and decoder block.
It achieves a PSNR of 29.05 dB on REDS-val-300.

\paragraph{Test Time Augmentation and Ensemble:}
We adopt flip and rotation as test time augmentation. It brings about 0.14 dB in PSNR. In addition, we randomly crop hundreds of patches, randomly adopt flip and rotation augmentation on them. It brings about 0.05 dB in PSNR. We simply average the predictions of 3 models as a model ensemble. It brings about 0.01 dB in PSNR. With these strategies, our model boost PSNR from 29.05 dB to 29.25 dB.

\paragraph{Development phase result:}
For the development phase, we randomly crop 720 patches. The results are shown in Table~\ref{result.devphase}.

\begin{table}[]
    \centering
    \tablestyle{5pt}{1.05}\setlength{\tabcolsep}{1.mm}\begin{tabular}{l|ccc}
    Participants & PSNR & SSIM & rank\\
    \hline
        \textbf{ours} & \textbf{29.25} & \textbf{0.8190} & 1 \\
         participant A & \underline{29.17} & \underline{0.8183} & 2\\
         participant B & 29.14 & 0.8170 & 3\\
         participant C & 29.11 & 0.8171 & 4\\
         participant D & 29.10 & 0.8165 & 5\\
         participant E & 29.01 & 0.8141 & 6\\
         participant F & 28.94 & 0.8145 & 7\\
         participant G & 28.75 & 0.8093 & 8\\
         participant H & 28.68 & 0.8103 & 9\\
         participant I & 28.66 & 0.8082 & 10\\
    \end{tabular}
    \vspace{-0.1cm}
    \caption{Development phase result of NTIRE 2021 Image Deblurring Challenge Track 2. JPEG artifacts~\cite{nah2021ntire}. Best and second best scores are \textbf{highlighted} and \underline{underlined}. Our proposed method outperform others by 0.08 dB in PSNR.}
    \label{result.devphase}
\end{table}

\paragraph{Test phase result:}
For the test phase, we randomly crop 1000 patches. The results are shown in ~\ref{result.testphase}.

\begin{table}\centering
\tablestyle{5pt}{1.05}\setlength{\tabcolsep}{1.mm}\begin{tabular}{l|ccc}
Participants & PSNR & SSIM & rank\\
\hline
\textbf{ours} & \textbf{29.70} & \underline{0.8403} & 1\\
Noah\_CVLab & \underline{29.62} & 0.8397 & 2\\
CAPP\_OB & 29.60 & 0.8398 & 3\\
Baidu & 29.59 & 0.8381 & 4\\
SRC-B & 29.56 & 0.8385 & 5\\
Mier & 29.34 & 0.8355 & 6\\
VIDAR & 29.33 & \textbf{0.8565} & 7\\
DuLang & 29.17 & 0.8325 & 8\\
TeamInception & 29.11 & 0.8292 & 9\\
Giantpandacv & 29.07 & 0.8286 & 10\\
Maradona & 28.96 & 0.8264 & 11\\
LAB FHD & 28.92 & 0.8259 & 12\\
SYJ & 28.81 & 0.8222 & 13\\
Dseny & 28.26 & 0.8081 & 14\\
IPCV IITM & 27.91 & 0.8028 & 15\\
DMLAB & 27.84 & 0.8013 & 16\\
Blur Attack & 27.41 & 0.7887 & 17\\
\end{tabular}
\vspace{-0.1cm}
\caption{NTIRE 2021 Image Deblurring Challenge Track 2. JPEG artifacts result~\cite{nah2021ntire}. Best and second best scores are \textbf{highlighted} and \underline{underlined}. We exceed other participants over 0.08 dB in PSNR.}
\label{result.testphase}
\end{table}

\section{Conclusion}

In this work, we reuse Normalization in image restoration tasks. Specifically, we introduce Instance Normalization into a residual block and design an effective and efficient block: Half Instance Normalization Block (HIN Block). In HIN Block, we apply Instance Normalization for half of the intermediate features and keep the content information at the same time. Based on HIN Block, we further propose a multi-stage network called HINet. Between each stage, we use feature fusion and attention-guided map~\cite{zamir2021multi} across stages to ease the flow of information and enhance the multi-scale feature expression. Our proposed HINet surpasses the SOTA on various image restoration tasks. In addition, by using HINet, we won 1st place on the NTIRE 2021 Image De-blurring Challenge - Track2. JPEG Artifacts~\cite{nah2021ntire}.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.87\textwidth]{figures/visual_more_bak.png}
    \caption{More visualized results of HINet on various image restoration tasks. For each image pair, the left one is degraded and the right one is predicted by HINet.}
    \label{fig:visual_more}
\end{figure*}


\clearpage
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
