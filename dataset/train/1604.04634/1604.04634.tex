\documentclass[journal]{IEEEtran}
\usepackage{newcent}
\usepackage{graphicx, color}
\usepackage{amsmath, amssymb}
\usepackage{subfig}
\usepackage{soul}
\usepackage{url}
\usepackage{wasysym}
\expandafter\def\expandafter\UrlBreaks\expandafter{\UrlBreaks \do\a\do\b\do\c\do\d\do\e\do\f\do\g\do\h\do\i\do\j \do\k\do\l\do\m\do\n\do\o\do\p\do\q\do\r\do\s\do\t \do\u\do\v\do\w\do\x\do\y\do\z\do\A\do\B\do\C\do\D \do\E\do\F\do\G\do\H\do\I\do\J\do\K\do\L\do\M\do\N \do\O\do\P\do\Q\do\R\do\S\do\T\do\U\do\V\do\W\do\X \do\Y\do\Z}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{cite}
\usepackage[]{algorithm2e}
\definecolor{mygreen}{rgb}{0,0.6,0}
\usepackage{listings}
\lstset{language=Java,
  showspaces=false,
  showtabs=false,
  tabsize=4,
  breaklines=true,
  showstringspaces=false,
  breakatwhitespace=true,
  commentstyle=\color{mygreen},
  keywordstyle=\color{blue},
  stringstyle=\color{red},
  basicstyle=\ttfamily,
  basicstyle=\footnotesize,
  moredelim=[il][\textcolor{grey}]{
\begin{split}
m(1,2)+ & m(2,3)+m(3,b)+m(b,d)<m(1,a)+m(a,d) \\
& \Rightarrow m(b,d) < m(a,d)
\end{split}

\begin{split}
m(3,2)+ & m(2,1)+m(1,a)+m(a,d)<m(3,b)+m(b,d) \\
& \Rightarrow m(a,d) < m(b,d)
\end{split}

\forall k\in [1,K], \, \forall d\in\overline{N}_k, \, \forall r\in R_k, \, \forall \vec{m}\in M_k:

e(r,d,\vec{m}) = b' \,\,\,\, \text{if} \,\,\,\, \delta (r,b',d,\vec{m}) = \min\{ \delta (r,b,d,\vec{m}) | b\in B_k \}

\vec{q}(k,\vec{m}) = (|R_k(b_1,\vec{m})|,\ldots , |R_k(b_\beta,\vec{m})|)

\delta (r_1,b_1) + m(b_1) < \delta (r_1,b_2) + m(b_2)

\delta (r_2,b_2) + m(b_2) < \delta (r_2,b_1) + m(b_1)

c_1 < m(b_1)-m(b_2) < c_2 

c_1=\delta (r_2,b_2)-\delta (r_2,b_1) < c_2=\delta (r_1,b_2)-\delta (r_1,b_1)\tag{}

c_1 > m'(b_1)-m'(b_2) > c_2

\Delta_k^\text{max} = \max\{\delta(r,b)-\delta(r',b') | r,r'\in R_k, \, b,b'\in B_k\}

\text{Minimize } \, \sum_{k\in[1,K]} \kappa(k)

\forall y\in Y, \, \forall k\in [1,K]: \,\, \kappa(k) \geq y_a\cdot \varepsilon(k) +y_b

\forall k\in [1,K]: \,\, \varepsilon(k) = \sum_{n\in N} \gamma(n,k)

\forall n\in N: \,\,
\mu(n) + \sum_{k\in[1,K]} \gamma(n,k) = 1

\forall k\in [1,K], \, \forall i,j\in N \text{ with } (i,j) \in L:

\gamma(i,k) - \mu(i) \geq \gamma(j,k)

\sum_{n\in N} \mu(n) \leq \text{MAX}

\text{Minimize}\,\,\,\,\,\, \sum_{\ell\in L} \sum_{t\in T} \psi(\ell , t) \cdot cost(t)

\forall \ell\in L: \,\,\sum_{p\in P} \rho(p) \cdot tr(p, l) \cdot dm(p) 
\leq \sum_{t\in T} \psi(\ell , t) \cdot cp(t) \cdot u_\text{max}
\label{eq1}
\forall f\in F: \,\, \sum_{p\in P} \rho(p) \cdot cr(f,p)=1
\label{eq2}
\forall k\in [1,K], \,\, \forall p\in P, \,\,  \forall d\in\overline{N}_k \,\, \text{with} \,\, dst(p,d):\\
\rho(p) \leq \sum_{\vec{m}\in M_k} \varphi (\vec{m}, d) \cdot cons(p,\vec{m}) \,\,\,\,\,\,\,\,\,
\label{eq3}
\forall k\in [1,K], \,\, \forall d\in \overline{N}_k:   \,\,\, \sum_{\vec{m} \in M_k} \varphi (\vec{m},d) =1

\text{Minimize}\,\,\,\,\,\, \sum_{\ell\in L} \kappa(\ell)
\ell\in L, \,\, \forall y\in Y:
\kappa(\ell) \geq y_a \cdot \Bigg( \sum_{f\in F} \bigg( \frac{dm(f)}{cp(\ell)} \sum_{p\in P} \rho(p)\cdot tr(p,\ell) \cdot cr(f,p) \bigg) \Bigg) + y_b

\text{Minimize:}\,\, \sum_{\ell\in L} \kappa(\ell) + \sum_{\varphi} \varphi \cdot cost(\varphi)

We define the here used cost parameter  for the advertisement of metric vectors as the number of individual metric changes multiplied by a predefined punishment cost. In other words, all components of a metric vector  advertised for a specific destination through failure recovery, which are different from the metric vector advertised for the same destination before the link failure are counted and multiplied with some punishment cost. This punishment cost is then summarized over all metric advertisement variables  and added to the objective function.




















\section{Numerical Analysis}\label{results}
For our performance analysis, we used the Cost266, the Janos-US-CA, and the Nobel-EU topologies from the SNDlib library~\cite{sndlib}. Figure~\ref{results_NE} shows the results of capacity planning in relation to the requirements of an OSPF-controlled network. OSPF is taken as worst case, as no load balancing is applied, whereas all other operational schemes allow to optimize the routing to improve resource utilization, which in turn allows to reduce the link capacities. Figure~\ref{results_NE} compares the capacity requirements in the three different network topologies depending on the used control scheme, whereas the SDN Partitioning results are furthermore classified depending on the actually applied partitioning into sub-domains of the initial topology. The Cost266 topology and the used partitionings into 2, 4, and 10 sub-domains is depicted in Figure~\ref{cost266}, the Janos-US-CA topology with partitionings into 2, 4, 6, and 10 sub-domains is depicted in Figure~\ref{janos}, and the Nobel-EU topology with partitionings into 2, 4, and 6 sub-domains is depicted in Figure~\ref{nobel}. We compare the performance of SDN Partitioning (using the optimization model introduced in Subsect.~\ref{math_ne}) furthermore with full SDN deployment and the most commonly used hybrid SDN/OSPF control plane scheme (denoted as the ``stacked'' hybrid scheme), where all nodes participate in OSPF and hybrid nodes can additionally be configured dynamically with high priority routing rules. For this scheme we assumed that (at least) 50\% of all nodes are SDN-enabled and the optimal location of these nodes was determined based on the location optimization method in~\cite{hybrid_2}. The actual number of SDN-enabled and legacy OSPF nodes is given in the second and third column of Figure~\ref{results_NE}.

\begin{figure}[t] \center
\includegraphics[width=\columnwidth]{./results_NE.pdf}
\caption{Required link capacities in the different topologies depending on the used control plane scheme (normalized to OSPF requirements).}
\label{results_NE} \end{figure}

The evaluation of capacity requirements were carried out as follows: we used the initially unpartitioned network for the ``OSPF'' case, assigned uniform link metrics, and determined the OSPF least cost paths, which resulted in minimum hop count routing. We then assigned uniformly distributed traffic demands to all source-destination pairs in the network and rescaled them all with the same scaling factor, such that the maximum link load is set to 80~Gbit/s. We assigned  minimum capacities to all links such that no link loads exceeds 80\% of the link's capacity. We assumed that link capacities are available in granularities 10~Gbit/s, 40~Gbit/s, and 100~Gbit/s. All other results in Figure~\ref{results_NE} show the minimum capacity requirements of the according control plane scheme after the routing has been optimized under the schemes' individual routing constraints. The first noticeable characteristic of this result is that \emph{all} evaluated schemes are able to save considerable amounts of link capacity compared to OSPF. This was however to be expected, as link utilization is not considered in the routing algorithm of OSPF, which thus can lead to significant capacity wasting. Packets are solely routed via shortest (i.e., least metric cost) paths, which may result in link loads that slightly exceed link capacity granularities (e.g., 11~Gbit/s traffic load necessitates 40~Gbit/s link capacity). More remarkable is however, to what extent SDN Partitioning can keep up with or even outperform the 50\% and 100\% SDN deployment. It can be seen in the figure that the partitioning with the most sub-domains is relatively close to the result of full SDN deployment in each tested topology. We generally conclude that a migration to SDN-enabled devices beyond the requirements of SDN Partitioning (with small sub-domains) can not result in significant further capacity savings. Another remarkable outcome of this evaluation is the fact that SDN Partitioning outperforms stacked hybrid SDN/OSPF operation with only a fraction of the required SDN-enabled nodes. It can finally be seen that even the partitioning into only two sub-domains can considerably improve resource utilization compared to plain OSPF, while the number of required SDN nodes is notably low.

\begin{figure}[t] \center
\includegraphics[width=\columnwidth]{./results_TE.pdf}
\caption{Histograms of link utilization of the different control plane schemes.}
\label{results_TE} \end{figure}

Figure~\ref{results_TE} shows the performance of load balancing in the Janos-US-CA topology in the form of histograms of link utilization, defined as the frequency of the occurrence of a particular link utilization value. The according experiments were carried out as follows: As initial scenario we used the traffic and link capacity values determined in the OSPF case of the previous experiment. The blue area in the figure depicts how OSPF utilizes the deployed links, which covers a wide range. This was again used as worst case result without any load balancing. We then used the routing optimization model detailed in Subsection~\ref{math_te} to balance the link loads such that the occurrence of higher utilization degrees is less frequent. We again used the identical objective for the 50\% (stacked hybrid) and the complete SDN deployment. The utilization cost function is superimposed in the figure (shown as the dotted red ``Cost'' plot). The optimality bound for load balancing is the case where all links are exactly equally utilized, which would result in a histogram with a single peak with 100\% of links. Indeed, the histogram of full SDN deployment (plotted as gray area) exhibits a strong peak (54.1\% of all links) right below 50\% link utilization, which is exactly the upper bound of the ``zero cost zone'' (i.e., links with  utilization cause zero cost in the routing optimization model). This result can be considered as the best case result for load balancing when routing is not constrained. Figure~\ref{results_TE} also shows the histograms for SDN Partitioning with 2 (dotted black line) and 10 (solid black line) sub-domains. (Please note that due to clarity of this illustration we omitted the plots for SDN Partitioning with 4 and 6 sub-domains, which however -- if plotted in the same figure -- would smoothly integrate between the plots for 2 and 10 sub-domains.) SDN Partitioning with 10 sub-domains allows for extensive routing control resulting in load balancing performance close to full SDN deployment, which indicates that a relatively small number of SDN-enabled routers (even compared to the stacked hybrid scheme with 50\% SDN-enabled nodes, plotted as solid red line) can enable almost full traffic engineering capabilities in a network. The figure also shows that SDN Partitioning with only 2 sub-domains can already considerably improve the load distribution compared to regular OSPF operation.

\begin{figure}[t] \center
\includegraphics[width=\columnwidth]{./results_FR.pdf}
\caption{Histograms of the averaged link utilization of the different control plane schemes after the occurrence of a link failure.}
\label{results_FR} \end{figure}

Our final result is depicted in Figure~\ref{results_FR} and shows (like in the previous result in the form of link utilization histograms) to what extent the compared operational schemes can handle the occurrence of a sudden fiber cut in the network. This experiment was carried out based on the previous load-balancing scenario, where we simply deleted one link and reoptimized the routing. The results are averaged over all possible link failures in the network. For this experiment, we shifted the cost function to 80\% in order to avoid only over-utilized links (which can easily occur in case of a fiber cut), while trying to minimize the number of events\footnote{As an event in the OSPF part of the control plan we consider each routing recomputation in an OSPF router due to a new Link State Advertisement.} in the OSPF part of the control plane. In other words, routing optimization using the formulation in~\ref{math_fr} aims on fewest LSAs and re-routes flows only in case of over-utilized (or failed) links. The distribution of link utilizations in case no routing re-optimization is possible -- which is the case in OSPF -- is shown as the blue area. Here, OSPF only assures that all nodes compute valid new shortest path routes, which is based only on link metrics and completely ignores the traffic load. Consequently, OSPF leads to the largest number of congested links. (See Table~\ref{droppedpackets} for a numerical congestion comparison.) SDN Partitioning with 2 sub-domains (i.e., the control plane scheme with the weakest control on routing) is plotted as dotted black line and can already provide significant improvements compared to OSPF in terms of congestion. More sophisticated routing control is provided by SDN Partitioning with 10 sub-domains (solid black line) and stacked hybrid control with 50\% SDN-enabled routers (solid red line), which both lead to a significant peak at the lower cost bound at 80\% link utilization on the one hand, and decreased congestion on the other hand. Full SDN deployment (plotted as gray area) can almost completely avoid congestion in our experimental set up. Please note that it is common in operative IP networks either to provide protection (i.e., idle backup links) or to overprovision link capacities such that congestion is avoided in case of link failures, which is expensive in terms of required capacity.

In the same experiment we measured the amount of excess traffic (i.e., packets that are dropped due to overloaded links) \emph{after the control plane has finished all its routing reconfigurations} after a link failure. (Note that traffic loss \emph{during} routing reconfiguration is ignored in this table, as we assume that its duration is very short compared to the duration of the link failure.) These measurements are provided in Table~\ref{droppedpackets}, which additionally provides the average fraction of links that exhibit congestion and a measure on OSPF routing stability quantified by the number of actually performed routing recomputations in OSPF routers. Given our assumption of an initial link utilization threshold of 80\%, a link failure in such an ``economically'' dimensioned OSPF network leads to drastic service degradation, which -- on average -- already entail more than 0.7\% of all packets dropped due to congestion (which also implies increased packet delays). Even though packet loss can not be avoided completely under these assumptions, the table shows that improved routing control can reduce the amount of excess traffic load significantly.

\begin{table}[t]\begin{center}\footnotesize
\begin{tabular}{ l c c c}
\toprule
\multirow{2}{*}{\textbf{Operational Scheme}} & \textbf{Traffic} & \textbf{Cong.} & \textbf{OSPF} \\
                                             & \textbf{Loss}    & \textbf{Links} & \textbf{Reconf.} \\
\midrule
OSPF &  & 1.73\% & 78 \\\addlinespace[1.0mm]
SDN Partitioning (2 Subs) &  & 1.19\% & 430.4 \\\addlinespace[1.0mm]
Stacked Hybrid, 50\% SDN &  & 0.81\% & 78 \\\addlinespace[1.0mm]
SDN Partitioning (4 Subs) &  & 0.68\% & 110.5 \\\addlinespace[1.0mm]
SDN Partitioning (6 Subs) &  & 0.60\% & 45.8 \\\addlinespace[1.0mm]
SDN Partitioning (10 Subs) &  & 0.60\% & 24.7 \\\addlinespace[1.0mm]
Complete SDN Deployment &  & 0.26\% & 0 \\\addlinespace[1.0mm]
\bottomrule
\end{tabular}\normalsize
\caption{OSPF routing stability and average traffic loss through overutilized links after a sudden fiber cut in the Janos-US-CA topology.}\label{droppedpackets}
\end{center}\end{table}

Routing stability in the OSPF part of a hybrid control plane is an important aspect, as each new LSA received by an OSPF router triggers a recomputation of the routing and forwarding table. The last column of Table~\ref{droppedpackets} shows the average number of such OSPF reconfigurations for each examined control plane. Regular OSPF triggers exactly 78 of such events after any link failure, as the used topology has 39 nodes and both adjacent routers advertise the topology change through flooding to the entire routing domain. The stacked hybrid control plane behaves identical, as all hybrid nodes perform regular OSPF below their SDN layer. However, as soon as all legacy nodes are substituted with SDN nodes, the legacy protocol can finally be turned off completely, which consequently results in zero OSPF reconfigurations for the case of complete SDN deployment. It can be seen from the last column of Table~\ref{droppedpackets} that in case of SDN Partitioning the number of OSPF reconfigurations strongly depends on the number of sub-domains. Using this scheme with only two sub-domains provokes excessive use of OSPF reconfigurations, which however allows at least to half the amount of lost traffic compared to native OSPF operation. Due to the low number of SDN routers (4 out of 39) in this scenario, the capability to reroute traffic around congested areas (or failed links) by means of flow table updates from the central SDN controller is comparably limited. The only other method to change routing in SDN Partitioning is to change the SDN border nodes used as sub-domain exit on a per-destination base, which in this case is heavily used by the failure recovery process to reduce packet loss and link congestion. It can however also be seen from the table that OSPF's routing stability increases rapidly in SDN Partitioning with an increasing number of sub-domains (and thus SDN nodes).





















\section{Conclusions}\label{conclusions}
The advantages of a hybrid SDN/OSPF control plane are broadly recognized in the networking community, as it promises the best of two worlds: programmability and agility of SDN and reliability and fault tolerance of OSPF. Moreover, such an architecture allows for a smooth and cost optimized migration to SDN. The common approach for such a control plane follows a ``ships-passing-in-the-night'' strategy, where the SDN part and the OSPF part are oblivious of what the other configures. We have argued that this is however not without issues, especially in terms of forwarding table sizes, routing convergence time, location of the SDN-enabled nodes, and in case of network failures. We have proposed SDN Partitioning in this paper as a new hybrid SDN/OSPF control plane that encapsulates OSPF into sub-domains and allows to steer the routing between sub-domains. We provided a new ILP-based algorithm for balanced vertex separators that can be used to equally partition a routing domain and demonstrated the correlation of the number of deployed SDN border nodes and sub-domain size. We have explained in detail all technical requirements and provided new mathematical models that take into account the specific routing constraints for common network management tasks, namely capacity planning, load balancing, and failure recovery. Finally, we numerically evaluated the performance of SDN Partitioning in comparison to OSPF operation, full SDN deployment, and hybrid SDN/OSPF (assuming a 50\% SDN deployment) without partitioning. Our results show that -- depending on the degree of partitioning -- SDN Partitioning provides network control capabilities between 50\% and full SDN deployment, but with relatively few SDN-enabled routers. Adjusting the sub-domain sizes allows to trade off the degree of dynamic control (and thus the performance of the evaluated management operations) against carefreeness and routing stability. This claim is confirmed by our numerical results: larger sub-domains provide less SDN control (due to more autonomous OSPF self-configuration), while smaller sub-domains increase the domination of the SDN control plane (and thus the performance of management operations that depend on dynamic routing control), but require a larger number of SDN-enabled nodes in the network. This also proves that SDN Partitioning provides a pragmatic and efficient migration path for network operators, as an initial partitioning into two sub-domains requires only a few SDN nodes. Sub-domains could iteratively be partitioned into smaller sub-domains in further migration steps, which would gradually increases the central control on routing for manageable investments in new equipment.














\section*{Acknowledgments}
This work has been supported by the German Federal Ministry of Education and Research (BMBF) under code 01BP12300A; EUREKA-Project SASER.











\begin{thebibliography}{1}

\bibitem{brocade} Brocade press release, \emph{``Brocade Advances SDN Leadership With OpenFlow 1.3 Support Across IP Routing and Switching Portfolio,''} March 3, 2014, \url{http://newsroom.brocade.com/press-releases/brocade-advances-sdn-leadership-with-openflow-1-3--nasdaq-brcd-1094247#.Vl2FpkMQ1WI}

\bibitem{picos} Whitepaper, \emph{``PicOS Overview,''} Pica8, Inc., 2014

\bibitem{Pepelnjak} Ivan Pepelnjak's Blog at at ipSpace.net: \emph{``Does centralized control plane make sense?'',} May 08, 2014, available at \url{http://blog.ipspace.net/2014/05/does-centralized-control-plane-make.html}

\bibitem{Dixon} Colin Dixon's Blog at Cyberpunkture: \emph{``On centralization in SDN and the applicability of OpenFlow,''} June 16, 2014, available at \url{https://blog.cyberpunkture.net/2014/06/on-centralized-sdn-and-openflow/}

\bibitem{hybrid_1} M. Campanella, L. Prete, P.L. Ventre, M. Gerola, E. Salvadori, M. Santuari, S. Salsano, G. Siracusano, \emph{``Bridging OpenFlow/SDN with IP/MPLS,''} poster presentation at TERENA Networking Conference, May 2014, Dublin, Ireland

\bibitem{hybrid_2} M. Caria, A. Jukan, M. Hoffmann, \emph{``A Performance Study of Network Migration to SDN-enabled Traffic Engineering,''} Globecom 2013, Atlanta, USA, December 2013

\bibitem{hybrid_3} D. Levin, M. Canini, S. Schmid, A. Feldmann, \emph{``Incremental SDN Deployment in Enterprise Networks,''} ACM SIGCOMM 2013, Hong Kong, China, August 2013

\bibitem{hybrid_4} S. Agarwal, M. Kodialam, T.V. Lakshman, \emph{``Traffic engineering in software defined networks,''} IEEE INFOCOM 2013, Turin, Italy, April 2013

\bibitem{Brockners} Frank Brockners' Blog at Cisco Blogs: \emph{``Distributed? Centralized? Both?,''} \url{http://blogs.cisco.com/getyourbuildon/distributed-centralized-both}

\bibitem{Vissicchio2} S. Vissicchio, L. Cittadini, O. Bonaventure, G.G. Xie, L. Vanbever, \emph{``On the co-existence of distributed and centralized routing control-planes,''} INFOCOM 2015

\bibitem{tcam} P.T. Congdon, P. Mohapatra, M. Farrens, V. Akella, \emph{``Simultaneously Reducing Latency and Power Consumption in OpenFlow Switches,''} IEEE/ACM Transactions on Networking, Vol.22, Iss.3, pp.1007-1020, June 2014

\bibitem{tamal_ICC} T. Das, M. Caria, A. Jukan, M. Hoffmann, \emph{``Insights on SDN Migration Trajectory,''} IEEE ICC 2015, London, UK, June 2015

\bibitem{steroids} Brent Salisbury's Blog: \emph{``OpenFlow: Proactive vs Reactive Flows,''}  \url{http://networkstatic.net/openflow-proactive-vs-reactive-flows/}

\bibitem{B4} S. Jain, A. Kumar, S. Mandal, J. Ong, L. Poutievski, A. Singh, S. Venkata, J. Wanderer, J. Zhou, M. Zhu, J. Zolla, U. H{\"o}lzle, S. Stuart, A. Vahdat, \emph{``B4: experience with a globally-deployed software defined WAN,''} SIGCOMM 2013

\bibitem{ospf} J. Moy, \emph{``OSPF Version 2,''} IETF, RFC 2328, April 1998

\bibitem{bgp} B. Quoitin, C. Pelsser, L: Swinnen, O. Bonaventure, S. Uhlig, \emph{``Interdomain traffic engineering with BGP,''} IEEE Communications Magazine, v.41, i.5, pp.122-128, May 2003

\bibitem{vissicchio} S. Vissicchio, L. Vanbever, O. Bonaventure, \emph{``Opportunities and Research Challenges of Hybrid Software Defined Networks,''} ACM SIGCOMM CCR 44(2), pp.70-75, April 2014

\bibitem{fibbing1} S. Vissicchio, L. Vanbever, J. Rexford, \emph{``Sweet Little Lies: Fake Topologies for Flexible Routing,''} ACM HotNets 2014, Los Angeles, California

\bibitem{fibbing2} S. Vissicchio, O. Tilmans, L. Vanbever, J. Rexford, \emph{``Central Control Over Distributed Routing,''} ACM SIGCOMM 2015, London, UK

\bibitem{ciscoproblem} Cisco Troubleshooting TechNotes, Document ID 13682: \emph{``Common Routing Problem with OSPF Forwarding Address,''} \url{http://www.cisco.com/c/en/us/support/docs/ip/open-shortest-path-first-ospf/13682-10.html}

\bibitem{juniperproblem} Juniper Knowledge Base article 13547: \emph{``LSA exists in the OSPF database, but not populated in the routing table,''} \url{http://kb.juniper.net/InfoCenter/index?page=content&id=KB13547}

\bibitem{OSPFforwardingaddress} Admin Articles - Articles and tutorials on networking and system administration: \emph{``OSPF forwarding address,''} \url{http://www.adminarticles.com/ospf-forwarding-address/}

\bibitem{divideandconquer} M. Caria, A. Jukan, M. Hoffmann, \emph{``Divide and Conquer: Partitioning OSPF networks with SDN,''} IM 2015, Ottawa, Canada, May 2015

\bibitem{caria_HPSR} M. Caria, A. Jukan, \emph{``The Perfect Match: Optical Bypass and SDN Partitioning,''} IEEE HPSR 2015, Budapest, Hungary, July 2015

\bibitem{Souza} E. Balas, C.C. de Souza, \emph{``The vertex separator problem: a polyhedral investigation,''} Mathematical Programming, vol.103, no.3, pp.583-608, July 2005

\bibitem{alpert} C.J. Alpert, A.B. Kahng, \emph{Recent Directions in Netlist Partitioning: A Survey,} Integration, the VLSI Journal,  vol. 19, no.1-2, pp.1-81, August 1995

\bibitem{sndlib} SNDlib library, \url{sndlib.zib.de}

\end{thebibliography}


\end{document}