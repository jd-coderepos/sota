\documentclass{article}
\usepackage{spconf,amsmath,graphicx}

\usepackage{cite}
\usepackage{txfonts}
\usepackage{setspace}
\usepackage{bm}
\usepackage{multirow}
\usepackage{subfig}
\usepackage{comment}
\usepackage{amssymb}
\usepackage[dvipdfmx]{hyperref}
\usepackage{xcolor}


\def\x{{\mathbf x}}
\def\L{{\cal L}}

\title{All for One and One for All:\\Improving Music Separation by Bridging Networks}

\name{Ryosuke Sawata, Stefan Uhlich, Shusuke Takahashi and Yuki Mitsufuji} \address{Sony Corporation, Tokyo, Japan \hspace{1cm}
Sony Europe B.V., Stuttgart, Germany}

\begin{document}
\ninept
\maketitle
\begin{abstract}
This paper proposes several improvements for music separation with \emph{deep neural networks} (DNNs), namely a \emph{multi-domain loss} (MDL) and two \emph{combination schemes}.
First, by using MDL we take advantage of the frequency and time domain representation of audio signals.
Next, we utilize the relationship among instruments by jointly considering them. We do this on the one hand by modifying the network architecture and introducing a \emph{CrossNet} structure. On the other hand, we consider combinations of instrument estimates by using a new \emph{combination loss} (CL).
MDL and CL can easily be applied to many existing DNN-based separation methods as they are merely loss functions which are only used during training and which do not affect the inference step.
Experimental results show that the performance of \emph{Open-Unmix} (UMX), a well-known and state-of-the-art open source library for music separation, can be improved by utilizing our above schemes.
Our modifications of UMX will be open-sourced together with this paper.
\end{abstract}
\begin{keywords}
Music source separation (MSS), Deep neural network (DNN), Loss function
\end{keywords}
\section{Introduction}
\label{sec:intro}
Many approaches have been researched in the field of music separation such as local Gaussian modelling \cite{mss_gmodel_1, mss_gmodel_2}, non-negative matrix factorization \cite{mss_nmf_1, mss_nmf_2, mss_nmf_3}, kernel additive modelling \cite{mss_kernel_additive_1} and hybrid methods combining these approaches \cite{mss_combi_1, mss_combi_2}.
In particular, many methods have been investigated which introduce \emph{deep neural networks} (DNNs) in order to improve the separation performance in recent years.
There are three basic DNN architectures, namely \emph{multi-layer perceptrons} (MLPs) \cite{mlp_org}, \emph{convolutional neural networks} (CNNs) \cite{cnn_org} and \emph{recurrent neural networks} (RNNs) \cite{rnn_org}, and all of them have been already introduced for the task of audio source separation.
For instance, an MLP was used to separate the input spectra and then obtain separated results in \cite{mss_mlp_1, mss_mlp_2}.
In \cite{mss_cnn_1, mss_rnn_1}, CNNs and RNNs were used to realize source separation with improved quality than previous MLP-based methods since CNNs and RNNs can consider the temporal contexts via convolution and recurrent layers. 

Although the aforementioned literature has improved the performance of music separation drastically, there are two problems with respect to training the separation networks: (1) most existing methods consider only the time or the frequency domain but not both, and, (2) they do not consider the mutual influence among output sources since loss functions are independently applied to each estimated source and the corresponding ground truth.
For example, one of the state-of-the-art open-source system for music source separation, called \emph{Open-Unmix} (UMX) \cite{umx}\footnote{\url{https://github.com/sigsep/open-unmix-[nnabla|pytorch]}}, conducts music source separation only in the frequency domain as the input and output of UMX are both spectrograms.
Furthermore, UMX applies the conventional \emph{mean squared error} (MSE) loss function to individual pairs of estimated and corresponding ground truth spectrograms for each instrument.
In other words, UMX trains networks one-by-one for each instrument.

In order to solve these problems, we propose schemes with respect to the used loss function and model architecture.
In the field of speech enhancement, which is a special case of audio source separation, the methods considering time and frequency domain have been researched in recent years \cite{mdphd, hifi_gan}.
For instance, Kim \textit{et al.} showed in \cite{mdphd} the effectiveness of multi-domain processing via hybrid denoising networks.
Furthermore, Su \textit{et al.} reported in \cite{hifi_gan} that building two discriminators which are responsible for time and frequency domain can realize effective denoising and dereverberation in their scheme of using \emph{generative adversarial networks} (GANs).
Inspired by these reports, we believe that considering both, time and frequency domain, is important to realize effective music source separation.
Next, in the field of audio source separation, the effectiveness of Conv-TasNet~\cite{conv_tasnet, conv_tasnet_mss}, a fully-convolutional time-domain audio separation network, was reported.
In particular, D\'{e}fossez \textit{et al.} reported in \cite{conv_tasnet_mss} that the performance of Conv-TasNet was higher than the one of UMX when trained and evaluated on the same dataset.
One of the reasons in our opinion is that the architecture of Conv-TasNet allows information sharing among sources as the convolutional layers take into account all input channels when computing one output channel. 
In contrast, UMX does not allow such a information sharing as it trains independent source extraction networks for each instrument.
Therefore, it is difficult for UMX to consider the mutual influence among instruments obtained from the same input mixture.

Motivated by the aforementioned discussion, we propose two new loss functions and a new model architecture which we add to UMX, called \emph{CrossNet-UMX} (X-UMX)\footnote{Our implementation using NNabla which is neural network libraries by Sony is available on \url{https://github.com/sony/ai-research-code/tree/master/x-umx}. Note that the PyTorch version is coming soon.}.
First, we introduce a \emph{multi-domain loss} (MDL) where we append an additional differentiable \emph{short-time Fourier transform} (STFT) or \emph{inverse STFT} (ISTFT) layer\footnote{If the network outputs a spectrogram, we append an ISTFT layer whereas a STFT layer is added if the network output is a time signal.} during training only. The loss is computed from the estimates before and after the STFT/ISTFT layer.
In this way, MDL can consider not only frequency but also time domain differences between estimates and ground truth.
Second, we also propose a further loss function, named \emph{combination loss} (CL), and bridging network paths for UMX.
As we mentioned above, not only UMX but also almost all conventional methods for music source separation train their networks for each source independently.
Thus, it is difficult to find the root-cause of performance degradation, i.e., which sources are leaking and thus producing incorrect instrument estimates.
To tackle this problem, CL considers the relationship among output sources by also producing the output spectrograms for combinations and applying MDL to them. If the performance of the th source separation is insufficient, other combinations including the th source will be adversely affected while the others which do not include the th source are not.
In addition, we bridge the network paths of UMX for different instruments and thus share information among all instruments. Our bridging operation is beneficial for networks like UMX which consists of individual extraction networks and not one joint separation network.
Hence, a network like Conv-TasNet which is already crossing among sources via convolutional layers does not need this operation.


The above proposed loss functions, i.e., MDL and CL, only affect the training step and, therefore, can be introduced to many conventional methods since they are just loss functions.
In addition, our bridging operation requires only a slight network modification but does not increase the number of parameters that need to be learned.
Consequently, performance improvements can be gained for most DNN-based source separation methods with introducing almost no additional computational costs at inference time.

\section{Proposed Loss Functions}
\label{sec:propose}
In this section, we describe in detail our new loss functions, i.e., MDL and CL, and discuss their merits.
We assume that the time-domain mixture signal  consists of  sources, i.e.,
 
where  denotes the time-domain signal of the th source and ,  are column vectors with the time-domain samples.
In this section, we also assume that the output of the DNN is a mask  which can extract the th desired source from the mixture spectrum :
 
where  and  are the forward and inverse operators of the STFT, respectively.
Furthermore,  and  are the predicted results of time and frequency domain ground truths  and .

\if0
\begin{figure*}[t]
\centering
\subfloat[Details for the proposed \emph{multi-domain loss} (MDL). Frequency and time domain loss functions are computed before and after the ISTFT layer.]{
\includegraphics[scale=0.325]{./Figs/MDL.eps}
\label{fig:MDL}}
\hspace{+2mm}
\subfloat[Details for the proposed \emph{combination loss} (CL). For illustration, this figure assumes that the mixture consists of four sources.]{
\includegraphics[scale=0.28]{./Figs/CL.eps}
\label{fig:CL}}


\caption{Proposed loss functions}
  \label{fig:overview}
\end{figure*}
\fi

\subsection{Multi-Domain Loss (MDL)}
\label{subsec:MDL}
\begin{figure}[!t]
\begin{minipage}[b]{1.0\linewidth}
  \centering
  \centerline{\includegraphics[width=8.75cm]{./Figs/MDL_freq.eps}}
\flushleft{(a) Frequency domain network with appended ISTFT layer.}\medskip
\end{minipage}
\begin{minipage}[b]{1.0\linewidth}
  \centering
  \centerline{\includegraphics[width=8.75cm]{./Figs/MDL_time.eps}}
\flushleft{(b) Time domain network with appended STFT layer.}
\end{minipage}
\caption{Multi-domain loss (MDL)}
\label{fig:MDL}
\vspace{-0.5cm}
\end{figure}
\begin{figure}[!t]
  \begin{center}
\includegraphics[width=8.75cm]{./Figs/CL_rev.eps}
\caption{Combination Loss (CL) for the case that the mixture consists of four sources.}
   \label{fig:CL}
   \vspace{-8mm}
  \end{center}
\end{figure}
In the scheme of MDL, we first append an additional differentiable and fixed STFT or ISTFT layer after the output layer as shown in Fig.~\ref{fig:MDL}.
This allows us to compute the loss in the time as well as the frequency domain.
Note that the STFT or ISTFT layer does not affect the inference step since this layer is only used during training for computing the MDL.
In our method, we use the \emph{mean squared error} (MSE) between separated and ground truth spectrograms as frequency domain loss, and the \emph{weighted signal-to-distortion ratio} (wSDR) \cite{dcunet_1} as time domain loss, i.e.,

where  is a scaling parameter and  denotes the th source.
The MSE  and wSDR  are respectively calculated as follows:

\mathcal{L}_\text{MSE}^j &= 
    \sum_{j=1}^J \sum_{t,f} \left\{\lvert X_j (t, f)\rvert - \lvert\hat{X}_j (t, f)\rvert\right\}^2, \\
\mathcal{L}_\text{wSDR}^j &= 
    \sum_{j=1}^J \left\{-\rho_j \frac{\bm{x}_j^\mathrm{T}\hat{\bm{x}}_j}{\|\bm{x}_j\| \: \|\hat{\bm{x}}_j\|} 
    - (1-\rho_j) \frac{(\bm{y}_j-\bm{x}_j)^\mathrm{T}(\bm{y}_j-\hat{\bm{x}}_j)}{\|\bm{y}_j-\bm{x}_j\| \: \|\bm{y}_j-\hat{\bm{x}}_j\|} \right\}, 
\label{eq:4}

where  and  denote the frame and frequency bin index of the spectrogram  and its estimate , respectively.
Moreover,  is the energy ratio between the th source  and the mixture  in the time-domain, i.e., .
Please note that the output range of wSDR in \eqref{eq:4} is bounded to . This range is useful for a stable training and no ``log'' operation is required (although SDR is traditionally calculated including the logarithm).

Using MDL, we take advantage of both domains, which provides a performance improvement as we will see in Sec.~\ref{sec:exp}. 
As MDL is merely a loss function, it can be used for many conventional methods without requiring additional calculations during inference. 
Please note that we focus in this paper on frequency domain networks, e.g., UMX, as this approach is more common than time domain networks.

\begin{figure*}[t]
\centering
\subfloat[UMX]{
\includegraphics[scale=0.47]{./Figs/umx_rev.eps}
\label{fig:umx}}
\hspace{+3mm}
\subfloat[X-UMX]{
\includegraphics[scale=0.47]{./Figs/crossnet_rev.eps}
\label{fig:cross}}


\caption{Comparison of network architectures used in our experiments.}
  \label{fig:comp_archi}
  \vspace{-3mm}
\end{figure*}

\subsection{Combination Schemes}
\label{subsec:combi}
In this subsection, we introduce the new combination loss (Sec.~2.2.1) and our new bridging network architecture (Sec.~2.2.2) to help each UMX's extraction network to support each other.

\subsubsection{Combination Loss (CL)}
\label{subsec:CL}
In the scheme of CL, we consider the combinations of output masks.
Specifically, we combine two or more estimated masks into new ones where each of them can extract two or more sources from the mixture.
By using the newly obtained combination masks, we can compute more loss functions than if we only compare each estimated mask with its target, i.e.,

where  is the total number of possible combinations except for mixing all  sources, namely , and  denotes the index of th combination\footnote{Initial experiments showed that the combination  is not adding further performance improvements and, hence, it is not used in \eqref{eq:5}.}.
For example, in the situation of separating four sources, we can consider 14  combinations in total as shown in Fig.~\ref{fig:CL}, 
while conventional methods consider each source independently.


In order to illustrate the benefit of CL, let us consider the following example: Assume that we have a system with leakage of \emph{vocals} into \emph{drums} and \emph{other} resulting in similar errors that both instruments exhibit. 
By considering the combination \emph{drums + other}, we will notice that the two errors are correlated, resulting in a even larger leakage of vocals which we try to mitigate by using our proposed CL loss.

\subsubsection{Bridging Networks}
\label{subsec:bridging}
In our method, the aforementioned CL aims to train each network with considering the relationship among output sources by combining output masks.
In addition, we observed that it is effective to cross not only the loss function via CL but also the network graphs in order to help each UMX's extraction network to support each other.
Hence, we also propose UMX with a crossing architecture, named \emph{CrossNet-UMX} (X-UMX).
Specifically, we connect the paths to cross each source's network by adding just two average operators to the original UMX model as shown in Fig.~\ref{fig:comp_archi}. 
Using these average operations does not change the total numbers of parameters which would not be the case if we would use a concatenation operation.
Please note that this average operation is only needed for models like UMX since UMX consists of individual extraction networks.


In this way, our method can consider multiple sources together, i.e., two or more source separation, than considering each source independently.
From a different viewpoint, CL particularly can be considered to provide a benefit similar to multi-task learning due to considering multiple sources jointly by computing combinational masks.
\\


We will see in Sec.~\ref{sec:exp} that MDL and our combination schemes provide a performance improvement for UMX. We can expect such an improvement also for many conventional methods without having to introduce additional computational costs at inference time since MDL and CL are merely loss functions and the bridging is achieved with a simple average operation without learnable parameters.

\if0
\begin{table*}[!thb]
\centering
\caption{Details of each method in our experiment and their SDR results. A ``\:\:'' indicates that our X-UMX architecture was used.}
\scalebox{1.0}[1.0]{
\begin{tabular}{ l | c | c c | c c c c c }
	\hline
\multirow{2}{*}{\textbf{METHOD}} & \multirow{2}{*}{\textbf{Network}} & \multicolumn{2}{|l|}{\textbf{Applying:}} &  \multicolumn{5}{l}{\textbf{Median of frames, Median of tracks:}} \\ 
                                 & & \textbf{MDL} & \textbf{CL} & \textbf{Bass} & \textbf{Drums} & \textbf{Other} & \textbf{Vocals} & \textbf{Avg.} \\ \hline \hline
C1 & UMX & \multirow{2}{*}{} & \multirow{2}{*}{} & 4.93 & 5.72 & 4.00 & 6.09 & 5.18 \\
 & X-UMX & & & 5.45 & 6.00 & 4.24 & 6.50 & 5.55 \\ \cline{1-4}
C2 & UMX & \multirow{2}{*}{\checkmark} & \multirow{2}{*}{} & 5.07 & 5.80 & 4.27 & 6.45 & 5.40 \\
 & X-UMX & & & \textbf{5.62} & 6.36 & 4.50 & \textbf{6.65} & 5.78 \\ \cline{1-4}
C3 & UMX & \multirow{2}{*}{} & \multirow{2}{*}{\checkmark} & 4.98 & 5.87 & 4.03 & 6.07 & 5.24 \\
 & X-UMX & & & 5.35 & 6.06 & 4.25 & 6.37 & 5.51 \\ \cline{1-4}
C4 & UMX & \multirow{2}{*}{\checkmark} & \multirow{2}{*}{\checkmark} & 5.07 & 6.19 & 4.23 & 6.29 & 5.44 \\
 = P (proposed) & X-UMX & & & 5.43 & \textbf{6.47} & \textbf{4.64} & 6.61 & \textbf{5.79} \\ \hline
\end{tabular}
\label{tb:methods}
}
\end{table*}
\begin{table*}[!thb]
\centering
\caption{Details of each method in our experiment and their SDR results.}
\scalebox{1.0}[1.0]{
\begin{tabular}{ l | c c c | c c c c c | c c c c c}
	\hline
 & & & & \multicolumn{10}{|c}{\textbf{Median of frames, Median of tracks:}} \\ 	
\multirow{2}{*}{\textbf{METHOD}} & \multicolumn{3}{|l|}{\textbf{Applying:}} &  \multicolumn{5}{c|}{SDR } & \multicolumn{5}{c}{SAR } \\ 
                                 & \textbf{MDL} & \textbf{CL} & \textbf{Bridging} & \textbf{Bass} & \textbf{Drums} & \textbf{Other} & \textbf{Vocals} & \textbf{Avg.} & \textbf{Bass} & \textbf{Drums} & \textbf{Other} & \textbf{Vocals} & \textbf{Avg.} \\ \hline \hline
C1 &  &  &  & 4.93 & 5.72 & 4.00 & 6.09 & 5.18 & 6.06 & 5.85 & 4.29 & 6.03 & 5.56\\
C2 & \checkmark &  &  & 5.07 & 5.80 & 4.27 & 6.45 & 5.40 & 6.17 & 5.62 & 4.52 & 6.44 & 5.69\\
C3 &  & \checkmark &  & 4.98 & 5.87 & 4.03 & 6.07 & 5.24 & 6.09 & 5.98 & 4.45 & 6.03 & 5.64\\
C4 &  &  & \checkmark & 5.45 & 6.00 & 4.24 & 6.50 & 5.55 & 6.20 & 6.05 & 4.57 & 6.18 & 5.75\\ 
C5 & \checkmark & \checkmark &  & 5.07 & 6.19 & 4.23 & 6.29 & 5.44 & 6.29 & \textbf{6.25} & 4.60 & 6.28 & 5.85\\
C6 & \checkmark &  & \checkmark & \textbf{5.62} & 6.36 & 4.50 & \textbf{6.65} & 5.78 & 6.20 & 6.23 & 4.57 & 6.37 & 5.84\\
C7 &  & \checkmark & \checkmark & 5.35 & 6.06 & 4.25 & 6.37 & 5.51 & \textbf{6.53} & 5.98 & 4.72 & 6.28 & 5.88\\
P (proposed) & \checkmark & \checkmark & \checkmark & 5.43 & \textbf{6.47} & \textbf{4.64} & 6.61 & \textbf{5.79} & 6.35 & 5.97 & \textbf{4.83} & \textbf{6.75} & \textbf{5.98}\\ \hline
\end{tabular}
\label{tb:methods}
}
\end{table*}
\begin{table}[!thb]
\centering
\caption{Summary of each method in our experiment.}
\scalebox{1.0}[1.0]{
\begin{tabular}{ l | c c c }
	\hline
\multirow{2}{*}{\textbf{METHOD}} & \multicolumn{3}{|l}{\textbf{Applying:}} \\ 
                                 & \textbf{MDL} & \textbf{CL} & \textbf{Bridging} \\ \hline \hline
C1 &  &  &  \\
C2 & \checkmark &  &  \\
C3 &  & \checkmark &  \\
C4 &  &  & \checkmark \\ 
C5 & \checkmark & \checkmark &  \\
C6 & \checkmark &  & \checkmark \\
C7 &  & \checkmark & \checkmark \\
P (proposed) & \checkmark & \checkmark & \checkmark \\ \hline
\end{tabular}
\label{tb:summary_methods}
}
\end{table}
\fi
\begin{figure*}[!thb]
\centering
\subfloat[SDR]{
\includegraphics[scale=0.5]{./Figs/SDR_GraphTable_rev.eps}
\label{fig:result_sdr}}
\subfloat[SAR]{
\includegraphics[scale=0.543]{./Figs/SAR_GraphTable_rev.eps}
\label{fig:result_sar}}
\vspace{-1mm}
\caption{Experimental results for proposed methods.}
\label{fig:results}
\vspace{-2mm}
\end{figure*}

\section{Experiments}
\label{sec:exp}
In this section, we conduct experiments of music separation in order to confirm the validity of our method.
The task is to separate a song into its four constituent instruments.

\subsection{Setup}
\label{subsec:setup}
In our experiments, we evaluate the proposed method on the MUSDB18 dataset \cite{musdb18} which is comprised of 150 songs each of which is recorded at 44.1kHz sampling rate.
MUSDB18 consists of two subsets (`train' and `test') where we split the train set further into `train' and `valid' as defined in the `musdb' package\footnote{\url{https://github.com/sigsep/sigsep-mus-db/blob/master/musdb/configs/mus.yaml}}. 
For each song, the mixture and its four sources, i.e., \textit{bass, drums, other} and \textit{vocals}, are available.


As CL needs to be applied to the joint instrument network due to the usage of the combinations of the output masks, we cannot use the original UMX implementation, which independently builds and trains a network for each instrument.
Hence, we always train in the following the four separation networks jointly, even in the case that no combination scheme is used, and the loss function is merely the mean of the four individual losses for each instrument.
This has the effect that the early stopping at the epoch with the smallest validation error is not done for each instrument individually (as is the case for the original UMX) but the early stopping is done at the same epoch for all four networks.
Furthermore, the learning rate drops, which are determined by the `ReduceLROnPlateau` function are done at the same epoch.
Hence, the results that we obtain in Fig.~\ref{fig:results} for ``C1'' differ from the results of the original UMX.
Besides the modifications mentioned above, all other experimental settings are the same as for the original UMX.


Finally, please note that the scaling parameter , introduced in \eqref{eq:3} for MDL, was set to  in order to approximately equalize the ranges of  and  by looking at the individual loss function's learning curves.

\subsection{Results}
\label{subsec:results}
To evaluate the performance of our method, we used the \emph{signal-to-distortion ratio} (SDR) and \emph{sources-to-artifacts ratio} (SAR) computed with BSSEval v4 called `museval'\footnote{\url{https://github.com/sigsep/sigsep-mus-eval}}, which was also the official evaluation scheme for SiSEC 2018~\cite{stoter20182018}.
\begin{table}[tb]
\centering
\caption{Comparison of X-UMX with other public methods in terms of SDR (``median of frames, median of tracks'').}
\vspace{-1mm}
\resizebox{\linewidth}{!}{
\begin{tabular}{ l | c c c c c }
	\hline
    \textbf{Method} 
                 & \textbf{Bass} & \textbf{Drums} & \textbf{Other} & \textbf{Vocals} & \textbf{Avg.}\\ \hline \hline
UMX \cite{umx} & 5.07 & 6.04 & 4.28 & 6.25 & 5.41 \\
Meta-TasNet \cite{meta_tasnet} & 5.58 & 5.91 & 4.19 & 6.40 & 5.52 \\
Demucs \cite{demucs} & \textbf{5.83} & 6.08 & 4.12 & 6.29 & 5.58 \\ 
Conv-TasNet \cite{conv_tasnet_mss} & 5.66 & 6.08 & 4.37 & \textbf{6.81} & 5.73 \\
X-UMX (proposed) & 5.43 & \textbf{6.47} & \textbf{4.64} & 6.61 & \textbf{5.79} \\
\hline
\end{tabular}
\label{tb:methods_pub}
}
\vspace{-3mm}
\end{table}

The experimental results are shown in Fig.~\ref{fig:results}.
Note that C1 is almost identical to original UMX since it uses the same network architecture and loss function.
However, C1's performance is inferior compared to the original UMX.
As we discussed in Sec.~\ref{subsec:setup}, this is due to the difference in the early stopping and learning rate drops.
First, each of our contributions, i.e., MDL, CL and Bridging, respectively enable UMX to improve performance since the results of C2-C4 outperform those of C1.
Next, we can confirm that all methods that use two modifications compared to the original UMX, i.e., C5-C7, also outperformed C1.
Particularly, collaborative using MDL and network bridging (C6) improved the SDR values of C1 drastically, which increases the average score from dB to dB.
We can observe that the improvements of MDL and bridging linearly add up by confirming the differences of the average score as follows:
dB, dB. 
Then the sum of them, i.e., dB + dB dB, is nearly equal to the improvement from C1 to C6 (dB).
Meanwhile, we can confirm that only CL seems to be not always provide improvement in terms of SDR when it is used with another scheme by focusing on the values of C4 (w/ Bridging) and C7 (w/ Bridging and CL).
On the other hand, we can observe that SAR is always improved by adding CL as shown in Fig.~\ref{fig:results}(b).
In particular, the SARs were improved as follows: +0.08 (C1  C3), +0.16 (C2  C5), +0.13 (C4  C7) and +0.14 (C6  P).
Thus, CL is effective to reduce artifacts and it is beneficial to introduce it since the improved SAR score leads to an improved sound quality as shown in \cite{ward2018bss}.


\if0
First, the validity of applying MDL was confirmed since the performances of C2 which only MDL is used for outperformed the C1 and even .
On the other hand, by comparing the performances of C1 and C3, we did not confirm the effectiveness of applying only CL alone since the C3's performances were less than or equal to those of C1.
However, if there is the condition which network has the crossing architecture (see Fig.~\ref{fig:comp_archi}(b)), the validity of CL was confirmed since the 's scores are superior to those of  as denoted in the table.
Therefore, conditional CL, i.e., CL with crossing networks, is valid.
In particular, the validity of just crossing network architecture was also confirmed since the results having ``+Cross'' architecture were i.e., - and P, were superior to the corresponding those, i.e., C1-C4.
Moreover, applying MDL with the bridging condition has the crossing architecture is more effective than applying only MDL alone.
This is because Table~\ref{tb:methods} showed that the performances of the aforementioned conditional MDL () outperformed the those of simple MDL (C2) drastically.
Hence, we can argue that music source separation should be trained not each source independently but all sources integrately to consider the relationship among output sources as we denoted in Sec.~\ref{sec:intro}.
\fi
Finally, we can confirm that collaborative using all our proposed modifications, i.e., MDL, CL and bridging operation, which is denoted as `P' in Fig.~\ref{fig:results}, gives the best performance in terms of SDR and SAR among all methods.
Finally, we can compare our method to other music source separation public state-of-the-art systems shown in Table~\ref{tb:methods_pub}.
\\

\if0
From the above experimental results, we can describe the following contributions:
\begin{description}
   \item[Multi-domain Loss (MDL)]\mbox{}\\
        Improving the performances of conventional methods becomes feasible by introducing MDL during training.
        Since MDL is only used for training without additional learning parameters and changing network architecture, MDL can realize useful and effective performance improvement.
    \item[Combination Loss (CL)]\mbox{}\\
        Although using CL provides only slight SDR improvement or comparable performance comparing with previous one, it provides SAR improvement.
        Furthermore, CL does not need additional learning parameters and changing network architecture.
\item[Bridging Networks (X-UMX)]\mbox{}\\
		Crossing network paths realized by simple average operators can enhance the degree of improvement of above MDL drastically.
		In addition, just applying crossing operation alone can also improve the performances of conventional methods
if the paths of original target network are separated like UMX.
\end{description}
\noindent
Finally, we argue that our proposal which collaboratively utilizes the above, i.e., MDL, CL and bridging network, is the most powerful and effective way to improve the performances of conventional DNN-based methods for music source separation.
\fi

\vspace{-3mm}
\section{Conclusions}
\label{sec:concludions}
\vspace{-2mm}
In this paper, we proposed two new loss functions called \emph{multi-domain loss} (MDL) and \emph{combination loss} (CL) and a suitable network architecture called \emph{CrossNet-UMX} (X-UMX) realized by a bridging operation.
We showed that MDL and CL are effective and convenient for music separation methods working in the frequency domain since both are loss functions which are used during training and thus do not change the inference step.
Hence, it is easy to apply them to many other conventional DNN-based methods.
In addition, if the target network is built up from sub-networks for each source, we showed that bridging the network paths by a simple averaging operation helps each extraction network to know each other better and, thus, improve performance.
In this paper, we applied MDL and CL to a well-known and state-of-the-art open source library Open-Unmix (UMX), by only adding two average operators to the X-UMX model and the improved results showed the validity of our approach. 

\clearpage
\bibliographystyle{IEEEbib}
\bibliography{refs_euc}

\end{document}
