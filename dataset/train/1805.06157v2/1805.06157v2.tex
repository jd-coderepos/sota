\section{Experiments}

In this section, we present our experimental evaluation of the proposed approach.  In \sect{dataset}, we describe the
ZSD datasets that we prepare and utilize.  In \sect{classembed}, we explain class embeddings used in our experiments.
Finally, in \sect{fashionexp} and \sect{pascalexp}, we give the implementation details and our experimental results.

\subsection{Datasets}
\label{sec:dataset}

We use two different datasets: Fashion-ZSD and Pascal-ZSD. 
We propose two new testbeds for evaluation of ZSD approaches. First, we create a synthetic dataset based on combinations
of objects from the Fashion-MNIST~\cite{xiao2017fashion} dataset. Second, 
we compose a new split based on existing Pascal VOC~\cite{pascal_voc_IJCV} benchmarks.
The details of these testbeds are described below.

\vspace{2mm}

\noindent \textbf{Fashion-ZSD:} This is a toy dataset that we generate for evaluation of ZSD methods, based on the Fashion-MNIST~\cite{xiao2017fashion} dataset. Fashion-MNIST originally consists of Zalando's article images with associated labels. This dataset contains 70,000 grayscale images of size 28x28, and 10 classes. For ZSD task, we split the dataset into two disjoint sets; seven classes are used in training and three classes are used as the unseen test classes (Table~\ref{table:zsd_fashion_results}). We generate multi-object images such that there are three different objects in each image. Randomly cropped objects are utilized to create clutter regions. As shown in Figure~\ref{fig:fashion_dataset}, we consider four scenarios: no noise or occlusion, scenes with partial occlusions, those with clutter, and, finally scenes with both partial occlusions and clutter regions.  images of the resulting  training images are held out for validation purposes. As a result, we obtain the Fashion-ZSD dataset with 8333 training, 8000 validation and 6999 test images. 


\begin{figure}
\resizebox{\textwidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=2.9cm]{images/fashion/train_86.jpg}&
\includegraphics[width=2.9cm]{images/fashion/train_44.jpg}&
\includegraphics[width=2.9cm]{images/fashion/train_48.jpg}&
\includegraphics[width=2.9cm]{images/fashion/train_54.jpg}\\
(a)&(b)&(c)&(d)
\end{tabular}
}
\caption{Ground truth object regions are shown with green and noise regions are shown in red boxes. The dataset consists of images from four different scenarios. From left-to-right, (a) full objects only, (b) partial occlusions, (c) clutter regions included, and (d) a scene with both partial occlusions and clutter regions.}
\label{fig:fashion_dataset}
\end{figure}

\vspace{2mm}

\noindent \textbf{Pascal-ZSD.} This is an adapted version of the Pascal VOC datasets~\cite{pascal_voc_IJCV}. We select 16 of the 20 classes for training and the remaining 4 classes (\ie car, dog, sofa and train) for test. The {\em train+val} subsets of Pascal VOC 2007 and 2012 datasets are used for training classes, and the {\em test} subset of Pascal 2007 is used for evaluation on the unseen classes. Images containing a mixture of train and test classes are ignored. 

\subsection{Class Embeddings}
\label{sec:classembed}

For the Fashion-ZSD dataset, we generate 300-dimensional GloVe word embedding vectors~\cite{pennington2014glove} for each class name, using Common Crawl Data\footnote{commoncrawl.org/the-data/}. For the class names that contain multiple words, we take the average of the word vectors. For Pascal-ZSD, we use attribute annotations of aPaY dataset~\cite{farhadi2009describing}, since aPascal(aP) part of this dataset is obtained from Pascal VOC images. We 
average 64-dimensional indicator vectors of per-object attributes over the dataset to obtain class embeddings. 

\subsection{Zero-Shot Detection on Fashion-ZSD Dataset}
\label{sec:fashionexp}

In this part, we explain our ZSD experiments on Fashion-ZSD dataset. We initialize the convolutional layers of our model
using the weights pre-trained on the ILSRVC12\cite{deng2009imagenet} classification images. Training of our approach is completed in 10 epochs,
where batch size is 32 and learning rate is 0.001. In our experiments, we first evaluate the performance of the trained
network on seen training classes. According to the results presented in Table~\ref{table:zsd_fashion_results}, the
proposed approach obtains  mAP on the validation images with seen classes, which shows the proper training
of the detection model. On the test set with unseen classes only, our proposed approach yields an mAP of
, highlighting the difficulty of zero-shot detection task even in simple settings.

On the combinated validation and test evaluation, our method achieves  mAP. This setting
is particularly interesting, as it requires recognition over both seen and unseen objects at detection time.
Our result suggests that the model is able to detect objects of unseen test classes even in the presence of seen 
classes, without being dominated by them.

\begin{table}[]
\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{c|ccccccc|ccc|c}
         & \multicolumn{7}{c|}{Training Classes}                       & \multicolumn{3}{c|}{Test Classes} &          \\
Test split  & t-shirt & trouser & coat & sandal & shirt & sneaker & bag  & pullover  & dress  & ankle-boot  & mAP (\%) \\
\hline
val      & .89    & .91    & .90  & .97   & .86  & .99    & .90  & -         & -      & -           & 91.9    \\
test     & -       & -       & -    & -      & -     & -       & -    & .49      & .49   & .95        & 64.9    \\
val+test & .89    & .90     & .90  & .97   & .86  & .99    & .91 & .45      & .40    & .90         & 81.7  
\end{tabular}
}
\caption{ZSD performances of proposed hybrid method on Fashion-ZSD dataset. We report class based average precision and mean average precision (mAP) scores.}
\label{table:zsd_fashion_results}
\end{table}

\subsection{Zero-Shot Detection on Pascal-ZSD Dataset}
\label{sec:pascalexp}

In this part, we explain our ZSD experiments on Pascal-ZSD dataset. Training settings of the proposed method on
Pascal-ZSD dataset are same with the previous experiment, except that the number of epochs is set to 30. 
We present the results our approach, as well as individual performances of convex combination and label embedding components,
in Table~\ref{table:zsd_pascal_Results}. The proposed hybrid approach yields  mAP on seen
classes,  mAP on unseen classes and  mAP on the combination of 
seen and unseen classes. By comparing individual components of the model, we observe that 
convex combination (CC) outperforms label embedding (LE), and the hybrid scheme further improves the results.

\vspace{4mm}

\begin{figure}
\resizebox{\textwidth}{!}{\begin{tabular}{ccc}
\includegraphics[width=4cm,height=3cm]{images/pascal/004202.png}&
\includegraphics[width=4cm,height=3cm]{images/pascal/007116.png}&
\includegraphics[width=4cm,height=3cm]{images/pascal/000835.png}\\
\includegraphics[width=4cm,height=3cm]{images/pascal/001283.png}&
\includegraphics[width=4cm,height=3cm]{images/pascal/009103.png}&
\includegraphics[width=4cm,height=3cm]{images/pascal/007264.png}\\
\includegraphics[width=4cm,height=3cm]{images/pascal/003533.png}&
\includegraphics[width=4cm,height=3cm]{images/pascal/004624.png}&
\includegraphics[width=4cm,height=3cm]{images/pascal/003559.png}\\
\end{tabular}
}
\caption{Successful detection results of unseen objects on Pascal-ZSD dataset using proposed hybrid region embedding.}
\label{fig:pascal_results}
\end{figure}

The reason why the performance of the individual label embedding component is much lower can potentially be explained by the
fact that the ZSD-Pascal dataset is relatively small: there are 16 classes in the training set, and this number is
most probably insufficient to learn a direct mapping from visual features to class embeddings.

\begin{table}[]
\centering
\resizebox{\columnwidth}{!}{\begin{tabular}{c | c | cccccccccccccccc|cccc|c}
\rotatebox{90}{Method}             & \rotatebox{90}{Test split}  & \rotatebox{90}{aeroplane} & \rotatebox{90}{bicycle} & \rotatebox{90}{bird} & \rotatebox{90}{boat}  & \rotatebox{90}{bottle}  & \rotatebox{90}{bus}   & \rotatebox{90}{cat}  & \rotatebox{90}{chair}  & \rotatebox{90}{cow}  & \rotatebox{90}{dining table} & \rotatebox{90}{horse} & \rotatebox{90}{motorbike} & \rotatebox{90}{person} & \rotatebox{90}{potted plant} & \rotatebox{90}{sheep}  & \rotatebox{90}{tvmonitor}   & \rotatebox{90}{car}  & \rotatebox{90}{dog}  & \rotatebox{90}{sofa} & \rotatebox{90}{train} & \rotatebox{90}{mAP (\%)}       \\
\hline
\multirow{3}{*}{LE} & v      & .46 & .50  & .44 & .28 & .12 & .59 & .44 & .20  & .11 & .38 & .35 & .47 & .65 & .16 & .18 & .53 & -    & -    & -    & -    & 36.8          \\
                   & t     & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & .54 & .79 & .45 & .12 & 47.9          \\
                   & v+t & .34 & .48 & .40  & .23 & .12 & .34 & .28 & .12 & .09 & .32 & .28 & .36 & .60  & .15 & .13 & .50  & .27 & .26 & .20  & .05 & 27.4          \\
\hline
\multirow{3}{*}{CC} & v      & .69 & .74 & .72 & .63 & .43 & .83 & .73 & .43 & .43 & .66 & .78 & .80  & .75 & .41 & .62 & .75 & -    & -    & -    & -    & 65.0          \\
                   & t     & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & .60  & .85 & .44 & .27 & 53.8          \\
                   & v+t & .67 & .73 & .70  & .59 & .41 & .61 & .58 & .32 & .32 & .65 & .74 & .68 & .72 & .39 & .57 & .72 & .49 & .24 & .10  & .15 & 52.0          \\
\hline
\multirow{3}{*}{H} & v      & .70  & .73 & .76 & .54 & .42 & .86 & .64 & .40  & .54 & .75 & .80  & .80  & .75 & .34 & .69 & .79 & -    & -    & -    & -    & \textbf{65.6} \\
                   & t     & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & -    & .55 & .82 & .55 & .26 & \textbf{54.2} \\
                   & v+t & .68 & .72 & .74 & .48 & .41 & .61 & .48 & .25 & .48 & .73 & .75 & .71 & .73 & .33 & .59 & .57 & .44 & .25 & .18 & .15 & \textbf{52.3}
\end{tabular}
}
\caption{ZSD performances of proposed label embedding (LE), convex combination (CC) and hybrid (H) methods on Pascal-ZSD dataset. We report class based average precision and mean average precision (mAP) scores of validation (v), test (t) and validation+test (v+t) images.}
\label{table:zsd_pascal_Results}
\end{table}

Qualitative results for our approach are provided in Figure~\ref{fig:pascal_results}. In this figure, example results of succesful detections
of objects of unseen classes with various poses and sizes are shown.
Additionally, example failure cases are shown on Figure~\ref{fig:pascal_results_failure}. Problems in detection include
missed detections, false positives, as well as misclassification of objects despite correct localization.
For instance, in the second image within
Figure~\ref{fig:pascal_results_failure}, we see that \textit{''picnic bench''} object is misrecognized  as \textit{''sofa''},
most probably due to relative similarity of the '\textit{'chair''} and \textit{''dining table''} seen classes in the embedding space.


\begin{figure}
\resizebox{\textwidth}{!}{
\begin{tabular}{ccc}
\includegraphics[width=6cm,height=4cm]{images/pascal/error.png}&
\includegraphics[width=6cm,height=4cm]{images/pascal/error2.png}&
\includegraphics[width=6cm,height=4cm]{images/pascal/error3.png}\\
\end{tabular}
}
\caption{Unsuccessful detection results of unseen objects on Pascal-ZSD dataset using hybrid region embedding.}
\label{fig:pascal_results_failure}
\end{figure}


