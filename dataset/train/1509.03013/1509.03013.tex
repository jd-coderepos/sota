\documentclass[submission,copyright]{eptcs}
\providecommand{\event}{FICS 2015} 


\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{stmaryrd}
\usepackage{breakurl}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{observation}{Observation}
\newtheorem{example}{Example}
\newtheorem{remark}{Remark}


\newcommand{\dnot}{not{\ }}
\newcommand*{\pnot}{\mathord{\sim}}

\newcommand{\mo}[1]{\llbracket#1\rrbracket}
\newcommand{\mwrt}[2]{\llbracket#1\rrbracket(#2)}
\newcommand{\mwrs}[3]{\llbracket#1\rrbracket_{#3}(#2)}

\newcommand{\lub}{\bigsqcup}
\newcommand{\lubr}[1]{\bigsqcup_{#1}}
\newcommand{\glb}{\bigsqcap}
\newcommand{\glbr}[1]{\bigsqcap_{#1}}

\newcommand{\aleq}[1][]{\sqsubseteq_{#1}}
\newcommand{\ageq}[1][]{\sqsupseteq_{#1}}

\newcommand{\ee}[1][I]{\rhd_{#1}}

\newcommand{\bezem}{\mathcal{M}_\mathsf{Gr(P)}}
\newcommand{\bezemTP}{\mathcal{T}_\mathsf{Gr(P)}}




\title{Equivalence of two Fixed-Point Semantics for Definitional Higher-Order
Logic Programs\thanks{This research was supported by the project ``Handling Uncertainty in Data Intensive Applications'',
co-financed by the European Union (European Social Fund) and Greek national funds,
through the Operational Program ``Education and Lifelong Learning'' of the National
Strategic Reference Framework (NSRF) - Research Program: THALES, Investing in
knowledge society through the European Social Fund.}}
\author{Angelos Charalambidis
\institute{University of Athens \\ Athens, Greece}
\email{a.charalambidis@di.uoa.gr}
\and
Panos Rondogiannis
\institute{University of Athens \\ Athens, Greece}
\email{prondo@di.uoa.gr}
\and
Ioanna Symeonidou
\institute{University of Athens \\ Athens, Greece}
\email{i.symeonidou@di.uoa.gr}
}
\def\titlerunning{Equivalence of two Definitional Higher-Order LP Semantics}
\def\authorrunning{A. Charalambidis, P. Rondogiannis \& I. Symeonidou}


\begin{document}
\maketitle

\begin{abstract}
Two distinct research approaches have been proposed for assigning a purely
  extensional semantics to higher-order logic programming. The former approach
  uses classical domain-theoretic tools while the latter builds on a fixed-point
  construction defined on a syntactic instantiation of the source program. The
  relationships between these two approaches had not been investigated until now.
  In this paper we demonstrate that for a very broad class of programs, namely
  the class of {\em definitional programs} introduced by W. W. Wadge, the two
  approaches coincide (with respect to ground atoms that involve symbols of the
  program). On the other hand, we argue that if existential higher-order
  variables are allowed to appear in the bodies of program rules, the two approaches
  are in general different. The results of the paper contribute to a better
  understanding of the semantics of higher-order logic programming.
\end{abstract}

\section{Introduction}
Extensional higher-order logic programming has been proposed~\cite{Wa91a,Bezem99,Bezem01,KRW05,CharalambidisHRW13,CharalambidisER14}
as a promising generalization of classical logic programming. The key idea behind this paradigm is
that the predicates defined in a program essentially denote sets and therefore one can use standard
extensional set theory in order to understand their meaning and reason about them. The main difference
between the extensional and the more traditional {\em intensional} approaches to higher-order logic 
programming~\cite{MN2012,CKW93-187} is that the latter approaches have a much richer syntax and 
expressive capabilities but a non-extensional semantics.

Actually, despite the fact that only very few articles have been written regarding extensionality in higher-order logic programming, two main semantic approaches can be identified. The work described in~\cite{Wa91a,KRW05,CharalambidisHRW13,CharalambidisER14}
uses classical domain-theoretic tools in order to capture the meaning of higher-order logic programs.
On the other hand, the work presented in~\cite{Bezem99,Bezem01} builds on a fixed-point
construction defined on a syntactic instantiation of the source program
in order to achieve an extensional semantics. Until now, the relationships between
the above two approaches had not yet been investigated.

In this paper we demonstrate that for a very broad class of programs, namely
the class of {\em definitional programs} introduced by W. W. Wadge~\cite{Wa91a},
the two approaches coincide. Intuitively, this means that for any given definitional
program, the sets of true ground atoms of the program are identical under the two
different semantic approaches. This result is interesting since it suggests that
definitional programs are of fundamental importance for the further study of extensional
higher-order logic programming. On the other hand, we argue that if we try to slightly
extend the source language, 
the two approaches give different
results in general. Overall, the results of the paper contribute to a better
understanding of the semantics of higher-order logic programming and pave the
road for designing a realistic extensional higher-order logic programming language.

The rest of the paper is organized as follows. Section~\ref{section2} briefly introduces
extensional higher-order logic programming and presents in an intuitive way the two existing
approaches for assigning meaning to programs of this paradigm. Section~\ref{section3} contains 
background material, namely the syntax of definitional programs and the formal details behind the
two aforementioned semantic approaches. Section~\ref{section4} demonstrates the
equivalence of the two semantics for definitional programs. Finally, Section~\ref{section5}
concludes the paper with discussion regarding non-definitional programs and
with pointers to future work.


\section{Intuitive Overview of the two Extensional Approaches}\label{section2}
In this section we introduce extensional higher-order logic programming and 
present the two existing approaches for assigning meaning to programs of this paradigm. 
Since these two proposals were initially introduced by W. W. Wadge and M. Bezem
respectively, we will refer to them as {\em Wadge's semantics} and {\em Bezem's semantics}
respectively. The key idea behind both approaches is that in order to achieve
an extensional semantics, one has to consider a fragment of higher-order logic
programming that has a restricted syntax.

\subsection{Extensional Higher-Order Logic Programming}
The main differences between extensional and intensional higher-order logic programming 
can be easily understood through two simple examples (borrowed from~\cite{CharalambidisHRW13}).
Due to space limitations, we avoid a more extensive discussion of this issue; the interested
reader can consult~\cite{CharalambidisHRW13}.
\begin{example}\label{intensional-predicate}
Suppose we have a database of professions, both of their membership
and their status. We might have rules such as:

with {\tt engineer} and {\tt programmer} used as predicates. In
intensional higher-order logic programming we could also have rules
in which these are arguments, eg:

Now suppose {\tt tom} and {\tt sally} are also avid users of
Twitter. We could have rules:

The predicates {\tt tweeter} and {\tt engineer} are
equal as sets (since they are true for the same objects, namely {\tt
tom} and {\tt sally}). If we attempted to understand the above
program from an extensional point of view, then we would have to
accept that {\tt profession(tweeter)} must also hold (since {\tt
tweeter} and {\tt engineer} are indistinguishable as sets). It is
clear that the extensional interpretation in this case is completely
unnatural. The program can however be understood intensionally: the
predicate {\tt profession} is true of the {\em name} {\tt engineer}
(which is different than the name {\tt tweeter}).\qed
\end{example}
On the other hand, there are cases where predicates can be
understood extensionally:
\begin{example}\label{extensional-predicate}
Consider a program that consists only of the following rule:

In an extensional language, predicate {\tt p} above can be
intuitively understood in purely set-theoretic terms: {\tt p} is the
set of all those sets that contain both {\tt 0} and {\tt 1}.

It should be noted that the above program is also a syntactically
acceptable program of the existing intensional logic programming
languages. The difference is that in an extensional language the
above program has a purely set-theoretic semantics.\qed
\end{example}


From the above examples it can be understood that extensional higher-order
logic programming sacrifices some of the rich syntax of intensional higher-order
logic programming in order to achieve semantic clarity.

\subsection{Wadge's Semantics}
The first proposal for an extensional semantics for higher-order logic programming
was given in~\cite{Wa91a} (and later refined and extended in~\cite{KRW05,CharalambidisHRW13,CharalambidisER14}).
The basic idea behind Wadge's approach is that if we consider a properly restricted
higher-order logic programming language, then we can use standard ideas from
denotational semantics in order to assign an extensional meaning to programs.
The basic syntactic assumptions introduced by Wadge in~\cite{Wa91a} are the following:
\begin{itemize}
\item In the head of every rule in a program, each argument of predicate type must be a variable; all such variables must be distinct.
\item The only variables of predicate type that can appear in the body of a
      rule, are variables that appear in its head.
\end{itemize}
Programs that satisfy the above restrictions are named {\em definitional} in~\cite{Wa91a}.
\begin{example}\label{example1}
The program\footnote{For simplicity reasons, the syntax that we use in our example programs is Prolog-like.
The syntax that we adopt in the next section is slightly different and more convenient for the theoretical
developments that follow.}:

is definitional because the arguments of predicate type in the head of the rule for {\tt r}
are distinct variables. Moreover, the only predicate variables that appear in the body of the
same rule, are the variables in its head (namely {\tt P} and {\tt Q}). \qed
\end{example}

\begin{example}\label{example2}
The program:

is not definitional because the predicate constant {\tt q} appears as an
argument in the second clause. For a similar reason, the program in
Example~\ref{intensional-predicate} is not definitional. The program:

is also not definitional because the predicate variable {\tt Q} is used twice in the
head of the above rule. Finally, the program:

is not definitional because the predicate variable {\tt Q} that appears in the
body of the above rule, does not appear in the head of the rule.\qed
\end{example}
As it is argued in~\cite{Wa91a}, if a program satisfies the above two syntactic restrictions,
then it has a {\em unique minimum model} (this notion will be precisely defined in
Section~\ref{section3}). Consider again the program of Example~\ref{example1}. In the minimum
model of this program, the meaning of predicate {\tt p} is the relation  and
the meaning of predicate {\tt q} is the relation . On the other hand, the meaning
of predicate {\tt r} in the minimum model is a relation that contains the pairs ,
,  and .
As remarked by W. W. Wadge (and formally demonstrated in~\cite{KRW05,CharalambidisHRW13}), the minimum
model of every definitional program is monotonic and continuous\footnote{The notion of continuity
will not play any role in the remaining part of this paper.}. Intuitively, monotonicity means
that if in the minimum model the meaning of a predicate is true of a relation, then it is also
true of every superset of this relation. For example, we see that since the meaning of {\tt r}
is true of  , then it is also true of 
(because  is a superset of ).

The minimum model of a given definitional program can be constructed as the least fixed-point
of an operator that is associated with the program, called the {\em immediate consequence operator}
of the program. As it is demonstrated in~\cite{Wa91a,KRW05}, the immediate consequence operator
is monotonic, and this guarantees the existence of the least fixed-point which is constructed
by a bottom-up iterative procedure (more formal details will be given in the next section).
\begin{example}\label{example3}
Consider the definitional program:

In the minimum model of the above program, the meaning of {\tt q} is the relation .
The meaning of {\tt p} is the set of all relations that contain (at least) {\tt a}; more formally,
it is the relation . The meaning of {\tt id} is the set of all pairs 
such that  belongs to ; more formally, it is the relation .\qed
\end{example}
Notice that in the construction of the minimum model, all predicates are initially assigned the
empty relation. The rules of the program are then used in order to improve the meaning assigned to
each predicate symbol. More specifically, at each step of the fixed-point computation, the meaning
of each predicate symbol either stabilizes or it becomes richer than the previous step.
\begin{example}\label{example4}
Consider again the definitional program of the previous example. In the iterative construction
of the minimum model, all predicates are initially assigned the empty relation (of the corresponding
type). After the first step of the construction, the meaning assigned to predicate {\tt q} is
the relation  due to the first two facts of the program. At this same step,
the meaning of {\tt p} becomes the relation . Also, the meaning of
{\tt id} becomes equal to the relation . Additional iterations will not
alter the relations we have obtained at the first step; in other words, we have reached the
fixed-point of the bottom-up computation.\qed
\end{example}
In the above example, we obtained the meaning of the program in just one step. If the source
program contained recursive definitions, convergence to the least fixed-point would in general
require more steps.

\subsection{Bezem's Semantics}
In~\cite{Bezem99,Bezem01}, M. Bezem proposed an alternative extensional semantics for higher-order
logic programs. Again, the syntax of the source language has to be appropriately restricted.
Actually, the class of programs adopted in~\cite{Bezem99,Bezem01} is a proper superset of the
class of definitional programs. In particular, Bezem proposes the class of {\em hoapata programs} which
extend definitional programs:
\begin{itemize}
\item A predicate variable that appears in the body of a rule, need not
      necessarily appear in the head of that rule.

\item The head of a rule can be an atom that starts with a predicate variable.
\end{itemize}
\begin{example}
All definitional programs of the previous subsection are also hoapata.
The following non-definitional program of Example~\ref{example2} is hoapata:

Intuitively, the above program states that {\tt p} is true of {\tt a}
if there exists a predicate that is defined in the program
that is true of {\tt a}. We will use this program
in our discussion at the end of the paper.

The following program is also hoapata (but not definitional):

Intuitively, the above program states that every binary relation is
true of the pair .\qed
\end{example}

Given a hoapata program, the starting idea behind Bezem's approach is to take its
``ground instantiation'' in which we replace variables with well-typed terms of
the Herbrand Universe of the program (ie., terms that can be created using only
predicate and individual constants that appear in the program).  For example, given
the program:

the ground instantiation is the following infinite ``program'':

One can now treat the new program as an infinite propositional one (ie., each ground atom can be seen
as a propositional one). This implies that we can use the standard least fixed-point construction
of classical logic programming (see for example~\cite{lloyd}) in order to compute the set of atoms
that should be taken as ``true''.  In our example, the least fixed-point will
contain atoms such as {\tt q(a)}, {\tt q(b)}, {\tt p(q)}, {\tt id(q)(a)}, {\tt p(id(q))},
and so on.

A main contribution of Bezem's work was that he established that the least fixed-point
of the ground instantiation of every hoapata program is {\em extensional}. This notion
can intuitively be explained as follows. It is obvious in the
above example that the relations {\tt q} and {\tt id(q)} are equal (they are both true of only the
constant {\tt a}, and therefore they both correspond to the relation ).
Therefore, we would expect that (for example) if {\tt p(q)} is true then {\tt p(id(q))}
is also true because {\tt q} and {\tt id(q)} should be considered as interchangeable.
This property of ``interchangeability'' is formally defined in~\cite{Bezem99,Bezem01} and it is
demonstrated that it holds in the least fixed-point of the immediate consequence operator
of the ground instance of every hoapata program.

\subsection{The Differences Between the two Approaches}
It is not hard to see that the two semantic approaches outlined in the previous
subsections, have some important differences. First, they operate on different
source languages. Therefore, in order to compare them we have to restrict Bezem's
approach to the class of definitional programs\footnote{Actually, we could alternatively
extend Wadge's approach to a broader class of programs. Such an extension has already
been performed in~\cite{CharalambidisHRW13}, and we will discuss its repercussions in the
concluding section.}.

The main difference however between the two approaches is the way that the least
fixed-point of the immediate consequence operator is constructed in each case.
In Wadge's semantics the construction starts by initially assigning to every predicate
constant the empty relation; these relations are then improved at each step until
they converge to their final meaning. In other words, Wadge's semantics {\em manipulates
relations}. On the other hand, Bezem's semantics works with the ground instantiation
of the source program and, at first sight, it appears to have a more syntactic flavor.
In our running example, Wadge's approach converges in a single step while Bezem's
approach takes an infinite number of steps in order to converge. However, one can easily verify that
the ground atoms that belong to the least fixed-point under Bezem's semantics, are also
true in the minimum model under Wadge's semantics. This poses the question whether
under both approaches, the sets of ground atoms that are true, are identical.
This is the question that we answer positively in the rest of the paper.

\section{Definitional Programs and their Semantics}
\label{sec:lang}
\label{section3}
In this section we define the source language  of definitional
higher-order logic programs. Moreover, we present in a formal way the two
different extensional semantics that have been proposed for such programs,
namely Wadge's and Bezem's semantics respectively.

\subsection{Syntax}
The language  is based on a simple
type system that supports two base types: , the boolean domain,
and , the domain of individuals (data objects). The composite
types are partitioned into three classes: functional (assigned to
function symbols), predicate (assigned to predicate symbols) and
argument (assigned to parameters of predicates).


\begin{definition}
A type can either be functional, argument, or predicate, denoted by , 
and  respectively and defined as:

\end{definition}

We will use  to denote an arbitrary type (either functional, argument or predicate one).
As usual, the binary operator  is right-associative. A
functional type that is different than  will often be written
in the form , . Moreover, it can
be easily seen that every predicate type  can be written in the
form ,
 (for  we assume that ).

We proceed by defining the syntax of :
\begin{definition}
The alphabet of the higher-order language  consists of the following:
\begin{enumerate}
  \item Predicate variables of every predicate type  (denoted by capital letters such as
      ).
  \item Individual variables of type  (denoted by capital letters such as
      ).
  \item Predicate constants of every predicate type  (denoted by lowercase letters such as
      ).
  \item Individual constants of type  (denoted by lowercase
      letters such as ).
  \item Function symbols of every functional type  (denoted by lowercase letters such as ).
  \item The logical conjunction constant , the inverse implication constant , the left and right parentheses,
        and the equality constant  for comparing terms of type .
\end{enumerate}
\end{definition}
The set consisting of the predicate variables and the individual variables of 
will be called the set of {\em argument variables} of . Argument variables will
be usually denoted by  and its subscripted versions.

\begin{definition}
The set of {\em terms} of the higher-order language  is defined as follows:
\begin{itemize}
  \item Every predicate variable (respectively predicate constant) of type  is a
        term of type ; every individual variable (respectively individual constant)
        of type  is a term of type ;
  \item if  is an -ary function symbol and 
        are terms of type  then  is
        a term of type ;
  \item if  is a term of type  and
         a term of type  then  is a term of type .
\end{itemize}
\end{definition}
\begin{definition}
The set of {\em expressions} of the higher-order language  is defined as follows:
\begin{itemize}
\item A term of type  is an expression of type ;
\item if  and  are terms of type , then  is an expression of type .
\end{itemize}
\end{definition}
We write  to denote the set of all the variables in .
Expressions (respectively terms) that have no variables will often be referred to as {\em ground expressions} (respectively {\em ground terms}). Expressions of type  will often be referred to as {\em atoms}. We will omit parentheses
when no confusion arises. To denote that an expression  has type  we will often write .

\begin{definition}
A {\em clause} is a formula ,
where  is a predicate constant, 
is a term of type  and  are expressions
of type . The term  is called the {\em head} of the
clause, the variables  are the {\em formal parameters} of the
clause and the conjunction  is its {\em body}.
A {\em definitional clause} is a clause that additionally satisfies the following
two restrictions:
\begin{enumerate}
\item All the formal parameters are distinct variables (ie., for all  such that ,
      ).

\item The only variables that can appear in the body of the clause are its formal parameters
      and possibly some additional individual variables (namely variables of type ).
\end{enumerate}
A {\em program}  is a set of definitional program clauses.
\end{definition}
In the rest of the paper, when we refer to ``clauses'' we will mean definitional ones.
For simplicity, we will follow the usual logic programming convention and we will write

instead of .



Our syntax differs slightly from the Prolog-like syntax that we have used in Section~\ref{section2}.
However, one can easily verify that we can transform every program from the former syntax to the latter.



\begin{definition}
For a program , we define the Herbrand universe for every argument type , denoted by
 to be the set of all ground terms of type , that can be formed out of the individual constants, function symbols and predicate constants in the program.
\end{definition}
In the following, we will often talk about the ``ground instantiation of a program''. This
notion is formally defined below.
\begin{definition}
A {\em ground substitution}  is a finite set of the form 
where the 's are different argument variables and each 
is a ground term having the same type as . We write
 to denote the domain of .
\end{definition}
We can now define the application of a substitution to an expression.
\begin{definition}
Let  be a substitution and  be an expression. Then, 
is an expression obtained from  as follows:
\begin{itemize}
  \item  if  is a predicate or individual constant;
  \item  if ; otherwise, ;
  \item ;
  \item ;
  \item .
\end{itemize}
\end{definition}
\begin{definition}
Let  be an expression and  be a ground substitution such that
. Then, the ground expression 
is called a {\em ground instantiation} of . A {\em ground instantiation of a clause}

with respect to a ground substitution  is the formula
.
The {\em ground instantiation of a program}  is the (possibly infinite)
set that contains all the ground instantiations of the clauses of 
with respect to all possible ground substitutions.
\end{definition}


\subsection{Wadge's Semantics}
\label{sec:hosem}
The key idea behind Wadge's semantics is (intuitively) to assign to program
predicates monotonic relations. In the following, given posets  and ,
we write  to denote the set of all monotonic
relations from  to .

Before specifying the semantics of expressions of  we need to
provide the set-theoretic meaning of the types of expressions of
 with respect to an underlying domain. It is customary in
logic programming to take the underlying domain to be the Herbrand
universe . In the following definition we define
simultaneously and recursively two things: the semantics 
of a type  and a corresponding partial order 
on the elements of . We adopt the usual ordering of the truth values
 and , i.e. ,
 and .
\begin{definition}
Let  be a program. Then,
\begin{itemize}
  \item  and  is the trivial partial order
        that relates every element to itself;
  \item . A partial order for this case is not needed;
  \item  and  is the partial order  on truth values;
\item  and 
  is the partial order defined as follows: for all ,
   iff  for all .
\end{itemize}
\end{definition}
We now proceed to define Herbrand interpretations and states.
\begin{definition}
A Herbrand interpretation  of a program  is an interpretation such that:
\begin{enumerate}
  \item for every individual constant  that appears in , ;
  \item for every predicate constant  that appears in , ;
  \item for every -ary function symbol  that appears in  and for all
  , .
\end{enumerate}
\end{definition}

\begin{definition}
  A Herbrand state  of a program  is a function that assigns to each argument variable 
  of type , an element .
\end{definition}
In the following,  is used to denote a state that is identical to  the
only difference being that the new state assigns to  the value .

\begin{definition}
  Let  be a program,  be a Herbrand interpretation of  and
   be a Herbrand state. Then, the semantics of the expressions of  is
  defined as follows:
\begin{enumerate}
  \item  if  is a variable;
  \item  if  is an individual constant;
  \item  if  is a predicate constant;
  \item ;
  \item ;
  \item  if  and  otherwise.
\end{enumerate}
\end{definition}
For ground expressions  we will often write  instead
of  since the meaning of  is independent of .

It is straightforward to confirm that the above definition assigns to every expression an element of the corresponding semantic domain, as stated in the following lemma:
\begin{lemma}
Let  be a program and let  be an expression. Also, let  be a Herbrand interpretation and  be a Herbrand state. Then .
\end{lemma}

\begin{definition}
Let  be a program and  be a Herbrand interpretation of .
Then,  is a Herbrand model of  iff for every clause
 in 
and for every Herbrand state , if for all ,  then
.
\end{definition}
In the following we denote the set of Herbrand interpretations of a program 
with . We define a partial order on  as
follows: for all , 
iff for every predicate  that appears in , .
Similarly, we denote the set of Herbrand states with  and we define
a partial order as follows: for all ,  iff
for all variables , .
The following lemmata are straightforward to establish:
\begin{lemma}
Let  be a program. Then,  is a complete lattice.
\end{lemma}

\begin{lemma} \label{interp-state-monotonicity}
Let  be a program and let  be an expression.
Let  be Herbrand interpretations and  be Herbrand states.
Then,
\begin{enumerate}
  \item If   then .
  \item If  then .
\end{enumerate}
\end{lemma}


We can now define the {\em immediate consequence operator} for
 programs, which generalizes the corresponding operator for classical (first-order)
programs~\cite{lloyd}.
\begin{definition}
  Let  be a program. The mapping 
  is called the {\em immediate consequence operator for } and is defined for every predicate
   and  as

\end{definition}



It is not hard to see that  is a monotonic function, and this leads to
the following theorem~\cite{Wa91a,KRW05}:
\begin{theorem}
Let  be a program.
Then 
is the minimum, with respect to , Herbrand model of .
\end{theorem}



\subsection{Bezem's Semantics}
\label{sec:bezemsem}
In contrast to Wadge's semantics which proceeds by constructing the meaning of predicates
as relations, Bezem's approach takes a (seemingly) more syntax-oriented approach. In particular,
Bezem's approach builds on the ground instantiation of the source program in order to
retrieve the meaning of the program. In our definitions below, we follow relatively closely
the exposition given in~\cite{Bezem99,Bezem01,Bezem2002}.
\begin{definition}
Let  be a program and let  be its ground instantiation.
An interpretation  for  is defined as a subset of 
by the usual convention that, for any , 
iff . We also extend the interpretation  for every 
atom as follows:  if  and  otherwise.\end{definition}

Observe that the meaning of  is fixed and independent of the interpretation.

\begin{definition}
We define the immediate consequence operator, , of  as follows:

\end{definition}

As it is well established in bibliography (for example~\cite{lloyd}), the least fixed-point of the immediate consequence operator of a propositional program exists and is the minimum, with respect to
set inclusion and equivalently , model of . This fixed-point, which we will henceforth denote by , is shown in~\cite{Bezem99,Bezem01} to be directly related to a notion of a model capable of capturing the perceived semantics of the higher-order program . In particular, this model by definition assigns to all ground atoms the same truth values as . It is therefore justified that we restrict our attention to , instead of the aforementioned higher-order model, in our attempt to prove the equivalence of Bezem's semantics and Wadge's semantics.



The following definition and subsequent theorem obtained in~\cite{Bezem2002},
identify a property of  that we will need in the next section.
\begin{definition}
Let  be a program and let  be the -minimum model of .
For every argument type  we define a corresponding partial order as follows: for type , we define
 as syntactical equality, i.e.  for all .
For type ,  iff . For a predicate type of
the form ,  iff
 for all .
\end{definition}

\begin{theorem}[-Monotonicity Property]\label{th-preceq-monotonicity}~\cite{Bezem2002}
Let  be a program and  be the -minimum model of . Then for all  and all  such that , it holds .
\end{theorem}

\section{Equivalence of the two Semantics}
\label{sec:positive}
\label{section4}
{In this section we demonstrate that the two semantics presented in the previous
section, are equivalent for definitional programs. To help us transcend the
differences between these approaches, we introduce two key notions, namely that
of the \emph{ground restriction} of a higher-order interpretation and its
complementary notion of the \emph{semantic extension} of ground expressions.
But first we present the following \emph{Substitution Lemma}, which will be useful in the proofs of later results.}
\begin{lemma}[Substitution Lemma]
\label{substitution_lemma}
Let  be a program and  be a Herbrand interpretation of . Also
let  be an expression and  be a ground
substitution with . If  is a Herbrand state such that, for all
, , then
.
\end{lemma}
\begin{proof}
By a structural induction on . For the basis case, if
 or  then
the statement reduces to an identity and if 
then it holds by assumption. For the induction step, we first examine the case that ;
then 
and .
By the induction hypothesis, , thus we have
.
Now consider the case that .
We have 
and .
Again, applying the induction hypothesis, we conclude that
.
Finally, if 
we have that  iff ,
which, by the induction hypothesis, holds iff
.
Moreover, we have  iff
,
therefore we conclude that  iff
.
\end{proof}

{Given a Herbrand interpretation  of a definitional program, it is straightforward to
devise a corresponding interpretation of the ground instantiation of the program,
by restricting  to only assigning truth values to ground atoms. As expected,
such a restriction of a model of the program produces a model of its ground
instantiation. This idea is formalized in the following definition and theorem.}
\begin{definition}
Let  be a program,  be a Herbrand interpretation of  and 
be the ground instantiation of . We define the \emph{ground restriction}
of , which we denote by , to be an interpretation of
, such that, for every ground atom
, .
\end{definition}


\begin{theorem}
\label{th_ground_model}
Let  be a program and  be its ground instantiation.
Also let  be a Herbrand model of  and  be the ground restriction of . Then  is a model of .
\end{theorem}
\begin{proof}
By definition, each clause in  is of the form
, i.e. the ground instantiation of a clause  in  with respect to a ground substitution , such that  includes  and all other (individual) variables appearing in the body of the clause and , for all .
Let  be a Herbrand state such that ,
for all . By the Substitution Lemma (Lemma \ref{substitution_lemma})
and the definition of ,
.
Similarly, for each atom  in the body of the clause,
we have .
Consequently, if  for all , we also have that .
As  is a model of , this implies that
 and
therefore  is a model of .
\end{proof}

{The above theorem is of course useful in connecting the
-minimum Herbrand model of a program to its ground instantiation. However,
in order to prove the equivalence of the two semantics under consideration,
we will also need to go in the opposite direction and connect the -minimum model of the ground program to the higher-order program. To this end we
introduce the previously mentioned \emph{semantic extensions} of a ground
expression.}
\begin{definition}
Let  be a program and  be the -minimum model of .
Let  be a ground expression of argument type  and  be an
element of . We will say that  is a semantic extension of  and
write  if
\begin{itemize}
\item  and ;
\item  and ;
\item  and for all  and ,
      such that , it holds that .
\end{itemize}
\end{definition}

{Compared to that of the ground restriction presented earlier, the notion of
extending a syntactic object to the realm of semantic elements, is more complicated.
In fact, even the existence of a semantic extension is not immediately obvious.
The next lemma guarantees that not only can such an extension  be constructed
for any expression of the language, but it also has an interesting property of
mirroring the ordering of semantic objects with respect to  in a
corresponding ordering of the expressions with respect to .}
\begin{lemma} \label{lm_order_preservation}
Let  be a program,  be its ground instantiation and
 be the -minimum model of . For every
argument type  and every ground term 
\begin{enumerate}
\item There exists  such that .
\item For all  and all , if ,  and , then .
\end{enumerate}
\end{lemma}
\begin{proof}
We prove both statements simultaneously, performing an induction on the structure
of . Specifically, the first statement is proven by showing that in each
case we can construct a function  of type , which is monotonic with
respect to  and satisfies .

In the basis case, the construction of  for types  and  is trivial.
Also, if , then both  and  reduce to equality,
so we have , which in this case is equivalent to
. On the other hand, for
,  identifies with equality, while  and
 identify with , so we have that
  implies
 .

For a more complex type , ,
we can easily construct , as follows:

To see that  is monotonic, consider ,
such that  and observe
that  implies , due to
the transitivity of .
We will now show that , i.e. for all  and
 such that , it
holds . This is trivial
if , since . Let
us now examine the case that . For the
sake of contradiction, assume . Then,
by the construction of , there must exist  and 
such that, for all , ,  and . By the induction hypothesis, we have that , for all . This, by the -Monotonicity Property of  (Theorem \ref{th-preceq-monotonicity}), yields that , which is obviously a contradiction. Therefore it has to be that .

Finally, in order to prove the second statement and conclude the induction step, we need to show that for all terms ,
it holds . By the induction hypothesis, there exist , such that .
Because  and  is of type , we
have  by definition.
Similarly, we also have . Moreover,
by  we have that
. This yields the desired result, since  identifies with .
\end{proof}


{The following variation of the Substitution Lemma states that if the building elements of an expression are assigned meanings that are semantic extensions of their syntactic counterparts, then the meaning of the expression is itself a semantic extension of the expression.}
\begin{lemma} \label{lm_state_substitution_extension}
Let  be a program,  be its ground instantiation and  be a Herbrand
interpretation of . Also, let  be an expression
of some argument type  and
let  be a Herbrand state and  be a ground substitution, both with domain .
If, for all predicates  of type  appearing in , 
and, for all variables  of type  in , , then
.
\end{lemma}
\begin{proof}
The proof is by induction on the structure of .
The basis cases  and 
hold by assumption and  is trivial.
For the first case of the induction step, let ,
where  are of type
. By the induction hypothesis, we have that
.
As  is defined as equality, we have that  and therefore .
For the second case, let ,
where  is of type  and  is of type ; then, .
By the induction hypothesis, 
and ,
thus, by definition, .
Finally, we have the case that , where  and  are both of type . The induction hypothesis yields  and  or, since  is defined as equality,  and . Then   iff   and, equivalently,  iff , which implies .
\end{proof}


{We are now ready to present the main result of this paper. The theorem
establishes the equivalence of Wadge's semantics and Bezem's semantics, in
stating that their respective minimum models assign the same meaning to all ground atoms.}
\begin{theorem}
Let  be a program and let  be its ground instantiation.
Let  be the -minimum Herbrand model of  and let  be the
-minimum model of . Then, for every 
it holds .
\end{theorem}
\begin{proof}


We will construct an interpretation  for  and prove
some key properties for this interpretation. Then we will utilize these properties
to prove the desired result. The definition of  is as follows:



Observe that  is a valid Herbrand interpretation of , in the sense
that it assigns elements in  (i.e. functions that are monotonic with
respect to ) to every predicate of type  in . Indeed,
if it was not so, then for some predicate ,
there would exist tuples  and  with
, such that
 and .
By definition, the fact that  is assigned the value
, would imply that there exist  and 
as in the above definition, such that  and
. Being that 
are transitive relations, the latter yields that
. Therefore, by definition,
 should also evaluate to , which constitutes a
contradiction and thus confirms that the meaning of  is monotonic with respect to .

It is also straightforward to see that , i.e.
for all  and all ground terms 
such that , we have
. Because
, this holds trivially if .
Now let  and assume, for the sake of
contradiction, that . Then, by the definition
of , there must exist  and  such that, for
all , ,  and .
Thus, by the second part of Lemma \ref{lm_order_preservation}, for all ,  and,
by the -Monotonicity Property of , ,
which is obviously a contradiction. Thus we conclude that .

Next we prove that  is a model of . Let  be a clause in  and let , with , for all , and , for all , be the set of variables appearing in the clause. Then, it suffices to show that, for any tuple  of arguments and any Herbrand state  such that  for all ,  implies that, for at least one , . Again, by the definition of , we see that if , then there exist  and ground terms  such that ,  and . Let  be a ground substitution such that  for all  and, for all , ; then there exists a ground instantiation  of the above clause in . As  is a model of the ground program,  implies that there exists at least one  such that . We are going to show that the latter implies that , which proves that  is a model of . Indeed, let  be a Herbrand state such that  for all  and  for all . As we have shown earlier,  for any predicate , thus by Lemma \ref{lm_state_substitution_extension} we get . Since  is of type , the latter reduces to . Also, because , i.e. , by the second part of Lemma \ref{interp-state-monotonicity} we get , which makes .

Now we can proceed to prove that, for all , .
Let  be of the form , where
 and let
. As we have shown,
 is a Herbrand model of , while  is the minimum, with respect to , of all Herbrand models of ,
therefore we have that . By definition, this gives us that
 and,
by the first part of Lemma \ref{interp-state-monotonicity}, that
.
Moreover, for all predicates  in , we have  and thus,
by Lemma \ref{lm_state_substitution_extension}, taking  and  to be empty,
we get . In conjunction with (2), the latter suggests
that if  then ,
or, in other words, that .
Because of (1), this makes it that
. On the
other hand, by Theorem \ref{th_ground_model},  is a model of  and therefore , since  is the minimum model of . By the definition of  and the meaning of application, the latter becomes
. The last relation and (3) can only be true simultaneously, if all the above relations hold as equalities, in particular if .
\end{proof}

\section{Discussion}
\label{sec:concl}
\label{section5}
We have considered the two existing extensional approaches to the semantics of higher-order
logic programming, and have demonstrated that they coincide for the class of definitional
programs. It is therefore natural to wonder whether the two semantic approaches continue
to coincide if we extend the class of programs we consider. Unfortunately this is not
the case, as we discuss below.

A seemingly mild extension to our source language would be to allow higher-order predicate
variables that are not formal parameters of a clause, to appear in its body. Such programs
are legitimate under Bezem's semantics (ie., they belong to the hoapata class). Moreover,
a recent extension of Wadge's semantics~\cite{CharalambidisHRW13} also allows such programs.
However, for this extended class of programs the equivalence of the two semantic approaches
no longer holds as the following example illustrates.
\begin{example}
Consider the following extended program:

Following Bezem's semantics, we initially take the ground instantiation of the program, namely:

and then compute the least model of the above program which assigns to the atom
{\tt p(a)} the value . On the other hand, under the approach
in~\cite{CharalambidisHRW13}, the atom {\tt p(a)} has the value 
in the minimum Herbrand model of the initial program. This is due to the fact that
under the semantics of~\cite{CharalambidisHRW13}, our initial program reads (intuitively
speaking) as follows: ``{\tt p(a)} is true if there exists a relation that is
true of {\tt a}''; actually, there exists one such relation, namely the set .
This discrepancy between the two semantics is due to the fact that Wadge's semantics is
based on {\em sets} and not solely on the syntactic entities that appear in the
program.\qed
\end{example}


Future work includes the extension of Bezem's approach to higher-order logic programs
with negation. An extension of Wadge's approach for such programs has recently
been performed in~\cite{CharalambidisER14}. More generally, the addition of negation
to higher-order logic programming appears to offer an interesting and nontrivial
area of research, which we are currently pursuing.

\bibliographystyle{eptcs}
\bibliography{fics15}

\appendix

\end{document}
