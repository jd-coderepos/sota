\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[pagenumbers]{cvpr} 

\usepackage{graphicx}
\graphicspath{{./images/}}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{dsfont}
\usepackage{soul, nicefrac}
\usepackage[shortlabels]{enumitem}

\usepackage[dvipsnames]{xcolor}

\usepackage{eucal}



\setlength{\belowcaptionskip}{0pt}


\usepackage{caption}
\captionsetup{labelfont=bf,tableposition=top,font=small}


\definecolor{citecolor}{HTML}{0071bc}
\usepackage[pagebackref,breaklinks=true,letterpaper=true,colorlinks,citecolor=citecolor,bookmarks=false]{hyperref}




\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Table}{Tables}

\DeclareMathOperator*{\argmax}{arg\,max}

\def\confName{CVPR}
\def\confYear{2022}

\def\prob{{\mathbf{P}}}
\def\f{{\mathbf{f}}}
\def\x{{\mathbf{x}}}
\def\z{{\mathbf{z}}}
\def\i{{\mathbf{i}}}
\def\t{{\mathbf{t}}}
\def\ImageEncoder{\mathbf{E}}
\def\TextEncoder{\mathbf{T}}
\def\I{\mathcal{I}}
\def\T{\mathcal{T}}
\def\Z{\mathcal{Z}}
\begin{document}


\title{Retrieval Augmented Classification for Long-Tail Visual Recognition\thanks{Part of this work was done when WY was with Amazon and CS was with The University of Adelaide.}  
}
\author{
Alexander Long, ~~ Wei Yin, ~~ Thalaiyasingam Ajanthan,
Vu Nguyen, ~~ 
Pulak Purkait, ~~ \\
Ravi Garg, ~~
Alan Blair, ~~
Chunhua Shen, ~~
Anton van den Hengel 
\
    {\rm BE}(\x,\f(\cdot)) = \sum_{y\in\mathcal{Y}}  \prob_{\x|y} \left(y \notin \argmax_{y' \in \mathcal{Y}} \f_{y'}(\x)  \right)

    \ell_{\text{BalCE}}(\x,y, \f_y(\cdot))= -\frac{1}{N_y} \log \frac{e^{\f_{y}(\x)}}{\sum_{y^{\prime} \in\mathcal{Y}} e^{\f_{y^{\prime}}(\x)}}.
 \label{eq:general}
\ell(\x,y, \f_y(\cdot)) = -\alpha_{y} \log \frac{e^{\f_{y}(\x)+\tau \cdot  \Delta y}}{\sum_{y^{\prime} \in\mathcal{Y}} e^{\f_{y^{\prime}}(\x)+\tau \cdot \Delta y'}}

    \Delta y = 
    \begin{cases}
N_y^{-1/4}& \text{if} \quad y'=y,\\
0 & \text{otherwise.}
    \end{cases}

    \f(\x) = \frac{L}{2} \left(  \frac{\f^{\text{ret}}(\x)}{||\f^{\text{ret}}(\x)||_2} + \frac{\f^{\text{base}}(\x)}{||\f^{\text{base}}(\x)||_2} \right),

    \alpha_y = \frac{1}{\log{N_y}}

    \alpha_y = \frac{1}{\sqrt{N_y}}

class-frequency based re-weighting of individual sample losses. 

We confirm 
that 
the same effect is present for RAC on Places365-LT, with overall accuracy increasing with the use of both re-weighting schemes, with improvement most pronounced for tail classes (\cref{tbl:reweighting}). However, this trend does not hold on iNat. 

\begin{figure}
    \centering
    \includegraphics[width=0.9\columnwidth]{tausweep.pdf}
    \caption{Effect of  within the LACE loss on balanced performance on the Places365-LT dataset.}
    \label{fig:tausweep}
\end{figure}

For Places365-LT, we also we perform a sweep across , to evaluate if the same effect can be achieved with manual temperature scaling (\cref{fig:tausweep}). Higher  does result in slightly higher overall accuracy, however this effect is minor in comparison to re-weighting. This divergence from theory is likely due to the non-separability of many classes in Places365-LT due to the high label noise.




\subsection{Index Ablations}
\begin{table*}
\centering
\begin{tabular}{@{}rllrrrrrrr@{}}
\toprule
\multirow{2}{*}{\textbf{Index Size}} &
  \multicolumn{1}{c}{\multirow{2}{*}{\textbf{Index Type}}} &
  \multicolumn{1}{c}{\multirow{2}{*}{\textbf{Distance}}} &
  \multicolumn{5}{c}{\textbf{Test}} &
  \textbf{Train} &
  \multirow{2}{*}{\textbf{QT (ms/sample)}} \\
 &
  \multicolumn{1}{c}{} &
  \multicolumn{1}{c}{} &
  \textbf{Many} &
  \textbf{Med} &
  \textbf{Few} &
  \textbf{Top-1} &
  \textbf{Top-5} &
  \textbf{Top-1} &
   \\ \midrule
62.5k & Exact &      & 39.97 & 26.74 & 18.65 & 29.91 & 53.81 & 99.97 & 1.12 \\
62.5k & Exact & Cosine & 39.84 & 26.51 & 18.03 & 29.64 & 53.31 & 99.96 & 1.14 \\
62.5k & HNSW  &      & 39.89 & 26.51 & 18.03 & 29.66 & 53.32 & 99.79 & 1.06 \\
62.5k & HNSW  & Cosine & 39.57 & 26.26 & 17.68 & 29.37 & 52.83 & 99.79 & 1.07 \\
11.2M & Exact &      & -     & -     & -     & -     & -     & -     & 7.96 \\
11.2M & HNSW  &      & -     & -     & -     & -     & -     & -     & 3.01 \\ \bottomrule
\end{tabular}
\caption{Index ablations on Places365-LT. QT indicates Query Time. Large-sample indices are filled with the ImageNet21k dataset. }
\label{tbl:retab}
\end{table*}

We examine the effect of the distance metric and index type on RAC's lookup performance and speed in \cref{tbl:retab}. To quantify error induced by an approximate index, we include the lookup accuracy on the index content itself (training set) in addition to the validation accuracy. Query Time (QT) includes encoding samples with a ViT-B-16 model, which is the primarily overhead on small indexes.

We observe that the choice of distance metric ( vs.\  cosine) has little effect, as may be expected, give the high dimentionality of the index. Cosine distance does introduce a minor computational overhead due to the need to normalize the embeddings prior to querying. The drop in accuracy due to use of an approximate (HNSW) instead of exact -NN is also minor, but comes with a significant (2) speedup on large index's. Construction time is constant across all indexes at s per sample, with the exception of large-index HNSW, which requires  per sample. In summary, performance differences are minor when querying small indexes, however as the index size grows, the choice of HNSW becomes critical to ensure lookup time does not bottleneck training.









\subsection{Per-class Accuracy on iNat}
We include the same per-class visualization presented in the main body for Places365-LT (\cref{fig:Per-class}), for iNat. Note that for iNat only 3 samples are present for each class in the validation set, hence the square-wave appearance of the plots (\cref{fig:inatperclass}). Nevertheless, the same trend is clearly visible in the sliding window moving average, with the retrieval module performing best on tail classes and the base network largely focusing on the many and mid-frequency classes.

\begin{figure}[b]
\centering
\includegraphics[width=\columnwidth]{inatbalance.pdf}
\caption{Per-class top-1 accuracy on iNat from each branch's output. The  sample moving average over classes (solid line) is shown for clarity.}
\label{fig:inatperclass}
\end{figure}





\section{Further Details}
For \textbf{Places365-LT} we use the training and validation splits during development and report final numbers on the test set, with no validation samples used during final training. For \textbf{iNaturalist2018}, following prior work, we report results on the released validation split, as labels for the test set are not publicly available. 

In the main text, we use several common model variants. While the architectures for these models are standard, we specify the high-level design choices in \cref{tbl:resnets,tbl:vits}. These choices are consistent across both the  and  variants.


\begin{table}[]\label{tbl:dataset}
\centering
\begin{tabular}{@{}lrr@{}}
\toprule
                 & \textbf{Places365-LT} & \textbf{iNat} \\ \midrule
Samples (train)  & 62,500                & 437,513       \\
Samples (test)   & 36,500                & 24,426        \\
Classes          & 365                   & 8,142         \\
Imbalance Factor & 500                   & 996           \\ \bottomrule
\end{tabular}
\caption{Dataset Details}
\end{table}

\begin{table}[]
\centering
\begin{tabular}{@{}lrr@{}}
\toprule
\textbf{Hyperparameter} & \multicolumn{1}{c}{\textbf{ViT-B-16}} & \multicolumn{1}{c}{\textbf{ViT-B-32}} \\ \midrule
Patch size     & 16        & 32        \\
Depth          & 12        & 12        \\
Embedding Dimension & 768       & 768       \\
Attention Heads    & 12        & 12        \\
Parameters      & 85.8M     & 87.4M     \\ \bottomrule
\end{tabular}
\caption{ViT model architecture details.}
\label{tbl:vits}
\end{table}

\begin{table}
	\centering
	\begin{tabular}{@{}lrr@{}}
		\toprule
		\textbf{Hyperparameter}  & \textbf{RN50}    & \textbf{RN152d}     \\ \midrule
		Input size               &          &           \\
		Head                     & Avg. Pool, FC     & Avg. Pool, FC       \\
		Convolutions             & standard          & standard           \\
		Stem Convolutions        & 1 layer,       & 3 layer,         \\
		Stem width               & 32                & (128, 128, 128)       \\
		Layers                   & {[}3, 4, 6, 3{]}  & {[}3, 8, 36, 3{]}   \\
		Pool size               &                &  \\
		Num. features      &    2048               & 2048 \\
		Parameters               & 23.5M             & 58.2M             \\ \bottomrule
	\end{tabular}
	\caption{ResNet model architecture details. }
\label{tbl:resnets}
\end{table}

All training is carried out on  GB A GPU's. We largely follow the procedures outlined in \cite{howtotrainvit}, with the following alterations. We finetune with AdamW \cite{adamw} instead of SGD, and make use of low-magnitude RandAugment \cite{randaugment} alone for data augmentation, with no Color-Jitter, Mixup, Cutmix, RandomErase or Augmix applied. Full hyperparameters are shown in \cref{tbl:vithyperparams}. While we found the use of Mixup and Cutmix does boost performance on standard ViTs trained under a BalCE loss, their use of combined targets requires special treatment to make compatible with the LACE loss, which requires hard targets in order to assign the class adjustment. While one approach may be to apply the `merged' class adjustment, the performance benefit is marginal and hence we simply did not include either approach in RAC's data augmentation pipeline.  


\begin{table}\label{tbl:trainingdataset}
\centering
\begin{tabular}{@{}lrr@{}}
\toprule
                 & \textbf{Places365-LT} & \textbf{iNat} \\ \midrule
Batch Size       & 200                   & 50            \\
Learning Rate    & 5e-5              & 1e-4      \\
Epochs           & 30                    & 20            \\ \bottomrule
\end{tabular}
\caption{Dataset specific training hyperparameters}
\end{table}

\begin{table}
	\centering
	\begin{tabular}{@{}lr@{}}
		\toprule
		\textbf{Hyperparameter}     & \textbf{Value}  \\ \midrule
		Global normalization means         & [0.5, 0.5, 0.5] \\
    	Global normalization stds          & [0.5, 0.5, 0.5] \\
    	Crop (train and test)       & 0.95    \\
		Distributed                 & DDP 8 GPU's    \\
		LR schedule                    & cosine         \\
		Min LR                        & 1e-7           \\
		Warmup LR                   & 1e-7              \\
		Warmup epochs               & 5              \\
		Optimizer                   & adamw           \\
		Beta 1                      & 0.9            \\
		Beta 2                      & 0.999          \\
		Eps.                         & 1e-8           \\
		Gradient clipping           &  Norm           \\
		Gradient clipping magnitude & 1.0            \\
		RandAugment magnitude       & 1              \\
		RandAugment layers          & 3              \\
		RandAugment noise std.      & 0.5            \\
		Weight decay                & 0.02           \\
		Label smoothing             & 0.1            \\
		Stochastic depth            & 0.1            \\
		Random erase prob.          & 0.0           \\
		Color jitter                & 0.0            \\
		Random scale                & {[}0.75, 1.33{]} \\
		Random crop                 & No             \\
		Horizontal flip prob.       & 0.5   \\
		Random rotation             & No             \\
		Mixed precision level       & O2             \\ \bottomrule
	\end{tabular}
\caption{Training hyperparameters for the ViT models}
\label{tbl:vithyperparams}
\end{table}




\section{Retrieval Branch Visualization}\label{apx:vis}
While \cref{tbl:retrieval} quantifies top-1 performance of the retrieval branch, non-exact match snippets will also effect RAC as they are still likely to be informative. If `plane', `runway', `concrete', `sky', `propeller' etc. are returned for example, it is not difficult for  to place a high score on `airport'. We visualize the returned strings for random samples by distance and frequency in \cref{fig:placesExamples,fig:iNatExamples}. For all runs,  as in the main work. 

Each column displays (from left to right):
\begin{enumerate}
\itemsep -0.0861cm
    \item 
 query image ,
 \item retrieved labels sorted by distance (distance shown in brackets, exact matches colored green),
 \item 
 retrieved labels and occurrence counts, sorted from most to least frequent,
 \item  histogram of distances to all returned samples,
 \item  the correct label. 

\end{enumerate}



We restrict the lists of retrieved labels to the top eight for visualization purposes. Note that as the distance metric is cosine, a higher value corresponds to more similar samples. 

\begin{figure*}    
    \centering
    \includegraphics[width=\textwidth]{entry.pdf}
    \caption{Retrieval branch visualization for randomly drawn samples from Places365-LT. For detailed explanation see \cref{apx:vis}.}
    \label{fig:placesExamples}
\end{figure*}


\begin{figure*}   
    \centering
    \includegraphics[width=\textwidth]{entryINat.pdf}
    \caption{Retrieval branch visualization for randomly drawn samples from iNaturalist2018. For detailed explanation see \cref{apx:vis}.}
     \label{fig:iNatExamples}
\end{figure*}

\end{document}
