\documentclass[]{llncs}

\usepackage[utf8]{inputenc}
\usepackage{amsfonts,amssymb} \usepackage{stmaryrd}
\usepackage{pgf}
\usepackage{tikz}
	\usetikzlibrary{trees,decorations,arrows,automata,positioning,plotmarks}
\usepackage{xspace}
\usepackage{extarrows}
\usepackage{color}
\usepackage[left=2cm, right=2cm, top=2cm, bottom=2cm]{geometry}

\usepackage{encodingSynPi}

\title{Is it a ``Good'' Encoding of Mixed Choice? (Technical Report) \thanks{This work was supported by the DFG (German Research Foundation), grant {NE-1505/2-1}.}}
\author{Kirstin Peters \and Uwe Nestmann}
\institute{TU Berlin, Germany}

\begin{document}

\maketitle

\begin{abstract}
	This technical report contains the proofs to the lemmata and theorems of \cite{petersNestmann12} as well as some additional material. As main contributions \cite{petersNestmann12} presents an encoding of mixed choice in the context of the \piCal-calculus and a criterion to measure whether the degree of distribution in process networks is preserved.
\end{abstract}

\section{Technical Preliminaries}
\label{sec:techPre}

\subsection{The \piCal-Calculus}
\label{sec:piCalculus}

Our source language is the monadic -calculus as described for instance in \cite{sangiorgiWalker01}. As already demonstrated in \cite{palamidessi03} the most interesting operator for a comparison of the expressive power between the full \piCal-calculus and its asynchronous variant is mixed choice, i.e., choice between input and output capabilities. Thus we denote the full -calculus also by \piMix. Let  denote a countably infinite set of names with  and  the set of co-names, i.e., . We use lower case letters  to range over names.

\begin{definition}[\piMix]
\label{def:piMix}
  The set of process terms of the \emph{synchronous \piCal-calculus (with mixed choice)}, denoted by , is given by
	
	where  for some names  and a finite index set .
\end{definition}
\noindent
The interpretation of the defined process terms is as usual. Moreover we consider two subcalculi of \piMix. The process terms  of \piSep|the \emph{\piCal-calculus with separate choice}|are obtained by restricting the choice primitive, such that in each choice either no input guarded or no output guarded alternatives appear.

\begin{definition}[\piSep]
  The set of process terms of the \emph{\piCal-calculus (with separate choice)}, denoted by , is given by
	
	where  and  for some names  and a finite index set .
\end{definition}

Finally, the process terms  of the \emph{asynchronous \piCal-calculus} \piAsyn \cite{boudol92,hondaTokoro91} are obtained by restricting each sum to be of length zero or one and requiring, that outputs can only guard the empty sum.
 
\begin{definition}[\piAsyn]
  The set of process terms of the \emph{asynchronous \piCal-calculus}, denoted by , is given by
	
	for some names  and some finite sequences of names .
\end{definition}

Note that we augment all three variants of the \piCal-Calculus with matching, because we need it at least in \piAsyn to encode mixed choice. Of course, the presence of match influences the expressive power of \piAsyn. However, we do not know, whether the use of match in the encoding of mixed choice can be circumvented, although there are reasons indicating that this is indeed not possible. We left the consideration of this problem to further research.

We use capital letters  to range over processes. Let , , and  denotes the sets of free names, bound names and all names occurring in P, respectively. Their definitions are completely standard. Given an input prefix  or an output prefix  we call  the subject and  the object of the action. Moreover we denote the subject of an action also as link or channel name, while we denote the object as value or parameter. Note that in case the object does not matter we omit it, i.e., we abbreviate an input guarded term  or an output guarded term  such that  by  or , respectively. Moreover we denote the empty sum with  and often omit it in continuations. As usual we sometimes notate a sum  by .

We use  to range over substitutions. A substitution is a mapping  from names to names. The application of a substitution on a term  is defined as the result of simultaneously replacing all free occurrences of  by  for , possibly applying alpha-conversion to avoid capture or name clashes. For all names  the substitution behaves as the identity mapping. Let  denote identity, i.e.  is the empty substitution. We naturally extend substitutions to co-names, i.e.  for all substitutions .

Moreover, let  denote a sequence of names. For simplicity, we occasionally treat  as a set. So  denotes a sequence of names of the set ,  is the length of the sequence , and  denotes that  is one of the names within the sequence . Accordingly, we use the notion of sequence to abbreviate multiple restrictions, i.e.,  for a sequence of names . Moreover we naturally extend substitutions to sequences of names, i.e.,  and  for two sequences of names  and .

\begin{figure}[htp]
	
	\caption{Structural congruence.} \label{fig:SC}
\end{figure}

The \emph{reduction semantics} of \piMix, \piSep, and \piAsyn are jointly given by the transition rules in Figure \ref{fig:concurrentReductionSemantics}, where \emph{structural congruence}, denoted by , is given by the rules in Figure \ref{fig:SC}. Note that the rule  for communication in \piAsyn is a simplified version of the rule  for communication in \piMix or \piSep. The differences between these two rules result from the differences in the syntax, i.e. the lack of choice and the fact that only input can be used as guard in \piAsyn. The same can be observed for the rules  and . As usual, we use  if we refer to alpha-conversion (the first rule of Figure \ref{fig:SC}) only.

\begin{figure}[htp]
	
	\caption{Concurrent reduction semantics.} \label{fig:concurrentReductionSemantics}
\end{figure}

Let  () denote existence (non-existence) of a step from , i.e. there is (no)  such that . Moreover, let  be the reflexive and transitive closure of  and let  define an infinite sequence of steps.

In Section \ref{sec:qualityCriteria}, we present several criteria to measure the quality of an encoding. The first of these criteria relies on the notion of a context. A \emph{context}  is a \piCal-term, i.e., a \piAsyn-term in case of Definition \ref{def:compositionality}, with~ so-called holes. Plugging the \piAsyn-terms  in this order into the holes  of the context, respectively, yields a term denoted . Therefore, we consider a context as a function from terms into terms, e.g., the context  maps  \piAsyn-terms onto a \piAsyn-term. Sometimes, we refer to  as the parameters of the context . Note that a context may bind some free names of . The \emph{arity} of a context is the number of its holes.

As usual we will use equivalence relations to compare \piCal-terms by means of their behaviour. Moreover, as explained in Section \ref{sec:qualityCriteria}, we use an equivalence to abstract from junk, i.e., remains of encoded terms that are no longer of any use. Since we use a reduction semantics, a standard equivalence to compare \piMix-terms is barbed congruence, denoted by . Its definition relies on the notion of an \emph{observable} or \emph{barb} (we refer to \cite{sangiorgiWalker01} for a detailed explanation).

\begin{definition}[Observable] \label{def:barb}
	Let . Then  has an \emph{input observable} , denoted by , if  can perform an input on , i.e.,
	
	and  has an \emph{output observable} , denoted by , if  can perform an output on , i.e.,
	
\end{definition}

\subsection{Abbreviations}
\label{sec:abbreviations}

To shorten the presentation and ease the readability of the rather lengthy encoding function in the next section, we use some abbreviations on \piAsyn-terms. 
First note that we defined only monadic versions of the calculi \piMix, \piSep, and \piAsyn, where over any link exactly one value is transmitted. However, within the presented encoding functions, we treat the target language \piAsyn as if it allows for polyadic communication. More precisely, we allow asynchronous links to carry any number of values from zero to five, of course under the requirement that within each \piAsyn-term no link name is used twice with different multiplicities. Note that these polyadic actions can be simply translated into monadic actions by a standard encoding as given in \cite{sangiorgiWalker01}. Thus, we silently use the polyadic version of \piAsyn in the following.
Second, as already done in \cite{nestmann00}, we use the following abbreviations to define boolean values and a conditional construct.

\begin{definition}[Tests on Booleans]
\label{def:testBoolean}
	Let  be the set of \emph{boolean values}, where  denotes \emph{true} and  denotes \emph{false}.
	
	Let  and . Then a \emph{boolean instantiation} of , i.e., the allocation of a boolean value to a link , and a \emph{test-statement} on a boolean instantiation are defined by
	
	for some .
\end{definition}

Finally, we define forwarders, i.e., a simple process to forward each received message along some specified set of links.

\begin{definition}[Forwarder]
\label{def:forwarder}
	Let  be a finite index set and for all  let  and  be channel names with multiplicity , then a \emph{forwarder} is given by:
	
	In case of a singleton set we omit the brackets, i.e., .
\end{definition}

\subsection{Quality Criteria for Encodings}
\label{sec:qualityCriteria}

Within this paper we consider two encodings, (1) an encoding from \piSep into \piAsyn presented in \cite{nestmann00}, denoted by , and (2) a new encoding from \piMix into \piAsyn, denoted by . To measure the quality of such an encoding, Gorla \cite{gorla10} suggested five criteria well suited for language comparison. Accordingly, we consider an encoding to be ``good'', if it satisfies Gorla's five criteria.

As in \cite{gorla10}, an encoding is a mapping from a source into a target language; in our case, \piMix and \piSep are source languages and \piAsyn is the target language. To distinguish terms on these languages or definitions for the respective encodings, we use , , and  as super- and subscripts. Thereby, the superscript usually refers to the source and the subscript the target language. Moreover, we use  to range over terms of the source languages and  to range over terms of the target language.

The five conditions are divided into two structural and three semantic criteria. The structural criteria include (1) \emph{compositionality} and (2) \emph{name invariance}. The semantic criteria include (3) \emph{operational correspondence}, (4) \emph{divergence reflection} and (5) \emph{success sensitiveness}. Note that for the definition of name invariance and operational correspondence a behavioural equivalence  on the target language is assumed. Its purpose is to describe the abstract behaviour of a target process, where abstract basically means with respect to the behaviour of the source term.

Intuitively, an encoding is compositional if the translation of an operator depends only on the translation of its parameters. To mediate between the translations of the parameters the encoding defines a unique context for each operator, whose arity is the arity of the operator. Moreover, the context can be parametrised on the free names of the corresponding source term.

\begin{definition}[Criterion 1: Compositionality]
\label{def:compositionality}
	The encoding  is \emph{compositional} if, for every k-ary operator  of  and for every subset of names , there exists a k-ary context  such that, for all  with , it holds that
	
\end{definition}

\noindent
If the context is again the original operator, i.e., if an operator is translated by encoding its parameters and apply the renaming policy, as in , we call this encoding \emph{\clean}. Note that Gorla requires that the parallel composition operator ``'' is binary and unique in the source as well as in the target language. Thus, compositionality prevents from introducing a global coordinator or to use global knowledge, i.e., knowledge about surrounding source terms or the structure of the parameters.

The second structural criterion states that the encoding should not depend on specific names used in the source term. This is important, since sometimes it is necessary to translate a source term name into a sequences of names or reserve some names for the encoding function. To ensure that there are no conflicts between these reserved names and the source term names, the encoding is equipped with a renaming policy , i.e., a substitution from names into sequences of names\footnote{To keep distinct names distinct Gorla assumes that  implies , where  is simply considered as set here.}. Since we translate source term names only into single names, the renaming policies introduced by  and  are injective substitutions from names into names. Based on such a renaming policy an encoding is independent of specific names if it preserves all substitutions  on source terms by a substitution  on target terms such that  respects the changes made by the renaming policy.

\begin{definition}[Criterion 2: Name Invariance]
\label{def:nameInvariance}
	The encoding  is \emph{name invariant} if, for every  and , it holds that
	
	where  is such that  for every .
\end{definition}

The first semantic criterion and usually the most elaborate one to prove is operational correspondence, which consists of a soundness and a completeness condition. \emph{Completeness} requires that every computation of a source term can be \simulated by its translation, i.e., the translation does not reduce the computations of the source term. Note that encodings often translate single source term steps into a sequence of target term steps. We call such a sequence an \emph{\simulation}\!\! of the corresponding source term step. \emph{Soundness} requires that every computation of a target term corresponds to some computation of the corresponding source term, i.e., the translation does not introduce new computations.

\begin{definition}[Criterion 3: Operational Correspondence]
\label{def:operationalCorrespondence}
	Let  be an arbitrary encoding.  Then, two operational criteria are defined as follows. 
        \begin{center}
          \begin{tabular}{ll}
            \emph{Completeness}: & For all , it holds that .\\
            \emph{Soundness}: & For all , there exists an  such that\\
            &  and .
          \end{tabular}
        \end{center}
\end{definition}

\noindent
Note that the definition of operational correspondence relies on the
equivalence  to get rid of junk possibly left over within
computations of target terms (compare to Section \ref{sec:transBarbBisim} for a discussion of that equivalence). Sometimes, we refer to the completeness criterion of operational correspondence as \emph{operational completeness} and, accordingly, for the soundness criterion as \emph{operational soundness}.

The next criterion concerns the role of infinite computations in encodings.

\begin{definition}[Criterion 4: Divergence Reflection]
\label{def:divergenceReflection}
  The encoding  \emph{reflects divergence} if, for every ,  implies .
\end{definition}

\noindent
The last criterion links the behaviour of source terms to the behaviour of their encodings.
With Gorla \cite{gorla10}, we assume a \emph{success} operator  as part of the syntax of both the source and the target language, i.e., of \piMix, \piSep, and \piAsyn. Since  can not be further reduced, the operational semantics is left unchanged in all three cases. Moreover, note that , so also interplay of  with the rules of structural congruence is smooth and does not require explicit treatment. The test for reachability of success is standard.

\begin{definition}[Success]
\label{def:success}
	A process  \emph{may lead to success}, denoted as , if (and only if) it is reducible to a process containing a top-level unguarded occurrence of , i.e. .
\end{definition}

\noindent
Note that we choose may-testing here. Finally, an encoding preserves the abstract behaviour of the source term if it and its encoding answer the tests for success in exactly the same way.

\begin{definition}[Criterion 5: Success Sensitiveness]
\label{def:succesSensitiveness}
  The encoding  is \emph{success sensitive} if, for every ,  if and only if .
\end{definition}

\noindent
This criterion only links the behaviours of source terms and their literal translations, but not of their continuations. To do so, Gorla relates success sensitiveness and operational correspondence by requiring that the equivalence on the target language never relates two processes with different success behaviours.

\begin{definition}[Success Respecting]
\label{def:successRespecting}
	 is \emph{success respecting} if, for every  and  with  and , it holds that .
\end{definition}

\section{Correctness of the Encodings} \label{sec:CorrectnessEncodings}

Let us first present the full representations of the encodings  in Figure \ref{fig:encodingSepAsyn} and  in Figure \ref{fig:encodingMixAsyn}. Note that in \cite{nestmann00,nestmannPierce00} slightly different version of \piSep and \piAsyn are used, namely  is no prefix and there are neither a match operator nor a success operator in the syntax of \piSep and \piAsyn. We choose the respective encodings to be \clean \ except for source terms guarded by . Since  guarded terms can reduce without a communication partner, we implement their translation by a simple test-statement on their sum lock in both encodings.

\begin{figure}[ht]
	
	\begin{center}
		Here  is some arbitrary injective substitution such that .
	\end{center}
	\caption{Encoding from \piSep into \piAsyn.} \label{fig:encodingSepAsyn}
\end{figure}

\begin{figure}[htp]
	
	\begin{center}
		Here  is some arbitrary injective substitution such that , where  is the set of reserved names, i.e., .
	\end{center}
	\caption{Encoding  from \piMix into \piAsyn.} \label{fig:encodingMixAsyn}
\end{figure}

In the following we will argue for the correctness of these encodings with respect to the criteria of Gorla presented in Section \ref{sec:qualityCriteria}.

\subsection{Structural Criteria} \label{sec:structuralCriteria}

The first two criteria to prove are the structural criteria; compositionality and name invariance. An encoding is compositional if it defines a fixed context for each operator including holes for the translation of its parameters. By Definition \ref{def:compositionality} of compositionality the context is allowed to depend on the free names of the parameters. However, both presented encodings,  and , do not use that feature, i.e., the contexts do not depend on any names. By Figure \ref{fig:encodingSepAsyn} and Figure \ref{fig:encodingMixAsyn} both encodings are obviously compositional.

Let us have a closer look at the contexts. In the encodings of restriction, matching and success the context is used only to translate source term names according to the renaming policy. Apart from that the encodings are \clean. The encoding of the sum operator inserts a positive instantiation of a fresh sum lock and splits up the encodings of the summands in parallel because there is no sum operator in the target language. Therefore of course we have to consider the sum operator as binary operator with an index set and a set of its summands as parameters, or as unary operator with the set or list\footnote{Usually an unordered set of summands suffice to describe a sum since usually we consider sums as being reflexive and symmetric, i.e.,  and . If for some reasons we have to abandon reflexivity and/or symmetry, e.g. in case of a randomised version of the calculi, an ordered list might be the better choice to describe a sum.} of its summands as parameter. We left the question whether there is an encoding from \piMix into \piAsyn with the binary sum operator as an open question to further research. The encodings of input and output guarded terms and the encoding of terms guarded by  introduce rather small contexts. However, in case of  the contexts introduced to translate the binary parallel operator and replicated input are rather complicated and huge. Remember that we claim in Section \ref{sec:qualityCriteria} that the parallel operator is binary. Comparing its encoding with the encoding of the sum operator we observe that this claim may be crucial because it forbids the introduction of a global coordinator for all parallel terms as the sum lock is for all the summands of a sum.

Name invariance follows by the fact that names are translated into single names again and that conflicts between names used by the encoding functions and translated source term names are ruled out by the renaming policy.

\begin{lemma} \label{lem:nameInvarianceSepAsyn}
	The encoding  is name invariant.
\end{lemma}

\begin{proof}
	By Definition \ref{def:nameInvariance} it suffice to show, that:
	
	Without loss of generality let  for some . We choose
	
	So . We proceed with an induction over the structure of .
	\begin{description}
		\item[Base Case:] Since  and , we have  and .
		\item[Induction Hypothesis:] 
		\item[Induction Step:] Let  be such that . Then . Moreover, since , we have . Note that:
			
			We proceed by a case split.
			\begin{description}
				\item[Case of :] Then
					
				\item[Case of :] Then
					
				\item[Case of :] Then
					
				\item[Case of :] Then
					
				\item[Case of :] Then
					
				\item[Case of :] Then
					
				\item[Case of :] Then
					
				\item[Case of :] Then
					
			\end{description}
	\end{description}
	\qed
\end{proof}

\begin{lemma}
	The encoding  is name invariant. \label{lem:nameInvarianceMixAsyn}
\end{lemma}

\begin{proof}
	By Definition \ref{def:nameInvariance} it suffice to show, that:
	
	Without loss of generality let  for some . We choose
	
	So . We proceed with an induction over the structure of .
	\begin{description}
		\item[Base Case:] Since  and , we have  and .
		\item[Induction Hypothesis:] 
		\item[Induction Step:] Let  be such that . Then . Moreover, since , where
			
			we have . Note that:
			
			We proceed by a case split.
			\begin{description}
				\item[Case of :] Then
					
				\item[Case of :] Then
					
				\item[Case of :] Then
					
				\item[Case of :] Then
					
				\item[Case of :] Then
					
				\item[Case of :] Then
					
				\item[Case of :] Then
					
				\item[Case of :] Then
					{\allowdisplaybreaks
					}
			\end{description}
	\end{description}
	\qed
\end{proof}

Analysing these proofs we observe (1) that  depends only on  and the respective renaming policy, and (2) that we can prove the first case of name invariance (compare to Definition \ref{def:nameInvariance}) for all kinds of substitutions , i.e., it suffice to consider equivalence modulo alpha conversion.

\begin{corollary}[Encoding substitutions] \label{col:encodingSubstitutions}
	For all substitutions  it holds that
	
	where  and .
\end{corollary}

\subsection{Basic Properties}

In the following we prove correctness with respect to the three semantical criteria. We observe, that in order to do so we do not have to prove conditions on arbitrary \piAsyn-terms but on encoded source terms and their derivatives. To simplify the argumentation we will denote such terms as \emph{target terms}.

\begin{definition}[Target Terms] \label{def:targetTerm}
	Let . Then  is a \emph{target term}, denoted by  (or ), if  (or ).
\end{definition}

\paragraph*{Requests.} Note that the encoding  translates source term observables by adding an instantiation of a sum lock (except from observables due to replicated inputs) to keep track of the information, whether this observable is still active, i.e., whether the corresponding in- or output can still be used to \simulate a source term step. Besides that additional information  does not change the observables. In contrast, the encoding  translates source term observables into requests, which are again augmented by sum locks. Requests are outputs with either three or four parameters. Input requests, i.e., requests that originate from the translation of an input guarded term or replicated input, are outputs with three parameters. Output requests, i.e., requests that originate from the translation of an output guarded term, are outputs with four parameters. Note that we can indeed consider any output of three or four parameters as request, because the encoding function does not use these multiplicities for other purposes (compare to Figure \ref{fig:encodingMixAsyn}).

\begin{definition}[Request] \label{def:request}
	An \emph{input request} is an unguarded output with three parameters, i.e., an output of kind  for some , and an \emph{output request} is an unguarded output with four parameters, i.e., an output of kind  for some . We refer to guarded variants of those outputs as \emph{guarded requests} and to  as \emph{request channel}.
\end{definition}
\noindent
Note that the channels introduced by the encoding function are somehow well typed in the sense, that each name once used as link with multiplicity  will never appear as link with a multiplicity different from . Because of that, it make sense to denote the channel  here as request channel, because whenever it is used as link name a request is transferred above that link. Moreover note, that the first parameter  of a request is always the translation of the respective source term channel and the second parameter  always refers to the sum lock that is connected to that requests, i.e., that covers the information about the liveness of the corresponding observable. Note that in case of an input request that originate from an replicated input the second parameter refers to a fake sum lock, which is never checked. In case of an input request the third parameter  refers to the corresponding receiver lock and in case of an output request the third parameter  refers to the corresponding sender lock and the fourth parameter  is the translation of the send value.

An interesting fact is, that requests are preserved by the encoding function, i.e., each derivative of a target term has all the requests of its predecessor. Note that we consider here two requests that only differ by their link name but not their values as the same request. Requests are pushed upwards along and from right to left within the parallel structure of the term but they are never completely consumed. If the message refers to an inactive observable the respective sum lock is instantiated false to ensure that such a request can no longer be used to \simulate a source term step. The corresponding output messages of the encoding, i.e., the requests, remain as junk (compare to Lemma \ref{lem:junkRequestsOnFalseSumLocks}).

\begin{lemma}[ preserves requests] \label{lem:encodingMixAsynPreserveRequests}
	
	and
	
\end{lemma}

\begin{proof}
	First note, that due to Figure \ref{fig:encodingMixAsyn} the translations of source term names are used as values only. So any in- or output of a target term is generated by the encoding function on special names reserved for the encoding. In case , i.e., in case the sequence  is empty, the lemma holds trivially. Let us consider the case of a single step, i.e., . The Lemma then follows by induction over the number of steps in the sequence .
	
	Analysing the encoding function in Figure \ref{fig:encodingMixAsyn} we observe, that any input with three or four parameters is due to the encoding of the parallel operator or a replicated input. In case of a forwarder the lemma again trivially holds, because each forwarder immediately restores each consumed message. The only remain inputs in the encoding of a parallel operator or a replicated input are due to the processing of right requests, i.e., due to \processRightOutputRequests \ and \processRightInputRequests.
	
	In case of \processRightOutputRequests \ there are two inputs on request channels, namely  and . In the first case, whenever a request is consumed by  it is immediately restored by . In the second case any consumed request is immediately restored by . So the Lemma holds. The argumentation for \processRightInputRequests \ is similar.
	\qed
\end{proof}

A closer look at this proof and the encoding function in Figure \ref{fig:encodingMixAsyn} reveals, that (1) any initial request is due to the encoding of a guarded term or a replicated input and (2) any other request is a copy of an existing request. Because of that, as long as we are only interested in the values a request may carry and do not concern the link over it is currently transmitted, then we can conclude that any request originate to the encoding of a guarded term or a replicated input.
\begin{corollary} \label{col:originRequests}
	Any request originates to the encoding of a guarded term or a replicated input.
\end{corollary}

\paragraph*{Sum locks.} Sum locks|for both considered encodings|are channels carrying a boolean value. They are used by the encoding functions to ensure that at most one summand of each sum is chosen for communication. Note that any channel used to transport a boolean value is a sum lock. However, since by Definition \ref{def:testBoolean} at page \pageref{def:testBoolean} booleans and test-statements are just abbreviations, we use some simple type informations to unambiguous identify sum locks in both encodings. So, to be precise, instantiations on sum locks are inputs carrying two values, that are links with multiplicity zero. So sum locks are the only channels of multiplicity two, that carry only values of multiplicity zero.

\begin{definition}[Sum lock] \label{def:sumLock}
	Let  (or ). A \emph{sum lock} of  is a name  that is used in  as link with multiplicity two carrying two links with multiplicity zero.
	
	Let  be a sum lock. Then we refer to unguarded occurrences of  as \emph{positive instantiation} and accordingly to unguarded occurrences of  as \emph{negative instantiation} of . An \emph{instantiation} of a sum lock  is either a positive or negative instantiation of .
\end{definition}

Note that in most of the following definitions and proofs we hide the definition of booleans as well as of the corresponding test-statement. To show that sum locks meet our intuition we prove that in each target term  there is at most one instantiation of each sum lock.

\begin{lemma} \label{lem:instantiationSumLocks}
	For each target term each sum lock is instantiated at most once, i.e.,
	
\end{lemma}

\begin{proof}
	By Figure \ref{fig:encodingSepAsyn} and Figure \ref{fig:encodingMixAsyn} this condition holds for all encoded source terms, i.e., for all target terms  for some  or , because for each sum there is exactly one positive instantiation of each sum lock and, since all sum locks appear restricted, the sum locks of different sums are different. All remainig instantiations of sum locks are guarded by a test-statement. To prove the condition for arbitrary target terms we take a closer look on these test-statements. We observe that for both encodings for each test-statement and for each of its possible outcomes the reduction of a test-statement unguards exactly one instantiation of a each sum lock that has to be consumed to reduce the respective test-statement. So for each new unguarded instantiation of a sum lock a former instantiation of the same lock was consumed.
	
	 \cite{nestmann00} proves that the encoding  does not introduce deadlock, i.e., whenever a test-statement consumes a sum lock a new instantiation of the same lock is eventually unguarded. Moreover, it shows that a complete ordering of the sum locks as implemented in  suffice to ensure that even in the case of source terms from  the test-statements can not cause a deadlock. So again for each consumed instantiation of a sum lock a new instantiation of the same lock is eventually unguarded.
	\qed
\end{proof}

Note that, analysing the encoding functions obviously any instantiation of a sum lock is a positive or negative instantiation. The prove of Lemma \ref{lem:instantiationSumLocks} also shows that (1) all instantiations of sum locks in encoded source terms are positive|negative instantiations are only due to reduction steps, (2) all sum locks are initially instantiated, and (3) for each consumed instantiation of a sum lock eventually a new instantiation is unguarded.
\begin{corollary} \label{col:initialSumLocksArePositive}
	Any sum lock is initially instantiated positive, i.e.,
	
	and
	
\end{corollary}

\begin{corollary} \label{col:instantiationsSumLocksAreRestored}
	Let  be a target term, i.e.,  or , and let  be the set of all sum locks of . Then
	
\end{corollary}

In the proof of Lemma \ref{lem:instantiationSumLocks} we observe that new instantiations of sum locks are unguarded by test-statements. So reducing a test-statement is the only possibility to change an instantiation of sum lock. A closer look reveals that positive instantiations can be changed into negative but never the other way around.

\begin{lemma} \label{lem:changeInstantiationSumLock}
	A negative instantiation of a sum lock can not be changed into a positive instantiation, i.e.,
	
\end{lemma}

\begin{proof}
	Revisiting the argumentation in the proof of Lemma \ref{lem:instantiationSumLocks} we observe that the reduction of a test-statement is the only way to change the instantiation of a sum lock. A closer look at the test-statements in Figure \ref{fig:encodingMixAsyn} and Figure \ref{fig:encodingSepAsyn} reveals that for both encoding functions and for each test-statements the then-case can change a positive instantiation of sum lock into negative instantiation but the else-cases always simply restore all consumed instances. Note that in case of the nested test-statement of the encoding of an input guarded term a positive instantiation of the first tested lock is changed only if the second tested lock is again positive instantiated. In this case both instantiations are changed into negative instantiations. Moreover note that all the other (single) test-statements change any consumed positive instantiation into a negative one. Because of that, it is possible to change a positive instantiation into a negative one but not the other way around.
	\qed
\end{proof}

\paragraph*{Sender and Receiver Locks.} The third parameter of an output request refers to a sender lock, while the third parameter of an input request refers to a receiver lock. In both encodings, sender and receiver locks are used to guard the encoded continuation of output or input guarded source terms or replicated inputs. Sender locks are links with multiplicity zero in both encodings, in opposite receiver locks are links with multiplicity zero in  and five in . Note that in  only sender locks appear as third parameter of an output request. Since by Lemma \ref{lem:encodingMixAsynPreserveRequests} the encoding function  preserves requests, they unambiguous define sender locks. In the encoding  also receiver locks are links that never transport any values (compare to Figure \ref{fig:encodingSepAsyn}). Moreover, the reserved names  and |necessary to implement booleans|are used as links without parameters in both encodings. To distinguish them in  note, that sender locks are used as input links, while receiver locks are used as replicated inputs only, and that in each case of a test-statement there is an unrestricted instantiation of a sum lock, whereas all instantiations of sum locks within an encoded source term appear restricted.

\begin{definition}[Sender Lock] \label{def:senderLock}
	Let . Then any name  is a \emph{sender lock} of  if
	
	Let . Then any name  is a \emph{sender lock} of  if
	
	An \emph{instantiation} of a sender lock is an output on a sender lock.
\end{definition}

Beside the blocking of the encoded continuation, in  the receiver lock is used by the encoding of the parallel operator and its pendant in the encoding of a replicated input to transmit the order of the sum locks back to the encoding of an input guarded source term. Remember, that the encoding of an input guarded source term tests these sum locks to \simulate a communication step of the source term and that the ordering of sum locks is necessary to avoid deadlock. In case of , receiver locks are again unambiguous identified by input requests. However they are also the only links in  carrying five parameters. In  receiver locks are the only links of multiplicity zero, that are used as replicated inputs.

\begin{definition}[Receiver lock] \label{def:receiverLock}
	Let . Then any name  is a \emph{receiver lock} of  if
	
	Let . Then any name  is a \emph{receiver lock} of  if
	
	An \emph{instantiation} of a receiver lock is an output on a receiver lock.
\end{definition}

Note that|for both encodings|for each input or output guarded source term exactly one receiver or sender lock is generated. Similarly, for each sum a unique sum lock is generated. However, since a sum may contain several input and/or output guarded summands, the encodings of different input or output guarded terms may share the same sum lock. But each encoded guarded term is connected to exactly one sum lock. The encoding  is obviously more complex than the encoding . But on the other hand the existence of requests outlines the connection between sum locks and sender or receiver locks|and with it to the corresponding encodings of guarded terms|more clearly.

\begin{definition} \label{def:connectionSumLockSenderReceiver}
	Let  and let . If  contains an unguarded input request with  as second and  as third parameter, i.e., if
	
	then we call the sum lock  and the receiver lock  \emph{connected}. Sometime we also say that  is the sum lock of the receiver lock .
	
	Accordingly, if  contains an unguarded output request with  as second and  as third parameter, i.e., if
	
	then we call the sum lock  and the sender lock  \emph{connected}. Sometime we also say that  is the sum lock of the sender lock .
\end{definition}

Of course, the connection of sum locks to sender or receiver locks is unambiguous.

\begin{lemma} \label{lem:sumLockOfReceiverOrSender}
	Let  be a target term. Then each receiver lock  and each sender lock  of  is connected to exactly one sum lock  of , i.e.,
	
	and
	
\end{lemma}

\begin{proof}
	Analysing the encoding function  in Figure \ref{fig:encodingMixAsyn} we observe that initially, i.e., for each target term  for some source term , for each receiver lock, i.e., for each encoding of an input guarded term or a replicated input, and for each sender lock, i.e., for each encoding of an output guarded term, exactly one request is generated. Since the receiver and sender locks are generated under restriction, for each encoded source term there are not two requests with the same receiver or the same sender lock, i.e., no two requests share their third parameter. Because of that the lemma holds for all  for some source term . By Corollary \ref{col:originRequests} then the lemma holds for all target terms  and  such that .
	\qed
\end{proof}

Note that this lemma does not only shows that the connection between sum locks and sender or receiver locks is unambiguous but moreover that the information carried by requests is persistent. It does not change while requests wander to the structure of the encoded term generated by the parallel operator nesting of the corresponding source term.

Since, in case of  receiver locks are not only used to guard the encoding of the continuation of an input guarded term or replicated input but also to send the order of the locks back to the corresponding test-statement, they carry all necessary informations to perform the test.

\begin{lemma} \label{lem:parametersReceiverLock}
	Let  and  be a receiver lock of . Then the first three parameters of  are sum locks, the fourth parameter is a sender lock , and the last parameter is a translated source term name. Moreover, the third sum lock belongs to  and among the first to sum locks one belongs to  and the other one is again the sum lock of .
\end{lemma}

\begin{proof}
	There are four different outputs on receiver locks, i.e., outputs of five parameters, one in each of \processRightOutputRequests \ and \processRightInputRequests \ in the encoding of a parallel operator and in the encoding of a replicated input (compare to Figure \ref{fig:encodingMixAsyn}).
	
	In \processRightOutputRequests \ the output  is guarded by a replicated input  of three parameters which is in turn guarded by an input  of four parameters. So to unguard the output on the receiver lock two requests|first an output request and then an input request|have to consumed. The values of the parameters of the output  are completely determined by these two requests. Because of that the first three parameters are sum locks, the fourth parameter is a sender lock , and the last parameter is a translated source term name. Moreover, the first parameter is the sum lock of the receiver lock and the second and third parameter are the sum lock of the sender lock.
	
	The case of \processRightInputRequests is similar but here the input request has to be consumed first, and the first and the third parameter are the sum lock of the sender lock and the second parameter is the sum lock of the receiver lock.
	\qed
\end{proof}

In order to ease the proof of Lemma \ref{lem:nonConflictingStepsMixAsyn} at page \pageref{lem:nonConflictingStepsMixAsyn} we introduce another kind of lock.  translates source term observables into requests, which are then combined to search for potential communication partners. In order to avoid divergence, requests can not be copied arbitrary often. To ensure that indeed each left request is combined with each possible matching right request, the right requests|in the encoding of a parallel operator as well as in the encoding of a replicated input|are linked within some kind of chain or list, along which the left requests are forwarded. Again to avoid divergence these chains or lists can not be infinitely long, so the links  and  are introduced by the encoding function to extent these chain or list by a new right request as soon as its last place is occupied. We will denote these links as \emph{chain locks}. Similarly, the chain lock  in the encoding of a replicated input is used to establish some kind of chain on encoded source terms|the encoded continuations of that replicated input|instead of right requests. Note that chain locks are the only links in target terms with multiplicity one.

\begin{definition}[Chain Lock] \label{def:chainLock}
	Let . Then any name  is a \emph{chain lock} of  if .
	
	An \emph{instantiation} of a chain lock is an output on a chain lock.
\end{definition}

Note that the value of a chain lock used to establish a chain of right requests is always a request channel, while the value of a chain lock used to establish a chain of encoded source terms is always a translated source term name, i.e., a value never used as link. Because of that, we can easily distinguish these two kinds of chain locks by a simple type information.

\subsection{Steps of an \Simulation} \label{sec:stepsSimulation}

Before we formally define receiver and sender locks in the last section we argue that they are introduced by the encoding function to guard the encoding of the continuation of a guarded source term. To mimic the behaviour of the source term, the encodings of continuations have to stay guarded until the source term step unguarding them in the source term is \simulated by its encoding. As already mentioned both encodings translate a single source term step into a sequence of target term steps called \simulation. However, in both encodings we can unambiguous allocate the main responsibility for an \simulation to a single step of that \simulation and call all the other steps pre- or postprocessing steps of that \simulation. In the following we will refer to the first kind of target term steps as \emph{\nonAdmin steps}, since they perform the main task of an \simulation and because of that constitute the transition from the \simulation of a source term to the \simulation of its successor. It turns out, that for both encodings the \nonAdmin steps are connected to the test-statements. More precisely, in case of an \simulation of a step on a term guarded by  or a replicated input, it is the consumption of the positive instantiation of a sum lock by the corresponding test-statement that performs the main task of the \simulation. In case of an \simulation of a step on an input guarded source term, it is the consumption of the second positive instantiation in the nested test-statement that we call \nonAdmin step.

\begin{definition}[\NonAdmin Step] \label{def:nonAdminStep}
	Let  (or ). A step  is a \emph{\nonAdmin step}, denoted by , if this step consumes a positive instantiation of a sum lock either within a single test-statement or within the second test of a nested test-statement.
\end{definition}

Note that, since negative instantiations of sum locks refer to encoded in- or outputs, that remains of a former \simulation as junk, we do not consider any consummation of a negative sum lock as \nonAdmin step. According, test-statements consuming a negative instantiation of a sum lock only restore all consumed information. In the following we prove our intuition of \nonAdmin steps by showing that encoded continuations can only be unguarded after a \nonAdmin step.

\begin{lemma} \label{lem:nonAdminStepContinuation}
	Only \nonAdmin steps may lead to the unguarding of the encoding of a continuation of some source term.
\end{lemma}

\begin{proof}
	Analysing the encoding functions in Figure \ref{fig:encodingSepAsyn} and Figure \ref{fig:encodingMixAsyn} we observe that the encoded continuations of output guarded source terms appear guarded by the respective sender lock. Moreover we observe that all instantiations of sender locks are guarded by test-statements. More precisely, they are guarded by the then-case of a single test-statement (due to the encoding of a replicated input) or the then-case of the second test in a nested test-statement (due to the encoding of an input guarded term). Note that in case of , by Lemma \ref{lem:parametersReceiverLock} the input on the receiver lock that guards the test-statements unambiguous identifies the following outputs of multiplicity zero as sender locks. So a \nonAdmin step is necessary to unguard them.
	
	In case of a source term guarded by  or an input guarded source term the respective encoded continuations appear directly as required in the respective then-cases of the test-statements. So, in these cases, the lemma holds directly by the Definition of the encoding functions.
	\qed
\end{proof}

Note that to our intuition for each \simulation of a source term step, there is exactly one \nonAdmin step. However, we will need some further information to prove that statement (compare to Lemma \ref{lem:simulationVSNonAdminStep} at page \pageref{lem:simulationVSNonAdminStep}). So let us have a closer look at the remaining pre- and post processing steps. There is one step of an \simulation, namely the unguarding of the encoded continuation of an output guarded source term by communication over a sender lock, that for certainty has to be performed after the \nonAdmin step of the corresponding \simulation. Because of that we can call reductions on sender locks postprocessing steps. There are also steps, as for instance reductions over receiver locks, that for certainty have to be performed before the corresponding \nonAdmin step. So we can call all reductions on receiver locks preprocessing steps. However, there are some steps that may be performed before or after the corresponding \nonAdmin step. Moreover, the fact whether a non \nonAdmin step was performed before or after the corresponding \nonAdmin step is usually not important and often hard to prove. So pre- or postprocessing steps is not a good characterisation for our purposes. Instead we will refer to those steps as \emph{\admin steps}, since they perform administrative tasks, that are necessary to perform an \simulation, but they do not carry the main responsibility for the \simulation, i.e., they do|at least for the general case|not inevitably implement the decision to \simulate a specific source term step.

\begin{definition}[\Admin Step] \label{def:adminStep}
	Let  (or ). A step  is a \emph{\admin step}, denoted by , if it is no \nonAdmin step.
	
	Let  denote a sequence of \admin steps, i.e.,  is the transitive and reflexive closure of .
\end{definition}

In the easiest case, none of the \admin steps influences the decision to \simulate a specific source term steps. That means: Consider a source term that can perform alternative but conflicting steps. So the encoding can perform different but conflicting \simulations. In this case none of the \admin steps should influences which of the \simulations may be completed, i.e., no sequence of \admin steps should be able to rule out the completion of one of these \simulations.

Unfortunately, for both of the presented encodings this turns out to be wrong. It is always a \nonAdmin step that finally decides which of the conflicting \simulations is completed by preventing any other conflicting \simulation from completion. However, in case there are more than two possible conflicting \simulations, a sequence of \admin steps may rule out one alternative while allowing for different still possible \simulations.

\begin{example} \label{exa:intermediateStates}
	Let us consider the source term  for some . So  as well as . The encoding of , regardless whether it is encoded by  or , generates three sum locks, one for each sum. Let us assume, the sum lock generated for  is , the sum lock for  is , and  is generated for .  can perform three conflicting steps leading to , , or , respectively. Each of these steps can be \simulated by both of the encodings. To \simulate the step to  for both encodings the positive instantiation of the sum lock  is consumed first and to complete the \simulation a positive instantiation of the sum lock  has to be consumed. However, it is possible, that the encoded term instead performs another (nested) test-statement and consume both positive instantiations of  and  to \simulate the step to  instead. Because of that, in case of a nested test-statement, we do not consider the first consumption of a positive instantiation of a sum lock as a \nonAdmin step. Even, if at this point the sum lock, that is tested next by this test-statement, is still instantiated positive, it can become negative by an interleaving other test-statement.
	
	So after the consumption of the positive instantiation of  in order to \simulate the source term step to , there is still the possibility to complete instead the \simulation of the source term step to . However, there is no possibility to complete the \simulation of the source term step to . Note that, to \simulate the step to , a positive instantiation of each of the locks  and  is necessary. Here, the instantiation of  is consumed. The only possibility to restore the positive instantiation is to consume a negative instantiation of  (compare to the nested test-statements in the encodings of input guarded terms in Figure \ref{fig:encodingSepAsyn} and Figure \ref{fig:encodingMixAsyn}). By Lemma \ref{lem:changeInstantiationSumLock}, then there is no possibility to change that negative instantiation back into a positive one. So, as soon as  is consumed, one of the three possible \simulations is ruled out while there are still two possible \simulations left.
\end{example}

\begin{figure}[ht]
	\centering
	\begin{tikzpicture}[auto,node distance=1.1cm]
		\node[state]	(S)					{};
		\node			(d1) [right of=S]	{};
		\node			(d2) [right of=d1]	{};
		\node			(d3) [right of=d2]	{};
		\node[state]	(T1) [above of=d3]	{};
		\node[state]	(T2) [below of=d3]	{};
		\node			(d6) [right of=d3]	{};
		\node			(d7) [right of=d6]	{};
		\node[state]	(S2) [right of=d7]	{};
		\node			(d8) [above of=S2]	{};
		\node[state]	(S1) [above of=d8]	{};
		\node			(d9) [below of=S2]	{};
		\node[state]	(S3) [below of=d9]	{};
		
		\path[->,green]	(S)		edge [loop left]	node {} ();
		\path[->,blue]	(S)		edge				node {} (T1);
		\path[->,green]	(T1)	edge [loop above]	node {} ();
		\path[->,red]	(T1)	edge				node {} (S1);
		\path[->,red]	(T1)	edge				node {} (S2);
		\path[->,blue]	(S)		edge				node {} (T2);
		\path[->,green]	(T2)	edge [loop below]	node {} ();
		\path[->,red]	(T2)	edge				node {} (S2);
		\path[->,red]	(T2)	edge				node {} (S3);
		\path[->,red]	(S)		edge [bend left]	node {} (S1);
		\path[->,green]	(S1)	edge [loop right]	node {} ();
		\path[->,red]	(S)		edge				node {} (S2);
		\path[->,green]	(S2)	edge [loop right]	node {} ();
		\path[->,red]	(S)		edge [bend right]	node {} (S3);
		\path[->,green]	(S3)	edge [loop right]	node {} ();
	\end{tikzpicture}
	\caption{Intermediate States.} \label{fig:intermediateStates}
\end{figure}
	
We visualise this phenomenon in Figure \ref{fig:intermediateStates} (for the case of ). Here the red lines denote sequences of steps with (exactly) one \nonAdmin step, the blue lines denote sequences without \nonAdmin steps but with at least one \impure \admin step, and the green lines denote sequences of only \pure \admin steps (compare to Definition \ref{def:pureImpureAdminStep}). Between the encoding of the source term  and the encodings of its reducts , , and  there are two \emph{intermediate states}, i.e., two states that differ from each encoded source term within that picture. Note that the observability of such an intermediate state depends on the chosen equivalence on target terms.

\begin{definition}[Intermediate State] \label{def:intermediateState}
	A term  is an \emph{intermediate state}, if
	
	i.e. if
	\begin{center}
		\begin{tikzpicture}[auto,node distance=1.2cm]
			\node (T)						{};
			\node (d1)	[right of=T]		{};
			\node (T')	[above right of=d1]	{};
			\node (d2)	[below right of=T']	{};
			\node (T2)	[right of=d2]		{};
			\node (T1)	[above of=T2]		{};
			\node (T3)	[below of=T2]		{};
			
			\def\myArrow(#1)#2(#3){
				\draw[|->,shorten >=-1pt,shorten <=-0.5pt] (#1) #2 (#3);
				\draw[double] (#1) #2 (#3);
			}
			
			\myArrow (T) -- (T');
			\draw[|->,shorten >=-1pt,shorten <=-0.5pt] (T) edge [bend left] (T1);
			\draw (T) edge [double,bend left] (T1);
			\myArrow (T) -- (T2);
			\myArrow (T) -- (T3);
			\myArrow (T') -- (T1);
			\myArrow (T') -- (T2);
		\end{tikzpicture}
	\end{center}
\end{definition}

Remarkably, the existence of intermediate states in  is independent of structural congruence|if two source terms are structural congruent, then their encodings have the same intermediate states|while this is not true for . Here the locks are always tested according to a total ordering created along the structure induced by the nesting of parallel operators of the source term. Because of that, this ordering of sum locks differ for source terms, that are structural congruent but differ in the order of their subprocesses, i.e. differ by rule . So structural congruent source terms can differ in the number and nature of reachable intermediate states; e.\,g.\ , which is structural congruent to  from Example \ref{exa:intermediateStates}, does not reach any of the above intermediate states. Instead, in  the first consumption of a positive instantiation of a sum lock, which is no \nonAdmin step here, completely determines which \simulation can be completed.

To capture that fact we further distinguish \admin steps, into \pure \admin steps|that never rule out the completion of any possible \simulation\!\!|and \impure \admin steps|that due to the consumption of a positive instantiation of a sum lock may possibly rule out the completion of an \simulation. Note that in case of  requests are copied to ensure that each possible combination of input and output requests is checked exactly once. Because of that steps on requests are \pure \admin steps. In opposite,  does not translate source term observables into requests. To check for a potential pair of translated communication partners a communication of the translated channel names is performed. Similar to the consumption of positive instantiations of sum locks this might rule out alternative \simulations. Because of that we consider steps on translated source term names as \impure \admin steps of . Also note, that in  translated source term names are used as values only; so there are no steps on translated source term names.

\begin{definition}[\Pure and \Impure \Admin Step] \label{def:pureImpureAdminStep}
	Let  (or ). A step  is a \emph{\pure \admin step}, denoted by , if it is neither on a sum lock nor on a translated source term name, else it is an \emph{\impure \admin step}, denoted by .
	
	Let  denote a sequence of \pure \admin steps, i.e.,  is the transitive and reflexive closure of .
\end{definition}

To show that the definition of \pure \admin steps meets our intuition, we prove some kind of local confluence property for most of the \pure \admin steps. Intuitively, it states that indeed none of the \pure \admin steps can rule out the completion of any \simulation, because they are (in most cases) not conflicting, i.e., does not rule out any other sequence of steps.

\begin{lemma} \label{lem:nonConflictingStepsSepAsyn}
	Within target terms \pure \admin steps are not conflicting, i.e.,
	
\end{lemma}

\begin{proof}
	In comparison to  the encoding  introduces only a few \pure \admin steps and all of them are not conflicting. First note that, since in \piAsyn there are no sums, two target term steps can only be in conflict if one of it consumes some input or output necessary to perform the other step. So it suffice to concentrate on steps on the same channel. Analysing the encoding function in Figure \ref{fig:encodingSepAsyn} we discover that steps on receiver or sender locks (compare to Definitions \ref{def:receiverLock} and \ref{def:senderLock}) are \pure \admin steps.
	
	In case of receiver lock, since they are generated under restriction, for each receiver lock there is exactly one replicated input and no other input. Because of that it does not matter how many other steps on (the same) receiver lock may appear within the sequence  the step  can be performed before or after that sequence and in both cases the same term  is reached.
	
	In case of sender locks, there is exactly one input and no replicated input for each sender lock. Moreover, we observe that initially there is no instantiation of a sender lock, and there is exactly one output (on a translated source term name) which carries the sender lock as value. This output is consumed to unguard a test-statement and that test-statement can then ungard again at most one output which carries the sender lock as value and which can itself unguard another test-statement. The only instantiations of sender locks are due to the then-case of a single test-statement in the encoding of a replicated input or the then-case of the second test-statement in the encoding of an input guarded term, and in both cases only a single instantiation of a sender lock is unguarded. So for each target term and each sender lock there can be at most one instantiation of a sender lock. Moreover note, that the output on the translated source term names does not only carry the sender lock, but also a sum lock. In order to obtain an instantiation of the sender lock this sum lock has to be instantiated positive. But whenever a sender lock is instantiated the encoding also generates a negative instantiation of that sum lock. By Lemma \ref{lem:changeInstantiationSumLock} that negative instantiation can never be turned into a positive one again; so there is no chance to generate a second instantiation on the same sender lock. Because of that, if  is a step on a sender lock, then none of the steps in  is a step on that sender lock. So the lemma holds.
	
	Besides these to steps there is another kind of \pure \admin steps that is not that obvious in Figure \ref{fig:encodingSepAsyn} because that kind of steps is hidden by the abbreviation used to introduce booleans and test-statements (compare to Definition \ref{def:testBoolean}). We observe, that a test-statement is reduced within two steps. The first consumes the instantiation of the sum lock and is thus no \pure \admin step. The second step unguards the corresponding then- or else-case. In both cases that step is a \pure \admin step. However the names  and  are restricted for each test-statement, are not used any there else by the encoding function, and thanks to the renaming policy are different from each translated source term name. Because of that, we can again conclude that, if  is a step on a version of  or , then none of the steps in  is a step on the same name. So the lemma holds.
	\qed
\end{proof}

\begin{lemma} \label{lem:nonConflictingStepsMixAsyn}
	Within target terms \pure \admin steps, that either are on sender locks or booleans, or do not unguard an instantiation of a chain lock carrying a request channel, are not conflicting, i.e.,
	
\end{lemma}

\begin{proof}
	 relies on much more \pure \admin steps than . First note that, the encoding of a parallel operator generates unguarded instantiations of chain locks carrying a request channel. Since a step on a sender lock and a step on  to unguard the then-case of a test-statement unguards an encoded continuation, they unguard instantiations of such chain locks, if the corresponding source term in the continuation contains a parallel operator. Nevertheless, we want to prove the condition also for steps on sender locks and booleans.
	
	Since source term names are translated into values, never used as links, it suffice to consider steps on names introduced by the encoding function. A look at the definition of the corresponding renaming policy in Figure \ref{fig:encodingMixAsyn} suggests the following case split\footnote{Note that in most cases the considered names are restricted, so a simple alpha conversion may change them. Because of that the use of concrete names in the following case split should not imply that we consider steps on these specific names. Instead the names refer to the meaning which is related to them by the encoding function.} on the subject of the step .
	\begin{description}
		\item[Case of :] All these names are request channels, i.e., there are introduced by  to transport requests. Note that the encoding function puts much effort in the direction of requests. Usually there is exactly one way for them, namely: (1) upwards in the structure generated by the nesting of parallel operators in the corresponding source term, (2) within the encoding of a parallel operator or each branch of the encoding of a replicated input from the left side to each right request, which are linked within a chain, and (3) within the encoding of a replicated input from each branch to each next branch, where each branch represents an encoding of the continuation of that replicated input and the branches are again linked within some kind of chain.
			
			Indeed there is only one point, at which the way of a requests is not completely determined. That is the point at which right requests are linked within a chain (compare to the encoding of a parallel operator or a replicated input). The order in which the right requests are consumed determines their order in the chain, so these steps are conflicting. They are steps on the first input on output requests in \processRightOutputRequests \ and on the first input on input requests in \processLeftOutputRequests.
			
			In both cases immediately an instantiation of a chain lock carrying a request channel is unguarded. So the lemma holds, because its precondition is violated.
			
			Let us have a look at the remaining request channels. Within the left side of the encoding of a parallel operator there are two restricted different replicated inputs on requests channels. Note that, the encoding function places all inputs or replicated inputs under restriction, i.e., for all source terms their encoding has no inputs or replicated inputs on free names. Because of that, for the request channels restricted at the left side of the parallel operator encoding there is exactly one replicated input and no other input. Thus it does not matter how many other steps on the same request channel may appear within the sequence , the step  can be performed before or after that sequence and in both cases the same term  is reached.
			
			Beside the already considered possibly conflicting input, there are two different replicated inputs on request channels and no other input on request channels within \processRightOutputRequests. The link of the first is bounded by a guarding replicated input on a chain lock. The link of the second is restricted. So we can again apply the argumentation of the case before. The same applies to \processRightInputRequests. The two links of replicated inputs in \pushRequests \ and the four links of replicated inputs \pushRequestsOut \ are restricted, apart from that, this case is similar to the cases before. In opposite, in case of \pushRequestsIn \ the links of both replicated inputs are bounded by a guarding input, apart from that, this case is similar to the cases before.
		\item[Case of :] These names is used as chain locks carrying a request channel (compare to Definition \ref{def:chainLock}). Those chain locks are used by the encoding function to direct the combinations of left and right requests in the encoding of a parallel operator as well as in the encoding of a replicated input. In order to avoid divergence, requests can not be copied arbitrary often. To ensure that indeed each left request is combined which each possible matching right request, the right requests are linked within some kind of chain or list, along which the left requests are forwarded. Again to avoid divergence these chains can not be infinitely long, so  and  allow to extent these chains by a new right request as soon as its last place is occupied. Since these names are generated under restriction, for each of them there is exactly one replicated input and no other input. Because of that it does not matter how many other steps on the same names may appear within the sequence , the step  can be performed before or after that sequence and in both cases the same term  is reached.
		\item[Case of :] Any of these names refer to a sum lock in the encoding given in Figure \ref{fig:encodingMixAsyn}. By Definition \ref{def:pureImpureAdminStep} steps on sum locks are no \pure \admin steps.
		\item[Case of :]  is used by the encoding function to introduce sender locks. For steps on sender locks it suffice to repeat the argumentation given in the proof of Lemma \ref{lem:nonConflictingStepsSepAsyn} for sender locks.
		\item[Case of :] In case of receiver lock, since they are generated under restriction, for each receiver lock there is exactly one replicated input and no other input. Because of that it does not matter how many other steps on (the same) receiver lock may appear within the sequence , the step  can be performed before or after that sequence and in both cases the same term  is reached.
		\item[Case of :]  again is a chain lock, this time carrying a translated source term name. Intuitively, it is used by the encoding function for a purpose similar to the usage of chain locks carrying a request channel. Instead of a chain of right requests,  as well as  are used to build up a some kind of chain of the encoded continuations of several reductions on the same encoded replicated input. As already explained our encoding  relies on the structure with is build by the parallel operators in the corresponding source term. Each reduction of a replicated input changes this structure. To allow for different encoded continuations to communicate among each other or with the encoded replicated input we link the encodings of the continuations. This time we have to add a new member, i.e., an encoded continuation, to the chain whenever the encoded replicated input is used to \simulate a step. Therefore  is instantiated within the then-case of the test-statement in the encoding of a replicated input. Since  is generated under restriction, for each  there is exactly one replicated input and no other input. Because of that, it does not matter how many other steps on the same name may appear within the sequence , the step  can be performed before or after that sequence and in both cases the same term  is reached.
		\item[Case of :] To link the members in the chain of right requests for each new member a new  or  is restricted and transmitted over  or . The encoded continuations of a replicated input are linked over  and , which are again restricted for each encoded continuation.  is used to transmit these new restricted names to the respective next member of the chain. Note that, this kind of link is generated always under restriction. Initially there is exactly one unguarded output and one input, guarded by a replicated input on a chain lock. Reducing this input immediately unguards some instantiations of chain locks, so the lemma holds, because its precondition is violated. Also note that, due to several \simulations on the encoded replicated input, there may be several unguarded inputs on . The order in which these inputs are consumed determines the order of the encoded continuations within the constructed chain. Because of that steps on  can be indeed conflicting.
		\item[Case of :] These names are used by the encoding function as values only, but never as links. So there are no (\pure \admin) steps on these names.
		\item[Case of :] These names are used only to implement the test-statements and the instantiation of sum locks. The reduction of a test-statement is performed in two steps. The first consumes the instantiation of a sum lock and is thus not a \pure \admin step. For the second one|necessary to unguard the then- or else-case of a test-statement|it suffice to repeat the argumentation given in the proof of Lemma \ref{lem:nonConflictingStepsSepAsyn} for these kind of steps.
	\end{description}
	\qed
\end{proof}

Note that the proof above provides a detailed explanation of the purposes of the names reserved by the encoding function . Moreover note that the \pure \admin steps that are conflicting are exactly the steps that introduce additional causal dependencies (compare to \cite{petersSchickeNestmann11} and thus prevent the preservation of the degree of distribution (compare to Section 4 in \cite{petersNestmann12}). In the following we strongly rely on the Lemmata \ref{lem:nonConflictingStepsSepAsyn} and \ref{lem:nonConflictingStepsMixAsyn}, because they basically allow us to ignore all not conflicting steps while considering the reachability of success or translated observables in the next section.

In order to show that the remaining \pure \admin steps do not cause any problems but in fact, as described in the proof of Lemma \ref{lem:nonConflictingStepsMixAsyn}, do only influence the order of right requests in the chain of right request or the order of encoded continuations of a replicated input generated by its encoding, we prove that those steps never cause any deadlock. Note that, \cite{nestmann00} proves that the encoding  does not introduce deadlocks.

\begin{lemma} \label{lem:pureAdminStepsNoDeadlock}
	\Pure \admin steps do not introduce deadlocks.
\end{lemma}

\begin{proof}
	In case of a step on a sender lock or a step which does not unguard an instantiation of a chain lock, this lemma directly follows by Lemma \ref{lem:nonConflictingStepsMixAsyn}.
	
	In case of a step on a request channel which does unguard an instantiation of a chain lock (compare to the first case of the proof of Lemma \ref{lem:nonConflictingStepsMixAsyn}), a step on the unguarded chain lock unguards another input on the same request channel. Moreover the corresponding continuations differ only on a single name free to that continuation. Let us denote the first such continuation by  and the second by , and the free link name by . Then it turns out, that  is connected to  by  and either  is connected in a similar way to another such continuation or  is connected to the requests from the left. The only requests travelling along  are left requests. However as soon as they arrive  they are copied and transmitted to . Because of that the order of  and  in that chain does not matter (at least as long as we do not consider causal dependencies). Of course, the step on the chain lock unguarding  is not forced to be performed immediately after the step on the request channel, but by Lemma \ref{lem:nonConflictingStepsMixAsyn} it will eventually happen. So the step on the request channel blocks alternative steps on this request channel for some time but not for ever, i.e., it does not introduce deadlock.
	
	In case of a step on a channel of multiplicity two|let us denote it |which does unguard an instantiation of a chain lock (compare to case  of the proof of Lemma \ref{lem:nonConflictingStepsMixAsyn}), immediately an other output on  is unguarded. As in the case before by the communication on the chain lock, the communication over  links the encodings of the continuations of the respective replicated input, in this case by two request channels. Apart from that, the situation is exactly the same as before. If there is an other encoded continuation of that replicated input|caused by another \simulation\!\!|it will eventually be linked within the chain and all requests that arrive at a previous member of that chain are forwarded to that member. Note that the encoded continuations initially are all equal. So the chains resulting from different orders of two members, that were available at the same time, are equal. We conclude that a step on  can not introduce deadlock.
	\qed
\end{proof}

\begin{lemma} \label{lem:impureAdminStepsNoDeadlock}
	\Impure \admin steps do not introduce deadlocks.
\end{lemma}

\begin{proof}
	In  any \impure \admin step reduces a test-statement by consuming an instantiation of a sum lock (compare to Definition \ref{def:pureImpureAdminStep}). Deadlock occurs, if|due to interleaving of these test-statements|the instantiations of a subset of the sum locks are consumed, such that none of the involved test-statements can be resolved. As already stated in \cite{nestmann00} a total ordering on the sum locks suffice to circumvent any potential deadlock. Note that the encodings of parallel operator and replicated input implement such a total ordering on sum locks. They somehow reuse the structure generated by the parallel operators of the corresponding source term to force the nested test-statements to always test the lock first, which is according to that parallel structure left to the other one. Since the parallel operator is binary, this structure is a binary tree. So testing always the left lock first, indeed implements a total ordering.
	\qed
\end{proof}

Note that, by Lemma \ref{lem:simulationVSNonAdminStep} at page \pageref{lem:simulationVSNonAdminStep}, \nonAdmin steps and the source term steps of the corresponding \simulations coincide. So Lemma \ref{lem:simulationVSNonAdminStep} in combination with the Lemma \ref{lem:pureAdminStepsNoDeadlock} and Lemma \ref{lem:impureAdminStepsNoDeadlock} proves that the encoding  does not introduce deadlocks.

\subsection{Translated Observables and Choosing a Bisimulation} \label{sec:transBarbBisim}

In order to prove the presented encodings correct with respect to the criteria of Gorla we have to choose an equivalence  for operational correspondence (compare to Definition \ref{def:operationalCorrespondence}). In \cite{gorla10} Gorla describes  as follows:
\begin{quotation}
	`` is a behavioural equivalence needed to describe the abstract behaviour of a process. Usually,  is a congruence at least with respect to parallel composition; it is often defined in the form of a barbed equivalence or can be derived directly from the reduction semantics.''
\end{quotation}
Moreover, by the criteria in Section \ref{sec:qualityCriteria}, we know that  should be success respecting (compare to Definition \ref{def:successRespecting}). The main purpose of  in the definition of operational correspondence is to abstract from junk, i.e., remains left over by former \simulations that do not influence the abstract behaviour of a target term. Usually, two kinds of junks are distinguished inactive junk, i.e., remains that neither can perform further reductions on its own nor interact with the surrounding target term, and active junk, i.e., remains that may by reduced or even interact with the surrounding target term. Of course, proving an encoding to be good requires to prove that its active junk does no harm, i.e., does not influence the abstract behaviour of the target term. However, the presented encodings  and  induce the consideration of a second dimension of junk, namely observable and inobservable junk. In most cases developers of encodings make sure that all produced junk is inobservable, i.e., using the standard notions of observables for the target language neither the steps on junk nor the junk itself is observable. Unfortunately, as for the presented encodings, it is not always possible to define the encoding function such that all produced junk is inobservable.

In the \piCal-calculus observables are usually defined to be the unguarded input or output guards of a term, whose channel name is not restricted (compare to Definition \ref{def:barb}). To encode sums both encodings split up the summands into parallel. Of course, while doing so, the information which of these summands originally belongs to the same sum gets lost. To recover it, the encodings introduce sum locks, which cover a boolean value to indicate whether the respective summands of that sum can still be used to complete an \simulation or whether a former \simulation already consume one of the summands and thus no other can be used any more. Thus the encoding functions translate a source term observable into an observable|in case of |or a request|in case of |both times augment with the information covered by the sum lock. So source term observables are not translated into single observables again.

\begin{definition}[Translated Observables] \label{def:transBarb}
	Let . Then  has a \emph{translated input observables} , denoted by , if
	
	and  has a \emph{translated output observables} , denoted by , if
	
	Let . Then  has a \emph{translated input observables} , denoted by , if
	
	and  has a \emph{translated output observables} , denoted by , if
	
	Moreover for some input or output observable  we define  and .
\end{definition}

Note that for all target terms  any output with three parameters is an input request and any output with four parameters is an output request. So a simple typing suffice to securely identify requests. Since requests already contain a reference to their related sum lock, the identification of the related sum lock instantiation is unambiguous as well. The condition  is necessary to rule out translated observables that corresponds to invisible in- or outputs of the source term (compare to Definition \ref{def:barb} at page \pageref{def:barb}). To show that the notion of translated observables indeed captures our intuition we prove that the set of observables reachable for a source term coincides with the set of translated observables reachable for its encoding.

\begin{lemma}
	The set of reachable observables of a source term and of reachable translated observables of its encoding coincide, i.e.,
	
	and
	
\end{lemma}

\begin{proof}
	By Corollary \ref{col:initialSumLocksArePositive} stating that initially all sum locks are instantiated positive and Figure \ref{fig:encodingMixAsyn} the set of observables of a source term  and the set of translated observables of  coincide, i.e.,
	
	In case of  we obtain a similar result after reducing all instantiation of receiver locks, since they guard the respective inputs (compare to Figure \ref{fig:encodingSepAsyn}). The lemma then follows by operational correspondence, i.e. by the Lemmata \ref{lem:operationalCompletenessSepAsyn} at page \pageref{lem:operationalCompletenessSepAsyn}, \ref{lem:operationalCompletenessMixAsyn} at page \pageref{lem:operationalCompletenessMixAsyn},  and \ref{lem:operationalSoundness} at page \pageref{lem:operationalSoundness}\footnote{Note that we present this fact just to visualize our intuition. We do not use it within another proof.}.
	\qed
\end{proof}

The problem now is, that the completion of an \simulation changes positive instantiations of sum locks into negative ones and so obviously influences the translated observables, but the corresponding requests|in case of |or in- and outputs of other summands|in case of |remain as observable junk. While active junk often aggravates the proof of correctness of an encoding, due to intricate proofs to show that it does no harm, observable junk turns out to be even worse for an encoding, because it prevents for the use of standard equivalences to describe the abstract behaviour of a target term.

Since the target language is the asynchronous \piCal-calculus, it seems natural to choose weak asynchronous bisimilarity  or asynchronous barbed congruence . Unfortunately for both choices the presented encodings are not good. Consider for example the source term . It can perform a reduction to . But, all derivatives of its encoding, i.e., all  with  or , are neither asynchronous bisimilar nor synchronous barbed congruent to the encoding of , i.e.,  and , where . Note that this is not due to the encoding of , which is indeed weak asynchronous bisimilar to  again, but to the observable junk, which suffice to distinguish the remains of \simulations from . Because of this, a proof of the correctness of these encodings with respect to  or  fails due to operational correspondence (compare to the Definition \ref{def:operationalCorrespondence}). Of course, you might argue that an encoding that can not get rid of observable junk is no good encoding. On the other side, Nestmann in \cite{nestmann00} gives some good reasons to accept  as a good encoding. Moreover, the translation of observables into something different seems to be a quite natural manner of encoding functions. And indeed rephrasing a standard equivalence to take instead of observables translated observables into account suffice to turn it into an equivalence that describes the abstract behaviour of encoded terms. The same holds if we do not consider observables at all, but e.g. only reachability of success.

Note that to test a sum lock it has to be consumed first. Analysing the encoding function we observe that in each case an instantiation of sum lock is consumed, another instantiation of that lock is restored as soon as the respective test statement is completed. However, since there may lay many steps between the start and the completion of a test statement, instantiations of locks may temporally not be available. Because of that, we will use the notion of  instead of  in the following.

\begin{definition}[Translated Barbed Bisimilarity] \label{def:transBarbBisim}
	Let . Then  and  are \emph{translated barbed bisimilar} with respect to , denoted by , if
	\begin{enumerate}
		\item  iff ,
		\item for all ,  iff ,
		\item for all ,  implies , and
		\item for all ,  implies .
	\end{enumerate}
	And  and  are \emph{translated barbed bisimilar} with respect to , denoted by , if
	\begin{enumerate}
		\item  iff ,
		\item for all ,  iff ,
		\item for all ,  implies , and
		\item for all ,  implies .
	\end{enumerate}
\end{definition}

Note that the first condition of each equivalence ensures that it is success respecting as required in Section \ref{sec:qualityCriteria} by Definition \ref{def:successRespecting}. Conditions 2. to 4. than define a version of weak barbed bisimilarity which utilises translated observables instead of standard barbs. Note that we consider the translation of input as well as output observables, although our target language is asynchronous. However, since in case of  both kinds of source term actions are translated into requests and instantiations of sum locks, i.e., into outputs, the presented kind of barbed bisimilarity does consider barbs on outputs only. So it is an asynchronous variant of barbed bisimulation. Moreover note, that due to the definition above we do not consider any barbs except for translated barbs. However, analysing the encoding function , we observe, that for all target terms all free in- or outputs are on the request channels  and . So, since we do only consider target terms, requests are indeed the only interesting barbs of .

Alternatively, we could decide not to consider barbs at all, by omitting the second condition of  and . We result then in an equivalence that considers only reachability of  as abstract behaviour of a term. Note that this intuition goes along very well with the criteria defined by Gorla as they also do only require a similar reachability of , because reachability of success is defined independent of a specific source or target language. An advantage of such an equivalence is the fact, that it is independent of the considered encoding function. However, the resulting equivalence is obviously strictly weaker then  and . Moreover,  and  much better describe how the encoding function proceeds source terms and \simulate source term steps. So we will use these equivalences in the following.

In case of  we are faced with an other problem concerning the choice of an appropriate equivalence, although that problem is by far not that crucial as observable junk. As explained above, the encodings of structural congruent source terms can differ in the number and nature of reachable intermediate states (compare to Example \ref{exa:intermediateStates}, Definition \ref{def:intermediateState}, and the following discussion above). Operational Soundness explicitly allows for intermediate states, i.e., target term states that due not map to the encodings of any of the corresponding source terms. However, if  does distinguish target terms by reachability of intermediate states, we have a problem with the \textsc{Cong} rule of Figure \ref{fig:concurrentReductionSemantics} and operational completeness of Definition \ref{def:operationalCorrespondence}. Let us consider the source terms  and  again. The source term  can reduce to  but by the \textsc{Cong} rule it can reduce to  as well.  can \simulate the first step modulo  but not the second step. Note that the \textsc{Cong} rule is used to shorten the presentation of the reduction semantics, but it is neither necessary nor was it the originally choice. So the most natural way to circumvent this problem is to rephrase the rules of the reduction semantics by avoiding the \textsc{Cong} rule and with it the possibility to arbitrary reorder the subprocesses during reductions. However we can also circumvent this problem by using an equivalence which does not distinguishes terms by the reachability of intermediate states.

\begin{definition}[Translated Barbed Bisimilarity] \label{def:transBarbBisimB}
	Let . Then  and  are \emph{translated barbed bisimilar} with respect to , denoted by , if
	\begin{enumerate}
		\item  iff ,
		\item for all ,  iff ,
		\item for all ,  implies that there exists some  such that  and , and
		\item for all ,  implies that there exists some  such that  and .
	\end{enumerate}
\end{definition}

Note that the second version of  is strictly weaker then the first version and that we only use it to circumvent the problem with the \textsc{Cong} rule in operational completeness (and the therefore necessary Lemma \ref{lem:preservesSCModuloTransBarbBisimMixAsyn}). Because of this we prove the remaining results using the stricter equivalence; silently omitting the subscript .

Before we use these relations, we prove that they are indeed equivalences.

\begin{lemma} \label{lem:transBarbBisimIsEquivalence}
	All presented translated barbed bisimulations are equivalence relations.
\end{lemma}

\begin{proof}
	We have to show that , , and  are reflexive, symmetric, and transitive. Reflexivity and transitivity follow directly by definition. For transitivity of  assume  such that  and . By the first condition we have  iff  iff . And by the second condition for all  we have  iff  iff . So we can conclude that  iff  and  iff .
	
	By the third condition for all  with  there is some  such that  and . Without loss of generality let us assume, that the sequence  is of length , i.e., there are  such that , , and . Let  and . Then, by the third condition, for each step in , i.e., for each  with , there is some  such that  with . So we conclude that for all  with  there is some  such that  and . The argumentation for the last condition is similar.
	
	The argumentation for  and  is similar.
	\qed
\end{proof}

The observable junk does not only rule out standard equivalences but also congruences with respect to contexts, that allow for interaction with observable junk. In both encodings such an interaction can for instance lead to a positive instantiation of a formerly negative instantiation of a sum lock and so turn observable junk into a translated observable, or it can instantiate a sender lock and so complete \simulations on junk.
\begin{example}
	Let us consider the target terms  and . By the Lemmata \ref{lem:junkRemainsOfSumsSepAsyn} and \ref{lem:junkRemainsOfSumsMixAsyn} in the next section, we prove that both terms are junk. They be produced as remains of \simulations (or a part of such a remain), e.g. for a source term . Since neither  nor  reaches any translated observables or unguarded occurrence of , we have  and . However, we can distinguish  from  by the context , because  but . So . Accordingly, we can distinguish  from  by the context , where  is the free output request channel of . Again we have  but , i.e., .
\end{example}
Because of this, in order to prove operational completeness, we have to reduce the number of contexts we consider to obtain a congruence. Intuitively, we consider only contexts that respect the protocol of the encoding function. Thus, we consider only contexts that, if their argument is a target term as for instance the encoding of , result in a target term.

\begin{definition}[Translated Barbed Congruence] \label{def:transBarbCong}
	Two terms  are \emph{translated barbed congruent} with respect to , denoted as , if
	
	Two target terms  are \emph{translated barbed congruent} with respect to , denoted as , if
	
	Two target terms  are \emph{translated barbed congruent} with respect to , denoted as , if
	
\end{definition}
\noindent
Note that we again usually only consider the stricter first variant of the congruence , while silently omitting the subscript . Operational correspondence considers only target terms, so it would suffice to define the congruence over target terms only. However, in defining it over all terms of the target language we gain more flexibility. We will use these flexibility in the proof of operational completeness to stepwise reduce junk which in some cases leads to non target terms. Since these non target terms are behavioural equivalent to the considered target terms, they serve as connecting pieces to link the target terms modulo  or . Moreover note that the respective congruence relations are strictly weaker than their corresponding equivalences.
\begin{example}
	Let us consider the target terms , , , and . Obviously  and . But neither  nor , because in both cases the context has only to provide a translated input observable on  or , respectively. So in case of  the context  suffice to distinguish  and , because  but . The argumentation for  is similar, but due to the complex encoding of the parallel operator the respective distinguishing context is rather large. Because of that, intuitively, two equivalent target terms are congruent, only if the encoded continuations of their translated observables are again equivalent.
\end{example}

Of course, all presented congruences are again equivalences.

\begin{lemma} \label{lem:transBarbCongIsEquivalence}
	All presented translated barbed congruences are equivalence relations.
\end{lemma}

\begin{proof}
	Let . Then  for all contexts ; so . Moreover, if , then  for all contexts  such that . Since  is an equivalence, then also  for all such contexts, i.e., . Finally, if  and , then  for all contexts  such that , and  for all such contexts. So also  for all such contexts, i.e., . We conclude that  is an equivalence.
	
	The argumentation for  and  is similar.
	\qed
\end{proof}

Moreover, the presented congruences include the structural congruence on the target language, because it is already included in the respective bisimulations.

\begin{lemma} \label{lem:transBarbBisimIncludesSC}
	Translated barbed bisimulation includes structural congruence, i.e.,
	
\end{lemma}

\begin{proof}
	Let us assume . Then, by rule \textsc{Cong} in Figure \ref{fig:concurrentReductionSemantics},  and  can perform exactly the same steps such that the successors are again structural congruent. Note that this holds even in case of  and is obviously a stronger feature than the third and fourth condition of  (compare to Definition \ref{def:transBarbBisimB}). Since, by Definition \ref{def:success}, reachability of success is defined modulo structural congruence,  and  have the same chance to reach success, i.e.,  iff . Similarly, translated observables are defined modulo structural congruence for both encodings in Definition \ref{def:transBarb}. Note that we do not consider translated observables on restricted names, since the corresponding in- and outputs in the source terms are no observables as well. Because of that translated observables can not be changed by alpha conversion. So  and  have the same set of translated observables and the same chance to reach a translated observable, i.e., , , , and  for all . So  and .
	\qed
\end{proof}

\begin{lemma} \label{lem:transBarbCongIncludesSC}
	Weak translated barbed congruence includes structural congruence, i.e.,
	
\end{lemma}

\begin{proof}
	By Definition \ref{def:transBarbCong},  is the largest congruence on contexts restricted to target terms included in , and  is the largest congruence on contexts restricted to target terms included in . Note that Definition \ref{def:transBarbCong} restricts only the contexts but not the considered terms. Thus, since by Lemma \ref{lem:transBarbBisimIncludesSC} structural congruence  is included in  and , it is included in  and .
	\qed
\end{proof}

Remember, that to our intuition \pure \admin steps are only pre- or postprocessing steps that do not influence which \simulations can be completed. To underpin that intuition, we prove that \pure \admin steps do not change the state of a target term modulo the considered equivalences and congruences.

\begin{lemma} \label{lem:pureAdminStepsTransBarbBisimSepAsyn}
	\Pure \admin steps do not influence the state of a target term modulo translated barbed bisimilarity or translated barbed congruence with respect to , i.e.,
	
\end{lemma}

\begin{proof}
	Translated barbed bisimilarity is some kind of weak bisimilarity that takes instead of observables the reachability of  and the reachability of translated observables into account. Note that it is not possible to reduce . So, in case , the only way that leads to  is that in the sequence of steps from  to  there is a step that rules out a former possible way to unguard some occurrence of . Since by Definition \ref{def:transBarb} \pure \admin steps can not consume translated observables, the same holds for the consideration of translated observables. We have to show, that it not possible when using only \pure \admin steps to rule out a way to a translated observable or an unguarded occurrence of .
	
	Obviously, in case none of the \pure \admin steps rules out any other sequence of steps, i.e. if none of the \admin steps is in conflict to any other sequence of step, this condition holds. Because of that, by Lemma \ref{lem:nonConflictingStepsSepAsyn},  implies .
	
	For the same reason, and since \pure \admin steps do neither consumes positive instantiations of sum locks nor outputs on translated source terms, they do not influence the set of reachable translated observables, i.e.,  iff  for all . Note, that such a step can restore a positive or negative instantiation of a sum lock by resolving a test on a negative instantiated sum lock or can unguard new requests and sum lock instantiations by a step on a sender lock, so \pure \admin steps influence the set of translated observables. But, since they do not rule out a run that leads to a translated observable, they do not influence the set of reachable translated observables. So .
	
	Since \pure \admin steps do not influence the state of arbitrary target terms modulo  and since the congruence  does only consider target term contexts (compare to Definition \ref{def:transBarbCong}), \pure \admin steps do not influence the state of target terns modulo , i.e., .
	\qed
\end{proof}

\begin{lemma} \label{lem:pureAdminStepsTransBarbBisimMixAsyn}
	\Pure \admin steps do not influence the state of a target term modulo translated barbed bisimilarity or translated barbed congruence with respect to , i.e.,
	
\end{lemma}

\begin{proof}
	Translated barbed bisimilarity is some kind of weak bisimilarity that takes instead of observables the reachability of  and the reachability of translated observables into account. Note that it is not possible to reduce . So, in case , the only way that leads to  is that in the sequence of steps from  to  there is a step that rules out a former possible way to unguard some occurrence of . Since by Definition \ref{def:transBarb} \pure \admin steps can not consume translated observables, the same holds for the consideration of translated observables. We have to show, that it not possible when using only \pure \admin steps to rule out a way to a translated observable or an unguarded occurrence of .
	
	Obviously, in case none of the \pure \admin steps rules out any other sequence of steps, i.e. if none of the \pure \admin steps is in conflict to any other sequence of steps, this condition holds. Fortunately, indeed most of the \pure \admin steps are not conflicting. By Lemma \ref{lem:nonConflictingStepsMixAsyn}, the condition  holds for all steps that are on a sender lock or do not unguard an instantiation of a chain lock carrying a request channel.
	
	Revisiting the argumentation in the proof of Lemma \ref{lem:nonConflictingStepsMixAsyn} we observe that the remaining steps either influence the order of requests in chains of right requests (compare to \processRightOutputRequests \ and \processRightInputRequests) or the order of encoded continuations in the chain build up by the encoding of a replicated input. By Lemma \ref{lem:pureAdminStepsNoDeadlock}, these steps do not introduce deadlock, moreover revisiting the argumentation of the proof of this lemma we observe, that their impact on the ordering within the chain is indeed their only impact on the behaviour of target terms. Since all encoded continuations of a replicated input are initially the same, their order does not matter for the reachability of  or translated observables. The same holds for the order of requests, because regardless of their order eventually each combination is checked. Indeed, a different order may only lead to more or less necessary invisible steps on requests channels to combine a specific pair of requests. Because of that, even the \pure \admin steps that unguards an instantiation of a chain lock do not influence the state of the target term modulo . So .
	
	Since \pure \admin steps do not influence the state of arbitrary target terms modulo  and since the congruence  does only consider target term contexts (compare to Definition \ref{def:transBarbCong}), \pure \admin steps do not influence the state of target terns modulo , i.e., .
	\qed
\end{proof}

Note that due to these two lemmata we can mostly ignore \pure \admin steps in the following proofs, since they are invisible modulo the considered equivalence and congruence relations. To handle the \textsc{Cong} rule in the proof of operational completeness we prove that both encodings preserve structural congruence of source terms modulo the presented equivalences and congruences.

\begin{lemma} \label{lem:preservesSCModuloTransBarbBisimSepAsyn}
	The encoding  preserves structural congruence of source terms modulo translated barbed bisimilarity and translated barbed congruence, i.e.,
	
\end{lemma}

\begin{proof}
	The strict use of the renaming policy , i.e., the fact that source term names are translated into single names not used by the encoding function for special purposes, ensures the preservation of equality modulo alpha conversion. Since the parallel operator, the match operator, and restriction are translated \cleanly, the encoding  preserves structural congruence of source terms for all rules except for , i.e., if  and  are structural congruent without using the rule , then . By Lemma \ref{lem:transBarbBisimIncludesSC}, then  and, by Lemma \ref{lem:transBarbCongIncludesSC}, then .
	
	The rule  is not preserved, because the empty sum  is not translated \cleanly, so e.g.  but . Note that, because of the renaming policy  and the \clean translation of restriction, the rule  is preserved, i.e., since , we have . However, since  is translated into a closed term that can not perform any step, its encoding behaves as . In particular  can not interact with any context and does not reach success or any translated observable on its own. So, even in this case, we have  and .
	\qed
\end{proof}

Since  does not translate the parallel operator \cleanly, it does not directly preserve structural congruence of source terms. But, since the encoding preserves the abstract behaviour of source terms, the encodings of structural congruent source terms are similar modulo equivalences measuring only these abstract behaviour. As already explained, to prove the following statement, the equivalence must not distinguish terms by their reachable intermediate states.

\begin{lemma} \label{lem:preservesSCModuloTransBarbBisimMixAsyn}
	The encoding  preserves structural congruence of source terms modulo translated barbed bisimilarity and translated barbed congruence, i.e.,
	
\end{lemma}

\begin{proof}
	Again, the strict use of the renaming policy , i.e., the fact that source term names are translated into single names not used by the encoding function for special purposes, ensures the preservation of equality modulo alpha conversion. So  implies . Also, the \clean translation of the match operator and restriction ensures the preservation of structural congruence modulo the rules , , , and  if . So, if  and  do only differ due to one or more of these four rules, then . By Lemma \ref{lem:transBarbBisimIncludesSC}, we conclude  and, by Lemma \ref{lem:transBarbCongIncludesSC}, we conclude  for both of the above cases.
	
	With the preservation of these rules in mind we show the lemma by an induction over the proof tree of , i.e., over the number of structural congruence rules which are applied to show .
	\begin{description}
		\item[Base Case:] If , then . So, by reflexivity,  and .
		\item[Induction Hypothesis:] If  and  can be proved to be structural congruent within  applications of structural congruence rules, then  and .
		\item[Induction Step:]  and  can be proved to be structural congruent within  applications of structural congruence rules. Let  be such that  and  can be proved to be structural congruent within  applications of structural congruence rules and  and  can be proved to be structural congruent directly by one application of a structural congruence rule, i.e., . By the induction hypothesis,  and . We proceed with a case split over the rule necessary to prove .
		\begin{description}
			\item[Case of Rule :] In this case  and  for some . By Figure \ref{fig:encodingMixAsyn},
				
				and . Obviously  and  are not structural congruent. However,  appears unguarded within , so if  reaches  or a translated observable then so does . Moreover we observe, that, since the encoding of  does not emit any requests, the hole right branch of 
				
				can do nothing but two steps on chain locks. Because of that requests of  are prepared to be transmitted to the right side by  and  but they are never received at the right side. What remains is the upward pushing of all requests of  by the interplay of , , and . Because of that, for all target term contexts  behaves as , i.e.,  and . Since  and  are equivalences (compare to Lemmata \ref{lem:transBarbBisimIsEquivalence} and \ref{lem:transBarbCongIsEquivalence}), by transitivity, we conclude  and .
			\item[Case of Rule :] In this case  and  for some . Their encodings are given by:
				
				Since all combinations of left and right requests are checked,  can \simulate the same source term steps as . However, since  and  are exchanged at the outermost parallel operator the roles of left and right requests are exchanged. As a consequence, if a combination of requests from  and  leads to a test on the respective sum locks, the order in which these locks are tested is different in  and . So  and  differ in their total ordering of sum locks. The ordering in  is based on the structure induced by the nesting of parallel operators in ; while the ordering in  is based on the structure induced by the parallel operator nesting in . Note that, since in both cases this structure is a binary tree, by Lemma \ref{lem:impureAdminStepsNoDeadlock}, the encoding does not introduce deadlock. But as explained in Example \ref{exa:intermediateStates} the different orderings may lead to different reachable intermediate states. Apart from intermediate states  and  are similar, i.e., they have the same chance to reach success or translated observables.
				
				By Definition \ref{def:transBarbBisimB},  explicitly allows for different reachable intermediate states. Because of that, . Analysing the encoding function in Figure \ref{fig:encodingMixAsyn} we observe that any encoded source term has at most two free names that are used as channels|remember that translated source term names are never used as channels within . Because of that, when placed within a target term context,  and  can start an interaction with the context only by transmitting their requests. Because we consider only target term contexts, i.e., contexts  such that , the context respects the protocol implemented by the encoding function. So, if  provides a translated observable and the context has the matching translated observable, then the context can interact with  to \simulate a source term step. Doing so, an encoded continuation, i.e., an encoded source term, is unguarded within the continuation of . Since , the same context can \simulate the same source term step when interacting with . Moreover, doing so, again an encoded source term is unguarded within the continuation of  and the respective source terms of these continuations in case of  and  are again structural congruent. Because of this we can prove the preservation of structural congruence of source terms is also preserved modulo  by assuming an arbitrary context and perform an induction over the number of \simulations resulting from an interaction of the context with . So we conclude .
				
				Since  and  are equivalences (compare to Lemmata \ref{lem:transBarbBisimIsEquivalence} and \ref{lem:transBarbCongIsEquivalence}), by transitivity, we conclude  and .
			\item[Case of Rule :] In this  and  for some . Their encodings are given by
				
				and
				
				In  the encoding of  appears left and the encoding of  appears right within the encoding of a parallel operator. Together they form the right branch of a surrounding encoding of a parallel operator, there the left branch is filled with . In opposite in  the terms  and  are left and right of a parallel operator encoding which is the left branch of a surrounding parallel operator encoding, where  appears right. However, since all requests are pushed upwards to each surrounding parallel operator encoding, again all combinations of requests among the three encoded subterms , , and  are checked in  as well as in . Moreover, we observe that in both encodings  and  the encoding of  is always left to the encodings of  and , and the encoding of  is always left to the encoding of . So in this case  and  do not differ by the underlying total ordering of sum locks, i.e., they reach the same intermediate states. So the behaviour of  and  does only differ by \pure \admin steps on requests but they have the same chance to reach  and translated observables, i.e., . Revisiting the argumentation of the case before we also get .
				
				Since  and  are equivalences (compare to Lemmata \ref{lem:transBarbBisimIsEquivalence} and \ref{lem:transBarbCongIsEquivalence}), by transitivity, we conclude  and .
			\item[Else:] For the reaming rules we can apply the above argumentation to show that . By the Lemmata \ref{lem:transBarbBisimIncludesSC} and \ref{lem:transBarbCongIncludesSC}, we have  and . By Lemma \ref{lem:transBarbBisimIsEquivalence} and Lemma \ref{lem:transBarbCongIsEquivalence},  and  are equivalences. Thus, by transitivity, we conclude  and .
		\end{description}
	\end{description}
	\qed
\end{proof}

These two lemmata finally prove that the intermediate states in combination with the application of the \textsc{Cong} rule on source terms do not falsify the criterion on operational completeness modulo .

\subsection{Junk}

We consider remains of \simulations that behave modulo  and  like  and do not influence the possibility or inability to \simulate further source term steps as junk. The \simulation of source term steps may leave different kinds of junk. So, e.g. in order to show operational completeness, we have to prove that junk does no harm.

Of course we are only interested in kinds of junk that appear in target terms, i.e., that are pieces of target terms. However, to ease the argumentation on the proof of operational completeness we want to allow to stepwise reduce junk. Unfortunately, as soon as we reduce a target term by the first piece of junk it is often no target term any more. So, in order to allow for a stepwise reduction of junk, we give a recursive definition of what it means to be a piece of a target term.

\begin{definition}[Piece of a Target Term] \label{def:pieceTargetTerm}
	A term  is a \emph{piece of a target term} of , denoted by , if
	
	Accordingly, a term  is a \emph{piece of a target term} of , denoted by , if
	
\end{definition}
\noindent
Intuitively, the definition above allows for a piece of a target term to recover the corresponding target term by stepwise restoring the reduced junk. Moreover note, that, although the relations  and  are not sensitive to divergence, they are sensitive to deadlock. That is why we require  or  to ensure that indeed only junk is removed and so, no deadlock is introduced.

\begin{definition}[Junk] \label{def:junk}
	A term  is called \emph{junk} of the encoding  modulo , if  behaves modulo  similar to  for all pieces of target terms, i.e.,
	
	A term  is called \emph{junk} of the encoding  modulo , if  behaves modulo  similar to  for all pieces of target terms, i.e.,
	
\end{definition}
\noindent
Since we do not consider junk modulo equivalences different from  and , we omit the equivalence in the following. Moreover we omit the encoding function if the considered junk appears within both encodings.

Of course, whenever we reduce a piece of a target term by removing junk, the result is again a piece of a target term. Moreover, reducing junk does not change the behaviour of such a term modulo  or .

\begin{lemma} \label{lem:removeJunk}
	Let  be a piece of a target term including some junk . Then removing this junk results a piece of a target term which is congruent to , i.e.,
	
	and
	
\end{lemma}

\begin{proof}
	Let  be junk. And let , , and  such that . We show the lemma for . The argumentation for  is then similar.
	
	Since, by Lemma \ref{lem:transBarbCongIncludesSC},  includes structural congruence,  implies . By Definition \ref{def:transBarbCong}, then  for all contexts  such that . Let . Then  is a context, i.e., , and, since  and , we have . Thus,  for all contexts  such that . Moreover,  implies  for all such contexts . By Definition \ref{def:junk} of junk, then  for all such contexts . Since  and since, by Lemma \ref{lem:transBarbBisimIncludesSC},  includes structural congruence, we deduce  for all such contexts . Because  is, by Lemma \ref{lem:transBarbBisimIsEquivalence}, an equivalence,  for all such contexts  and  for all such contexts  implies  for all such contexts . Thus, by Definition \ref{def:transBarbCong}, we conclude .
	
	Finally, since  includes structural congruence and is an equivalence,  implies . Thus, since , we conclude .
	\qed
\end{proof}

Using this lemma we can remove junk from a target term . As result we obtain a piece of a target term  such that  or , respectively. Then we can further reduce  by removing junk such that we result in a piece of a target term  with  or  and so forth. Note that, we spend some effort in defining the notion of a piece of a target term to allow the stepwise remove of junk. This allows us to consider different kinds of junks separately. If we instead consider all possible junk of a target term at one go, then for the definition of junk it suffice to require that the context  is such that  is a target term. However, it seems to be more efficient and more descriptive to consider the different kinds of junk separated.

In the simplest case junk is a closed process that can not perform any step, i.e., junk is invisible and inactive. Such kind of junk is produced e.g. as remain of a test-statement. By Definition \ref{def:testBoolean}, a test-statement and the corresponding instantiations of booleans are defined as:

Depending on whether we test a positive or a negative instantiation we result either in the then-case  or the else-case . Due to the renaming policy within target terms  and  are neither free in  nor in . So we can pull out the interesting cases  or  and  or  remain as inobservable and inactive junk.

\begin{lemma} \label{lem:junkTestStatement}
	For any  and any  the terms  and  are junk.
\end{lemma}

\begin{proof}
	Let  and .  as well as  are closed terms, which can not perform any step. Moreover, they reach neither success nor any translated observable, i.e., , , , , , and  for all . Because of that, for all contexts  we have  and . Thus, by Definition \ref{def:junk},  and  are junk.
	\qed
\end{proof}

Note that, due to this lemma, we can securely omit the remains of test-statements in the following. An other kind of inobservable and inactive junk is produced by the translation of the empty sum . It results in a positive instantiation of a sum lock that is not used anywhere. However, let us generalise this case a little bit to an arbitrary instantiation of a sum lock (either positive or negative) that is not used anywhere.

\begin{lemma} \label{lem:junkEmptySum}
	For any name  the term , where , is junk.
\end{lemma}

\begin{proof}
	Let .  is a closed term, which can not perform any step. Moreover, this term can reach neither success nor any translated observable, i.e., , , and  for all . So for all contexts  we have  and . Thus, by Definition \ref{def:junk},  is junk.
	\qed
\end{proof}
\noindent
Note that this lemma especially shows that the translation of the empty sum is junk, i.e., we translate nothing into nothing but junk. Moreover we will use it to reduce the remains left over by \simulations. In the following lemma we prove, that requests on negative instantiations of sum locks are junk of the encoding from \piMix into \piAsyn. Note that in this case we consider potentially observable and active junk.

\begin{lemma} \label{lem:junkRequestsOnFalseSumLocks}
	Requests on negative instantiations of sum locks are junk of , i.e.,
	
	and
	
\end{lemma}

\begin{proof}
	Let  and .
	
	Since we require , we consider only contexts that respect the protocol implemented by the encoding function . By analysing the encoding function in Figure \ref{fig:encodingMixAsyn}, we observe that there are many forwarders for requests, i.e., many replicated inputs that consume requests and immediately restore a request on a different channel but with exactly the same values. Note that by such forwarders requests are multiplied. Most of these copies turn out to be junk. However, note that the encoding function restricts the request channels|except for the outermost|and provides for each such channel exactly one (replicate) input and no inputs or replicated inputs for unrestricted request channels. Because of that, the way a request may travel is completely determined, i.e., given a target term there is no choice about which way a request may take.
	
	Moreover, if the context puts the requests at the outermost position, then they can not be consumed at all, i.e., in this case the requests are observable but inactive junk. By Lemma \ref{lem:instantiationSumLocks}, the negative instantiation of the sum lock  is the only instantiation of that lock and, by Lemma \ref{lem:changeInstantiationSumLock}, it can not be changed by the context into a positive instantiation. So, by Definition \ref{def:transBarb}, the requests are not considered as translated observables, i.e.,  and  for all . Obviously,  and  also have no possibility to reach , i.e.,  and . Thus for all contexts  such that , , and , we have  and .
	
	Note that we consider only contexts  and , such that  and  are pieces of target terms. So all requests|including  and |origin from the translation of input or output guarded terms or replicated inputs. All inputs on request channels, i.e., channels that can transport either three or four values, origin from the translation of the parallel operator or a replicated input. We observe that, for each request, the encoding of a parallel operator receives from one of its encoded parameters, one copy of that request is pushed upwards. Similarly, for each request of each branch of an encoded replicated input one copy is pushed to the right. Because of that, requests never vanish. As soon as a request in a target term is unguarded for the first time, there will always be a copy of that request possibly on another channel but with the same values (compare to Lemma \ref{lem:encodingMixAsynPreserveRequests}).
	
	Note that all inputs on request channels are replicated inputs except for the first inputs in the processing of right in- or output requests in the encoding of a parallel operator or a replicated input (compare to \processRightOutputRequests \ and \processRightInputRequests). However, even in these two cases the consumption of a request enables|after one internal step on a chain lock|the processing of another request in exactly the same way modulo some forwarding processes. So the order in which requests are consumed does not matter (compare to Lemma \ref{lem:pureAdminStepsNoDeadlock}). Moreover note, that the step on the chain lock is completely determined again, i.e., there is no choice about eventually doing it or how to do it. Because of that, the fact, that a request was already pushed further or not, does neither influence the reachability of success nor the reachability of translated observables.
	
	Except from transferring them the encoding function can proceed requests only by combining them.  ensures, that each pair of requests is combined at most once and that each pair of an input and an output requests, which do not both origin from the same leaf concerning the structure of parallel operator encodings, is eventually combined. Because of that, again the order in which those combinations are performed does not matter. However, the order in which tests on sum locks are induced does indeed matter, because a test induced on only positive instantiations of sum locks turns them into negative instantiations and so a former such test may influences later tests. Since the test is always induced on the sum locks related to the respective request, all test that are induced because of the requests  or  are on at least one negative instantiation of a sum lock, i.e., on  in the current case. Note that, by Lemma \ref{lem:instantiationSumLocks}, the negative instantiation of the sum lock  is the only instantiation of that lock and, by Lemma \ref{lem:changeInstantiationSumLock}, it can not be changed by the context into a positive instantiation. If we now analyse the test-statements in the encodings of an input guarded term or a replicated input, we observe that this false instantiation of  reduces the test-statements to some kind of forwarders that consumes one or two instantiations of sum locks and since there are no deadlocks on these test-statements eventually restores them on exactly the same channel and with exactly the same value. So again the processing of  or  do neither influence the reachability of success nor the reachability of translated observables.
	
	So for all contexts , such that , we have
	
	for all . Since all steps that results from an interaction with  and  are \admin steps, that neither rule out a way leading to an unguarded occurrence of  nor to a translated observable, they do not influence the state of a term modulo . Thus, we conclude  and .
	\qed
\end{proof}

Next we show, that|for both encodings|encoded guarded terms linked to negative instantiations of sum locks are junk, as well. Note that such encoded guarded terms linked to negative instantiations of sum locks result from encoded sums of which already one summand was used to \simulate a source term step.

\begin{lemma} \label{lem:junkRemainsOfSumsSepAsyn}
	For any name , any finite index set , all guards , and all processes  the term
	
	is junk of .
\end{lemma}

\begin{proof}
	Let . By Definition \ref{def:junk}, we have to show that for all contexts  such that  we have .
	
	By Lemma \ref{lem:instantiationSumLocks}, the negative instantiation of the sum lock  is the only instantiation of that lock and, by Lemma \ref{lem:changeInstantiationSumLock}, it can not be changed by the context into a positive instantiation. Analysing the encoding function in Figure \ref{fig:encodingSepAsyn} we observe, that all unguarded in- or outputs with three parameters in  are connected to . Thus  has no translated observables, i.e.,  for all . Moreover, because of the guards ,  has no unguarded occurrence of  and can not reach some on its own, i.e., .
	
	 can perform a step on its own only if for some  the guard  is equal to  or is an input guard. Note that in the second case  can only perform finitely many steps on receiver locks. Since  is instantiated by ,  can reduce to  only. Therefore,  has to consume  but the instantiation is always eventually restored. Because of that, we can ignore all  for , i.e., they are junk. Let . Moreover, obtain  from  by reducing all free inputs on receiver locks.
	
	Then  can not perform any step, since either all remaining guards are output guards and so all unguarded inputs in the encoded subterms are on not instantiated sender locks, or all remaining guards are input guards and so the encoded subterms are input guarded, i.e., . In case the index set  is empty, we can apply Lemma \ref{lem:junkEmptySum}. Else, there are either free outputs or free inputs on translated source term names. So  can communicate with the context over these translated source term names. As a result of such a communication a test-statement is unguarded. In case this test-statement is within , the sum lock  is tested first. Since  is instantiated by , the test-statement restores both, the consumed negative instantiation of  and the output on the translated source term name, which was consumed to unguard this test-statement. Else, if the unguarded test-statement is not within , then|besides the negative instantiation of the sum lock| includes only encodings of output guarded source terms. In this case all these encodings of output guarded source terms provide exactly one output on a translated source term name, which sends as first value the sum lock . In the communication with the context one of these outputs was consumed and, because of that, the unguarded test-statement is either a nested test-statement testing  as second lock or it is a single test-statement testing only . In both cases all information necessary to unguard and to reduce the test-statement except for the output on the source term name is restored. Because of that, each such output can be used as most once. In both cases no step that results from an interaction with  influences the reachability of success or of translated observables. Moreover each such step is either a \pure \admin step, which by Lemma \ref{lem:pureAdminStepsTransBarbBisimSepAsyn} do not influence the state of a term modulo , or it is an \impure \admin step. Since reachability of  is not influenced at all and all translated observables of the context which are consumed to unguard the test-statement are eventually restored, i.e., reachability of translated observables is not affected, even these \impure \admin steps do not influence the state of the context modulo  here.
	
	Thus for all contexts , such that , we have  and  for all . Moreover no step of  on its own or that results from an interaction with  does influence the state of the context modulo . So, .
	\qed
\end{proof}

\begin{lemma} \label{lem:junkRemainsOfSumsMixAsyn}
	For any name , any finite index set , all guards , and all processes  the term
	
	is junk of .
\end{lemma}

\begin{proof}
	Let . By Definition \ref{def:junk}, we have to show that for all contexts  such that  we have .
	
	By Lemma \ref{lem:instantiationSumLocks}, the negative instantiation of the sum lock  is the only instantiation of that lock and, by Lemma \ref{lem:changeInstantiationSumLock}, it can not be changed by the context into a positive instantiation. Analysing the encoding function in Figure \ref{fig:encodingMixAsyn} we observe, that all unguarded requests in  are connected to  (compare to Definition \ref{def:connectionSumLockSenderReceiver} and Lemma \ref{lem:sumLockOfReceiverOrSender}). Thus  has no translated observables, i.e.,  for all . Moreover, because of the guards ,  has no unguarded occurrence of  and can not reach some on its own, i.e., .
	
	 can perform a step on its own only if for some  the guard  is equal to . Since  is instantiated by ,  can reduce to  only. Therefore,  has to consume  but the instantiation is always eventually restored. Because of that, we can ignore all  for , i.e., they are junk. Let .
	
	Then  can not perform any step, i.e., . There are no unguarded inputs on free names of . In case the index set  is empty, we can apply Lemma \ref{lem:junkEmptySum}. Else, there are free requests, i.e., free outputs on requests channels. So  can communicate with the context by transmitting its requests. By Lemma \ref{lem:junkRequestsOnFalseSumLocks} these requests are junk. Moreover by revisiting the argumentation in the proof of Lemma \ref{lem:junkRequestsOnFalseSumLocks} we observe, that the false instantiation of  reduces all tests on that lock to simple forwarders. As a consequence no such test can unguard the encoding of a guarded source term, i.e., no such test can unguard new requests or former unguarded occurrences of success. So again we observe that no interaction with  or  can influence the ability of the context to reach success or translated observables and no step that results from an interaction with  or  influences the state of the context modulo .
	
	Thus for all contexts , such that , we have  and  for all . Moreover no step of  on its own or that results from an interaction with  does influence the state of the context modulo . So, .
	\qed
\end{proof}

Analysing the encoding function we observe, that the input on a receiver lock of an encoded input guarded source term, that guards a test-statement, is a replicated input. Of course, such a test-statement can only be used once to \simulate a source term step. After such an \simulation this replicated input becomes junk.

\begin{lemma} \label{lem:junkReceiverMixAsyn}
	For any  and any  the term
	
	in combination with a negative instantiation of the sum lock that belongs to  is junk of , i.e.,
	
\end{lemma}

\begin{proof}
	Analysing the encoding function in Figure \ref{fig:encodingMixAsyn} we observe that the request  implies that each test induced on  tests the sum lock  (compare to Lemma \ref{lem:sumLockOfReceiverOrSender}). Since that lock is already instantiated by false, we can revisit the argumentation of the proof of Lemma \ref{lem:junkRemainsOfSumsMixAsyn} to conclude that each test induced on  reduces to a simple forwarder, which restores all consumed information. So  can be ignored, i.e.,  is Junk.
	\qed
\end{proof}

Another remain of an \simulation, which we can simply consider as junk, is the preparation of a test on a negative instantiated sum lock.

\begin{lemma}  \label{lem:junkInduceTest}
	The preparation of a test on a negative instantiation of a sum lock is junk of , i.e.,
	
	and
	
\end{lemma}

\begin{proof}
	First note that here not  but only  and  are considered as junk. If these terms are omitted then the respective  reduces to the forwarder  or .
	
	In the first case|regardless whether the receiver lock  belongs to an encoded input guarded term or an encoded replicated input|the output  induces a test on the sum lock . Since that lock is already instantiated by false we can revisit the argumentation of the proof of Lemma \ref{lem:junkRemainsOfSumsMixAsyn} to conclude that we can ignore this induced test. So we can also ignore the inducing output . The remainig term  is equal to the forwarder .
	
	For the second case, since there is a negative instantiation of , the receiver lock  was not created by the encoding of a replicated input. So again the output  induces a test on the sum lock . The rest of that case is similar to the case before.
	\qed
\end{proof}

Unfortunately, we can not declare any remains of \simulations as junk, because we can not ignore the forwarding of left requests in the chains of right requests which is left over by former considered right requests. However, after extracting the junk, by Lemma \ref{lem:junkInduceTest}, there is indeed nothing more left, than a simple forwarder, which can not influence the state of the process modulo . That suffice to prove operational completeness.

\subsection{Semantical Criteria}

Among the semantical criteria operational correspondence is the most elaborate to prove. Therefore we show the both its conditions, operational completeness and operational soundness, separately. In order to show operational completeness, we have to show how source terms steps are \simulated by the encodings.

\begin{lemma}[Operational Completeness] \label{lem:operationalCompletenessSepAsyn}
	The encoding  fulfils operational completeness.
\end{lemma}

\begin{proof}
	By Definition \ref{def:operationalCorrespondence} it suffice to show that:
	
	The lemma then holds by induction over the number of steps in . To prove the condition above, we perform an induction over the proof tree that leads to the step .
	\begin{description}
		\item[Base Case:] By the rules in Figure \ref{fig:concurrentReductionSemantics} each step on  is based either on Rule , , or .
			\begin{description}
				\item[Case of Rule] \textbf{:} In this case  is a single sum, of which one summand is guarded by , and  is the continuation of this  guarded summand, i.e., there are some finite index set , some guards , and some processes  such that  with  for some  and . The corresponding encodings are given by the following terms:
					
					We observe that  can \simulate the step  by reducing the test-statement in the encoding of the 's summand, i.e., by
					
					Note that, since the test-statement and the implementation of booleans are no native \piCal-terms but abbreviations for \piCal-constructs, this reduction indeed requires two steps. Moreover note, that we silently omit junk that results from the reduction of test-statements (compare to Lemma \ref{lem:junkTestStatement}) here and in the following proofs. Further, we observe that , since, due to the renaming policy , the name  is not free in . So the \simulation leaves over the term , which is by Lemma \ref{lem:junkRemainsOfSumsSepAsyn} junk. By Lemma \ref{lem:removeJunk}, we conclude that .
				\item[Case of Rule] \textbf{:} Here  is a parallel composition of two sums and  is the parallel composition of the continuations of an input guarded summand of the first and a matching output guarded summand of the second sum, i.e., there are two finite index sets , some guards , and some processes  such that  with  and  for some , some , and  and . The encodings of  and  are given by the following terms:
					
					To \simulate the source term step  first the receiver lock has to be reduced to enable a communication over . Then the test-statement and the sender lock are reduced to complete the \simulation of the source term step.
					
					
					By Corollary \ref{col:encodingSubstitutions}, . To show that  we stepwise reduce  by ignoring junk. Since , we can reorder the term according to the restrictions on  and the restriction on  can be omitted. The term
					
					is obviously junk, since it is closed and can not perform any step.	Moreover, by Lemma \ref{lem:junkRemainsOfSumsSepAsyn}, the terms  and  are junk. So, by Lemma \ref{lem:removeJunk}, we conclude .
				\item[Case of Rule] \textbf{:} Here  is a parallel composition of a replicated input and a sum and  is the parallel composition of the replicated input, the continuation of the replicated input, and the continuation of a matching output guarded summand, i.e., there is a finite index sets , some guards , and some processes  such that  with  for some  and , and . The encodings of  and  are given by the following terms:
					
					To \simulate the source term step , first the two subprocesses of  communicate over . Then the test-statement and the sender lock are reduced to complete the \simulation of the source term step.
					
					By Corollary \ref{col:encodingSubstitutions}, . To show that  we stepwise reduce  by ignoring junk. Since , we can reorder the term according to the restriction on  and the restriction on  can be omitted. By Lemma \ref{lem:junkRemainsOfSumsSepAsyn}, then  is junk. Note that, by Lemma \ref{lem:transBarbCongIncludesSC}, the relation  includes structural congruence. Thus, by Lemma \ref{lem:removeJunk}, we conclude .
			\end{description}
		\item[Induction Hypothesis:] 
		\item[Induction Step:] We have to consider the remaining three rules \textsc{Par}, \textsc{Res}, and \textsc{Cong} of Figure \ref{fig:concurrentReductionSemantics}.
			\begin{description}
				\item[Case of Rule] \textsc{Par}\textbf{:} Then  for some , , and . By the induction hypothesis there is some  such that  and . Since the encoding of the parallel operator is \clean, i.e.,  and , we can apply rule \textsc{Par} to conclude from  to . By Definition \ref{def:transBarbCong},  implies  for all contexts  such that . Since , the quantification over  includes all contexts  such that . Because of that, we have  for all contexts  such that . By Definition \ref{def:transBarbCong}, we conclude .
				\item[Case of Rule] \textsc{Res}\textbf{:} Then  for some  and some , , and . By the induction hypothesis there is some  such that  and . Since the encoding of restriction is \clean, i.e.,  and , we can apply rule \textsc{Res} to conclude from  to . By Definition \ref{def:transBarbCong},  implies  for all contexts  such that . Since , the quantification over  includes all contexts  such that . Because of that, we have  for all contexts  such that . By Definition \ref{def:transBarbCong}, we conclude .
				\item[Case of Rule] \textsc{Cong}\textbf{:} Then  for some , , and . By Lemma \ref{lem:preservesSCModuloTransBarbBisimSepAsyn}, the encoding  preserves structural congruence of source terms modulo . So  and  implies  and . By Definition \ref{def:transBarbCong}, for all contexts  such that  we have , i.e., especially . Thus, by Definition \ref{def:transBarbBisim}, for each sequence  there is a sequence  for some  such that . The same holds for all Contexts , i.e., since , for each sequence  there is a sequence  for some  such that . So, by Definition \ref{def:transBarbCong}, . By the induction hypothesis . Since, by Lemma \ref{lem:transBarbCongIsEquivalence},  is an equivalence, , , and  implies .
			\end{description}
	\end{description}
	\qed
\end{proof}

\begin{lemma}[Operational Completeness] \label{lem:operationalCompletenessMixAsyn}
	The encoding  fulfils operational completeness.
\end{lemma}

\begin{proof}
	By Definition \ref{def:operationalCorrespondence} it suffice to show that:
	
	The lemma then holds by induction over the number of steps in . To prove the condition above, we perform an induction over the proof tree that leads to the step .
	\begin{description}
		\item[Base Case:] By the rules in Figure \ref{fig:concurrentReductionSemantics} each step on  is based either on Rule , , or .
			\begin{description}
				\item[Case of Rule] \textbf{:} In this case  is a single sum, of which one summand is guarded by , and  is the continuation of this  guarded summand, i.e., there are some finite index set , some guards , and some processes  such that  with  for some  and . The corresponding encodings are given by the following terms:
					
					We observe that  can \simulate the step  by reducing the test-statement in the encoding of the 's summand, i.e., by
					
					We observe that , since, due to the renaming policy , the name  is not free in . So the term  is leftover, which is by Lemma \ref{lem:junkRemainsOfSumsMixAsyn} junk. By Lemma \ref{lem:removeJunk}, we conclude that .
				\item[Case of Rule] \textbf{:} Here  is a parallel composition of two sums and  is the parallel composition of the continuations of an input guarded summand of the first and a matching output guarded summand of the second sum, i.e., there are two finite index sets , some guards , and some processes  such that  with  and  for some , some , and , and . Unfortunately the encodings of these terms are rather long:
					
					To \simulate the source term step , the endings of the two sums in  have to interact with the encoding of the parallel operator between them. At first the input and output register themselves to the encoding of the parallel operator by pushing requests. These requests are then combined and a test on the respective sum locks\footnote{In order to avoid a deadlock caused by multiple simultaneous such tests on sum locks, the sum locks are ordered by ensuring that always the left one is checked first.} is induced by providing an output on the receiver lock. At least the test-statement is reduced to complete the \simulation of the source term step.
					
					
					By Corollary \ref{col:encodingSubstitutions}, . To show that , we stepwise reduce  by ignoring junk. By Lemma \ref{lem:junkRequestsOnFalseSumLocks}, we can ignore the requests , , and . Next, by Lemma \ref{lem:junkReceiverMixAsyn}, we can ignore the term
					
					And, by Lemma \ref{lem:junkInduceTest}, we can also ignore , so
					
					becomes . Note that this forwarder and the following forwarder  for an other instance of  may be necessary to \simulate further source term steps, but, since they perform only invisible steps, they do not influence the state of  modulo  in comparison to a fresh chain of right requests as in . At least, since , we can reorder the term according to the restrictions on  and the restriction on  can be omitted. By Lemma \ref{lem:junkRemainsOfSumsMixAsyn}, then  and  are junk. So, by Lemma \ref{lem:removeJunk}, we conclude .
				\item[Case of Rule] \textbf{:} Here  is a parallel composition of a replicated input and a sum and  is the parallel composition of the replicated input, the continuation of the replicated input, and the continuation of a matching output guarded summand, i.e., there is a finite index sets , some guards , and some processes  such that  with  for some  and , and . Unfortunately, the encodings of  and  are again long:
					
					To \simulate the source term step , the two subterms of  have to interact with the encoding of the parallel operator between them. At first the replicated input and the output register themselves to the encoding of the parallel operator by pushing requests. There the requests are combined and a test on the sum lock of the sender is induced by providing an output on the receiver lock. Next the test-statement is reduced. To complete the \simulation of the source term step, at least the continuation of the replicated input encoding is unguarded and placed within an adoption of the parallel operator encoding.
					{\allowdisplaybreaks
					}
					By Corollary \ref{col:encodingSubstitutions}, . Unfortunately, this time it does not suffer to ignore junk to prove that , because in  there are two encoded parallel operators whereas in  there is only one. Nevertheless, we start reducing  by omitting junk. Since the sum lock  is instantiated by false, by Lemma \ref{lem:junkRequestsOnFalseSumLocks}, the request  is junk. Moreover, by Lemma \ref{lem:junkInduceTest}, the term
					
					reduces to the forwarder . Since , we can reorder the term according to the restrictions on , , and  and the restriction on  can be omitted. By Lemma \ref{lem:junkRemainsOfSumsMixAsyn}, then  is junk. By Lemma \ref{lem:removeJunk}, we deduce , where  is:
					
					Analysing  we observe that in comparison to  the encoded subterms , , and the term representing  appear in the wrong order. However, since  and , by Lemma \ref{lem:preservesSCModuloTransBarbBisimMixAsyn}, preserves structural congruence of source terms, we have , i.e., the order of these subterms does not matter. As in the case before, on the right side of the parallel operator encoding there are the two forwarders  and  (for different instances of ). Again they are necessary to \simulate further source term steps on the continuation , but, since they perform only invisible steps, they do not influence the state of  modulo .
					
					Moreover there is the request , to enable an \simulation of a communication of  and . Note that there is also the request  at the right side of the parallel operator encoding, but the request , which belongs to , is missing. However, since by  the request  is forwarded to  within a \pure \admin step and since this configuration is equal to one application of \processLeftInputRequests \ on , which is again a \pure \admin step, these two requests in comparison to  do not influence the state of  modulo .
					
					What remains as difference of  and  is the fact, that in  the encoding of  appears within a branch of the replicated input encoding whereas in  it appears as right branch of a parallel operator encoding, i.e., it remains to show that , where
					
					First, note that the term
					
					exactly corresponds to the right branch of . If we compare \pushRequestsIn \ with \processLeftOutputRequests \ and \processLeftInputRequests, then we observe that the former includes exactly the same forwarders as the later but also some additional forwarders. The same holds for \pushRequestsOut \ and \pushRequests. Note that the additional forwarders ensures that each requests of each branch of the replicated input encoding is forwarded to each next right branch, and so these additional forwarders are necessary in case there is more than one branch. Also note that the given forwarders guarantee that each pair of requests, such that one is an input and the other one an output request and both requests do not origin from the same sum, can be combined. Moreover, note that the only request from the left side, i.e., of the encoding of the replicated input, is transmitted to the right side, i.e., the only branch of the replicated input, by the request  and \pushRequestsIn. So these forwarders do not distinguish  and  modulo .
					
					Since  and  do only differ by the forwarding of requests but nevertheless allow for the same combinations, we deduce that . Thus, by Lemma \ref{lem:transBarbCongIsEquivalence}, we conclude .
			\end{description}
		\item[Induction Hypothesis:]  implies 
		\item[Induction Step:] We have to consider the remaining three rules \textsc{Par}, \textsc{Res}, and \textsc{Cong} of Figure \ref{fig:concurrentReductionSemantics}.
			\begin{description}
				\item[Case of Rule] \textsc{Par}\textbf{:} Then  for some , , and . By the induction hypothesis there is some  such that  and . The corresponding encodings are given by the following terms:
					
					Since  and since  is not guarded in , we can use the rules \textsc{Par}, \textsc{Res}, and \textsc{Cong} in the asynchronous calculus to show that:
					
					By Definition \ref{def:transBarbCong},  implies  for all contexts  such that . Since , the quantification over  includes all contexts  such that:
					
					Because of that, we have  for all contexts  such that . By Definition \ref{def:transBarbCong}, we conclude .
				\item[Case of Rule] \textsc{Res}\textbf{:} Then  for some  and some , , and . By the induction hypothesis there is some  such that  and . Since the encoding of restriction is \clean, i.e.,  and , we can apply rule \textsc{Res} to conclude from  to . By Definition \ref{def:transBarbCong},  implies  for all contexts  such that . Since , the quantification over  includes all contexts  such that . Because of that, we have  for all contexts  such that . By Definition \ref{def:transBarbCong}, we conclude .
				\item[Case of Rule] \textsc{Cong}\textbf{:} Then  for some , , and . By Lemma \ref{lem:preservesSCModuloTransBarbBisimMixAsyn}, the encoding  preserves structural congruence of source terms modulo . So  and  implies  and . By Definition \ref{def:transBarbCong}, for all contexts  such that  we have , i.e., especially . Thus, by Definition \ref{def:transBarbBisim}, for each sequence  there is a sequence  for some  such that . The same holds for all Contexts , i.e., since , for each sequence  there is a sequence  for some  such that . So, by Definition \ref{def:transBarbCong}, . By the induction hypothesis . Since, by Lemma \ref{lem:transBarbCongIsEquivalence},  is an equivalence, , , and  implies .
			\end{description}
	\end{description}
	\qed
\end{proof}

If we analyse the proofs of the Lemmata \ref{lem:operationalCompletenessSepAsyn} and \ref{lem:operationalCompletenessMixAsyn}, we observe that for each \simulation there is exactly one \nonAdmin step, i.e., there is exactly one \nonAdmin step for each of the rules , , and  and the \simulation of the remaining rules do not introduce additional \nonAdmin steps. This underpins our intuition of \nonAdmin steps (compare to Section \ref{sec:stepsSimulation}) that any \simulation of a source term step is connected to exactly one \nonAdmin step. Moreover, any \nonAdmin step marks exactly one \simulation of a source term step by steering the \simulation to the ``point of no return'', i.e., to a point, from where no other sequence of steps can disable the completion of that \simulation and from where any possibility to \simulate a conflicting source term step is ultimately withdrawn.

\begin{lemma} \label{lem:simulationVSNonAdminStep}
	Any \simulation of a source term step includes exactly one \nonAdmin step and any \nonAdmin step steers the \simulation of a source term step to a point, from where it eventually has to be completed.
\end{lemma}

\begin{proof}
	If we analyse the reduction rules in Figure \ref{fig:concurrentReductionSemantics}, we observe that the result of a source term step is the unguarding of one or two former guarded subterms. If we rely on this fact to mark the essence of a step, then an \simulation is characterised by the unguarding of the respective encoded continuations. Analysing the encoding functions in Figure \ref{fig:encodingSepAsyn} and Figure \ref{fig:encodingMixAsyn} we observe that such encoded continuations are guarded either by a sender lock or a test-statement. Note that, as proved in \cite{nestmann00} for  and by the Lemma \ref{lem:pureAdminStepsNoDeadlock} and Lemma \ref{lem:impureAdminStepsNoDeadlock}, neither \pure nor \impure \admin steps can introduce deadlock.
	
	The reduction of a summand guarded by  is the only case of a reduction step that does not require the interaction of a receiver and a sender (compare to rule ). Both encodings introduce a sum lock to encode a sum and translate summands guarded by  into a single test-statement, that tests the corresponding sum lock and in case of success unguards the encoded continuation and provides a negative instantiation of the sum lock. Note that to \simulate such a source term for both encodings only two steps are necessary to reduce the test-statement. The first consumes the instantiation of the sum lock. If this instantiation is positive we call that step a \nonAdmin step. Note that before this step, an \simulation of a conflicting source term step may change the instantiation of the sum lock into a negative instantiation and thus withdraw the possibility to \simulate the step. On the other side as soon as the positive instantiation of the sum lock is consumed, there is, by Lemma \ref{lem:nonConflictingStepsSepAsyn} and Lemma \ref{lem:nonConflictingStepsMixAsyn}, no possibility to prevent that the second step necessary to complete the \simulation eventually happens. So, whenever such \nonAdmin step is performed, eventually the encoded continuation is unguarded. Moreover, the only way to instantiate the consumed sum lock is to complete the \simulation, which leads to a negative instantiation of that sum lock. By Lemma \ref{lem:changeInstantiationSumLock}, there is no chance to unguard a positive instantiation of that sum lock afterwards. Note that any source term step, that is in conflict to the considered step on the  guarded summand, have to reduce another summand of the same sum. Remember that, by Lemma \ref{lem:junkRemainsOfSumsSepAsyn} and \ref{lem:junkRemainsOfSumsMixAsyn}, encoded summands connected to a negative instantiation of a sum lock are junk. So the consumption of the positive instantiation of the sum lock immediately rules out any \simulation of a conflicting source term step. Moreover, since there is no possibility to reach a positive instantiation of that sum lock again, there is no possibility to \simulate this source term step twice and any translated observable connected to this sum lock, i.e., to this sum, is immediately withdrawn by the consumption of the positive instantiation. Because of that, for any \simulation of a source term step based on rule  there is exactly one \nonAdmin step and for any such \nonAdmin step exactly one source term step is \simulated.
	
	In case of rule  the source term step is on an interaction of an input guarded and an output guarded summand. The encoding of the continuation of the receiver is guarded by the second of a nested test-statement, while the encoded continuation of the sender is guarded by a sender lock, which in turn is guarded by the nested test-statement. In Example \ref{exa:intermediateStates} we explain that reducing the first test-statement does not ensure, that the \simulation can be completed. However, as soon as the positive instantiation of the second sum lock is consumed we can repeat the argumentation of the case above to show that the point of no return of that \simulation is reached. We observe that the consumption of the second positive sum lock instantiation is indeed the only \nonAdmin step necessary to \simulate this source term step. It immediately withdraw any possibility to complete the \simulation of a conflicting source term step, because it ensures that both consumed positive instantiations of sum lock are never restored. With that it also immediately withdraws all translated observables on the summands of these to sums. Moreover, by Lemma \ref{lem:nonConflictingStepsSepAsyn} and Lemma \ref{lem:nonConflictingStepsMixAsyn}, the encoded continuations of the respective sender and receiver have eventually to become unguarded. Thus again for any \simulation of a source term step based on rule  there is exactly one \nonAdmin step and for any such \nonAdmin step exactly one source term step is \simulated.
	
	In case of rule  the source term step is on an interaction of a replicated input and an output guarded summand. The encoding of the continuation of the receiver is guarded by a single test-statement, while the encoded continuation of the sender is guarded by a sender lock, which in turn is guarded by the single test-statement. As soon as the positive instantiation of the second sum lock is consumed we can repeat the argumentation of the first case to show that the point of no return of that \simulation is reached. We observe that the consumption of the positive sum lock instantiation is indeed the only \nonAdmin step necessary to \simulate this source term step. It immediately withdraw any possibility to complete the \simulation of a conflicting source term step, because it ensures that the consumed positive instantiation of the sum lock is never restored. With that it also immediately withdraws all translated observables on the summands of that sum. Moreover, by Lemma \ref{lem:nonConflictingStepsSepAsyn} and Lemma \ref{lem:nonConflictingStepsMixAsyn}, the encoded continuations of the respective sender and receiver have eventually to become unguarded. Thus again for any \simulation of a source term step based on rule  there is exactly one \nonAdmin step and for any such \nonAdmin step exactly one source term step is \simulated.
	\qed
\end{proof}

Based on this Lemma we prove operational soundness, by showing that each target term is part of an \simulation of some source term step.

\begin{lemma}[Operational Soundness] \label{lem:operationalSoundness}
	The encodings  and  fulfil operational soundness.
\end{lemma}

\begin{proof}
	We start with . By Definition \ref{def:operationalCorrespondence}, we have to show that:
	
	Note that  is a target term, i.e., . By Lemma \ref{lem:pureAdminStepsTransBarbBisimSepAsyn}, \pure \admin steps do not influence the state of a target term modulo , i.e.,  implies . Because of that, it suffice to consider \impure \admin and \nonAdmin steps, i.e., steps on translated source term names or sum locks. Moreover note, that steps on negative instantiations of sum locks reduce the corresponding test-statements to simple forwarders, that immediately restore the information consumed to resolve this test-statement. Thus \impure \admin steps on negative instantiations of sum locks do not change the state of a target term modulo .
	
	By Lemma \ref{lem:simulationVSNonAdminStep}, \nonAdmin steps indicate the border between the encoding of one source term and the encoding of its reduction. While, \pure \admin steps do not influence the state of a source term modulo , the \nonAdmin steps do. \NonAdmin steps finally rule out each way to reach one of the consumed translated observables and all translated observables connected to the same sums. With that, they also rule out each \simulation of conflicting source term steps and accordingly the reachability of the corresponding translated observables and occurrences of . On the other hand, since all post-processing steps of all \simulations are \pure \admin steps, they ensure that eventually the respective encoded continuations are unguarded. Because of that immediately after the \nonAdmin step all translated observables and all reachable occurrences of  of the encoded continuations are reachable. Because of that, source term steps and their \simulations handle source term observables and their translated observables in exactly the same way, i.e., they remove old and unguard new in the same way. So, if we consider only \pure \admin steps and a single \nonAdmin step, i.e., the sequence  for a source term , then each target term in the sequence , including , is congruent to  modulo  and each target term in the sequence , including , is congruent to  modulo . By Lemma \ref{lem:simulationVSNonAdminStep}, the step  marks the \simulation of a source term step. Thus,  must be able to perform a step, i.e.,  such that , and the sequence  \simulates this step by unguarding the encodings of the subterms of  and removing the translated observables that refer to the observables removed from  during the step to . Moreover, note that, since all post-processing steps are \pure \admin steps, it is always possible to complete the \simulation after the \nonAdmin step. Thus  such that  is the result of the completion of the \simulation of , i.e.,  and .
	
	Unfortunately, \impure \admin steps complicate the situation. As described in Example \ref{exa:intermediateStates} they can already rule out some \simulations on conflicting source term steps by disabling the reachability of some translated observables (e.g. by consuming their respective positive instantiations of sum locks). If they rule out all \simulations on conflicting source term steps, then they behave like \nonAdmin steps and we are back to the situation descripted above. But, if they only rule out some \simulations on conflicting source term steps, we result in what we denote as intermediate state (compare to Definition \ref{def:intermediateState}). Intermediate states are in general not congruent to any of the surrounding encoded source terms modulo ; neither to the encoded source term there we start our \simulation attempt nor to any encoding of the possible reductions. Note that the Definition \ref{def:operationalCorrespondence} of operational soundness explicitly allows for the presence of such intermediate states as long as we can ensure, that from each intermediate state a state, that is congruent modulo  to an encoded source term, is reachable. So let us have a closer look on these \impure \admin steps. By Definition \ref{def:pureImpureAdminStep}, \impure \admin steps are steps on translated source term names or on sum locks. They prepare an \simulation by unguarding and/or partially reducing a test-statement. Since for all sum locks eventually an instantiation is restored, each of these test-stements is eventually resolved (compare to the proof in \cite{nestmann00} that the encoding  does not introduce deadlock).
	
	So let us consider a sequence . If the \nonAdmin step  rules out any \simulation attempt except for the one it steers to the point of no return, then we can use the same argumentation as in the case without \impure \admin steps to show that  and  such that , , i.e., , and .
	
	However, by performing several \impure \admin steps in , several \simulations can be started by unguarding and/or partially reducing test-statements before a single of them is resolved. In this case, the resolution of one of these test-statements may not directly lead to a term congruent modulo  to an encoded source term. This can happen, if the source term can perform several sets of conflicting steps, i.e., there are at least two non conflicting but parallel steps and for each of these steps there can be some conflicting alternatives. To reach again a term, that is congruent modulo  to an encoded source term,  has to finally decide on which of the started \simulations are completed and rule out all conflicting \simulations. Note that, therefore in general it is not necessary to resolve all unguarded or partially reduced test-statements. However, since the  does not introduce deadlock, all unguarded and partially reduced test-statements in  can be resolved, which definitely completes some of the started \simulations by \nonAdmin steps and rules out the completion of any remaining started \simulation\footnote{Note that the completion of \simulations, that are up to now only started by performing some \pure \admin steps, possibly might not be ruled out by resolving these test-statements. However, since \pure \admin steps do not influence the state of a target term modulo , such \simulations can be ignored.}. Thus  such that  is the target term that is reached after all unguarded or started test-statements of  are resolved and all necessary post-processing steps to complete the respective \simulations are performed, i.e., . Then for each \nonAdmin step in the sequence  there is one source term step of  or a reduction of . Note that in  several \simulations are started, but, since there are no \nonAdmin steps, none of these \simulations is completed. So  must be able to perform all source term step, that correspond to an \simulation completed in , in parallel. Because of that, we can split up  into  parallel subterms , \ldots, , where  is the number of \simulations completed in . Then we can prove the lemma for the subterms using the cases above, i.e., we have  implies  and  such that , , and . Since  can perform all these source term steps in parallel, it can also perform them arbitrarily ordered in a sequence, i.e.,  such that  and  is structural congruent to the parallel composition of the reductions , \ldots, . Then we use an argumentation similar to the case of the \textsc{Par} rule in the proof of Lemma \ref{lem:operationalCompletenessSepAsyn} to conclude that  such that  and  for all  with  implies .
	
	Finally, let us consider an arbitrary sequence , which may even include \nonAdmin steps. Note that, in opposite two the cases before, this sequence covers the case there already some \simulations are completed while for other \simulations\!\!|possibly of parallel source term steps|up to now only test-statements are unguarded and/or partially reduced. However, revisiting the argumentation of the case before,  such that  and  is the result from resolving all unguarded and partially reduced test-statements in  and performing all post-precessing steps necessary to complete all \simulations in , that are already driven beyond their point of no return by the respective \nonAdmin step. By concentrating again only on the \impure \admin and \nonAdmin steps|and ignoring \impure \admin steps that do not lead to a completed \simulation in |we can split up this sequence into subsequences of subsequent bundles of completed \simulations, such that each such bundle can not be further subdivided into such bundles. Then, if necessary, we split up these bundles into the parallel branches of the corresponding source terms as in the case before. Repeating this, we result in a tree of completed \simulation of subsequently and parallel source term steps, where for each parallel source term step there is a branch in the respective subtree. Now each line between a parent and its direct child node within this tree represents one of the above considered cases. So we can conclude the proof by an induction over this tree. Thus,  such that  and .
	
	\vspace*{1em}
	\noindent The argumentation for  is similar to the argumentation for  above. Of course, the Lemmata \ref{lem:pureAdminStepsTransBarbBisimSepAsyn} and \ref{lem:operationalCompletenessSepAsyn} have to be replaced in the argumentation by \ref{lem:pureAdminStepsTransBarbBisimMixAsyn} and \ref{lem:operationalCompletenessMixAsyn}, respectively. Moreover note, that the combination of the Lemmata \ref{lem:pureAdminStepsNoDeadlock}, \ref{lem:impureAdminStepsNoDeadlock}, and \ref{lem:simulationVSNonAdminStep} proves that  does not introduce deadlock. Finally, in  there are no steps on translated source term names, so there are less \impure \admin steps.
	\qed
\end{proof}



\begin{lemma}[Divergence Reflection] \label{lem:divergenceReflectionSepAsyn}
	The encoding  reflects divergence.
\end{lemma}

\begin{proof}
	By Lemma \ref{lem:simulationVSNonAdminStep}, \simulations and \nonAdmin steps corresponds. Because of that, an infinite sequence  with infinite many \nonAdmin steps implies that infinitely many source term steps are \simulated, i.e., that . Because of that, it suffice to show that each sequence  on target terms  between two \nonAdmin steps is finite. The argumentation for the sequence of \admin steps  before the first \nonAdmin step and for the sequence of \admin steps after the last \nonAdmin step|in case of a terminating process|is then similar.
	
	A look at the definition of the corresponding renaming policy in Figure \ref{fig:encodingSepAsyn} suggests the following case split\footnote{Note that in most cases the considered names are restricted, so a simple alpha conversion may change them. Because of that, as already in the proof of Lemma \ref{lem:nonConflictingStepsSepAsyn}, the use of concrete names in the following case split should not imply that we consider steps on these specific names. Instead the names refer to the meaning which is related to them by the encoding function.} on the links of the steps in .
	\begin{description}
		\item[Case of :] The name  is used by the encoding function to denote sender locks. By Definition \ref{def:senderLock}, sender locks are channels of multiplicity one, that are used as input but not as replicated input channels and within the continuation of such an input there is no unguarded and unrestricted instantiation of a sum lock. Their purpose is to guard the encoded continuations within the encoding of output guarded source terms. Since we consider only terms with finite representation, there are only finitely many unguarded instantiations on sender locks in . Analysing the encoding function in Figure \ref{fig:encodingMixAsyn} we observe, that new instantiations on sender locks appear only in the then-case of the (nested) test-statement in the encoding of input guarded source terms and in the encoding of a replicated input. Because of that, new instantiations on sender locks can be unguarded only by a \nonAdmin step followed by a \pure \admin step to reduce the test-statement to the then-case. Some of these \nonAdmin steps may have happened before , but of course only finitely many. So within the sequence  only finitely many new instantiations on sender locks can be unguarded. We conclude that within the sequence  there are only finitely many steps on sender locks.
			
			Note that the encoded continuation of input guarded source terms or a replicated input appears in parallel to such an instantiation of a sender lock within the then-case of a (nested) test-statement. Because of that, within the sequence  only finitely many encoded source terms, i.e., continuations, can be unguarded.
		\item[Case of Outputs on Translated Source Term Names:] Since we consider only terms with finite representations, there are only finitely many unguarded outputs on translated source term names in . Analysing the encoding function in Figure \ref{fig:encodingSepAsyn} we observer that there are only two ways to unguard a new output on a translated source term name. First, they can be unguarded by unguarding an encoded source term as continuation of an \simulation. By the case before, within the sequence  only finitely many encoded source terms can be unguarded, so there can only finitely many new outputs on translated source term names can be unguarded that way. Second, in the else-case of the first test-statement in the encoding of an input guarded source term there is such an unguarded output. To unguard this test-statement an instantiation of a receiver lock is consumed, but no new is unguarded by the else-case of the first test-statement. Analysing the encoding function we observer that all receiver locks are generated under restriction and initially there is exactly one instantiation of each receiver lock. Moreover, receiver locks are never transmitted over these restriction and to unguard a new instantiation (in the else-case of the second test-statement) a former instantiation of that receiver lock has to be consumed. Because of that, in each target term there is at most one instantiation of each receiver lock. Thus, reducing the nested test-statement to the else-case of the first test-statements, prevents any further unguarding of this test-statement. Since in  there are only finitely many different guarded or unguarded replicated inputs on receiver locks guarding such a nested test-statement, it is not possible to unguard initially many new outputs on translated source term names that way. We conclude that within the sequence  only finitely many outputs on translated source term names can be unguarded.
		\item[Case of :] The name  is used by  to introduce receiver locks. Since we consider only terms with finite representations, there are only finitely many unguarded instantiations on receiver locks in . Analysing the encoding in Figure \ref{fig:encodingSepAsyn} we observer that there are only two ways to unguard new instantiations on receiver locks. First, they can be unguarded by unguarding an encoded source term as continuation of an \simulation. By the first case, within the sequence  only finitely many encoded source terms can be unguarded, so there can only finitely many new instantiations on receiver locks be unguarded that way. Second, in the else-case of the second test-statement in the encoding of an input guarded source term there is such an unguarded instantiation on a receiver lock. However, to unguard such a nested test-statement an output on a translated source term name has to be consumed. Since by the case before there are only finitely many such outputs, there is no possibility to unguard infinity many instantiations on receiver lock this way. We conclude that within the sequence  there are only finitely many steps on receiver locks.
			
			Note that in  there are only finitely many unguarded test-statements and new test-statements can only be unguarded by unguarding an encoded source term or by a step on a receiver lock. Thus, since by the first two cases only finitely many encoded source terms can be unguarded and by the current case there are only finitely many steps on receiver locks, within the sequence  only finitely many new test-statements can be unguarded.
		\item[Case of Inputs on Translated Source Term Names:] Since we consider only terms with finite representations, there are only finitely many unguarded inputs on translated source term names in . New inputs on source terms names can only be unguarded by a step on a receiver lock. Since by the case before the number of steps on receiver locks is finite, within the sequence  only finitely many inputs on translated source term names can be unguarded. Moreover, since by the second case the number of outputs on translated source term names is finite as well, there are only finitely many steps on translated source term names within the sequence .
		\item[Case of :] Both names are used by the encoding function to refer to sum locks. The only steps on sum locks are to reduce a test-statement. Note that in case of a nested test-statement two sum locks are reduced, i.e., there are two steps on sum locks. However, since by the third case there are only finitely many test-statements, within the sequence  there are only finitely many steps on sum locks.
		\item[Case of :]  and  are used by the encoding function to implement booleans. As in the case of sum locks, all steps on these names are used to reduce a test-statement. So again, since there are only finitely many test-statements, within the sequence  there are only finitely many steps on  and .
	\end{description}
	\qed
\end{proof}

\begin{lemma}[Divergence Reflection] \label{lem:divergenceReflectionMixAsyn}
	The encoding  reflects divergence.
\end{lemma}

\begin{proof}
	By Lemma \ref{lem:simulationVSNonAdminStep}, \simulations and \nonAdmin steps corresponds. Because of that, an infinite sequence of target term steps  with infinite many \nonAdmin steps implies that infinitely many source term steps are \simulated, i.e., that . Because of that, it suffice to show that each sequence  on target terms  between two \nonAdmin steps is finite. The argumentation for the sequence of \admin steps  before the first \nonAdmin step and for the sequence of \admin steps after the last \nonAdmin step|in case of a terminating process|is then similar.
	
	Since source term names are translated into values, never used as links, it suffice to consider steps on names introduced by the encoding function. A look at the definition of the corresponding renaming policy in Figure \ref{fig:encodingMixAsyn} suggests the following case split\footnote{Note that in most cases the considered names are restricted, so a simple alpha conversion may change them. Because of that, as already in the proof of Lemma \ref{lem:nonConflictingStepsMixAsyn}, the use of concrete names in the following case split should not imply that we consider steps on these specific names. Instead the names refer to the meaning which is related to them by the encoding function.} on the links of the steps in .
	\begin{description}
		\item[Case of :] The name  is used by the encoding function to denote sender locks. By Definition \ref{def:senderLock}, sender locks are carried as third value of output requests. Their purpose is to guard the encoded continuations within the encoding of output guarded source terms. Since we consider only terms with finite representation, there are only finitely many unguarded instantiations on sender locks in . Analysing the encoding function in Figure \ref{fig:encodingMixAsyn} we observe, that new instantiations on sender locks appear only in the then-case of the (nested) test-statement in the encoding of input guarded source terms and in the encoding of a replicated input. Because of that, new instantiations on sender locks can be unguarded only by a \nonAdmin step followed by a \pure \admin step to reduce the test-statement to the then-case. Some of these \nonAdmin steps may have happened before , but of course only finitely many. So within the sequence  only finitely many new instantiations on sender locks can be unguarded. We conclude that within the sequence  there are only finitely many steps on sender locks.
			
			Note that the encoded continuation of input guarded source terms appears in parallel to such an instantiation of a sender lock within the then-case of a nested test-statement. Because of that, within the sequence  only finitely many encoded continuations of encodings of input or output guarded source terms can be unguarded.
		\item[Case of :] These two names are used to link the encoded continuations of several reductions of the same replicated input within a chain. Note that the first name denotes a chain lock carrying a translated source term name (compare to Definition \ref{def:chainLock}). Again, since we consider only terms with finite representations, there are only finitely many instances, i.e., outputs, on these names. For each step on the chain lock a new output on an instance of  is unguarded. So the number of steps on instances of   is bounded by the number of steps on chain lock carrying a translated source term name. New instantiations of such chain locks are unguarded as instantiations of sender locks only in the then-case of the test-statement in the encoding of a replicated input. Because of that, new instantiations on such chain locks can be unguarded only by a \nonAdmin step followed by a \pure \admin step to reduce the test-statement to the then-case. Some of these \nonAdmin steps may have happened before , but of course only finitely many. So within the sequence  only finitely many new instantiations on such chain locks can be unguarded. We conclude that within the sequence  there are only finitely many steps on such chain locks and instances of .
			
			Because of that, within the sequence  only finitely many encoded continuations of encodings of replicated inputs can be unguarded.
		\item[Case of :] All these names are request channels, i.e., there are introduced by  to transport requests. Since we consider only terms with finite representations, there are only finitely many unguarded requests in . Moreover, by the two cases above, only finitely new requests can be unguarded within the sequence  by unguarding source term encodings. Thus there are only finitely many different unguarded requests within the sequence . We have already argued that the encoding  puts much effort in restricting the way a request may take. We underpin this fact here, by proving that these ways do not include cycles. Note that inputs on requests channels do only appear within the encoding of the parallel operator or a replicated input (compare to Figure \ref{fig:encodingMixAsyn}).
			
			Let us consider the encoding of a parallel operator first. The terms \processLeftOutputRequests \ and \processLeftInputRequests \ transmit all requests of the left side of a parallel operator encoding to the right side and upwards over the restriction on the request channels. In \processRightOutputRequests \ and \processRightInputRequests \ the requests of the right side of the parallel operator encoding are linked in two chains, one for input and one for output requests. Therefore the requests of the right side are consumed, but a single copy of them is pushed upwards over the restriction on the request channels again. Then all left requests can be received by the respective first member of the chain of requests of opposite kind to the left request. Within these first members all left requests are consumed to combine them with the respective request behind this member and a copy of this left requests is further pushed along the chain. Now each member of that chain subsequently receives the left requests from its predecessor and sends a copy to its successor. Since the chains have no cycles and can not be infinitely long, each left request is only finitely often transmitted within each of these chains. In \pushRequests for each left and right requests, that was pushed over the restriction on request channels at the left and right side of a parallel operator, a single copy either under the restriction of a surrounding parallel operator encoding or on free source term names is generated. Note that the requests on free source term names can never be consumed. Moreover, for each parallel operator encoding there is a parallel operator in the corresponding source term. Thus the parallel operator encodings cause the structure of a finite binary tree, i.e., there are only finitely many instances of the terms \processLeftOutputRequests, \processLeftInputRequests, \processRightOutputRequests, \processRightInputRequests, and \pushRequests. Note that because of the two first cases only finitely many new encodings of parallel operators can be unguarded. Because of that and since a tree is free of cycles, within the sequence  there are only finitely many steps on requests, that are induced by a parallel operator encoding.
			
			In the last case we prove, that only within  only finitely many encoded continuations of encodings of replicated inputs can be unguarded. Because of that, there are only finitely many instances of \encodedContinuation. Within each of these instances all requests originate from the respective replicated input or a more left instance of \encodedContinuation of the same replicated input encoding are copied twice by \pushRequestsIn; one copy is generated under a restriction of this instance of \encodedContinuation \ to be combined with the requests within this branch and one copy is prepared to be transmitted to the respective next right branch of that encoded replicated input. All these first copies are proceed by \processRightOutputRequests \ and \processRightInputRequests \ as a request of the left side of a parallel operator encoding, while each requests of the respective encoded continuation is proceed by these terms as a right request. For each such right request in \pushRequestsOut a single copy is generated and the restriction of the surrounding parallel operator encoding. Moreover for each such left and each such right request a single copy is generated under the binding of the \encodedContinuation, that is the next one in the chain. Since again there are no cycles, there are only finitely many steps on requests, that are induced by a \encodedContinuation. We conclude, that within the sequence  there are only finitely many steps on requests.
		\item[Case of :] These names implement chain locks carrying a request channel. They are used to allow for a new request at the right side of a parallel operator encoding to be linked in the corresponding chain. By the third case there are only finitely many such right requests and chains, so within the sequence  there are only finitely many steps on such chain locks.
		\item[Case of :] The name  is used by  to introduce receiver locks. Since we consider only terms with finite representations, there are only finitely many unguarded instantiations on receiver locks in . Anything the encoding in Figure \ref{fig:encodingMixAsyn} we observer that new instantiations on receiver locks are only unguarded due to a a matching pair of requests. By the third case, there are only finitely many different requests and steps on request channels within the sequence . Moreover we observe that no request is ever combined with itself and no pair is combined twice. Because of that, within the sequence  only finitely many new instantiations on receiver locks can be unguarded, i.e., there are only finitely many steps on receiver locks.
			
			Note that in  there are only finitely many unguarded test-statements and new test-statements can only be unguarded by unguarding an encoded source term or by a step on a receiver lock. Thus, since by the first two cases only finitely many encoded source terms can be unguarded and by the current case there are only finitely many steps on receiver locks, within the sequence  only finitely many new test-statements can be unguarded.
		\item[Case of :] All these names are used by the encoding function to refer to sum locks. The only steps on sum locks are to reduce a test-statement. Note that in case of a nested test-statement two sum locks are reduced, i.e., there are two steps on sum locks. However, since by the case before there are only finitely many test-statements, within the sequence  there are only finitely many steps on sum locks.
		\item[Case of :]  and  are used by the encoding function to implement booleans. As in the case of sum locks, all steps on these names are used to reduce a test-statement. So again, since there are only finitely many test-statements, within the sequence  there are only finitely many steps on  and .
		\item[Case of :] These names are used by the encoding function as values only, but never as links. So there are no (\admin) steps on these names.
	\end{description}
	\qed
\end{proof}

\begin{lemma}[Success Sensitiveness] \label{lem:successSensitiveness}
	The encodings  and  are success sensitive.
\end{lemma}

\begin{proof}
	We start with . By Definition \ref{def:succesSensitiveness}, we have to show that . Let  be an arbitrary source term. We prove both directions separately.
	\begin{description}
		\item[Case of]  \textbf{implies} \textbf{:} By Definition \ref{def:success},  implies that there are some  such that  and . By operational completeness (Lemma \ref{lem:operationalCompletenessSepAsyn}), the sequence  can be \simulated by , i.e., there exists some  such that  and . By Figure \ref{fig:encodingSepAsyn}, . Thus . Since by Lemma \ref{lem:preservesSCModuloTransBarbBisimSepAsyn} the encoding  preserves structural congruence of source terms modulo ,  implies . By Definition \ref{def:transBarbCong}, then for all contexts  such that  we have . Then, by the first condition of Definition \ref{def:transBarbBisim},  iff  for all such contexts . Thus  implies . By the same argumentation we conclude that  implies . Since , we conclude .
		\item[Case of]  \textbf{implies} \textbf{:} By Definition \ref{def:success},  implies that either there is an unguarded occurrence of  in  or there are some  such that  and . In the first case, since the only way to obtain an occurrence of success in a target term is by , we conclude that there is an unguarded occurrence of success in . In the other case, by operational soundness (Lemma \ref{lem:operationalSoundness}), then there are some  and  such that , , and . Since  and  can not be reduced, we have . By Definition \ref{def:transBarbCong},  implies  for all contexts  such that . By the first condition of Definition \ref{def:transBarbBisim},  iff  for all such contexts . Thus  implies . Moreover, since  includes an unguarded occurrence of success and since all occurrences of  in target terms are due to the encoding , the sequence  \simulates a sequence  of target terms unguarding an occurrence of . So  has an unguarded occurrence of , i.e., . We conclude .
	\end{description}
	The argumentation in case of  is similar to the argumentation of  above. For the first case note that, by Figure \ref{fig:encodingMixAsyn}, the parallel operator is not translated \cleanly but since  and the encodings of the parameters of a parallel operator appear unguarded within the encoding of the parallel operator, the unguarded occurrence of  in  implies that there is an unguarded occurrence of  in .
	\qed
\end{proof}

\begin{theorem}
	The encodings  and  are good.
\end{theorem}

\begin{proof}
	By Figure \ref{fig:encodingSepAsyn} and Figure \ref{fig:encodingMixAsyn}, both encodings are compositional. Name invariance is proved in the Lemmata \ref{lem:nameInvarianceSepAsyn} and \ref{lem:nameInvarianceMixAsyn}. Operational correspondence follows by the Lemmata \ref{lem:operationalCompletenessSepAsyn}, \ref{lem:operationalCompletenessMixAsyn}, and \ref{lem:operationalSoundness}. Lemma \ref{lem:divergenceReflectionSepAsyn} proves that  do not introduce divergence, while Lemma \ref{lem:divergenceReflectionMixAsyn} proves the same condition for . Finally, by Lemma \ref{lem:successSensitiveness}, both encodings are success sensitive. Thus both encodings are good with respect to the five criteria introduced by Gorla.
	\qed
\end{proof}

\section{Degree of Distribution} \label{sec:proofsDistributability}

In the following we prove that  preserves the degree of distribution of its source terms, while  does not. For a definition what it means to preserve the degree of distribution have a look at Definition 5 in \cite{petersNestmann12}. Moreover, we present an encoding function from \piMix (without replicated input) into \piAsynTwo, the asynchronous \piCal-calculus augmented with a two-level polyadic synchronisation.

Note that for simplicity we omit in Figure \ref{fig:SC} a structural congruence rule for replicated input. However, of course a replicated input represents a not determined number of instances of the corresponding input guarded term in parallel. In order to allow for the distribution of replicated inputs, we augment structural congruence by an additional rule, i.e.,  is structural congruence  augmented with the additional rule  to split up replicated inputs.

\begin{lemma}
	The encoding  preserves the degree of distribution.
\end{lemma}

\begin{proof}
	Let  such that  and  for all  with . Then, by Definition 5 in \cite{petersNestmann12}, we have to show that:
	
	Revisiting the argumentation in the proof of Lemma \ref{lem:preservesSCModuloTransBarbBisimSepAsyn}, the encoding  preserves structural congruence of source terms except for the rule , because it translates restriction, the parallel operator, and the match operator \cleanly. Moreover, because of the \clean translation of the parallel operator, even the additional rule  is preserved. Thus  implies , i.e., we can choose  for all  with  and . By operational completeness (compare to Lemma \ref{lem:operationalCompletenessSepAsyn}), then  implies  for all  with , i.e., .
	\qed
\end{proof}

\begin{lemma}
	Any good encoding, that translates the parallel operator \cleanly\ and preserves enough of the structural congruence on source terms to ensure that  implies , preserves the degree of distribution.
\end{lemma}

\begin{proof}
	Let  be terms of the source language such that  and  for all  with . Then, by Definition 5 in \cite{petersNestmann12}, we have to show that:
	
	Since the encoding translates the parallel operator \cleanly\ and preserves enough of the structural congruence on source terms to ensure that  implies , we have , i.e., we can choose  for all  with  and . By operational completeness (compare to Definition \ref{def:operationalCorrespondence}), then  implies  for all  with , i.e., .
	\qed
\end{proof}

\begin{lemma}
\label{lem:EncodingMixAsynNotPreservesDegreeOfDistribution}
	The encoding  does \emph{not} preserve the degree of distribution.
\end{lemma}

\begin{proof}
	Consider the counter example .  can perform two different reductions, which are independent of each other. So  with  and  such that  and . Of course, since  is good,  can \simulate both steps in either order. But it can not \simulate both truly in parallel.
	
	To prove this fact, let us assume the contrary, i.e., let us assume the encoding  preserves the degree of distribution of . Then, by Definition 5 in \cite{petersNestmann12}, we have:
	
	The encoding of  is given by:
	
	We observe that for both source term steps their \simulations require that the corresponding requests are combined at the outermost parallel operator encoding, i.e., the one given above. Moreover, in both \simulations the output requests arrive at the left and the input requests arrive at the right side of this parallel operator encoding. Thus, for both \simulations the requests are proceed by \processRightInputRequests.
	
	Note that, since  and  appear unguarded in , it is not difficult to distribute  over  and , because the respective context introduced by the corresponding parallel operator encoding is not used within the considered \simulations, i.e., they can be proved to be junk. The same holds for . Moreover, since none of the terms \processLeftInputRequests, \processRightOutputRequests, and \pushRequests \ of the outermost parallel operator encoding is of any importance for the considered \simulations, it does not matter whether we put them within  or . Note that for each of the considered \simulations it is necessary to transmit one left output request to the right side of the outermost parallel operator encoding by the forwarder in \processLeftOutputRequests. However, since this forwarder is guarded by a replicated input we can use the rule  to distribute this forwarder, e.g. by placing  within  and the rest of the forwarder within . The only remaining term to distribute is \processRightInputRequests.
	
	Since  and , both  and  need the ability to proceed a request from . Since the respective right requests are restricted the only possibility to process them is \processRightInputRequests. We observe that the main part of \processRightInputRequests \ is guarded by a replicated input and can thus be distributed as \processLeftOutputRequests \ before. But there is only one unguarded instantiation of the corresponding chain lock  and without it the remaining term guarded by the replicated input on this chain lock is useless. Because of that \processRightInputRequests \ can not be distributed, i.e., it is not possible to distribute the encoding of  such that , , and .
	
	Because of that  can not \simulate both source term steps without sequentialising the linking of the respective right requests within the required chain. So  can not completely \simulate the independent source terms steps in parallel.
	\qed
\end{proof}

\begin{lemma}
	Any good encoding  preserves the criterion: For every  such that  and  for all  with , there exists  and a context  with  holes such that  and  for all  with .
\end{lemma}

\begin{proof}
	Assume  and  are terms of the source language such that  and . Moreover, for simplicity, let us assume, that , but note that the actually orientation of the brackets is not import for the rest of the proof. Let  be the context introduced by the encoding of the parallel operator, i.e.,  for all  in the source language. Then . So we can choose  for all  and . By operational completeness (compare to Definition \ref{def:operationalCorrespondence}), then  for all  with .
	\qed
\end{proof}

\begin{theorem}
	There is no good encoding from \piMix into \piAsyn that preserves the degree of distribution.
\end{theorem}

\begin{proof}
	By the Theorem in \cite{petersSchickeNestmann11}, any good encoding from \piMix into \piAsyn introduces additional causal dependencies. Note that in \cite{petersSchickeNestmann11} slightly different definitions of \piMix and \piAsyn are used, i.e., they use  instead of replicated input, have no match in the source language, and no -prefix. However, revisiting the argumentation on the proof of the Theorem in \cite{petersSchickeNestmann11} we observe that these details are not crucial.
	
	A closer look at the definition of additional causal dependencies used in \cite{petersSchickeNestmann11} reveals, that they show that any good encoding from \piMix into \piAsyn introduces causal dependencies between some \simulations of independent source term steps. As already stated in the discussion of \cite{petersSchickeNestmann11}, because of this causal dependency some \simulations of independent source terms steps have to be sequentialised, i.e., the \simulations can still be performed in either order and even somehow overlapping but not completely independent. Note that this is exactly what we observe in Lemma \ref{lem:EncodingMixAsynNotPreservesDegreeOfDistribution}. Because of that, there is no good encoding from \piMix into \piAsyn that preserves the degree of distribution.
	\qed
\end{proof}

Let  be the asynchronous \piCal-culus augmented with poliadic synchronisation on channels composed by up to two names as introduced by \cite{carboneMaffeis03}.

\begin{definition}[]
  The set of process terms of the \emph{asynchronous \piCal-calculus with two-level poliadic synchronisation}, denoted by , is given by
	
	for some names , some finite sequences of names , and either  or  for some .
\end{definition}

\begin{figure}[htp]
	
	\begin{center}
		Here  is some arbitrary injective substitution such that , where . The remaining operators restriction, sum,  guarded terms, and  are translated as in  or  again.
	\end{center}
	\caption{Encoding  from \piMix without replicated input into .} \label{fig:encodingMixAsynTwo}
\end{figure}

For simplicity, we do not consider replicated input on the source language. Then the encoding , given in Figure \ref{fig:encodingMixAsynTwo}, is a good encoding from \piMix without replicated input into \piAsynTwo. Note that, to prove that  is correct with respect to the criteria presented in Section \ref{sec:qualityCriteria}, we can argument very similar as for , because the main feature, i.e., the way in which sum locks are ordered, is the same for both encodings. On the other side, as already stated by \cite{carboneMaffeis03}, there is no good encoding from \piMix into \piAsynTwo, that translates the parallel operator \cleanly. Note that the separation result in \cite{carboneMaffeis03} does not rely on replication, i.e., it also implies that there is no such encoding from \piMix without replicated input into \piAsynTwo.

\addcontentsline{toc}{section}{References}
\bibliographystyle{alpha}
\bibliography{encodingSynPi}

\end{document}