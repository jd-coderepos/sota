

\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}      

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage[numbers,sort,compress]{natbib}


\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage{overpic}        
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{listings}
\usepackage{wrapfig}
\usepackage{amsthm}
\usepackage{colortbl}
\usepackage{makecell}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{verbatim}
\usepackage[dvipsnames]{xcolor}
\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false,citecolor=blue,linkcolor=blue]{hyperref}

\usepackage[accsupp]{axessibility} 

\graphicspath{{./images/}}
\DeclareGraphicsExtensions{.pdf,.jpg,.png}

\usepackage[capitalize]{cleveref}
\crefname{equation}{Eq.}{Eq.}
\crefname{figure}{Fig.}{Fig.}
\crefname{table}{Tab.}{Tab.~}
\crefname{section}{Sec.}{Sec.~}
\crefname{algorithm}{Alg.}{Alg.~}
\crefname{thm}{Theorem}{Theorem~}
\crefname{lemma}{Lemma}{Lemma~}
\crefname{appendix}{Appendix}{Appendix~}
\newtheorem{theorem}{Theorem}

\def\ie{\textit{i.e.,~}}
\def\eg{\textit{e.g.,~}}
\def\etc{\textit{etc~}}
\def\etal{\textit{et al.~}}
\def\wrt{\textit{w.r.t.~}}
\def\vs{\textit{v.s.~}}
\def\resp{\textit{resp.~}}
\def\sota{state-of-the-art~}


\definecolor{tomato}{rgb}{1.0, 0.39, 0.28}
\definecolor{cornflowerblue}{rgb}{0.39, 0.58, 0.93}



\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
 
\newcommand{\tbf}[1]{\textbf{#1}}
\newcommand{\ul}[1]{\underline{#1}}



\def\f{f_\theta}
\newcommand{\F}[1]{f_\theta \left(#1\right)}
\def\zstar{\rvz^*}
\def\z{\rvz}
\def\x{\rvx}

\def\p{\rvp}
\def\c{\rvc}
\def\u{\rvu}
\def\q{\rvq}
\def\h{\rvh}
\def\flow{\rvf}
\def\hstar{\rvh^*}
\def\fstar{\rvf^*}

\newcommand{\Rdim}[1]{\mathbb{R}^{#1}}

\def\ExactGrad{\frac{\partial \gL}{\partial \theta}}
\def\PhantomGrad{\widehat{\frac{\partial \gL}{\partial \theta}}}

\def\J{\left( I - \frac{\partial \f}{\partial \zstar} \right)}
\def\Jinline{\left( I - \partial \f / \partial \zstar \right)}
\def\invJ{\J^{-1}}
\def\invJinline{\Jinline^{-1}}

\def\Jtheta{J_\theta \left(\zstar\right)}


\newcommand{\emptybox}[2][\textwidth]{\begingroup
  \setlength{\fboxsep}{-\fboxrule}\noindent\framebox[#1]{\rule{0pt}{#2}}\endgroup
}

\definecolor{codeblue}{rgb}{0.25, 0.5, 0.5}
\definecolor{codekw}{rgb}{0.35, 0.35, 0.75}
\lstdefinestyle{Pytorch}{
    language         = Python,
    backgroundcolor  = \color{white},
    basicstyle       = \ttfamily\footnotesize,
    columns          = fullflexible,
    breaklines       = true,
    captionpos       = b,
    commentstyle     = \fontsize{4pt}{4pt}\color{codeblue},
    keywordstyle     = \fontsize{4pt}{4pt}\color{codekw},
    morekeywords     = with,
}

\makeatletter
\apptocmd\@maketitle{{\vspace{-10pt}\mainfigure{}\vspace{10pt}\par}}{}{}
\makeatother


\newcommand\mainfigure{\centering
\vspace{-.2cm}
\includegraphics[width=\textwidth]{images/visualization/demo}
\vspace{-.6cm}
\captionof{figure}{\textbf{A deep equilibrium (DEQ) flow estimator directly models the flow as a path-independent, ``infinite-level'' fixed-point solving process.} We propose to use this implicit framework to replace the existing recurrent approach to optical flow estimation. The DEQ flows converge faster, require less memory, are often more accurate, and are compatible with prior model designs like RAFT~\cite{RAFT}.
}
\label{fig:demo}
}

\def\cvprPaperID{11243} \def\confName{CVPR}
\def\confYear{2022}


\begin{document}

\title{Deep Equilibrium Optical Flow Estimation}

\author{
    Shaojie Bai\textsuperscript{1}\footnotemark[1]
    \qquad
    Zhengyang Geng\textsuperscript{2}\footnotemark[1]
    \qquad
    Yash Savani\textsuperscript{1}
    \qquad
    J. Zico Kolter\textsuperscript{1,3}
    \\
    \quad Carnegie Mellon University \quad Peking University \quad Bosch Center for AI
    \\
    {\tt\small \{shaojieb,ysavani,zkolter\}@cs.cmu.edu} \quad {\tt\small zhengyanggeng@gmail.com}
}

\maketitle


\begin{abstract}
    Many recent state-of-the-art (SOTA) optical flow models use finite-step recurrent update operations to emulate traditional algorithms by encouraging iterative refinements toward a stable flow estimation.
However, these RNNs impose large computation and memory overheads, and are not directly trained to model such ``stable estimation''. They can converge poorly and thereby suffer from performance degradation.
To combat these drawbacks, we propose deep equilibrium (DEQ) flow estimators, an approach that directly solves for the flow as the infinite-level fixed point of an implicit layer (using any black-box solver)~\cite{DEQ}, and differentiates through this fixed point analytically (thus requiring  training memory).
This implicit-depth approach is not predicated on any specific model, and thus can be applied to a wide range of SOTA flow estimation model designs (\eg RAFT~\cite{RAFT} and GMA~\cite{GMA}). 
The use of these DEQ flow estimators allows us to compute the flow faster using, \eg fixed-point reuse and inexact gradients, consumes  less training memory than the recurrent counterpart, and achieves better results with the same computation budget. 
In addition, we propose a novel, sparse fixed-point correction scheme to stabilize our DEQ flow estimators, which addresses a longstanding challenge for DEQ models in general.
We test our approach in various realistic settings and show that it improves SOTA methods on Sintel and KITTI datasets with substantially better computational and memory efficiency.
\end{abstract}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnotetext[1]{Equal contribution. Our \href{https://github.com/locuslab/deq-flow}{code} is available.}
\renewcommand*{\thefootnote}{\arabic{footnote}}

\begin{comment}
\begin{figure*}[t]
\emptybox[18cm]{3cm}
\caption{Splash figure 1. See \url{https://arxiv.org/pdf/2104.02409.pdf} for example.}
\vspace{-.3cm}
\end{figure*}
\end{comment}

\section{Introduction}
\label{sec:intro}
Optical flow estimation is the classic computer vision task of predicting the pixel-level motions between video frames~\cite{lucas1981iterative,horn1981determining,flownet,maskflownet,RAFT}. Learning-based approaches to this problem, which outperformed classical approaches, proposed the use of conventional deep convolutional networks to learn a flow estimate~\cite{flownet,liteflownet2,maskflownet}.
Recent progress has shown that finite-step, unrolled and recurrent update operations significantly improve the estimation performance, exemplified by the emergence of the RAFT~\cite{RAFT} method. Contemporary optical flow models that employ this approach typically rely on a Gated Recurrent Unit (GRU)~\cite{GRU} to \emph{iteratively refine} the optical flow estimate. 
This approach was motivated to emulate traditional optimization-based methods, and the update operators defined accordingly have become the standard design for state-of-the-art flow models~\cite{RAFT,autoflow,GMA,eldesokey2021normalized,Jiang2021LearningOF}.

Despite their superior performance, these rolled-out recurrent networks suffer from a few drawbacks.
First, training these models involves tracking a long hidden-state history in the backpropagation-through-time (BPTT) algorithm~\cite{werbos1990backpropagation}, which yields a significant computational and memory burden. Therefore, these models tend to scale poorly with larger images and more iterations. 
Second, although these models were designed to emulate \emph{traditional optimization approaches} which solve for a ``stable estimate" with as many steps as needed, the recurrent networks do not directly model such a minimum-energy optima state. Rather, they stop after a predefined  update steps, and are still trained in a path-dependent way using BPTT. We also show later in Fig.~\ref{fig:deq-reuse} that the GRUs frequently oscillate instead of converging.


In this work, we introduce deep equilibrium (DEQ) flow estimators based on recent progresses in implicit deep learning, represented by DEQ models~\cite{DEQ,MDEQ,MON,kawaguchi2020theory,Kolter2020}. 
Our method functions as a superior and natural framework to replace the existing recurrent, unrolling-based flow estimation approach. 

There are multiple reasons why this method is preferable.
\textbf{First}, instead of relying on the na\"ive iterative layer stacking, DEQ models define their outputs as the fixed points of a single layer  using the input , \ie , modeling an ``infinite-layer'' equilibrium representation. We can directly solve for the fixed point using specialized black-box solvers, \eg quasi-Newton methods~\cite{broyden1965class,anderson1965}, in a spirit much more consistent with the traditional optimization-based perspective~\cite{fleet2006optical,horn1981determining}. This approach expedites the stable flow estimation process while often yielding better results.
\textbf{Second}, we no longer need to perform BPTT. Instead, DEQ models can directly differentiate through the final fixed point  without having to store intermediary states during the forward computation, considerably lowering the training memory cost.
\textbf{Third}, this fixed-point formulation justifies numerous implicit network enhancements such as 1) fixed-point reuse from adjacent video frames; and 2) inexact gradients~\cite{Ham,SamyFPN,PhantomGrad}. The former helps avoid redundant computations, thus substantially accelerating flow estimations; and the latter makes the backward pass computationally \emph{almost free}!
\textbf{Fourth}, the DEQ approach is not predicated on any specific structure for . Therefore, DEQ is a \emph{framework} that applies to a wide range of these SOTA flow estimation model designs (\eg RAFT~\cite{RAFT}, GMA~\cite{GMA}, and Depthstillation~\cite{aleotti2021learning}), and we can obtain the aforementioned computational and memory benefits with even additional gain based on the specific structure of .

In addition to suggesting DEQ flow estimators as a superior replacement to the existing recurrent approach, we also tackle the longstanding instability challenge of training DEQ networks~\cite{chen2018neural,DEQ,DEQ_JR,MON}. Inspired by the RAFT model, we propose a novel, sparse fixed-point correction scheme that substantially stabilizes our DEQ flow estimators.

The contributions of this paper are as follows. 
\textbf{First}, we propose the deep equilibrium (DEQ) approach as a new natural starting point for formulating optical flow methods. A DEQ approach directly models and substantially accelerates the fixed-point convergence of the flow estimation process, avoids redundant computations across video frames, and comes with an almost-free backward pass.
\textbf{Second}, we show that the DEQ approach is orthogonal to, and thus compatible with, the prior modeling efforts (which focus on the model design and feature extraction)~\cite{RAFT,GMA} and data-related efforts~\cite{autoflow}. With DEQ, these prior arts are now more computationally and memory efficient as well as more accurate. For instance, on KITTI-15~\cite{kitti} (\emph{train}) a zero-shot DEQ-based RAFT model further reduces the state-of-the-art F1-all measure by  while using the underlying RAFT design.
\textbf{Third}, we introduce a sparse fixed-point correction scheme that significantly stabilizes DEQ models on optical flow problems while only adding minimal cost, and show that on flow estimation tasks this approach is superior to the recently proposed Jacobian-based regularization~\cite{DEQ_JR}.


\section{Related Work}
\label{sec:related_work}

\paragraph{Iterative Optical Flow.} Although optical flow is a classic problem, there has recently been substantial progress in the area.
Earlier methods~\cite{horn1981determining,black1993framework,Zach2007ADB,Wedel2008AnIA,Brox2011LargeDO} formulated the optical flow prediction as an energy minimization problems using continuous optimization with different objective terms. This perspective inspired multiple improvements that used discrete optimization to model optical flows, \ie those based on conditional random fields~\cite{Menze2015DiscreteOF}, global optimization~\cite{Chen2016FullFO}, and inference on the global 4D cost volume~\cite{Xu2017AccurateOF}. 
More recently, with the advancement of deep learning, there have been an explosion of efforts trying to emulate these optimization steps via deep neural networks. For example, a number of optical flow methods are based on deep architectures that rely on coarse-to-fine pyramids~\cite{pwcnet,pwcnet+,liteflownet,liteflownet2,flownet,ilg2017flownet,vcn}. Specifically, recent research efforts have turned to iterative refinements, which typically involves stacking multiple direct flow prediction modules~\cite{ilg2017flownet,ranjan2017optical}. The RAFT model~\cite{RAFT}, which inspired this work, first showed they could achieve state-of-the-art performance on optical flow estimation using a global correlation volume and a ConvGRU update operator that mimics the behavior of traditional optimizers, which tends to converge to a stable flow estimate. Built on top of this recurrent unrolling framework of RAFT, \citet{GMA}, and \citet{Zhang2021SepFlow} introduced additional attention-style modules prior to the recurrent stage to improve the modeling of occlusions and textureless areas. Another contemporary work, AutoFlow~\cite{autoflow}, exploits bilevel optimization to automatically render and augment training data for optical flow. Finally, \citet{jiang2021learning} proposes to speed up these flow estimators by replacing the dense correlation volume with a sparse alternative.

The focus of this paper is on a direction that is largely orthogonal to and thus complementary to these modeling efforts. We challenge and improve the ``default'' \emph{recurrent, unrolled} formulation of training flow estimators themselves. With the help of the recent progress in implicit deep learning (see below), we can maintain the same convergent flow estimation formulation while paying substantially less computation and memory costs.

\vspace{-.25cm}
\paragraph{Implicit deep learning.} Recent research has proposed a new class of deep learning architectures that do not have prescribed computation graphs or hierarchical layer stacking like conventional networks. Instead, the output of these implicit networks is typically defined to be the solution of an underlying dynamical system~\citep{Kolter2020,amos2017optnet,chen2018neural,DEQ,elghaoui2019implicit,Ham}. For example, Neural ODEs~\citep{chen2018neural} model infinitesimal steps of a residual block as an ODE flow. A deep equilibrium (DEQ) network~\citep{DEQ} (which primarily inspired this work) is another class of implicit model that directly solves for a fixed-point representation of a shallow layer  (\eg, a Transformer block) and differentiates through this fixed point without storing intermediate states in the forward pass. This allows one to train implicit networks with \emph{constant} memory, while fully decoupling the forward and backward passes of training. However, it is known that these implicit models suffer from a few serious issues that have been studied by later works, such as computational inefficiency~\citep{chen2018neural,dupont2019augmented}, instability~\citep{chen2018neural,DEQ,DEQ_JR}, and lack of theoretical convergence guarantees~\citep{kawaguchi2020theory,MON}. On a positive note, followup works have also shown that DEQ-based models can achieve competitive results on challenging tasks such as language modeling~\citep{DEQ}, generative modeling~\citep{lu2021implicit}, semantic segmentation~\citep{MDEQ}, etc. However, to the best of our knowledge, these implicit models have not been applied to the task of optical flow estimation. In this paper, we show that this task could substantially benefit from the DEQ formulation as well.

\section{Method}
\label{sec:method}

We start by introducing some preliminaries of existing flow estimators. These modules are typically applied directly on raw image pairs, with the extracted representations then passed into the iterative refinement stage. We use RAFT~\cite{RAFT} as the illustrative example here while noting that cutting-edge flow estimators generally share similar structure (\ie, for context extraction and correlation computations).

\subsection{Preliminaries}
\label{subsec:preliminaries}

Given an RGB image pair , an optical flow estimator aims to learn a correspondence  between two coordinate grids  (\ie ), which describes the per-pixel motion between consecutive frames in the horizontal () and vertical () directions. To process the matched image pair, we first encode features  of , and produce a context embedding  from the first image . Then, we construct a group of pyramid global correlation tensors , where  is found by first calculating the inner product between all pairs of hyperpixels in  and  as , \ie

followed by downsampling the last two dimensions to produce  (). The correlation pyramid  and context embedding , which allow the model to infer large motions and displacements in a global sense, are then passed as inputs into the \emph{iterative refinement} stage. 

In this work, we keep the correlation and context computation part intact (see Fig.~\ref{fig:recurrent-vs-deq}) and concentrate on the iterative refinement stage. We refer interested readers to \citet{RAFT} for a more detailed description of the feature extraction process. 

\subsection{Deep Equilibrium Flow Estimator}
\label{subsec:deq-flow-estimator}

\begin{figure*}[t]
\centering
\vspace{-.1cm}
\includegraphics[width=1.02\textwidth]{images/architecture/model_picture}
\caption{A visual comparison of the DEQ flow estimator and the recurrent unrolled flow estimator. After the correlation and context modules (see Sec.~\ref{subsec:preliminaries}), a DEQ flow uses a fast, black-box fixed-point solver (e.g., Anderson) to directly solve for a stable (fixed-point) flow , and differentiate through  with a cheap inexact gradient. This makes a DEQ flow's backward pass almost free. In contrast, a recurrent flow estimator has to be unrolled for many steps, and needs to perform BPTT, which is costly in both computation and memory.}
\vspace{-.4cm}
\label{fig:recurrent-vs-deq}
\end{figure*}

Due to the inherent challenges of the flow estimation task, prior works have shown that explicit neural networks struggle to predict the flow accurately, requiring a prohibitively large number of training iterations~\cite{flownet}. Recent works~\cite{RAFT,GMA,aleotti2021learning} have resorted to mimicking the flavor of traditional optimization-based algorithms~\cite{horn1981determining} with RNNs (\eg convGRUs). However, these methods are still quite different from the traditional methods in a few ways. For example, optimization-based methods 1) have an adaptive and well-defined stopping criteria (\eg whenever they reach the optima); 2) are agnostic to the choice of solver (\eg first- or second-order methods);  and 3) are essentially path-independent (\ie the output alone is the only thing we should need). None of these properties are directly characterized by the finite-step unrolling of recurrent networks.

We propose to close this gap with a DEQ-based approach. Specifically, given the context embedding  and the pyramid correlation tensor , a DEQ flow estimator simultaneously solves for the fixed-point convergence of two alternate streams: 1) a latent representation , which constructs the flow updates; and 2) the flow estimate  itself, whose updates are generically related as follows:

This formulation captures the form of prominent flow estimator model designs like RAFT~\cite{RAFT} or GMA~\cite{GMA}. Formally, the input  and model parameters  jointly define a dynamical system that the DEQ flow model can \emph{directly} solve the fixed point for using the following flow update equation in its forward pass:

Intuitively, this corresponds to an ``infinite-depth'' feature representation  where, if we perform one more flow update step , both flow estimation  and latent state  will not change (thus reaching a fixed point, \ie an ``equilibrium''). Importantly, we can leverage much more advanced root solving methods like quasi-Newton methods (\eg Broyden's method~\cite{broyden1965class} or Anderson mixing~\cite{anderson1965}) to find the fixed point. These methods guarantee a much faster (superlinear) and better-quality convergence than if we perform infinitely many na\"ive unrolling steps (as do recurrent networks but only up to a finite number of steps due to computation and memory constraints). Moreover, we note that prior works on implicit networks have shown that the exact structure of  subsumes a wide variety of model designs, such as a Transformer block~\cite{DEQ,vaswani2017attention}, a residual block~\cite{MDEQ,he2016deep}, or a graph layer~\cite{gu2020implicit,park2021convergent,liu2021eignn}. Similarly, for the deep equilibrium flow estimator, \cref{eq:deq-flow-abs} engulfs exactly the designs of state-of-the-art optical flow models, which we follow and use without modification. For example, for RAFT~\citep{RAFT},
0.3mm]
& \hstar      & = & \text{ConvGRU}\left(\hstar, [\x,\, \q] \right)   \
where  stands for the correlation lookup as in RAFT~\cite{RAFT}. We also show in Appendix that GMA~\citep{GMA} can be easily written in a similar update form.

The key question is, how do we update and train a DEQ flow estimator. It turns out that we can directly differentiate through this ``infinite-level'' flow state, , without any knowledge of the forward fixed-point trajectory:
\begin{theorem}
\label{th:ift}
(Implicit Function Theorem (IFT)~\cite{krantz2012implicit,DEQ}) Given the fixed-point flow representation , the corresponding flow loss  and input , the gradient of DEQ flow is given by

\end{theorem}
\noindent For the proof, see \citet{DEQ}. Importantly, this theorem enables us to \emph{decouple} the forward and backward passes of a DEQ flow estimator; \ie to perform gradient update, we only need the final output  and do not need to run backpropagation-through-time (BPTT). It means a huge memory reduction: whereas an -step recurrent flow estimator takes  memory to perform BPTT, a DEQ estimator reduces the overhead by a factor of  to be  (\eg RAFT uses  for training, so using a DEQ flow can theoretically reduce the iterative refinement memory cost by ).

To summarize, a DEQ flow's forward pass directly solves a fixed-point flow-update equation via black-box solvers; and its backward pass relies only on the final optimum , which make this flow estimation process much more akin to the optimization-based perspective~\citep{horn1981determining}.

\begin{figure*}[t]
\centering
  \begin{subfigure}[b]{0.64\textwidth}
  \includegraphics[width=1.02\textwidth]{images/architecture/reuse}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.34\textwidth}
  \includegraphics[width=\textwidth]{images/results/deq-raft-reuse-convergence}
  \end{subfigure}
\vspace{-.2cm}
\caption{(Left) By reusing fixed-point  from the previous frame's flow estimation, we can ``jump start'' the subsequent equilibrium solving, essentially amortizing the solver cost and speeding up convergence. (Right) Comparing forward convergence of DEQ and recurrent flow estimators on Sintel videos (50 frames). "DS" stands for deep supervision used by RAFT~\cite{RAFT}. DEQ flow with fixed-point reuse converges best; and overall, DEQ flows converge faster than RAFT~\cite{RAFT}.}
\label{fig:deq-reuse}
\vspace{-.4cm}
\end{figure*}

\subsection{Accelerating DEQ Flows}
\label{subsec:accelerate-deq-flow}
Formulating optical flow estimation as a deep equilibrium solution also enables us to fully exploit the toolkit from implicit deep learning. We elaborate below on examples of how this equilibrium formulation can substantially help us improve the forward and backward pipeline and significantly simplify the overall overhead of modern flow estimators.

\vspace{-.5cm}
\paragraph{Inexact Gradients for Training DEQs.} Despite the niceness of the implicit function theorem (IFT), inverting the Jacobian term could quickly become intractable as we deal with high-dimensional feature maps. To combat this, \citet{DEQ} proposed exploiting fast vector-Jacobian products and solving a linear fixed-point system . However, this approach is still iterative in nature, and in practice, it is no cheaper than the forward flow solving process.

Recent works on implicit networks' backward dynamics~\cite{Ham,SamyFPN,PhantomGrad} suggest that they can typically be trained, and even benefit from, simple approximations of the IFT, while still modeling an ``infinite-depth'' representation through the fixed-point forward pass. That is, we do not need the exact solution to Thm.~\ref{th:ift} to train these networks. Instead we use

where  is a Jacobian (inverse) approximation term. For example,~\cite{Ham,SamyFPN} proposes to use  (\ie, 1-step gradient), which simplifies the backward pass of a DEQ flow estimator to . Therefore, unlike the BPTT-based recurrent framework used by existing flow estimators, a DEQ flow estimator's backward pass that uses inexact gradient consists of a single step (and thus is almost free)! Empirically, since we almost eliminate the backward pass cost, the inexact gradients significantly reduce the total training time for DEQ flow estimator further by a factor of almost . The capability of using inexact gradients is a direct and unique consequence of the fixed-point formulation and assumes a certain level of stability for the underlying dynamics~\cite{Ham,SamyFPN,PhantomGrad,DEQ_JR}. We discuss an additional approach that further improves the stability of these estimates next.

\vspace{-.35cm}
\paragraph{Sparse fixed-point correction of DEQ flows.} A longstanding challenge in training implicit networks is \emph{the growing instability problem}~\cite{DEQ,DEQ_JR,MON,SamyFPN,PhantomGrad,chen2018neural,dupont2019augmented,kelly2020learning}. In short, since DEQ flow estimators have no discrete layers, they struggle to converge during training.
In other words, the stable flow estimate  could become computationally expensive to reach. This suggests that the optical flow estimation process gets slower during training.

In this work, we propose sparsely applying a fixed-point correction term to stabilize the DEQ flow convergence. Formally, suppose the black-box solver (e.g., Broyden's method) yields a convergence path , where  is the initial guess and  is the final flow estimate. We then randomly pick  on this path (e.g., can be uniformly spaced), and define our total loss to be

where  is a loss weight hyperparameter. This was inspired by the dense step-wise deep supervision used by conventional flow estimators like RAFT~\cite{RAFT}. However, our application here differs in two significant ways. First, we apply this in a sparse manner, with our primary goal being correcting instability. Second, unlike in RAFT, which performs costly BPTT through the RNN chain, this fixed-point correction loss is still \emph{path-independent} and can be understood as a coarse-grained fixed-point estimate. Therefore, we could also perform inexact gradient updates on this correction loss as well; \ie

Empirically, we find this significantly stabilizes the DEQ flow estimator while having no noticeable negative impact on performance. This result is in sharp contrast to existing stabilization methods like Jacobian regularization~\cite{DEQ_JR,hutchinson1989stochastic} which 1) apply only locally to ; and 2) usually hurt model performance (see the ablation study in Sec.~\ref{sec:experiments}). Moreover, due to the inexact gradient in Eq.~(\ref{eq:correction-grad}), our method adds almost no extra computation or memory cost. 

While our scope is limited to flow estimation here, we believe this approach suggests a potentially valuable and lightweight solution to the generic instability issue of implicit models, which we leave for future work.

\vspace{-.25cm}
\paragraph{Fixed-point reuse for better initialization.} The DEQ flow estimator's unique formulation also inherits many useful properties from the general optimization framework. One of these nice properties is the ability to perform fixed-point reuse to further accelerate flow estimation convergence. The motivation for this comes from the fact that consecutive frames of a video are typically highly correlated. For instance, perhaps only a few objects are moving in the foreground, while most of the other content and background are nearly identical across these adjacent frames. More formally, if , , and  are 3 consecutive video frames, then the ground-truth optical flow  (between  and ) is usually highly correlated to the next ground-truth optical flow . Thus, when we perform real-time flow estimation with conventional networks like FlowNet~\cite{flownet} and RAFT~\cite{RAFT}, we frequently perform a lot of \emph{redundant} computations. In contrast, with a DEQ flow, we can 
recycle the fixed-point solution  of the previous frame, which estimates , as the initial guess  for the subsequent frame's fixed-point solver. Intuitively, these DEQ flows are able to automatically adjust their forward optimization by exploiting this more informed initial guess, which facilitates convergence speed. It amortizes the cost of flow estimation over long video sequences, since only frame 0 requires full fixed-point solving while the remaining frames can all recycle their predecessor's flow.
We note that such reuse is related to, but still different from the warm-up scheme of RAFT~\cite{RAFT}, which only applies to , excludes , and still has to be unrolled for many steps. In our case, because a DEQ flow directly models a fixed point, such an adaptive computation by exploiting the inductive bias of video data is well-justified.

Fig.~\ref{fig:deq-reuse} shows the practicality of fixed-point reuse on Sintel video sequences. By re-using the fixed point, we can further accelerate the DEQ flow estimator's inference speed by a factor of about . Interestingly, while RAFT's iterative unrolling aims to mimic the iterative convergence, we find its activations usually oscillate at a relatively high level after about 15 update iterations.

To summarize, while a conventional recurrent flow estimator like RAFT needs to be unrolled for some finite  steps and back-propagated through the same -step chain, a deep equilibrium flow estimator: 1) leverages the IFT and requires only  training memory, 2) uses inexact gradients to reduce the backward pass to  computation, and 3) can take advantage of correlation between adjacent frames to amortize the flow estimation cost across a long sequence, thus significantly accelerating the forward pass. 


\section{Experiments}
\label{sec:experiments}


\setlength\tabcolsep{4pt}
\begin{table*}[t]

\centering
\newcolumntype{C}{>{\centering\arraybackslash}X}
\resizebox{\textwidth}{!}{
\begin{tabularx}{\textwidth}{@{}c l C C C C C C C C@{}}

\toprule
\multirow{2}{*}{Data} & \multirow{2}{*}{Method} & \multicolumn{2}{c}{Sintel (train)} & \multicolumn{2}{c}{KITTI-15 (train)} & \multicolumn{2}{c}{Sintel (test)} & \multicolumn{2}{c}{KITTI-15 (test)}\\
\cmidrule(lr){3-4}
\cmidrule(lr){5-6}
\cmidrule(lr){7-8}
\cmidrule(lr){9-10}
& & Clean & Final & AEPE & F1-all & Clean & Final & F1-fg & F1-all\\

\midrule    
\multirow{14}{*}{C + T} 
    & LiteFlowNet\cite{liteflownet}      & 2.48  & 4.04  & 10.39 & 28.5 & - & - & - & - \\
    & PWC-Net\cite{pwcnet}               & 2.55  & 3.93 & 10.35 & 33.7 & - & - & - & - \\
    & LiteFlowNet2\cite{liteflownet2}    & 2.24  & 3.78  & 8.97 & 25.9 & - & - & - & - \\
    & VCN\cite{vcn}                      & 2.21  & 3.68  & 8.36 & 25.1 & - & -     & - & - \\ 
    & MaskFlowNet\cite{maskflownet}      & 2.25 & 3.61 & - & 23.1 & - & - & - & - \\ 
    & FlowNet2\cite{ilg2017flownet}      & 2.02  & 3.54 & 10.08 & 30.0 & 3.96  & 6.02 & - & - \\
    \cmidrule[\lightrulewidth](r{0.3em}){2-10}
    & RAFT\cite{RAFT}                    & 1.43       & 2.71        & 5.04       & 17.4       & - & - & - & - \\
    & DEQ-RAFT-B                         & 1.48       & 2.81        & 5.01       & 16.3       & - & - & - & - \\
& DEQ-RAFT-L                         & 1.40       & \ul{2.65}   & 4.76       & 16.1       & - & - & - & - \\
& DEQ-RAFT-H                         & 1.41       & 2.75        & \ul{4.38}  & \ul{14.9}  & - & - & - & - \\
    & DEQ-RAFT-H               & 1.34       & \tbf{2.60}  & \tbf{3.99} & \tbf{13.5} & - & - & - & - \\
    \cmidrule[\lightrulewidth](r{0.3em}){2-10}
    & GMA\cite{GMA}                      & \tbf{1.30} & 2.74        & 4.69     & 17.1 & - & - & - & - \\ 
    & DEQ-GMA-B                          & 1.35       & 2.90        & 4.84     & 16.2 & - & - & - & - \\ 
    & DEQ-GMA-L                          & \ul{1.33}  & 2.71        & 4.72     & 16.4 & - & - & - & - \\ 
\midrule
\multirow{6}{*}{C+T+S+K+H}
    & LiteFlowNet2\cite{liteflownet2}    & (1.30) & (1.62) & (1.47) & (4.8)      & 3.48     & 4.69    & 7.62  &  7.62 \\
    & PWC-Net+\cite{pwcnet+}             & (1.71)     & (2.34)  & (1.50) & (5.3) & 3.45     & 4.60    & 7.88  &  7.72 \\
    & VCN \cite{vcn}                     & (1.66)     & (2.24) & (1.16) & (4.1)  & 2.81     & 4.40    & 8.66  &  6.30 \\
    & MaskFlowNet\cite{maskflownet}      & - & - & - & -                         & 2.52     & 4.17    & 7.70  &  6.10 \\
    \cmidrule[\lightrulewidth](r{0.3em}){2-10}
    & RAFT\cite{RAFT}                    & (0.76)  & (1.22)  & (0.63)  & (1.5)   & 1.94       & \tbf{3.18}   & 6.87       & 5.10       \\ 
    & DEQ-RAFT                           & (0.73)  & (1.02)  & (0.61)  & (1.4)   & \tbf{1.82} & 3.23         & \tbf{6.06} & \tbf{4.91} \\
\bottomrule
\end{tabularx}
}
\vspace{-.1cm} 
\caption{\tbf{Evaluation on Sintel and KITTI 2015 datasets.} We report the Average End Point Error~(AEPE), F1-fg (\%), and F1-all (\%) (lower is better). ``C+T'' refers to results that are pre-trained on the Chairs and Things datasets. ``S+K+H'' refers to methods that are fine-tuned on the Sintel, KITTI, and HD1K datasets. The bold font stands for the best result and the underlined results ranks 2nd.  corresponds to the results using a 3-step phantom gradient~\cite{PhantomGrad}. DEQ flow achieves SOTA zero-shot generalization results even w/o attention.
}
\vspace{-0.2cm}
\label{Tab:main_results}
\end{table*}


 
\begin{figure*}[!t]
    \centering
    \begin{overpic}[width=\linewidth]{images/results/ablation_correction.pdf}
        \put(14,-1.2){\scriptsize{(a) Training DEQ with Anderson forward solver}}
        \put(63.0,-1.2){\scriptsize{(b) Training DEQ with Broyden forward solver}}
        \put(11.4,23.3){\scriptsize{Performance}}
        \put(37.2,23.3){\scriptsize{Stability}}
        \put(61.15,23.3){\scriptsize{Performance}}
        \put(86.8,23.3){\scriptsize{Stability}}
    \end{overpic}
    \vspace{-3mm}    \caption{Performance and convergence stability (measured by absolute residual error) of the DEQ flow. Frequency indicates how many correction terms we pick, with  meaning no correction. See the comparison with Jacobian Regularization~\cite{DEQ_JR} in the Appendix. DEQ flows trained with our proposed correction enjoy superior performance and stability.}
    \label{fig:correct}
    \vspace{-6mm}
\end{figure*}

We present the results of our experiments in this section. Specifically, we highlight the computational and memory efficiency of DEQ flow estimators and analyze how the fixed-point correction improves the DEQ flow.
Our method achieves \sota zero-shot performance on both the MPI Sintel~\cite{sintel} dataset and the KITTI 2015~\cite{kitti} dataset, with an astonishing  error reduction in the F1-all measure and  improvement in EPE for KITTI-15 (while still using a similar training budget to RAFT~\cite{RAFT}).


\subsection{Results}
\label{sec:results}

Our quantitative evaluation is presented in \cref{Tab:main_results}.
Following previous work~\cite{RAFT,GMA}, we first pretrain the DEQ flow model on the FlyingChairs~\cite{flownet} and FlyingThings3D~\cite{mayer2016large} datasets. We then test the model on the training set of MPI Sintel~\cite{sintel} and KITTI 2015~\cite{kitti} datasets. This model is denoted ``C + T''; it evaluates the \textit{zero-shot generalization} of the DEQ flow model. 
Then, we fine-tune the DEQ flow estimator on FlyingThings3D~\cite{mayer2016large}, MPI-Sintel~\cite{sintel}, KITTI 2015~\cite{kitti}, and HD1K~\cite{hd1k} for the test submission.

The models are of exactly the same size as RAFT~(5.3M)~\citep{RAFT} and GMA~(5.9M)~\citep{GMA} except they use DEQ flow formulation instead of recurrent updates.
They are denoted as DEQ-RAFT-B and DEQ-GMA-B, respectively.
Exploiting the memory efficiency of the DEQ flow model (see \cref{subsec:performance-compute-tradeoff}), we can fit much larger models into the same compute budget of two 11~GB 2080Ti GPUs.
To this end, we also trained DEQ-RAFT-L~(8.4M) and DEQ-RAFT-H~(12.8M) by increasing the the width of hidden layers inside the equilibrium module .
As shown in \cref{fig:cost-comparison}, even the largest DEQ-RAFT-H model only consumes less than half of the flow estimation memory used by a standard-sized RAFT model, while achieving significantly better accuracy (4.38 AEPE and 14.9 F1-all score on KITTI-15, see \cref{Tab:main_results}).

\begin{figure}[t]
\centering
\includegraphics[width=.43\textwidth]{images/results/deq-raft-cost-comparison.pdf}
\vspace{-.2cm}
\caption{Comparing the training memory, inference speed and performance on Sintel (clean) with image size . The same model design (based on RAFT) consumes much less memory and computes much quicker than the recurrent counterpart. All results are benchmarked on a single Quadro RTX 8000 GPU.}
\label{fig:cost-comparison}
\vspace{-.4cm}
\end{figure}

\subsection{Performance-Compute Tradeoff}
\label{subsec:performance-compute-tradeoff}

We further verify the aforementioned computational and memory benefits of the DEQ flow model on the Sintel (clean)~\citep{sintel} dataset with a RAFT-based update operator (see Eq.~(\ref{eq:deq-flow-raft})) trained on FlyingChairs~\citep{flownet} and FlyingThings3D~\citep{mayer2016large}. The results are shown in Fig.~\ref{fig:cost-comparison}. Specifically, when training the DEQ flow estimator on Sintel with a batch size of 3 per GPU (the maximum that RAFT can fit with a 11~GB GPU), we observe that the memory cost of the flow estimation process reduces by a factor of over  (\textcolor{red}{red} bars). Note that since we keep the rest of the model intact (e.g., correlation pyramid and context extraction; see Sec.~\ref{subsec:preliminaries}), the DEQ flow estimator does not improve those parts of the memory burden, which now becomes the new dominant source of memory overhead. In addition, when we use the model for inference, we follow~\citet{RAFT} using 32 recurrent steps for RAFT (with warm-start), and the Anderson solver for DEQ-RAFT (with reuse), which stops if relative residual falls below . Our results suggest that the DEQ flow converges to an accurate solution, and it is in practice about 20\% faster than the RAFT models with the same structure and size (\textcolor{blue}{blue} bars). Finally, we show that we can exploit such memory savings to build even larger and more accurate flow estimators (DEQ-RAFT-H), while still staying well within the compute and memory budget.

\vspace{-0.1cm}
\subsection{Ablation Study}

In this subsection, we aim to answer the following questions: 1) How useful is the fixed-point correction compared with canonical IFT in performance, stability, and speed? 2) How does the convergence of a DEQ flow correlate with the quality of the flow estimation? As in \cref{subsec:performance-compute-tradeoff}, we use the model design from RAFT~\cite{RAFT} to instantiate our DEQ flow. 
By default, we conduct the ablation experiments on the FlyingChairs~\cite{flownet} dataset using the default training hyperparameters of RAFT and report the Average End Point Error~(AEPE) on its validation split. 

\vspace{-0.3cm}
\paragraph{Stabilizing DEQ by Fixed-Point Correction.} As mentioned in Sec.~\ref{subsec:accelerate-deq-flow}, unregularized canonical DEQ models (as well as other implicit networks like Neural ODEs~\citep{chen2018neural}) typically suffer from a growing instability issue typically symptomized by an increasingly costly forward fixed-point solving process. We perform an ablation experiment to study how our proposed sparse fixed-point correction scheme could help alleviate this issue.
To understand the scheme's effect, we train a DEQ flow model using both an Anderson~\cite{anderson1965} and a Broyden~\cite{broyden1965class} solver with 36 and 24 forward iterations, respectively. For simplicity, we equally divide the solver convergence trajectory into  segments (where  is the frequency in \cref{fig:correct}) and impose a correction loss after each trajectory clip. As mentioned in Sec.~\ref{subsec:accelerate-deq-flow}, we apply the 1-step gradient~\citep{Ham,SamyFPN,PhantomGrad} to the correction loss. 

We visualize results of DEQ flow models trained with 3 different settings: 1) a DEQ flow trained by IFT directly without an auxiliary correction loss; 2) a DEQ flow trained by 1-step gradient without an auxiliary correction loss; and 3) DEQ flows trained by 1-step gradient \emph{as well as} 1-3 fixed-point correction terms. Our results are reported in terms of AEPE (which measures performance) and absolute fixed-point residual error  (which measures stability).
As shown in Fig.~\ref{fig:correct}, our proposed fixed-point correction significantly outperforms the standard IFT training protocol by about , and reduces the fixed-point error by a conspicuous margin, \eg over . Moreover, we find that the significant improvement in stability quickly diminishes as we apply more corrections, which suggests a sparse correction scheme.
Together with the inexact 1-step gradient, the total training time can be streamlined over  compared with the IFT training schedule, while the backward pass of a DEQ flow is still almost \textit{free}.

\begin{figure}
\label{fig:corr}
\centering
\includegraphics[width=.45\textwidth]{images/results/kitti_corr_mag_epe_abs.pdf}
\vspace{-.4cm}
\caption{Correlation between convergence and performance. We also observe that harder examples (e.g., those with large motion) typically lead to more challenging fixed-point convergence.}
\vspace{-.4cm}
\end{figure}

\vspace{-.3cm}
\paragraph{Correlation between Performance and Convergence.} A potential question is whether better fixed-point convergence can lead to better performance. To tackle this, we evaluate the DEQ flow model trained using the standard ``C+T'' training protocol (see \cref{sec:results}) on the KITTI-15~\cite{kitti} training set. We visualize the per-frame EPE and the convergence (measured by the absolute fixed point error) in \cref{fig:corr} and dye the scatter plot with the average norm of per-pixel flow across the frame, which can be understood as an indicator of hardness due to the large displacements. 
\begin{figure}
    \centering
    \includegraphics[width=7cm]{images/results/corr_mag_epe_abs.pdf}
    \vspace{-0.3cm}
    \caption{Pearson correlation coefficient across per-frame EPE, fixed-point error, and the magnitude of flow.}
    \label{fig:pearson}
    \vspace{-0.4cm}
\end{figure}
The Pearson correlation coefficient between the fixed-point error and EPE is over \textcolor{SeaGreen}{\textbf{0.86}} (see \cref{fig:pearson}) supporting the claim that convergence is strongly correlated with the flow performance. From \cref{fig:pearson}, we see that hard flows with large motions are also challenging for a naive solver. This demonstrates the necessity of advanced solvers in DEQ flow estimation.

\vspace{-0.2cm}
\section{Limitations}
The improved performance and efficiency of our approach comes at the cost of a slightly more complex training pipeline. 
Implementing the na\"ive unrolled flow estimation as presented in \citet{RAFT} and \citet{GMA} is simple using most libraries equipped with automatic differentiation that directly handle BPTT.
On the other hand, our approach involves some finagling of the training protocol (\eg fixed-point solvers, IFT, inexact gradients, \etc.). To help alleviate this complexity and promote the use of DEQ flows, we release our code at \url{https://github.com/locuslab/deq-flow}.

In addition, while DEQ flows provide a novel and more efficient framework to train and use these flow estimators, we still occasionally need to be careful about the stability of this approach. For example, what would happen if the solver \emph{converges poorly} (or even diverges) on a dynamical system? In such case, the behavior of the DEQ flow estimation would not be well-defined. In practice, we rarely observe such instability (as long as we spend enough solver steps); but as we analyzed in Sec. 4, harder examples also typically lead to more lengthy convergence path. We leave a more thorough study of estimation stability to future work.

\vspace{-0.2cm}
\section{Conclusion}
\label{sec:conclusion}

In this work, we introduce a new framework for modeling optical flow estimation. A deep equilibrium (DEQ) flow directly models and solves a fixed-point \emph{stable} flow estimate, and offers a set of tools that make these flow models' training and inference process highly efficient (e.g., they enjoy an almost-free backward pass). Moreover, the use of such equilibrium formulation is largely orthogonal to, and thus complements, the prior modeling and data efforts. We empirically show that it is possible to integrate the DEQ flow estimator with these model designs and achieve better performance on realistic optical flow datasets.
This implicit framework provides a strong (drop-in) replacement for existing recurrent update operators used by most cutting-edge flow estimators. The DEQ flows are both more powerful and lightweight --- both computationally and memory-wise. We believe this suggests an exciting direction for building more efficient, large-scale and accurate flow models in the future.

{\small
\bibliographystyle{unsrtnat}
\bibliography{deq}
}

\clearpage
\appendix

\section{Pseudo Code}

We provide a PyTorch-style~\cite{pythorch} pseudo-code for the DEQ flow in \cref{alg:deq-torch-short}. Besides fixed-point reuse and an inexact (one-step) gradient as shown previously, we also include the fixed-point correction loss (applied with \texttt{freq}). In practice, we can set \texttt{freq}, and use either Broyden's method~\cite{broyden1965class} or Anderson acceleration~\cite{anderson1965} as \texttt{solver}. This sparse fixed-point correction scheme encourages stable training dynamics, which we analyze further in \cref{fig:jr-correction}.


\begin{algorithm}[t]
\caption{DEQ flow (PyTorch-style). Note that we reuse the fixed point and perform fixed-point correction.}
\label{alg:deq-torch-short}
\begin{lstlisting}[style=Pytorch,escapeinside={(@}{@)}]
# solver: fixed-point solver, e.g., Broyden(@~\cite{broyden1965class}@)
# func: layer (@@) that defines dynamic system
# dist: loss function for fixed point correction
# x: input information (@@) of frame (@@)
# z: fixed-point flow estimation (@@)
# f: ground truth optical flow (@@)
# freq: frequency of correction
# gamma: coefficient of correction
# prev_z: (@@) of the last frame (if exists)
# training: bool indicating training/inference

# Forward pass (w/ backward pass by autodiff)
def forward(x, f, gamma, freq=1, 
    training=True, prev_z=None):
    with torch.no_grad(): # Fixed-Point Reuse
        z, z_m = solver(func, x, freq, z0=prev_z) 
        
    if training:
        loss = dist(f, func(z, x))
        # Fixed Point Correction w/ 1-step gradient
        for i in range(freq):
            z_mi = func(z_m[i], x)
            loss = loss + gamma[i] * dist(f, z_mi)
        return loss
        
    return z
\end{lstlisting}
\vspace{-0.1cm}
\end{algorithm}


\section{Experiment Settings}
In this section, we present the detailed experiment settings for training and inference with the DEQ flow estimators. The code will be made publicly available upon acceptance.

\subsection{Model Design}

As mentioned previously, a deep equilibrium (DEQ) flow estimator subsumes a wide variety of model designs, and can be integrated with the latest, cutting-edge update operators. We show the integration of two of the most prominent designs that have achieved state-of-the-art optical flow results below, while noting in general that other alternatives are also possible.

\paragraph{DEQ flow by RAFT.}
Without any modification to the original design of RAFT~\cite{RAFT}, we can instantiate a DEQ-RAFT by defining the equilibrium system as follows, 
0.3mm]
& \hstar      & = & \text{ConvGRU}\left(\hstar, [\x,\, \q] \right)   \
where  stands for the correlation lookup as in RAFT~\cite{RAFT}, \text{Conv2d} stands for 2D convolutional layers with ReLU activations, and \text{ConvGRU} represents a GRU-style gated activation following convolutions, respectively. We refer the readers to~\citet{RAFT} and the code base\footnote{\href{https://github.com/princeton-vl/RAFT}{https://github.com/princeton-vl/RAFT}} for more details.

\paragraph{DEQ flow by GMA.}
More recently,~\citet{GMA} show that we can improve on the formulation of RAFT above by adding an attention module to better model the occlusion scenarios in video frames. Specifically, we also provide an instantiation of such Global Motion Aggregation~(GMA) update operator~\citep{GMA} in the context of DEQ flows, where we solve for the equilibrium  that satisfies
0.15mm]
& \hat{\x}    & = & \text{Attention}\left(\q,\, \q,\, \x\right)                   \0.15mm]
& \fstar      & = & \fstar + \text{Conv2d}\left(\hstar \right)                    \\
\end{array} 

    \rho(J_{\f}(\zstar)) \leq \| J_{\f}(\zstar) \|_F = \sqrt{\text{tr}(J_{\f}^\top J_{\f})},

    \text{tr}(J_{\f}^\top J_{\f}) = \mathbb{E}_{\epsilon\sim p(\epsilon)} \left[\epsilon^\top J_{\f}^\top J_{\f} \epsilon \right] \approx \sum_{\epsilon\sim p(\epsilon)} \| J_{\f} \epsilon \|_2^2,

where  can be the Gaussian distribution  or the Rademacher distribution.
Different from prior works, we advocate for exploiting the benefit of IFT and inexact gradient to \emph{sparsely} apply a fixed-point correction scheme to the convergence path. 

In this section, we present an ablation study on FlyingChairs~\cite{flownet} that compare the stability and generalization performance of DEQ flow models trained in three different settings: 1) standard implicit differentiatio (i.e., IFT); 2) standard IFT with Jacobian regularization~\citep{DEQ_JR}; and 3) our proposed fixed-point correction scheme with a single correction term.
As mentioned previously, we perform 1-step inexact gradient on the correction loss as well. For the purpose of this ablation, we run the forward fixed-point solver for a limited compute budget of 16 Anderson~\cite{anderson1965} steps in all three settings, and analyze their convergence behavior accordingly.

As shown in \cref{fig:jr-correction}, the model trained using the standard implicit function theorem (IFT) suffers from the ``growing instability'' issue (see \textcolor{tomato}{red} curve in \cref{fig:jr-correction} (a)), as described in prior works indeed~\citep{DEQ,DEQ_JR,chen2018neural,MON}. While strong enough Jacobian regularization can indeed stabilize the training process and lead to good overall convergence (see \textcolor{orange}{orange} curve in \cref{fig:jr-correction} (a)), we observe that it is usually at a heavy cost of optical flow estimation accuracy (see \cref{fig:jr-correction} (b)). This agrees with the conclusion of~\citet{DEQ_JR}. In contrast, we find it suffices to use a single fixed-point correction term in DEQ flow to achieve the same stabilizing effect (see \textcolor{cornflowerblue}{blue} curve in \cref{fig:jr-correction} (a)) \emph{at no extra cost} to the average EPE on the validation set. We hypothesize that such a fixed-point correction method may suggest an elegant and lightweight solution to the growing instability problem in the broader implicit deep learning community beyond the scope of optical flow estimation.

\section{Qualitative Results}

We visualize the flow estimation by the DEQ flow model in \cref{fig:demo-clean-ambush-1}, \cref{fig:demo-clean-cave-3}, \cref{fig:demo-clean-market-1}, \cref{fig:demo-final-bamboo-3}, \cref{fig:demo-final-temple-1}, and \cref{fig:demo-kitti} using consecutive frames of the MPI Sintel~\cite{sintel} test set and KITTI~\cite{kitti} test set. Flow estimation errors are downloaded from the leaderboard.


\begin{figure*}[!ht]
    \centering
    \begin{overpic}[width=0.24\linewidth]{demo/clean_ambush_1_img/frame_0012.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_ambush_1_img/frame_0013.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_ambush_1_img/frame_0014.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_ambush_1_img/frame_0015.png}
    \end{overpic}\\
    \begin{overpic}[width=0.24\linewidth]{demo/clean_ambush_1_flow/frame0012.png}
        \put(34,-6.0){\scriptsize{(a) Frame 12}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_ambush_1_flow/frame0013.png}
        \put(34,-6.0){\scriptsize{(b) Frame 13}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_ambush_1_flow/frame0014.png}
        \put(34,-6.0){\scriptsize{(c) Frame 14}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_ambush_1_flow/frame0015.png}
        \put(34,-6.0){\scriptsize{(d) Frame 15}}
    \end{overpic}\vspace{4.5pt}
    \caption{
      Visualization on the Sintel test set, \texttt{ambush\_1} sequence of the clean split.
    }
    \label{fig:demo-clean-ambush-1}
    \vspace{-6pt}
\end{figure*}
\begin{figure*}[!ht]
    \centering
    \begin{overpic}[width=0.24\linewidth]{demo/clean_cave_3_img/frame_0034.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_cave_3_img/frame_0035.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_cave_3_img/frame_0036.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_cave_3_img/frame_0037.png}
    \end{overpic}\\
    \begin{overpic}[width=0.24\linewidth]{demo/clean_cave_3_flow/frame0034.png}
        \put(34,-6.0){\scriptsize{(a) Frame 34}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_cave_3_flow/frame0035.png}
        \put(34,-6.0){\scriptsize{(b) Frame 35}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_cave_3_flow/frame0036.png}
        \put(34,-6.0){\scriptsize{(c) Frame 36}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_cave_3_flow/frame0037.png}
        \put(34,-6.0){\scriptsize{(d) Frame 37}}
    \end{overpic}\caption{
      Visualization on the Sintel test set, \texttt{cave\_3} sequence of the clean split.
    }
    \label{fig:demo-clean-cave-3}
    \vspace{-6pt}
\end{figure*}
\begin{figure*}[!ht]
    \centering
    \begin{overpic}[width=0.24\linewidth]{demo/clean_market_1_img/frame_0025.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_market_1_img/frame_0026.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_market_1_img/frame_0027.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_market_1_img/frame_0028.png}
    \end{overpic}\\
    \begin{overpic}[width=0.24\linewidth]{demo/clean_market_1_flow/frame0025.png}
        \put(34,-6.0){\scriptsize{(a) Frame 25}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_market_1_flow/frame0026.png}
        \put(34,-6.0){\scriptsize{(b) Frame 26}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_market_1_flow/frame0027.png}
        \put(34,-6.0){\scriptsize{(c) Frame 27}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/clean_market_1_flow/frame0028.png}
        \put(34,-6.0){\scriptsize{(d) Frame 28}}
    \end{overpic}\caption{
      Visualization on the Sintel test set, \texttt{market\_1} sequence of the clean split.
    }
    \label{fig:demo-clean-market-1}
    \vspace{-6pt}
\end{figure*}
\begin{figure*}[!ht]
    \centering
    \begin{overpic}[width=0.24\linewidth]{demo/final_bamboo_3_img/frame_0038.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/final_bamboo_3_img/frame_0039.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/final_bamboo_3_img/frame_0040.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/final_bamboo_3_img/frame_0041.png}
    \end{overpic}\\
    \begin{overpic}[width=0.24\linewidth]{demo/final_bamboo_3_flow/frame0038.png}
        \put(34,-6.0){\scriptsize{(a) Frame 25}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/final_bamboo_3_flow/frame0039.png}
        \put(34,-6.0){\scriptsize{(b) Frame 26}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/final_bamboo_3_flow/frame0040.png}
        \put(34,-6.0){\scriptsize{(c) Frame 27}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/final_bamboo_3_flow/frame0041.png}
        \put(34,-6.0){\scriptsize{(d) Frame 28}}
    \end{overpic}\caption{
      Visualization on the Sintel test set, \texttt{bamboo\_3} sequence of the final split.
    }
    \label{fig:demo-final-bamboo-3}
    \vspace{-6pt}
\end{figure*}
\begin{figure*}[!ht]
    \centering
    \begin{overpic}[width=0.24\linewidth]{demo/final_temple_1_img/frame_0019.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/final_temple_1_img/frame_0020.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/final_temple_1_img/frame_0021.png}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/final_temple_1_img/frame_0022.png}
    \end{overpic}\\
    \begin{overpic}[width=0.24\linewidth]{demo/final_temple_1_flow/frame0019.png}
        \put(34,-6.0){\scriptsize{(a) Frame 25}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/final_temple_1_flow/frame0020.png}
        \put(34,-6.0){\scriptsize{(b) Frame 26}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/final_temple_1_flow/frame0021.png}
        \put(34,-6.0){\scriptsize{(c) Frame 27}}
    \end{overpic}\begin{overpic}[width=0.24\linewidth]{demo/final_temple_1_flow/frame0022.png}
        \put(34,-6.0){\scriptsize{(d) Frame 28}}
    \end{overpic}\caption{
      Visualization on the Sintel test set, \texttt{temple\_1} sequence of the final split.
    }
    \label{fig:demo-final-temple-1}
    \vspace{-6pt}
\end{figure*}
\begin{figure*}[!ht]
    \centering
    \begin{overpic}[width=0.9\linewidth]{demo/KITTI/data.png}
        \put(46.5, -3.75){\scriptsize{Input frame}}
    \end{overpic}\\ 
    \vspace{1cm}
    \begin{overpic}[width=0.45\linewidth]{demo/KITTI/RAFT_pred.png}
        \put(42, -7.5){\scriptsize{RAFT prediction}}
    \end{overpic}\begin{overpic}[width=0.45\linewidth]{demo/KITTI/RAFT_error.png}
        \put(43, -7.5){\scriptsize{RAFT error}}
    \end{overpic}\\ 
    \vspace{1cm}
    \begin{overpic}[width=0.45\linewidth]{demo/KITTI/AGMA_pred.png}
        \put(41.8, -7.5){\scriptsize{GMA prediction}}
    \end{overpic}\begin{overpic}[width=0.45\linewidth]{demo/KITTI/AGMA_error.png}
        \put(42.8, -7.5){\scriptsize{GMA error}}
    \end{overpic}\\ 
    \vspace{1cm}
    \begin{overpic}[width=0.45\linewidth]{demo/KITTI/DEQ_pred.png}
        \put(38.7, -7.5){\scriptsize{DEQ Flow prediction}}
    \end{overpic}\begin{overpic}[width=0.45\linewidth]{demo/KITTI/DEQ_error.png}
        \put(39.4, -7.5){\scriptsize{DEQ Flow error}}
    \end{overpic}\\ 
    \vspace{0.7cm}
    \caption{
      Visualization on the KITTI test set.
    }
    \label{fig:demo-kitti}
\end{figure*}

\end{document}
