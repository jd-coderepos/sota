\documentclass{LMCS}
\usepackage{latexsym}
\usepackage{amssymb,xspace,latexsym,epic,eepic,graphicx}
\usepackage{epsfig,amsmath}
\usepackage{oldgerm}
\usepackage{color}
\usepackage{enumerate,hyperref}


\newcommand{\OMIT}[1]{}
\newcommand{\dupl}{Player II}
\newcommand{\spoiler}{Player I}
\newcommand{\M}{{\mu}} 
\newcommand{\ret}{\M}  
\newcommand{\w}{{\bar{w}}}
\newcommand{\echild}{\prec_{\rm ch}}
\newcommand{\esib}{\prec_{\rm sb}}
\newcommand{\ch}{\echild}
\newcommand{\sbl}{\esib}
\newcommand{\e}{\varepsilon}
\newcommand{\dm}{\Diamond}
\newcommand{\raiz}{{\tt root}}
\newcommand{\desc}{\preceq_{\rm desc}}\newcommand{\sib}{\preceq_{\rm sib}}\newcommand{\lsib}{\prec_{\rm sib}}

\newcommand{\bpre}{\Box(\ch)}
\newcommand{\dpre}{\dm(\ch)}
\newcommand{\bsib}{\Box(\sbl)}
\newcommand{\dsib}{\dm(\sbl)}
\newcommand{\calcmu}{L_\mu} 
\newcommand{\muc}{\calcmu}
\newcommand{\calcmuq}{C^{{\rm mod}}_\mu}
\newcommand{\mucmod}{\calcmuq}
\newcommand{\calcmuqsim}{\mucmod}
\newcommand{\calcmuth}{C_\mu}
\newcommand{\cmuc}{\calcmuth}
\newcommand{\calcmuthsim}{\cmuc}
\newcommand{\calcmusib}{\muc^{{\rm full}}}
\newcommand{\fmuc}{\calcmusib}
\newcommand{\cfmuc}{\cmuc^{{\rm full}}}
\newcommand{\fcmuc}{\cfmuc}
\newcommand{\calcmusibsim}{\fmuc}

\newcommand{\ctl}{{\rm CTL}^\star}
\newcommand{\ctlpast}{\ctl_{{\rm past}}}
\newcommand{\ctlth}{{\rm CTL}^\star_{{\rm count}}}
\newcommand{\cctl}{\ctlth}
\newcommand{\cctlpast}{\ctl_{{\rm count,}\;{\rm past}}}
\newcommand{\msom}{\rm{MSO}(\desc)}
\newcommand{\mso}{\rm{MSO}(\desc,\sib)}
\newcommand{\fo}{\rm{FO}(\desc,\sib)}
\newcommand{\fom}{\rm{FO}(\desc)}  
\newcommand{\CMSO}{{\rm CMSO}}
\newcommand{\cmso}{\rm{CMSO}(\desc)}
\newcommand{\inv}[1]{(#1)_{{\rm inv}}}
\newcommand{\invmso}{(\rm{MSO}(\desc)\,+ <_{\rm sib})_{\rm{inv}}}
\newcommand{\invfo}{(\rm{FO}(\desc)\,+ <_{\rm sib})_{\rm{inv}}}
\newcommand{\invfom}{(\rm{FO}(\desc)\, + <)_{\rm{inv}}}
\newcommand{\invmsom}{(\rm{MSO}(\desc)\, + <)_{\rm{inv}}}
\newcommand{\htau}{\hat{\tau}}
\newcommand{\cdott}{\!\cdot\!}
\newcommand{\sProof}[1]{\vspace{2mm}{\noindent\em Proof.~}#1\qed} 
\newcommand{\aProof}[2]{\vspace{2mm}{\noindent\em Proof of
#1.~}#2\qed}
\newcommand{\A}{{\mathcal{A}}}
\newcommand{\B}{{\mathcal{B}}}
\newcommand{\C}{{\mathcal{C}}}
\newcommand{\R}{{\mathcal{R}}}
\newcommand{\LL}{{\mathcal{L}}}
\newcommand{\CC}{{\mathcal{C}}}
\newcommand{\WW}{{\mathcal{W}}}
\newcommand{\MM}{\mathfrak{M}}
\renewcommand{\SS}{{\mathcal{S}}}

\newcommand{\E}{{\mathbf E}}
\newcommand{\G}{{\mathbf G}}

\newcommand{\F}{{\mathbf F}}
\newcommand{\X}{{\mathbf X}}
\newcommand{\Y}{\X^-}
\newcommand{\HP}{{\mathbf H}}
\newcommand{\EX}{\E\X}
\newcommand{\U}{{\mathbf U}}
\newcommand{\Uabs}{\U_\M}
\renewcommand{\S}{{\mathbf S}} 
\newcommand{\Sabs}{\S_\M}

\newcommand{\next}{\text{\raisebox{1pt}{}}}
\renewcommand{\X}{\next}
\newcommand{\Xd}{\X_{\!\downarrow}}
\newcommand{\Xr}{\X_{\!\rightarrow}}
\newcommand{\Yd}{\X_{\!\uparrow}}
\newcommand{\Yr}{\X_{\!\leftarrow}}
\newcommand{\Ud}{\U_{\!\downarrow}}
\newcommand{\Sd}{\S_{\!\downarrow}}


\newcommand{\T}{\mathfrak{T}}
\newcommand{\LLL}{\mathfrak{L}}
\newcommand{\boxtheorem}{\hfill }
\newcommand{\K}{{\mathcal{K}}} 

\newcommand{\MSO}{{\rm MSO}}
\newcommand{\FO}{{\rm FO}}
\renewcommand{\l}{\ell} 
\renewcommand{\phi}{\varphi}
\newcommand{\fth}{\hfill }

\renewcommand{\P}{{\mathbf P}}
\newcommand{\wt}{\iota_{\text{\rm w-t}}}


\newcommand{\fc}{\prec_{{\rm fc}}}
\newcommand{\suc}{<^{\rm succ}}
\renewcommand{\suc}{-\!\!\!\!\!\;<}

\newcommand{\crc}[1]{#1^\circ}
\newcommand{\tp}{\text{\rm tp}}
\newcommand{\qr}{\text{\sf qr}}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}

\theoremstyle{definition}

\newtheorem{observation}[theorem]{Observation}
\newtheorem{definition}{Definition}[section]


\newcommand{\ppath}{\sigma} \newcommand{\Ul}{\U}
\newcommand{\Sl}{\S}
\newcommand{\Uc}{\U^c}
\newcommand{\aUc}{\U^{c'}}
\newcommand{\Sc}{\S^c}
\newcommand{\Ur}{\U^a}
\newcommand{\Sr}{\S^a}
\newcommand{\Up}{\U^\ppath}
\newcommand{\Sp}{\S^\ppath}
\renewcommand{\Uabs}{\Ur}
\renewcommand{\Sabs}{\Sr}
\newcommand{\Us}{\Up_s}
\newcommand{\Ss}{\Sp_s}
\newcommand{\Uss}{\Up_{ss}}
\newcommand{\Sss}{\Sp_{ss}}









\renewcommand{\c}[1]{\mathcal{#1}}


\newcommand{\qdp}[1]{\mathrm{qdp}(#1)}       

\newcommand{\odp}[1]{\mathrm{odp}(#1)}       

\newcommand{\ie}{i.\,e.}                     

\newcommand{\false}{\bot}                    

\newcommand{\true}{\top}                     

\newcommand{\ucaret}{\text{unary-}\caret}
\renewcommand{\ucaret}{\text{unary-}\nwtl}
\newcommand{\utl}{\ucaret}

\newcommand{\fotwo}{\FO^2}   







\newcommand{\always}{\Box} 
\newcommand{\eventually}{\text{\Large }}
\newcommand{\anext}{\bigcirc^a}
\newcommand{\since}{\S}  \newcommand{\auntil}{\Uabs}
\newcommand{\puntil}{\Up}
\newcommand{\asince}{\Sabs}
\newcommand{\psince}{\Sp}
\newcommand{\prev}{{\text{\Large }}}

\newcommand{\aprev}{\prev^a}

\newcommand{\dmd}{{\qbezier(0,0)(0.5,0.5)(1,1) \qbezier(0,0)(-0.5,0.5)(-1,1)
    \qbezier(0,2)(0.5,1.5)(1,1) \qbezier(0,2)(-0.5,1.5)(-1,1)}}

\newcommand{\dmdminus}{{\unitlength1.5mm
    \begin{picture}(2.2,2)(-1,0)
      \dmd \put(-0.5,1){\line(1,0){1}}
    \end{picture}}}
\newcommand{\eventuallyk}{\eventually}
\newcommand{\nextk}{\next}
\newcommand{\peventually}{\dmdminus}
\newcommand{\previously}{\prev}
\newcommand{\until}{\U}

\newcommand{\NP}{{\sc Np}}
\newcommand{\EXPTIME}{{\sc Exptime}}
\newcommand{\PTIME}{{\sc Ptime}}

\newcommand{\caret}{\text{CaRet}}

\newcommand{\ra}{\rightarrow}

\newcommand{\retr}{\mathit{ret}}
\renewcommand{\int}{\intt}
\newcommand{\AP}{\mathit{AP}}
\def\Cl{{\it cl\/}}



\def\buchi{B\"{u}chi}

\newcommand{\mret}{{\tt{mret}}}
\newcommand{\mcall}{{\tt{mcall}}}
\newcommand{\pret}{\tt{pret}}
\newcommand{\pcall}{\tt{pcall}}


\def\h{\leadsto}
\def\minus{-\infty}
\def\plus{+\infty}
\def\lt{\langle}
\def\rt{\rangle}
\def\cd{\delta_c}
\def\rd{\delta_r}
\def\prd{\delta_{pr}}
\def\id{\delta_i}

\newcommand{\dpuntil}{{\,\U^{\ppath\downarrow}}}
\newcommand{\upuntil}{{\,\U^{\ppath\uparrow}}}

\newcommand{\ltlv}{\text{\rm LTL}^\M}
\newcommand{\ltlvp}{\ltlv}\newcommand{\nwtl}{\text{\rm NWTL}}
\newcommand{\nwtlf}{\nwtl^{\text{\rm future}}}
\newcommand{\nwtlp}{\nwtl^+}
\newcommand{\nwtls}{\nwtl^s}
\newcommand{\nwtlss}{\nwtl^{ss}}
\newcommand{\intt}{{\tt int}} 
\newcommand{\LTL}{{\rm LTL}} 
\newcommand{\tltree}{\text{\rm TL}^{\text{\rm tree}}}
\newcommand{\mmuc}{\muc^m} 
\newcommand{\pres}{{\tt present}} 
\newcommand{\rett}{{\tt ret}}
\newcommand{\call}{{\tt call}}
\renewcommand{\retr}{\rett}
\renewcommand{\dpre}{\Diamond(\prec^-)}
\newcommand{\dmm}{\dm_{\M}}
\newcommand{\dmminus}{\dm^-}
\newcommand{\dmmminus}{\dm_{\M}^-}




\renewcommand{\dm}{\next}
\renewcommand{\dmminus}{\prev}
\renewcommand{\dmm}{\dm_\M}
\renewcommand{\dmmminus}{\dmminus_{\M}}


\newcommand{\sleft}{s^{\leftarrow}}
\newcommand{\sright}{s^{\rightarrow}}
\newcommand{\efeq}{\equiv}
\newcommand{\nn}{{\mathbb N}}

\newcommand{\Fraisse}{Fra\"{\i}ss\'e}
\newcommand{\LRA}{\Leftrightarrow}

\newcounter{example}
\renewcommand{\theexample}{\arabic{example}}
\newenvironment{example}{
        \refstepcounter{example}
        {\vspace{1ex}\noindent\bf Example
        \theexample}}{\boxtheorem\newline}




\def\doi{4 (4:11) 2008}
\lmcsheading {\doi}
{1--44}
{}
{}
{Jan.~17, 2008}
{Mar.~\phantom03, 2011}
{}   

\begin{document}

\title[First-Order and Temporal Logics for Nested Words]{First-Order and Temporal Logics for Nested Words}


\author[R.~Alur]{Rajeev Alur\rsuper a}
\address{{\lsuper a}Department of Computer and Information Science, University of Pennsylvania}
\email{alur@cis.upenn.edu} 

\author[M.~Arenas]{Marcelo Arenas\rsuper b}
\address{{\lsuper b}Department of Computer Science, Pontificia Universidad Cat\'olica de Chile}
\email{marenas@ing.puc.cl}

\author[P.~Barcel\'o]{Pablo Barcel\'o\rsuper c}
\address{{\lsuper c}Department of Computer Science, Universidad de Chile}
\email{pbarcelo@dcc.uchile.cl}

\author[K.~Etessami]{Kousha Etessami\rsuper d}
\address{{\lsuper d}School of Informatics, University of Edinburgh, Edinburgh}
\email{kousha@inf.ed.ac.uk}

\author[N.~Immerman]{Neil Immerman\rsuper e}
\address{{\lsuper e}Department of Computer Science,University of Massachusetts}
\email{immerman@cs.umass.edu}

\author[L.~Libkin]{Leonid Libkin\rsuper f}
\address{{\lsuper f}School of Informatics, University of Edinburgh, Edinburgh}
\email{libkin@inf.ed.ac.uk}

\keywords{Nested Word, Temporal Logic, First-Order Expressive
Completeness, Three-Variable Property,  Nested Word Automata, Model
Checking}
\subjclass{F.1.1, F.3.1, F.4.1}

\begin{revision}
  This is a revised and corrected version of the article originally
  published on November 25, 2008.
\end{revision}

\begin{abstract}
Nested words are a structured model of execution paths in procedural
programs, reflecting their call and return nesting structure.  Finite
nested words also capture the structure of parse trees and other
tree-structured data, such as XML.

We provide new temporal logics for finite and infinite nested words,
which are natural extensions of LTL, and prove that these logics are
first-order expressively-complete.  One of them is based on adding a
``within'' modality, evaluating a formula on a subword, to a logic 
previously studied in the context of verifying properties of recursive
state machines (RSMs). The other logic, NWTL, 
is based on the notion of a summary
path that uses both the linear and nesting structures. For NWTL
we show that satisfiability is EXPTIME-complete, and that
model-checking can be done in time
polynomial in the size of the RSM model and exponential in the size of
the NWTL formula (and is also 
EXPTIME-complete).

Finally, we prove that first-order logic over nested words has the
three-variable property, and we present a temporal logic for nested
words which is complete for the two-variable fragment of first-order.
\end{abstract}

\maketitle
\vfill\eject

\section{Introduction} 
\noindent An execution of a procedural program can reveal
not just a linear sequence of program states encountered during the
execution, but also the correspondence between each point during the
execution at which a procedure is called and the point when we return
from that procedure call.  This leads naturally to the notion of a
finite or infinite nested word (see \cite{nested,VPL,AEM04}).  A
nested word is simply a finite or -word supplied with an
additional binary matching relation which relates corresponding call
and return points (and of course satisfies ``well-bracketing''
properties).  Finite nested words offer an alternative way to view any
data which has both a sequential string structure as well as a
tree-like hierarchical structure.  Examples of such data are XML
documents and parse trees.

Pushdown systems (PDSs), Boolean Programs, and Recursive State
Machines (RSMs), are equivalent abstract models of procedural
programs, with finite data abstraction but unbounded call stack.
Software model checking technology is by now thoroughly developed for
checking -regular properties of runs for these models, when
the runs are viewed as ordinary words (see 
\cite{BallRajamani,moped,RSM}).  Unfortunately, temporal logic and
-regular properties over ordinary words are inadequate for
expressing a variety of properties of program executions that are
useful in interprocedural program analysis and software verification.
These include Hoare-like pre/post conditions on procedures, stack
inspection properties, and other useful program analysis properties
that go well beyond -regular (see \cite{AEM04} for some
examples).  On the other hand, many such program analysis properties
can easily be expressed when runs are viewed as nested words.  
Runs of Boolean Programs and RSMs can naturally be viewed as
nested words once we add ``summary edges'' between matching calls and
returns, and we can thus hope to extend model checking technology for
procedural programs using richer temporal logics over nested words
which remain tractable for analysis.

These considerations motivated the definition 
of Visibly Pushdown Languages (VPLs) \cite{VPL} and
the call-return temporal logic \caret{} \cite{AEM04}.
\caret\ is a temporal logic over nested words\footnote{Although
the ``nested word'' terminology was not yet used in that paper.}
which extends LTL with new temporal operators that allow for
navigation through a nested word both via its ordinary sequential
structure, as well as its matching 
call-return summary structure.
The standard LTL model checking
algorithms for RSMs and PDSs can be extended to allow model
checking of \caret{}, with essentially the same complexity \cite{AEM04}.
VPLs \cite{VPL} are a richer class of languages
that capture MSO-definable properties of nested
words.  
Recently, results about VPLs have been recast in light
of nested words, and in particular in terms of Nested Word Automata
\cite{nested} which offer a machine acceptor 
for (-)regular nested words, with all the
expected closure properties.

Over ordinary words, LTL has long been considered
the temporal logic of choice 
for program verification, not only
because its temporal operators offer the right abstraction for reasoning
about events over time, but
because it provides a good balance
between expressiveness (first-order complete), 
conciseness (can be exponentially more succinct compared to automata), 
and the complexity of  
model-checking (linear time
in the size of the finite transition system, 
and PSPACE in the size of the temporal formula).

This raises the question: 
{\em What is the right temporal logic 
for nested words?
}

The question obviously need not have a unique answer, particularly
since nested words can arise in various application domains: for
example, 
program verification, as we already discussed, or navigation and querying XML
documents under ``sequential'' representation (see, e.g., \cite{SV02}).
However, it is reasonable to hope that any good temporal logic for
nested words should possess the same basic qualities that make LTL a
good logic for ordinary words, namely: 
\begin{enumerate}[(1)]
\item  {\em first-order
expressive completeness:} LTL has the same expressive power as
first-order logic over words, and we would want the same over nested
words (of course, even more expressiveness, such as full MSO, would
be nice but natural temporal logics are subsumed by first order logic
and any further expressiveness typically comes at a cost, even over
words, of some other desirable properties); 
\item {\em reasonable
complexity for model checking and satisfiability;} and 
\item {\em nice
closure properties}: LTL is closed under boolean combinations
including negation without any blow-up, and we would want the same
for a logic over nested words. 

Finally (and perhaps least easy to
quantify), we want 
\item  {\em natural temporal operators with simple and
intuitive semantics}.  
\end{enumerate}

Unfortunately, the logic \caret{} appears to be deficient with respect
to some of these criteria: although it is easily first-order
expressible, it is believed to be incomplete but
proving incompleteness 
appears to be difficult.  
\caret{}  can express
program 
path properties (for example, every {\it lock\/} operation is
eventually followed by an {\em unlock\/} operation) and local path
properties (for example, if a procedure executes a {\em lock\/}
operation then the same procedure later executes an {\em unlock\/}
operation before returning), but it seems incapable of expressing
scope-bounded path properties (for example, every {\it lock\/}
operation in a procedure is eventually followed by an {\em unlock\/}
operation before the procedure returns).  Such scope-bounded path
properties are natural program requirements, and are expressible in
the first-order logic of nested words.  There is much related work in
the XML community on logics for trees (see, e.g., surveys
\cite{KSS03,Lib05,vianu-pods}), but they tend to have different kinds
of deficiencies for our purposes: they concentrate on the hierarchical
structure of the data and largely ignore its linear structure; also,
they are designed for finite trees.


We introduce and study new temporal logics over nested
words.  The main logic we consider, \emph{Nested Word Temporal Logic}
() extends LTL with both a future and past variant of the
standard Until operator, which is interpreted over {\em summary paths}
rather than the ordinary linear sequence of positions.  A summary
path is the unique shortest directed path one can take
between a position in a run and some future position, if one is
allowed to use both successor edges and matching call-return
summary edges.  We show that  possesses all the desirable
properties we want from a temporal logic on nested words.  In
particular, it is both first-order expressively complete and has good
model checking complexity.  Indeed we provide a tableaux construction
which translates an  formula into a Nested Word Automaton,
enabling the standard automata theoretic approach to model checking of
Boolean Programs and RSMs with complexity that is polynomial in the
size the model and EXPTIME in the size of the formula (and indeed
EXPTIME-complete). 


We then explore some alternative temporal logics, which extend
variants of \caret{} with variants of unary ``Within'' operators
proposed in \cite{AEM04}, and we show that these extensions are also
FO-complete.  However, we observe that the model checking and
satisfiability problems for these logics are 2EXPTIME-complete.  
These logics are -- provably -- more concise than , but we pay
for conciseness with added complexity.

It follows from our proof of FO-completeness for  that over
nested words, every first-order formula with one free variable can be
expressed using only 3 variables.  More generally, we show, using EF
games, that 3 variables suffice for expressing any first order formula
with two or fewer free variables, similarly to the case of words
\cite{IK} or finite trees \cite{marx-tods}.  Finally, we show that a
natural unary temporal logic over nested words is expressively
complete for first-order logic with 2 variables, echoing a similar
result known for unary temporal logic over ordinary words
\cite{EVW02}.


\subsection*{Related Work}  

VPLs and nested words were introduced
in \cite{VPL,nested}. The logic \caret\ was defined in  \cite{AEM04} 
with the goal of expressing
and checking some natural non-regular program specifications.  The
theory of VPLs and \caret\ has been recast in light of nested words in 
\cite{nested}.
Other aspects of nested words (automata
characterizations, games, model-checking) were further studied in
\cite{RSM,nested,AEM04,LMS04}. It was also observed that nested
words are closely related to a sequential, or ``event-based'' API for
XML known as SAX \cite{sax} (as opposed to a tree-based DOM API
\cite{dom}). SAX representation is very important in streaming
applications, and questions related to recognizing classes of nested
words by the usual word automata have been addressed in
\cite{SV02,Baranystacs}. 

While finite nested words can indeed be seen as XML documents under
the SAX representation, and while much effort has been spent over the
past decade on languages for tree-structured data (see,
e.g., \cite{KSS03,Lib05,vianu-pods} for surveys), adapting the logics
developed for tree-structured data is not as straightforward as it
might seem, even though from the complexity point of view,
translations between the DOM and the SAX representations are easy
\cite{luc-pods03}.  The main problem is that most such logics rely on
the tree-based representation and ignore the linear structure, making
the natural navigation through nested words rather unnatural under the
tree representation. Translations between DOM and SAX are easy for
first-order properties, but verifying navigational properties
expressed in first-order is necessarily non-elementary even for words
if one wants to keep the data complexity linear \cite{FG02}.  On the
other hand, logics for XML tend to have good model-checking properties
(at least in the finite case), typically matching the complexity of
LTL \cite{GK-jacm,neven00}.  We do employ such logics (e.g., those in
\cite{marx-pods04,marx-tods,Schl92}) in the proof of the expressive
completeness of , first by using syntactic translations that
reconcile both types of navigation, and then by combining them with a
composition game argument that extends the result to the infinite
case, which is not considered in the XML setting. This, however,
involves a nontrivial amount of work. Furthermore, ``within''
operators do not have any natural analog on trees, and the proof for
them is done by a direct composition argument on nested words.


\subsection*{Organization}
Basic notations are given in Section \ref{notations-sec}. Section
\ref{tl-sec} defines temporal logics on nested words, and Section
\ref{expcompl-sec} presents expressive completeness results. We study
model-checking in Section \ref{mc-sec}, and in Section \ref{fv-sec} we
prove the 3-variable property and present a logic for the 2-variable
fragment. 


\section{Notations} 
\label{notations-sec}

\subsection{Nested Words}

A {\em matching\/} on  or an interval  of 
consists of a binary relation  and two unary relations 
 and , satisfying the following: (1) if
 holds then  and  and ; 
(2) if  and  hold
then  and if  and  hold then ; 
(3) if  and  and  then
there exists  such that either  or .

Let  be a finite alphabet.  A {\em finite nested word} of
length  over  is a tuple , where
, and  is a matching on
.  A {\em nested -word} is a tuple
, where , and
 is a matching on .

We say that a position  in a nested word 
 is a {\em call} position if  holds;
a {\em return} position if  holds;
and an {\em internal} position if it is
neither a call nor a return.
If  holds, we say that  is the matching call of , and  is
the matching return of , and write  and . 
Calls without matching returns are {\em pending\/} calls, and returns without
matching calls are {\em pending\/} returns (sometimes we will
alternatively refer to such calls and returns as {\em unmatched}).
A nested word is said to be {\em well-matched\/} if no calls or returns are 
pending. Note that for well-matched nested words, the unary predicates
 and  are uniquely specified by the relation .

A nested word  is represented as a first-order structure
 where  is
 if  is a finite word of length  and  if
 is a nested -word;  is the usual ordering,  is
the set of positions labeled , and  is the matching
relation. When we talk about first-order logic (\FO) over nested words,
we assume \FO\ over such structures
 (i.e. the vocabulary is that of words plus the matching relation).

For a nested word , and two elements  of , we denote by
 the substructure of  (i.e. a finite nested word) induced
by elements  such that . If  we assume
that  is the empty nested word.
For nested -words , we let  denote the substructure
induced by elements .

When this is clear from the context, we do not 
distinguish references to positions in subwords  and 
itself, e.g., we shall often write  to mean
that  is true at the first position of .  

\begin{figure}
\begin{center}
\begin{picture}(0,0)\epsfig{file=nw.pstex}\end{picture}\setlength{\unitlength}{1658sp}\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup \begin{picture}(17120,1904)(2764,-4036)
\put(17101,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}6}}}}}
\put(3601,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}1}}}}}
\put(5401,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}3}}}}}
\put(6301,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}4}}}}}
\put(7201,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}5}}}}}
\put(9001,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}7}}}}}
\put(9901,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}8}}}}}
\put(10801,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}9}}}}}
\put(4501,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}2}}}}}
\put(8101,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}6}}}}}
\put(12601,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}1}}}}}
\put(14401,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}3}}}}}
\put(15301,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}4}}}}}
\put(16201,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}5}}}}}
\put(18001,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}7}}}}}
\put(18901,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}8}}}}}
\put(19801,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}9}}}}}
\put(13501,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\familydefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}2}}}}}
\end{picture} \caption{Sample nested words}
\label{fig:shape}
\end{center}
\end{figure}



Figure~\ref{fig:shape} shows two finite nested words (without the
labeling with alphabet symbols).  Nesting edges are drawn using dashed
lines.  For the first word, the relation  is ,
the set  is , and the set  is .
For the second word, the
relation  is , the set  is , and the
set  is .

Note that our definition allows a nesting edge from a position  to
its linear successor, and in that case there will be two edges from
 to ; this is the case for positions 2 and 3 of the second
sequence.  The second sequence has two pending calls and two pending
returns.  Pending calls are depicted by dashed outgoing edges and
pending returns are depicted by dashed incoming edges.  Note that
all pending return positions in a nested word appear before any of the
pending call positions (this is enforced by condition (3) of the
definition of matchings).

\subsection{Games and types}


The {\em quantifier rank} (or {\em quantifier depth}) of
an  formula  is the depth of quantifier nesting in .
The  {\em rank- type} of a structure  over a relational vocabulary
is the set \phik, 
where  ranges over FO sentences over the vocabulary.
It is well-known that there are finitely many rank- types for all
, and  
for each rank- type  there is an  sentence 
 such that  iff
the rank- type of  is . 
Sometimes we 
associate types with formulas that define them.

Many proofs in this paper make use of {\em Ehrenfeucht-Fra\"iss\'e}
(EF) games, see for example \cite{I}. This game is played on two structures,  and ,
over the same vocabulary, by two players, {\em \spoiler} and {\em
\dupl}.  In round  \spoiler\ selects a structure, say , and an
element  in the domain of ; \dupl\ responds by selecting an
element  in the domain of .  \dupl\ {\em wins} in 
rounds, for , if  defines a
partial isomorphism between  and .  Also, if  is an
-tuple in the domain of  and  is an -tuple in the
domain of , where , we write  whenever \dupl\ wins in  rounds no matter how
\spoiler\ plays, but starting from position .

We write  iff  and  have the same
rank- type, that is for every  sentence  of quantifier
rank-, . 
It is well-known that  iff \dupl\ has a
winning strategy in the -round Ehrenfeucht-Fra\"iss\`e game on
 and . 

In the proof of Theorem \ref{3var th}, we shall also use {\em
  -pebble games}. In such a game, \spoiler\ and \dupl\ have access
  to
  matching pebbles each, and each round consists of \spoiler\ 
  either removing, or placing, or replacing a pebble in one structure,
  and \dupl\ replicating the move in the other structure. The
  correspondence given by the matching pebbles should be a partial
  isomorphism. If \dupl\ can play while maintaining partial
  isomorphism for  rounds, then the structures agree on all 
  sentences of quantifier rank up to ; if \dupl\ can play while
  maintaining partial
  isomorphism forever, then the structures agree on all 
  sentences.  ( is first-order logic where at most 
  distinct variables may occur.)


\section{Temporal Logics over Nested Words}
\label{tl-sec}

\noindent We now describe our approach to temporal logics for nested words. It
is similar to the approach taken by the logic
 \cite{AEM04}. Namely, we shall consider LTL-like
logics that define the next/previous and until/since operators for
various types of paths in nested words.

All the logics will be able to refer to propositional letters,
including the base unary relations  and ,
and will be closed under all Boolean  combinations. We shall write 
for true and  for false. For all the logics, we shall define the
notion of satisfaction with respect to a position in a nested word: we
write  to denote that the formula  is true in 
position  of the word .

Since nested words are naturally represented as transition
systems with two binary relations -- the successor and the matching
relation -- in all our logics we introduce {\em next operators} 
and . The semantics of those is standard:  iff , 

iff  is a call with a matching return  (i.e.,  holds)
and .
Likewise, we shall have {\em past} operators  and :
that is,   is true in position
 iff  is true in position , and  is true
in position  
if  is a return position with matching call  and  is true at  .


\subsection{Paths in Nested Words}

The {\em until/since operators} depend on what a path is.
In general, there are various notions of paths through a nested word.
We shall consider until/since operators for paths that are unambiguous: that is, for
every pair of positions  and  with , there could be at
most one path between them. 
Then, with respect to any such given notion of a path, we
have the until and since operators with the usual semantics:
\begin{enumerate}[]
\item  iff there is a position  and a path  between them such that
   and  for every .
\item  iff there is a position  and a path  between them such that
   and  for every .
\end{enumerate}

The approach of  was to introduce three types of paths, based on
the linear successor (called {\em linear paths}), the call-return
relation (called {\em abstract paths}), and  the innermost
call relation (called {\em call paths}).

To define those, 
we need the notions  and  for each position 
-- these are the innermost call within which the current action  is
executed, and its corresponding return. 
Formally,  is the greatest
matched call position  whose 
matching return is after  (if such
a call position exists), and  is the least matched 
return position  whose matching call is before .



\begin{definition}[Linear, call and abstract paths]
Given two
 positions , a sequence 
is 
\begin{enumerate}[]
\item a {\em linear path} if  for all ;
\item a {\em call path} if  for all ;
\item an {\em abstract path} if 
\end{enumerate}
We shall denote until/since operators corresponding to these paths by 
 for linear paths,  for call paths, and 
for abstract paths.
\end{definition}



Our logics will have some of the next/previous and until/since operators. 
Some examples are:
\begin{enumerate}[]
\item When we 
restrict ourselves to the purely linear fragment, our operators are
 and , and  and , i.e., precisely LTL 
(with past operators).
\item
The logic  \cite{AEM04} has the following operators:
the next operators  and ;
the linear and abstract untils (i.e.,  and ), the call
since (i.e., ) and a previous operator ,
defined by:  
 iff  is defined and .
\end{enumerate}

Another notion of a path combines both the linear and the nesting
structure. It is the shortest directed path between two positions 
 and . Unlike
an abstract path, it decides when to skip a 
call based on position . Basically, a summary path from  to  moves along successor
edges until it finds a call position . 
If  has a matching return  such that  appears after ,
then the summary path skips the entire call from  to  and
continues from ; otherwise 
the path continues as a successor path.
Note that every abstract path is a summary path, but there are summary paths that are
not abstract paths.

\begin{definition}
A {\em summary path} between  in a nested word  is a sequence
 such that for all , 

The corresponding until/since operators are denoted by  and
. 
\end{definition}

We will also consider two special kinds of summary paths: {\em
summary-down\/} paths are allowed to use only {\em call} edges (from a
call position,  to  where  is not a return), {\em nesting} edges (from
a call to its matching return), and {\em internal} edges (from some
 to  where  is not a call and  is not a return), and {\em
summary-up\/} paths are allowed to use only {\em return} edges (from a
position preceding a return to the return), nesting edges and internal
edges.  (In other words, summary-down paths are summary paths with no
return edges and summary-up paths are summary paths with no call edges.)

We will use  and  to denote the
corresponding until operators.  A general summary path is a concatenation of a summary-up path and
summary-down path:  is equivalent to
. 


We will also study the expressiveness of various until modalities when
the logic is extended with the {\em within\/} operator, which allows
restriction to a subword.  If  is a formula, then  is a
formula, and  iff  is a call, and
, where  if  is a matched call,
 if  is an unmatched call and  is finite, and  otherwise.  In other words,  evaluates  on a
subword restricted to a single procedure.



To understand the various notions of paths in a nested word, let us
consider the left word shown in Figure~\ref{fig:shape} again.  An
abstract path uses internal and nesting edges; for
example,  and  are
abstract paths.  Summary-down paths, in addition, can use call edges;
for example,  is a summary-down
(but not an abstract) path.  Summary-up paths 
can use internal and nesting edges, and can also go 
along return edges; for example,  is a
summary-up path.  A summary path is a summary-up path followed by a
summary-down path; for example,  
in the right word of Figure ~\ref{fig:shape} is a
summary path (which also happens to be a linear path).  
Every two positions have a unique
summary path connecting them, and this is the ``shortest'' path in the
underlying graph between these positions.

\subsection{Specifying Requirements}
We now discuss how the various operators can be used for
specifying requirements for sequential structured programs.
In the classical linear-time semantics of programs,
an execution of a program is modeled as a word over program states.
In the nested-word semantics, this linear structure 
is augmented with nesting edges from
entries to exits of program blocks.
The main benefit is that using nesting edges one can 
skip procedure calls entirely, and continue to
trace a local path through the calling procedure.
A program is now viewed as a generator of nested words,
and requirements are written using temporal logics over nested words.

Suppose we want to express the requirement that, along a global
program execution, every write to a variable is followed by a read
before the variable is written again.  If  and  denote the
atomic propositions that capture write and read operations,
respectively, then the requirement is expressed by the until formula
over linear paths,

  Here,  is defined in the usual manner from the linear
until:  stands for .  This
property is clearly already expressible in LTL and does not use nesting
edges at all.

Now let us review some of the properties expressible in the nested
call-return logic \caret{} of \cite{AEM04}, but
not expressible in LTL.  In the classical verification
formalisms such as Hoare logic, correctness of procedures is expressed
using pre and post conditions.  Partial correctness of a procedure 
specifies that if the pre-condition  holds when the procedure 
is invoked, then if the procedure terminates, the post-condition 
is satisfied upon return. Total correctness, in addition, requires the
procedure to terminate.  Assume that all calls to the procedure 
are characterized by the proposition . Then, the requirement
 expresses the total correctness, while  expresses the
partial correctness.  Both these specifications crucially rely upon
the abstract-next operator.

The abstract path starting at a position inside a procedure  is
obtained by successive applications of internal and nesting edges,
 and skips over invocations of
other procedures called from . 
Using the abstract versions of temporal operators, we 
 can specify properties of such
abstract paths. For example, suppose we want to specify that
if a procedure writes to a variable, then it (that is, the same 
invocation of the same procedure) will later read it and do so before writing to it again.
The requirement is expressed by the
until formula over abstract paths


The call since-path starting at a position inside a procedure  is
obtained by successively jumping to the innermost call positions, and
encodes the active stack at that position.  Stack inspection can
specify a variety of security properties. For instance, the
requirement that a procedure  should be invoked only within the
context of a procedure , with no intervening call to an overriding
module , is expressed by the formula 

Finally, we turn to {\em scope-bounded linear-path\/} properties.  For
a procedure, the corresponding scope-bounded linear path is the linear
path (that is, the path obtained by following linear edges) from its
call to it return.  That is, a scope-bounded path corresponding to a
procedure  includes the executions of the procedures (transitively)
called by , but terminates when the current invocation of 
returns.  Properties about scope-bounded paths are useful in asserting
contracts for modules.

Suppose we want to assert that a procedure , and the procedures it
calls, do not write to a variable before it returns.  This is an
invariant of the scope-bounded path, and is captured by the formula:
 
Recall that the within operator  restricts the evaluation of a
formula to a single procedure call. 
The same requirement can also be captured using summary
paths. It is even easier to state it using summary-down paths:
  

Suppose we want to specify the requirement that if a procedure writes
to a variable then it is read along the scope-bounded path before
being written again.  We can use the within modality to express this
property:  This requirement can also
be alternatively specified using summary-down paths as follows:

The formula says that from every write operation, there is a read
operation along some summary-down path (and thus, within the same
scope) such that along the path, there is no write, and if the path
uses a summary edge, then the enclosed subword also does not contain a
write.


It is easy to see that the above requirements 
concerning scope-bounded paths are specifiable in the first-order
logic of nested words. It is conjectured that they
are not specifiable in \caret{}. 


\section{Expressive Completeness}
\label{expcompl-sec}

\noindent In this section, we study logics that are expressively complete for
\FO, i.e. temporal logics that have exactly the same power as \FO\
formulas with one free variable over finite and infinite nested words.
In other words, for every formula  of an expressively complete
temporal logic there is an \FO\ formula  such that
 iff  for every nested word 
and position  in it, and conversely, for every \FO\ formula  
there is a temporal formula  such that  iff
. 

Our starting point is a logic  (nested-word temporal logic) based
on summary paths introduced in the previous section. We show that this
logic is expressively complete for FO, and of course remains expressively
complete with the addition of other first-order expressible operators
which may be  useful for
verification of properties of procedural programs. 
When we provide upper bounds on the complexity of model checking
for , we shall in fact show that the upper bounds hold
with respect to an extension, ,  which includes
a number of additional operators.


We then look at logics close to those in the verification literature,
i.e., with operators such as {\em call} and {\em abstract until} and {\em since}, and ask
what needs to be added to them to get expressive completeness. We
confirm a conjecture of \cite{AEM04} that a {\em within} operator is
sufficient.  Such an operator evaluates a formula on a nested
subword.
We then discuss the role of this within operator. We show that, if
added to , it does not increase expressiveness, but makes the
logic exponentially more succinct.

\subsection{Expressive completeness and NWTL}

The logic  ({\em nested words temporal logic}) has next and
previous operators, as well as until and since with respect to summary
paths. That is, its formulas are given by:

where  ranges over . We use abbreviations
 for  (true in an internal
position). Note that in the absence of pending calls and returns,
 and  are definable as  and ,
respectively. 



\begin{theorem}
\label{nwtl-thm}
 over both finite and infinite nested words.
\end{theorem}

\medskip
\noindent
{\em Proof}.
 We start with the easy direction .

\begin{lemma}
\label{nwtl-to-fo-lemma}
For every  formula , there exists an \FO\ formula
 that uses at most three variables  such that
for every nested word  (finite or infinite), and every position,
 in , we have
 iff .
\end{lemma}

\aProof{Lemma \ref{nwtl-to-fo-lemma}}{The proof is by induction
on the formulas and very simple for all the cases except  and
: for example,
 

For translating , we need a few auxiliary formulas. Our first
goal is to define a formula  saying that  is
, i.e. the return of the innermost call within which  is
executed. For that, we start with 
 saying that  is a return that
is preceded by  and whose matching call precedes , 
that is,  is a
candidate for . Then the formula  is given by

Likewise, we define  stating that that  equals
, that is, the innermost call within which  is executed. 
Now define 
 
and  as . Then this
formula says that the summary path from  to  does not pass
through , assuming . With this,
 is given by

The proof for  is similar. This concludes
 the proof of
the lemma.}

In the proof of the other direction, , we shall
use a tree representation of nested words. 
The translation is 
essentially the same as in \cite{nested}. For each nested word  we
have a binary tree  (i.e., its nodes are elements of )
and a function  that maps each
position of  to a node of  as follows:
\begin{enumerate}[]
\item the first position of  is mapped into the root of ;
\item if  then:
\begin{enumerate}[(1)]
\item if  is an internal, or an unmatched call, or a matched call
  whose return is the last position of , or an unmatched
  return,
  and  is not the last position of
, then  has only child  and ;
\item if  is a matched call whose return is not the last position
  in , then  has both children  and
   and , and 
  .
\item
 if  is a matched return, then  has no children.
\end{enumerate}
\end{enumerate}
The -labels of  and  are the same. 
If  was a pending call, we label  with , and if 
was a pending return, we label  with . 

Note that 
is a bijection, and that labels  and  may only occur on
the leftmost branch of . An example of a nested word and its
translation are given in Fig.~\ref{transl-fig}.

To relate paths in nested words and paths in their tree translations,
we introduce the notions of semi-strict and strict paths. Intuitively,
a semi-strict path in a nested word corresponds to a path on
its tree translation that, in addition to following tree edges, can
jump from a node with no children to its successor in the depth-first
traversal of the tree (where depth-first starts with the right subtree
and then moves to the left subtree). A strict path is just a
path that follows tree edges.  These are both slight modifications of
summary paths.

More precisely, 
a {\em semi-strict path}
between positions  and , with , in a nested word , is
a sequence  such that

That is, when skipping a call, instead of jumping to the matching return
position, a semi-strict path will jump to its successor. 

A {\em strict path} is a semi-strict path  in which no  with  is a
matched return position. In other words, a strict path stops if it
reaches a matched return position. In particular there may be positions  in a nested word such that no strict path exists between
them.  

For example, in Fig.~\ref{transl-fig},  is a
semi-strict path. Although  is not a path in
the tree (we jump from 5 to 6), this is allowed under the definition
of semi-strict paths. Strict paths are exactly the paths on the
tree; for example,  is such a path.

\begin{figure*}
\begin{center}

\setlength{\unitlength}{0.001in}
\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup {\renewcommand{\dashlinestretch}{30}
\begin{picture}(4397,2527)(0,1010)
\put(3196,1357){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}5}}}
\put(721.000,1638.250){\arc{487.500}{3.5364}{5.8884}}
\put(46,1725){\blacken\ellipse{40}{40}}
\put(46,1725){\ellipse{40}{40}}
\put(496,1725){\blacken\ellipse{40}{40}}
\put(496,1725){\ellipse{40}{40}}
\put(946,1725){\blacken\ellipse{40}{40}}
\put(946,1725){\ellipse{40}{40}}
\put(1396,1725){\blacken\ellipse{40}{40}}
\put(1396,1725){\ellipse{40}{40}}
\put(1846,1725){\blacken\ellipse{40}{40}}
\put(1846,1725){\ellipse{40}{40}}
\put(2296,1725){\blacken\ellipse{40}{40}}
\put(2296,1725){\ellipse{40}{40}}
\put(3646,2330){\blacken\ellipse{40}{40}}
\put(3646,2330){\ellipse{40}{40}}
\put(3346,2025){\blacken\ellipse{40}{40}}
\put(3346,2025){\ellipse{40}{40}}
\put(3346,1425){\blacken\ellipse{40}{40}}
\put(3346,1425){\ellipse{40}{40}}
\put(3646,1725){\blacken\ellipse{40}{40}}
\put(3646,1725){\ellipse{40}{40}}
\put(3946,2025){\blacken\ellipse{40}{40}}
\put(3946,2025){\ellipse{40}{40}}
\put(4246,1725){\blacken\ellipse{40}{40}}
\put(4246,1725){\ellipse{40}{40}}
\path(46,1732)(496,1732)
\blacken\path(376.000,1702.000)(496.000,1732.000)(376.000,1762.000)(376.000,1702.000)
\path(496,1732)(946,1732)
\blacken\path(826.000,1702.000)(946.000,1732.000)(826.000,1762.000)(826.000,1702.000)
\path(946,1732)(1396,1732)
\blacken\path(1276.000,1702.000)(1396.000,1732.000)(1276.000,1762.000)(1276.000,1702.000)
\path(1396,1732)(1846,1732)
\blacken\path(1726.000,1702.000)(1846.000,1732.000)(1726.000,1762.000)(1726.000,1702.000)
\path(1846,1732)(2296,1732)
\blacken\path(2176.000,1702.000)(2296.000,1732.000)(2176.000,1762.000)(2176.000,1702.000)
\path(3646,2332)(3346,2032)
\blacken\path(3409.640,2138.066)(3346.000,2032.000)(3452.066,2095.640)(3409.640,2138.066)
\path(3646,2332)(3946,2032)
\blacken\path(3839.934,2095.640)(3946.000,2032.000)(3882.360,2138.066)(3839.934,2095.640)
\path(3946,2032)(4246,1732)
\blacken\path(4139.934,1795.640)(4246.000,1732.000)(4182.360,1838.066)(4139.934,1795.640)
\path(3946,2032)(3646,1732)
\blacken\path(3709.640,1838.066)(3646.000,1732.000)(3752.066,1795.640)(3709.640,1838.066)
\path(3646,1732)(3346,1432)
\blacken\path(3409.640,1538.066)(3346.000,1432.000)(3452.066,1495.640)(3409.640,1538.066)
\put(26,1499){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}1}}}
\put(486,1499){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}2}}}
\put(946,1499){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}3}}}
\put(1396,1499){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}4}}}
\put(1846,1499){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}5}}}
\put(2296,1499){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}6}}}
\put(3571,2407){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}1}}}
\put(3196,2032){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}6}}}
\put(4021,2032){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}2}}}
\put(4321,1732){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}3}}}
\put(3496,1732){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}4}}}
\put(946.000,1063.250){\arc{2242.522}{3.7806}{5.6441}}
\end{picture}
}

\caption{A nested word and its tree translation}
\label{transl-fig}
\end{center}
\end{figure*}

\OMIT{
\begin{figure*}
\begin{center}
\setlength{\unitlength}{0.001in}
\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup {\renewcommand{\dashlinestretch}{30}
\begin{picture}(4997,1177)(0,-10)
\put(4131,82){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}5}}}
\put(946.000,-143.000){\arc{2250.000}{3.7851}{5.6397}}
\put(496,525){\blacken\ellipse{40}{40}}
\put(496,525){\ellipse{40}{40}}
\put(946,525){\blacken\ellipse{40}{40}}
\put(946,525){\ellipse{40}{40}}
\put(1396,525){\blacken\ellipse{40}{40}}
\put(1396,525){\ellipse{40}{40}}
\put(46,525){\blacken\ellipse{40}{40}}
\put(46,525){\ellipse{40}{40}}
\put(1846,525){\blacken\ellipse{40}{40}}
\put(1846,525){\ellipse{40}{40}}
\put(2296,525){\blacken\ellipse{40}{40}}
\put(2296,525){\ellipse{40}{40}}
\put(4546,990){\blacken\ellipse{40}{40}}
\put(4546,990){\ellipse{40}{40}}
\put(4846,675){\blacken\ellipse{40}{40}}
\put(4846,675){\ellipse{40}{40}}
\put(4546,375){\blacken\ellipse{40}{40}}
\put(4546,375){\ellipse{40}{40}}
\put(4246,75){\blacken\ellipse{40}{40}}
\put(4246,75){\ellipse{40}{40}}
\put(4246,675){\blacken\ellipse{40}{40}}
\put(4246,675){\ellipse{40}{40}}
\put(3946,375){\blacken\ellipse{40}{40}}
\put(3946,375){\ellipse{40}{40}}
\path(46,532)(496,532)
\blacken\path(376.000,502.000)(496.000,532.000)(376.000,562.000)(376.000,502.000)
\path(496,532)(946,532)
\blacken\path(826.000,502.000)(946.000,532.000)(826.000,562.000)(826.000,502.000)
\path(946,532)(1396,532)
\blacken\path(1276.000,502.000)(1396.000,532.000)(1276.000,562.000)(1276.000,502.000)
\path(1396,532)(1846,532)
\blacken\path(1726.000,502.000)(1846.000,532.000)(1726.000,562.000)(1726.000,502.000)
\path(1846,532)(2296,532)
\blacken\path(2176.000,502.000)(2296.000,532.000)(2176.000,562.000)(2176.000,502.000)
\path(4546,982)(4246,682)
\blacken\path(4309.640,788.066)(4246.000,682.000)(4352.066,745.640)(4309.640,788.066)
\path(4546,982)(4846,682)
\blacken\path(4739.934,745.640)(4846.000,682.000)(4782.360,788.066)(4739.934,745.640)
\path(4246,682)(3946,382)
\blacken\path(4009.640,488.066)(3946.000,382.000)(4052.066,445.640)(4009.640,488.066)
\path(4246,682)(4546,382)
\blacken\path(4439.934,445.640)(4546.000,382.000)(4482.360,488.066)(4439.934,445.640)
\path(4546,382)(4246,82)
\blacken\path(4309.640,188.066)(4246.000,82.000)(4352.066,145.640)(4309.640,188.066)
\put(26,270){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}1}}}
\put(476,270){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}2}}}
\put(926,270){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}3}}}
\put(1376,270){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}4}}}
\put(1826,270){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}5}}}
\put(2276,270){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}6}}}
\put(4546,1057){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}1}}}
\put(4096,757){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}2}}}
\put(4921,682){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}6}}}
\put(3796,382){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}3}}}
\put(4621,382){\makebox(0,0)[lb]{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}4}}}
\put(721.000,438.250){\arc{487.500}{3.5364}{5.8884}}
\end{picture}
}
\caption{A nested word and its tree translation}
\label{transl-fig}
\end{center}
\end{figure*}
} 


The until/since operators for semi-strict paths and
strict paths will be denoted by  and ,
respectively. Versions of  in which  are replaced by
 () will be denoted by  ().





We will use  for , 
and  for , to capture matching return and call
positions, respectively.

The proof is based on two lemmas.

\begin{lemma}
\label{nwtl-lemma-one}
.
\end{lemma}

\begin{lemma}
\label{nwtl-lemma-two}
.
\end{lemma}

This of course implies the theorem: . Note that as a corollary we
also obtain . 

\aProof{Lemma \ref{nwtl-lemma-one}}{For translating an  
formula  into an equivalent formula  of 
we need to express  with , which is simply
, and likewise for
the since operators. For translating each  formula 
into an equivalent  formula , again we need to consider
only the case of until/since operators. The formula  is
translated into
{\small

where  is a formula defined as follows:

}
The idea is that we split a semi-strict path into a semi-strict up
path (where call edges are excluded) followed by a semi-strict down
path (where return edges are excluded).  The first Until in
(\ref{trans-eq}) captures the semi-strict up path and the second Until
in  captures the semi-strict down path.
The translation for  is similar. 

The proof that the translation is correct is a rather detailed case
analysis which we have relegated to the appendix.}


\aProof{Lemma \ref{nwtl-lemma-two}}{We start with the finite case,
and then show how the inclusion extends to nested -words.

As a tool we shall need a slight modification of a result from
\cite{Schl92,marx-pods04} providing an expressively complete temporal
logic for trees with at most binary branching.  We consider binary
trees whose domain  is a prefix-closed subset of , and
we impose a condition that if  then .
When we refer to \FO\ on trees, we assume they have two successor
relations  and the descendant relation  (which is
just the prefix relation on strings) plus the labeling predicates,
which include two new labels  and  (for pending calls
and returns). Each node can be labeled 
by either a letter from , or by a letter from  and
, or by a letter from  and  (i.e. labels
 and  need not be disjoint from other labels).


We also consider the following logic :

where  ranges over , with the following semantics:
\begin{enumerate}[]
\item  iff  for some ;
\item  iff  (where
   is either  or );
\item  iff ;
\item  iff ;
\item  iff there exists  such that , , and  for all
   such that ;
\item  iff there exists  such that , , and  for all
   such that .
\end{enumerate}

\begin{lemma}
\label{marx-lemma}
(see \cite{marx-pods04})\ For unary queries over finite binary trees,
.
\end{lemma}

This lemma is an immediate corollary of expressive completeness of
logic  from \cite{marx-pods04} on
ordered unranked trees, as for a fixed number of siblings, the until
and since operators can be expressed in terms of the next and previous
operators. The result of \cite{marx-pods04} applies to arbitrary
alphabets, and thus in particular to our labeling that may use
 and .

The following is immediate by using the tree representation of nested
words and a straightforward
translation of formulae. 

\begin{claim}
\label{fo-to-fo-claim}
For every  formula  over nested words there is an \FO\
formula  over trees such that for every nested word  and
a position  in it, we have  iff
. 
\end{claim}


In fact the converse, that \FO\ over trees  can be translated
into \FO\ over nested words, is true too, but we do not need it in this
proof.

Since  by Lemma \ref{marx-lemma}, all that remains to
prove is the following claim.

\begin{claim} 
\label{tltree-to-nwtl}
For every  formula , there exists an  formula
 such that for every nested word  and every position 
in it, we have 

\end{claim}

This is now done by induction, omitting the obvious cases of
propositional letters and Boolean connectives. 
We note that a path down the tree from  to 
corresponds precisely to the strict path from  to  (that
is, if such a strict path is , then
 is the path from  to
 in ). Hence, the translations of until and since
operators are:

For translating next and previous operators, and pending calls/returns, define:

Then the rest of the translation is as follows:

Now with the proof completed for finite nested words, we extend it to
the case of nested -words. Note that Claim
\ref{fo-to-fo-claim} continues to hold, and Claim
\ref{tltree-to-nwtl} provides a syntactic translation that applies to
both finite and infinite nested words, and thus it suffices to  prove an
analog of Lemma \ref{marx-lemma} for trees of the form , where
 ranges over nested -words. 

If  is a nested -word, then  has exactly one
infinite branch, which consists precisely of all nodes of the form  where  is an
{\em outer} position, i.e., not inside any (matched) call. We say that  is
inside a call if there exists a call  with a matching return 
such that . If  is an outer position, then we
shall call  an {\em outer} node in the tree  as well.

If  is an outer position which is not a matched call, then  is
also an outer position and
 is the left successor of . If  is an outer
position and a call with  being its matching return, then the
left successor of  on the infinite path is
. Furthermore, the subtree , which has  as the
root, plus its right child, and all the descendants of the right child, is
finite and isomorphic to  (note that  has no
pending calls/returns). If  is an outer position other than a
matched call, we let  be a
single node tree labeled with 's label in .

Let  now be a nested -word. For each outer position 
we let  be the rank- type of . If  is not
a matched call, such a type is completely described by 's label
(which consists of a label in  and potentially  or
). 

If  is not
an outer position, and  is an outer position such that , where  is the matching return of , then  is
the rank- type of  (i.e., the type of
 with a distinguished node corresponding to ).

Next, for a nested -word , let  be a node in 
such that . Let  enumerate all the outer
positions of , and assume that  is such that  -- that is,  is a node in the subtree . We
now define a finite word  of length  such that
its positions  are labeled , and an -word  such that
its positions  are labeled by . Next we show:

\begin{claim}
\label{nwtl-comp-claim}
Let  be two nested -words, and 
two nodes in  and  such that:
\begin{enumerate}[\em(a)]
\item ;
\item ;
\item .
\end{enumerate}
Then .
\end{claim}

\sProof{A standard composition argument shows that \dupl\ wins. If 
enumerate outer positions in  and , then a
move by \spoiler, say, in , occurs either in  with
, or in , or in  with . \dupl\
then selects  so that the response is in  according
to his winning strategy in games either (a) or (b) (if  is in
, then  is in ), and then, since the
rank- types of  and the chosen  are the same,
selects the actual response according to the winning strategy
.}

Next we show how Claim \ref{nwtl-comp-claim} proves that  is
expressible in  over infinite trees . 
First note that being an outer node is expressible: since  is
true in right children of matched calls, then 

is true if no node on the path to the root is inside a call, that is,
precisely in outer nodes. 

Next note that for each rank- type  of a tree there is a 
formula  such that if  is an outer node of
, then  iff the rank- type of
 is . If  is not a matched call, then such a type is
uniquely determined by 's label and perhaps  or ,
and thus is definable in . 

If  is a matched call, the existence of such a formula  
follows from the fact that the rank- type of
 is completely determined by the label of  and the
rank- type  of the subtree  of  rooted
at the right child of  (recall that the root only has a right
child, by the definition of ). Type  is expressible in
FO and, since  is finite, by Lemma \ref{marx-lemma} it is
expressible by a  formula . If we now
inductively take conjunction of every subformula in 
with , we obtain  
a formula  such that 
 iff 
 iff 
the rank- type of  is
. 
Hence,  is expressible in  as a Boolean
combination of propositional letters from  and formulas . Note that in this case,  does not use
 and . 

By Claim \ref{nwtl-comp-claim}, we need to express, for each node ,
the rank- types of  and  in
 over , as well as the rank- type of ,
in order to express a quantifier-rank  formula, as it will be a
Boolean combination of such formulas. Given , we need to define
 -- the outer position in whose scope  occurs -- and then
from that point evaluate two FO formulas, defining rank- types of
words over the alphabet of rank- types of finite trees. By Kamp's
theorem \cite{Kamp}, each such FO formula is equivalent to an LTL formula whose
propositional letters are rank- types of trees.

Assume we have an LTL formula  expressing the rank- type
 of . By Kamp's theorem and the separation
property for LTL, it is written using only propositional letters,
Boolean connectives,  and  (that is, no  and
). We now inductively take conjunction of each subformula of
 with  (i.e., a  formula which is true
in left successors), replace LTL connectives  and  by 
and , and replace each propositional letter  by
, to obtain a  formula . Then
 iff  has type
. Thus, for a formula 

is true in  iff the rank- type of 
is . 

The proof for  is similar. Since this word is finite,
by Kamp's theorem and the separation property, there is an LTL formula
 that uses , , propositional letters and Boolean
connectives such that  evaluated in the last position of the
word expresses its rank- type. Since there is exactly one path from
each node to the root, to translate  into a  formula
 we just need to replace propositional letters by the corresponding
formulas , and  by . Then, as for the case 
of , we have that  evaluated in 
expresses the type of . Then finally the same formula
as in the case of  evaluated in  expresses that
type.

Finally we need a  formula that expresses , the
rank- type of , when evaluated in . 
We can split this into two cases. If  is 
true in , then, as explained earlier,
the rank- type of  is a Boolean combination of
propositional 
letters, and thus definable. 

 So we now consider the case when  is 
not true in . Then  
is given by a Boolean combination of formulas that specify (1)
the label of , and (2) the rank- type of the subtree of
 rooted at the right child of  with  as a 
distinguished node. This type can be expressed by a formula 
in  over  by \cite{marx-pods04}. Hence if in
 we recursively take the conjunction of each subformula with
, we obtain a formula  of  that
expresses the type of  when evaluated in
. Thus,  is expressible by a Boolean combination
of formulas  and  where  is a propositional letter.

This completes the proof of translation of \FO\ into  over
nested -words, and thus the proof of Lemma
\ref{nwtl-lemma-two} and 
Theorem \ref{nwtl-thm}.}


Recall that  stands for a fragment of \FO\ that consists of
formulas which use at most  variables in total.
First, from our
translation from  to \FO\ we get:
\begin{corollary}
Over nested words,
every \FO\ formula with at most one free variable is equivalent to an
 formula.
\end{corollary}


\OMIT{

Furthermore, for \FO\ {\em sentences}, we can eliminate the since operator.


\begin{corollary}
\label{nwtl-cor}
For every \FO\ sentence  over finite or infinite nested words,
there is a formula  of  that does not use the since
operator  such that  iff .
\end{corollary}

{\em Proof}. 
In the proof of Theorem \ref{nwtl-thm}, we show that every \FO\
sentence over a nested word  can be translated into an
\FO\ sentence over the tree , and then, by the separation property
of  \cite{marx-pods04} is equivalent to a  formula
that does not use  and . Then, given that in the translation
of  into  we only use  in the rule
, we see that the
equivalent  formula does not use . Thus, given that in the
proof of Lemma \ref{nwtl-lemma-one}, no since operator is used in the
translations of  into  and  into , the
corollary follows for the finite case.

For the infinite case, we note that in the proof of Theorem
\ref{nwtl-thm}, for the case of \FO\ sentences we only need to specify
the type of  where  is the root. Thus, one can see
that in this case the use of  in  formulas is not
required, and hence the resulting formulas are translated into
 formulas without .
\fth
}

It is well known that LTL over -words has the separation
property, and in particular, every LTL formula is equivalent to an LTL
formula without the past connectives when evaluated in the first
position of an -word. In the case of nested words, however,
the situation is quite different from LTL. The following proposition
shows that past connectives are necessary even when one evaluates
formulae in the first position of a nested word.  We let  be
the future fragment of  (i.e. the fragment that does not use
 and the operators  and ).

\begin{proposition}
\label{nwtlf-prop}
There are \FO\ sentences over nested words that cannot be expressed in
.
\end{proposition}

{\em Proof}. 
We shall look at finite nested words; the proof for the infinite case
applies verbatim. To evaluate a formula  of  in position
 of a nested word  of length  one only needs to look at
. That is, if  and  of length  and 
respectively are such that , then
 iff  for every formula 
of . 

Furthermore, for every collection of  formulas
, one can find a number 
such that  In particular, if  stands for the word
of length  in which all positions are labeled  and the matching
relation is empty, there are numbers 
depending only on , such that 


Now consider the following  formula:  saying that the first position is
a call, and the predecessor of its matching return is labeled .  We
claim that this is not expressible in .

Assume to the contrary that there is a formula  of 
equivalent to . Let  be the collection of all
subformulas of , including  itself, and let  and
 be constructed as above. We now consider two nested words 
and  of length  whose
underlying words are  of length , such that the matching relation
 of  has one edge , and the matching relation
 of  has one edge . In other words, the only
return position of  is , and  the only
return position of  is , and thus
 and . 
Further notice that for every  we have . 

Observe that  and . 

We now prove by induction on formulas in  that for each such 
formula  we have  iff
, thus proving that  and  cannot
be equivalent. 

\begin{enumerate}[]
\item The base case of propositional letters is immediate.
\item The Boolean combinations are straightforward too.
\item Let . Then 

since .
\item Let . Then 

since .
\item Let . Assume
  . Consider three cases.
\begin{enumerate}[(1)]
\item[]Case 1: . By the hypothesis
   and we are done. 

\item[]Case 2: The witness for  occurs beyond the only
  return. Then  and
  . Since  we have
  , and by the hypothesis,
  , so .


\item[]Case 3: The witness for  occurs inside the
  call. Since for every position  we have 
  iff  and likewise for , the same summary
  path witnesses  in . 
\end{enumerate}
Thus, . 

Now assume . In the proof of
 is the same as above in Cases 1 and 2. For
Case 3, assume that in the path which is a witness for 
the position in which  is true is the 2nd or the 3rd position in
the word. Then the same path witnesses , as in
the proof of Case 3 above. Next assume it is a position with index 
higher than  (which is still labeled ) where  first
occurs. Then  must be true in all positions  with  in . Hence  is true in all such positions in
 as well, and thus the summary path in  that skips the
first call (i.e. jumps from  to ) witnesses . Hence, in all the cases
 implies , which
completes the inductive proof, and thus shows the inexpressibility of
 in . 
\qed
\end{enumerate}

\noindent
Note also that adding all other until/since pairs 
to  does not
change its expressiveness. That is, if we let  be 
, then:
\begin{corollary}
.
\end{corollary}

Later, when we provide our upper bounds for model-checking,
we shall pride the upper bounds
with respect to   rather than just .

{\em Remark}\ In the conference version, we had a corollary stating
that the since operator can be eliminated for formulae evaluated in
the first position of a nested word. It relied on the proof of Theorem
\ref{nwtl-thm} and the {\em separation property} for  claimed
in \cite{marx-pods04}. The latter, as was discovered recently, is
incorrect. The proof of  Theorem
\ref{nwtl-thm} relies only on the expressive completeness of 
which is correct \cite{Schl92,marx-tods} and thus is not affected.




\subsection{The {\em within} operator}
\label{sec-within}
We now go back to the three until/since operators originally proposed
for temporal logics on nested words, based on the the linear, call,
and abstract paths. In other words, our basic logic, denoted by 
, is 


We now extend this logic with the {\em within}  operator proposed
in \cite{AEM04}. Recall that  iff  is a call,
and , where  if  is a matched call,
 if  is an unmatched call and  is finite, and  otherwise.
  We denote this extended logic by .

\begin{theorem}
\label{within-thm}
 over both finite and infinite nested words.
\end{theorem}

\proof
The translation from  into  is similar to the
translation used in the proof of Theorem \ref{expcompl-one}. To prove
the other direction, we show how to translate  into
. Recall that by Lemma \ref{nwtl-lemma-two}, we know that
 over both finite and infinite nested words.  More
precisely, for every formula  in , we show how to
construct a formula  in  such that for
every nested word  (finite or infinite) and position  in it, we
have that  if and only if .

Since  includes the same past modalities as ,
 is trivial to define for the atomic formulas, Boolean
combinations and next and previous modalities:

Thus, we only need to show how to define  and
. Formula  is defined as: 

where  is defined as , to capture
matching return positions,  is defined as  and formulas ,  are defined as:

Moreover, formula  is defined as: 

This concludes the proof of the theorem. \qed

\subsection{\texorpdfstring{}{CaRet} and other within operators}

\newcommand{\first}{{\tt first}}

The logic , as defined in \cite{AEM04}, did not have all the
operators of . In fact it did not have the previous operators
 and , and it only had linear and abstract until
operators, and the call since operator.
That is,  was defined as 

and we assume that  ranges over , 
where 
  is true in pending returns. Notice that  is not expressible
  with the remaining operators. Recall that the operator 
  is the previous operator corresponding to call paths; formally,
   iff  is defined and .

A natural question is whether there is an expressively-complete
extension of this logic. It turns out that the past modality
, together with two {\em within} operators
based on  and  (the innermost call and its return) functions
provide such an extension.  
We
define two new formulas  and  with the semantics as
follows: 

\begin{enumerate}[]

\item 
iff , where  if  is
defined, and  otherwise.

\item  if , 
where  if  is defined, and  (if  is
finite) or  (if  is infinite) otherwise. 
\end{enumerate}



The logic obtained by adding  and  to  is denoted by
. 

\begin{theorem}
\label{expcompl-one}
 over both finite and infinite nested words.
\end{theorem}

As a corollary (to the proof) we obtain the following: 

\begin{corollary}
For every FO formula  over finite or infinite nested words, there is a
formula  of  that does not use the 
operator, such that  iff .  
\end{corollary}

The proof of this result is somewhat involved, and
relies on different techniques. The operators used in  do not
correspond naturally to tree translations of nested words, and the
lack of all until/since pairs makes a translation from 
hard. We thus use a composition argument {\em directly} on nested
words. The theorem is proved for finite nested words, but 
the same techniques can be used to prove the infinite case. 

\renewcommand{\min}{{\rm min}}
\newcommand{\maxx}{{\rm max}}

We extend the vocabulary with two constants  and , and
assume that  is always interpreted as the first element of the
nested word and  as the last element. 

Let  be a finite nested word of length  and   
and  an element in . Let
 , where , be all elements in  such that,
 for each ,  and there is an
 element  such
  that  and . Assume without loss of
 generality that .  

Fix .  Let  be the set of all rank- types of
nested words with distinguished constants  and 
(including the rank- type of the empty nested word). We define the
word  over alphabet  as follows:

\begin{enumerate}[] 

\item The element  is labeled
with the tuple whose first component is
 the rank- type of
  and whose second component is the rank-  
type of 
 if  (notice that if  then 
 is the empty nested word, and the same is true of
 if ); otherwise, it 
is labeled with the tuple whose first component is
 the rank-  type of
  and whose second component is the rank-  
type of 
 (notice that if  then 
 is the empty nested word);

\item 
for each , the element  is labeled with the tuple whose
 first component is 
 the rank- type of  and 
whose second component is 
 the rank- type of ; and 

\item if  then the element 
 is labeled with the 
the tuple whose first component is the 
rank- type of  and 
whose second component is the rank- type of 
.    
\end{enumerate} 

The following is our composition argument: 

\begin{lemma}[Composition Method] \label{lemma:comp} Let  and
 be two nested words, and let  and  be two elements in
 and , respectively.  
Then  implies .  \end{lemma}

\proof
First we need to introduce some terminology.  Let  be a finite nested
word of length  and  be a position in . Assume elements
 are defined as above.  With each element 
of  we associate an element  of  as
follows:

\begin{enumerate}[]

\item If  and  belongs to  or
, then  is the first element of
. In such case we say that  and
 are the left and right intervals represented by
, respectively. 

If  and  is an arbitrary
element of , then  is also the first (and unique) element of
. In such case we say that  and
 are the left and right intervals represented by ,
respectively.

\item 
If  and  belongs to  or , then
 is the last element of . 
In such case we say that
 and  are the left and right intervals 
represented by , 
respectively.  

\item 
If  and  belongs to  or
, for some , then
 is the -th element of . 
In such case we say that
 and 
 are the left and right intervals represented by , 
respectively.  

\end{enumerate} We denote by  and  the left and right
intervals represented by , respectively.

We now prove the lemma.  For each round  () of the
-round game on  and ,
\dupl's response  in  to an element  in , played
by \spoiler\, is defined as follows (the strategy for the case when
\spoiler\ picks a point in  is completely symmetric). Assume
that \spoiler\ plays element  in  in round
 of the -round game on  and
. Then given that , \dupl\ uses her winning strategy to choose a
response  in  to . Thus, by
definition of , we have that the right and left intervals
represented by  have the same rank- type as the right and
left intervals represented by , respectively. Hence, if 
belongs to the left interval represented by , then the \dupl\
can find response  to  according to the winning strategy for
the -round game on  and , and if  belongs to
the right interval represented by , then the \dupl\ can find
response  to  according to the winning strategy for the
-round game on  and .

Assume that for round  the elements played by following
this strategy are (1)  in , (2)
 in , (3)  in
, and (4)  in . We note that by
definition of the strategy, for every , we have that  or . Since we assume that the 's and
's are played according to a winning strategy for \dupl\ in the
-round game on  and , it
is the case that:  By the way the
strategy is defined, for each , if  and
 are the subtuples of  containing the
elements from  that belong to  and
, respectively, then the corresponding subtuples  and  of  contain the elements
from  that belong to  and ,
respectively. Further, by definition of the strategy, we also have
that  and .



We now show how to define \dupl's response in the round .  Let us
assume without loss of generality that for round  of the game on
 and , \spoiler\ picks an
element  in  that belongs to the left interval
represented by  (all the other cases can be treated in a
similar way). \dupl\ response  in  is defined as
follows. First, there must be an element  in 
such that  where
. The latter, together with the way that the
strategy is defined, implies that there is an element  in 
such that , where  is the subtuple of
 containing all the elements in 
that belong to  and  is the corresponding
subtuple of . We then set .

We show by induction that, for each , if 
and  are the first  moves played by \spoiler\ and
\dupl\ on  and ,
respectively, according to the strategy defined above, then
 defines a partial isomorphism
between  and . This is
sufficient to show
 that .
  
Assume . Since , it must be th case that the labels of the last
elements of  and  coincide.
Thus, , and we conclude that  and
 have the same label, and  is a call (resp. return) iff  is
a call (resp. return). Further, if  then 
has only one element and that element is 
   labeled , for some . Since
   ,
    also has a single element and that element is
   labeled
   . It follows that . The converse can be
   proved analogously. In the same way it is possible to show that  iff .


Assume that the property holds for . Also, assume without loss of
generality that for the round  of the game on
 and , \spoiler\ picks an
element  in  that belongs to the right interval
represented by  (all the other cases can be treated in a
similar way). We prove that  as defined above preserves the
partial isomorphism.  First we show that  iff . In this case  is the last element of
, and  implies that  is the last element of
. Since  is the first element of
,  has to be the first element of ,
which is .  

In the same way it is possible to prove that  iff
, and that  iff .


Further, it is also clear that the label of  in  is 
iff the label of  in  is , for each . Next we consider the remaining cases.

\begin{enumerate}[]

\item . Then , where  is the subtuple of  containing all the elements in  that
belong to  and  is the corresponding subtuple of
. This immediately implies that . The converse is proved analogously.

\item . This is similar to the previous
  case. 

\item Suppose first that  holds for some . Since  belongs to , we have that 
belongs to  and, thus, we only need to consider the cases
 and . If , then  and, therefore,  also
holds. If , then  and, thus,
 holds since  and  belong to 
and , respectively. 

Suppose, on the other hand, that  holds for some . We need to consider three cases: ,
 and . If , then  and, therefore,  also
holds. If , then  belongs to  and
 and, thus,  holds since 
belongs to  while  belongs to
. Finally, if , then  and, thus,  holds since  belongs
to  and every element in  is bigger than
every element in either  or .

The converse is proved analogously. 

\item Suppose first that  holds for some .  Since  belongs to the right interval represented by
, it is the case that  also belongs to
. Thus, given that , we conclude that  holds.

Second,  holds for some . It is not
hard to see that . 
We need to consider two cases: If  belongs to
, then , and thus,  holds. If
 belongs to , then 
 is the first element of  and
 is the last element of . Thus, since 
, we conclude that  is
the first element of . Further, since 
, 
we conclude that
 is the last element of . Therefore,
 holds.

The converse is proved analogously. 
\end{enumerate} 
This concludes the proof of the lemma.\qed

We now present the proof of Theorem \ref{expcompl-one}. 

\aProof{Theorem \ref{expcompl-one}}{We first show that every
 formula  is equivalent to an  formula
 over nested words, that is, for every nested word
 it is the case that  iff .  The translation is standard, and can be done by
recursively defining  from  as shown
below.  We use the notation  for the {\em
relativization} of  to elements in the interval ,
that is,  is obtained from  by replacing
each subformula of the form  with  and each subformula of the form
 with .  Here is the translation:

{\small


}


We now show the other direction, that is, .  We start by proving the result for  sentences
(that is, we prove that for every  sentence  there is an
 formula , such that  iff
), and then extend it to the case of 
formulas with one free variable.  Let  be an FO sentence. We use
induction on the quantifier rank to prove that  is equivalent to
an  formula.

For  the property trivially holds, as  is a Boolean
combination of formulas of the form , , , , etc. All of them can be easily expressed in
.

We now prove for  assuming that the property holds for .
Since every  sentence of quantifier rank  is a Boolean
combination of  sentences of the form , where
 is a formula of quantifier rank , we just have to show
how to express in  a sentence of this form.

Let  be the set of all rank- types of nested words over
alphabet . We distinguish by
 the rank- type of the empty nested word. By
induction hypothesis, for each  there is an
 formula  such that  iff the rank- type of  is .  



Let  be the set of all rank- types of words over
alphabet . We first construct, for each , an   formula  over
alphabet   such that,

 for each nested 
word  and position  of . 
    
Fix .  From Kamp's theorem \cite{Kamp}, there is
an LTL formula  over alphabet 
such that a word  satisfies  evaluated on its last
element iff the rank- type of  is . By the
separation property of LTL, we can assume that  only mentions
past modalities  and . Moreover, given that , we can also assume that  is a Boolean
combination of formulas of the form either  or , where  does not mention any temporal modality and
 is an arbitrary past LTL formula. Thus, since
 is closed under Boolean combinations, to show how
to define  from , we only need to
consider two cases: (1)  is an LTL formula over  without temporal modalities, and (2)  is
of the form , where  is an arbitrary past LTL
formula over . Next we consider these two cases.

\begin{enumerate}[] 

\item Assume that  is an LTL formula without temporal
  modalities. Then  is defined to be
  , where  is defined recursively as
  follows. Given ,  is defined as follows, where we assume that 
is the rank- type of any nested word with a single element labeled
 (): 
\begin{enumerate}[(1)]
\item If , then  is defined as the
  disjunction of the following formulas: \begin{enumerate}[(a)] 

\item
  ;

\item ; 

\item
    ; 

\item ; 

\item ; 

\item
    .
    
\end{enumerate} 

\item if  then
     is simply ; and 

\item if  and , then  is
    defined as .
    \end{enumerate}

Furthermore, if  and  are
LTL formulas without temporal modalities, then 

\item Assume that  is a formula of the form , where  is an arbitrary past LTL formula. Then
 is defined to be , where  is defined recursively as follows. Given ,  is defined as 
follows: 

\begin{enumerate}[(1)] 

\item If , then
 is defined as the disjunction of the following formulas:

\begin{enumerate}[(a)] 

\item ; 

\item ; 

\item ;

\item .

\end{enumerate}

\item if  and , then
 is defined as ;

\item if  and , then
 is defined as ; and

\item if  then  is
defined as . 

\end{enumerate} 

Furthermore, if 
and  are past LTL formulas, then  \end{enumerate}

Now, let  be an  sentence such that the
quantifier rank of  is . Then, from our composition method
 can be expressed in  as the formula
, where  is the set of all rank- types of words over
alphabet  that belong to . Thus,  can be expressed as the
following  formula: . This concludes the proof of the
theorem.

Finally, from the composition method and the previous proof we see
that the equivalence  also holds for unary
queries over nested words.}





\section{Model-Checking and Satisfiability}
\label{mc-sec}

\noindent In this section we show that both satisfiability and model-checking
are decidable in single-exponential-time for , and
in polynomial time in the size of the model.
Here we assume the model of the procedural
program is given as a Recursive State Machine (RSM) \cite{RSM}.
(Runs of an RSM can naturally be viewed as nested words
 when matching function calls (or ``box entries'') and returns 
 (or ``box exits'') along the run are paired together.) 
In fact we prove this bound
for , an \FO-complete extension of  with all of . We use automata-theoretic techniques: 
translating formulae into equivalent automata on nested words. We then
show that the logic based on adding the
{\em within} operator to , (and even just adding 
{\em within} to ) 
 requires doubly-exponential time for
model-checking, but is exponentially more succinct.

\subsection{Nested word automata}

A {\em nondeterministic \buchi\ nested word automaton\/} (BNWA)  
over an alphabet 
is a structure  consisting of
a finite set of states ,
a set of initial states ,
a set of \buchi\ accepting states   ,
a set of hierarchical symbols ,
a set of initial hierarchical symbols ,
a set of final hierarchical symbols ,
a call-transition relation ,
an  internal-transition relation , 
and a return-transition relation .
The automaton  starts in an initial state and reads the nested word from left to
right. The state is propagated along the linear edges as in the case of
a standard word automaton.
However, at a call, the nested word automaton propagates state
along the linear edge as well as a hierarchical symbol 
along the nesting edge 
(if there is no matching return,
then the latter is required to be in   for acceptance). 
At a matched return, the new state is determined based on the
state propagated along the linear edge as well as the symbol along the
incoming
nesting edge (edges incident upon unmatched returns are assumed to be labeled with
initial hierarchical symbols).


Formally, a {\em run\/}  of the automaton  over a nested word
 is a sequence  of
states along the linear edges,
and a sequence , for every call position , of hierarchical symbols 
along nesting edges,
such that  and for each position , if  is a call 
then ; 
if  is internal, then ; if  is a return such
that , then ;
and if  is an unmatched return then  for some .
The run  is accepting if 
(1) for all pending calls , , and 
(2) the final state  if  is a finite word of length , 
and for infinitely many positions , , if  is a nested -word.  
The automaton 
accepts the nested word  if it has an accepting run over .

Nested word automata have the same expressiveness as 
the monadic second order logic over
nested words, and the language emptiness problem for them can be
decided in polynomial-time~\cite{nested}.

\subsection{Tableau construction}



We now show how to build a BNWA
accepting the satisfying models of a formula of .
This leads to decision procedures for satisfiability and
model checking.


Given a formula , we wish to construct a \buchi\ nested word
automaton  whose states correspond to sets of subformulas
of .  Intuitively, given a nested word , a run , which
is a linear sequence  of states and symbols 
labeling nesting edges from call positions, should be such that each state  is
precisely the set of formulas that hold at position . The label
 is used to remember abstract-next formulas that hold at
position  and the abstract-previous formulas that hold at matching return.
For clarity of presentation, we first focus on formulas with next
operators  and , and until over summary-down paths.  



Given a formula , the closure of , denoted by
, is the smallest set that satisfies the following
properties: 
\begin{enumerate}[]
\item
 contains , , ,
, and ; 
\item
if either , or  or
 is in  then ; 
\item 
if , then ;
\item
if , then , ,
, and 
 are in
; and
\item
if  and  is not of
the form  (for any ), then . 
\end{enumerate}
It is straightforward to see that the size of
 is only linear in the size of .  Henceforth,
we identify  with the formula .

An \emph{atom} of  is a set 
that satisfies the following properties:
\begin{enumerate}[]
 \item For every , 
            iff  .
 \item For every formula ,
            iff ( or ).
 \item 
       For every formula ,
            iff
           either  or ( and  and
                      ) or
 ( and ).
 \item  contains exactly one of the elements in the set .
\item If  for some , then .
\end{enumerate}
These clauses capture local consistency requirements.
In particular, a summary-down until formula  holds at a position if either
the second argument  holds now, or  holds now and satisfaction of 
is propagated along a call, internal, or nesting edge.

A hierarchical-atom of  is a set  such that
if  then .
A hierarchical-atom contains possible abstract-next obligations to be propagated across
nesting edges.

Given a formula , we build a nested word automaton  as follows.
The alphabet  is , where  is the set of atomic
propositions. 
\begin{enumerate}[(1)]
\item
Atoms of  are states of ;
\item
An atom  is an initial state iff ;
\item
Hierarchical-atoms of  are hierarchical symbols of ;
\item
All hierarchical symbols are initial;
\item
For atoms  and a symbol ,
 is an internal transition of  iff
(a) ; and
(b) for ,  iff ; and
(c) for each ,
 iff .
\item
For atoms , a hierarchical-atom , and a symbol ,
 is a call transition of  iff
(a) ; and
(b) for ,  iff ; and
(c) for each ,
 iff ; and
(d) for each ,
 iff .
\item
For atoms , hierarchical-atom , and a symbol ,
 is a return transition of  iff
(a) ; and
(b) for ,  iff ; and
(c) for each ,
 iff ; and
(d) for each ,
 iff .

\end{enumerate}
The transition relation ensures that the current symbol is consistent
with the atomic propositions in the current state, and next operators
requirements are correctly propagated.

The sole final  hierarchical symbol is the empty hierarchical-atom.
This ensures that, in an accepting run,
at a pending call, no requirements are propagated along the nesting edge.
For each until-formula  in the closure, let  be the set
of atoms that either do not contain  or contain the second argument of .
Then a nested word  over the alphabet  satisfies   iff
there is a run  of  over  such that 
all pending call edges are labeled with the sole final hierarchical symbol, and
for each until-formula , for infinitely many positions ,
. 
This multi-\buchi\ accepting condition  can
be translated to \buchi\ acceptance as usual by adding a counter.


Now we proceed to show how to handle various forms of until operators.
In each case, we specify the changes needed to the definition of the closure
and local consistency requirements for atoms. 
\begin{enumerate}[\hbox to6 pt{\hfill}]
\item\noindent{\hskip-10 pt\bf Global paths:}\
If , then , ,
 are in .
Local consistency of  requires that
for every formula ,
            iff
           either  or ( and
                      ).
\item\noindent{\hskip-10 pt\bf Summary-up paths:}\
If , then , ,
, and 
 are in .
Local consistency of  requires that
for every formula ,
            iff
           either , or 
           ( and  and ), or
( and  and ).
\item\noindent{\hskip-10 pt\bf Abstract paths:}\
If , then , ,
, , and 
 are in .
Local consistency of  requires that
for every formula ,
            iff
           either , or 
           ( and  and ), or
( and  and  and ), 
or ( and  and  and
).
The last case accounts for propagation of the eventuality across unmatched returns.
\item\noindent{\hskip-10 pt\bf Call paths:}\
Recall that positions along a call path are related by the innermost call operator:
a call path jumps from a call position  to a position  such that .
Thus, a call path can be simulated by a summary-down path consisting of
call edges, summary edges and internal edges, where the formula is asserted
only before following the call edge. This effect is captured by using an auxiliary
operator as follows.
If , then , , ,
, and 
 are in
.
Local consistency of  requires that
for every formula ,
            iff
           either  or ( and  and
  );
and 
            iff
           either , or , or
 ( and ).
\item\noindent{\hskip-10 pt\bf Summary paths:}\
 The summary-until is handled using the fact that
 is equivalent to
.
\end{enumerate}\smallskip

\noindent Note that the definition of  stays unchanged, as
the correct propagation of requirements is handled by next and
abstract-next formulas ensured by local consistency. The eventual
satisfaction of until formulas is handled the same way as before: for
each until-formula  in the closure, let  be the set of
atoms that either do not contain  or contain the second argument
of , and it is required that each such  is visited
infinitely often.

The past-time formulas (previous, abstract-previous, and various forms of since
operators) are handled in a symmetric manner.
Thus, we have shown:

\begin{theorem}\label{exp-buchi}
For a formula  of ,
one can effectively construct a nondeterministic \buchi\ nested word automaton 
of size  accepting 
the models of .
\end{theorem}

Since the automaton  is exponential in the size of , we
can check satisfiability of  in exponential-time by testing emptiness
of . \EXPTIME-hardness follows from the corresponding hardness result for
.

\begin{corollary}
The satisfiability problem for  is \EXPTIME-complete.
\end{corollary}

When programs are modeled by nested word automata  (or
equivalently, pushdown automata, or recursive state machines), and
specifications are given by formulas  of  , 
we can use the classical automata-theoretic approach:
negate the specification, build the NWA  accepting
models that violate , take the product with the program
, and test for emptiness of .  Note
that the program typically will be given more compactly, say, as a
Boolean program~\cite{BallRajamani}, and thus, the NWA  may itself
be exponential in the size of the input.

\begin{corollary}
Model checking  specifications with respect to Boolean programs
is \EXPTIME-complete.  If the program model is given as a recursive
state machine or nested word automaton, the running time is
polynomial in the model and exponential in the  formula,
and remains \EXPTIME-complete.
\end{corollary}

\subsection{Checking the {\em within} operator}

We now show that adding {\em within} operators makes model-checking
doubly exponential. 
Given a formula  of  or , let  be a special
proposition that does not appear in . Let  be the
language of nested words  such that for each position ,
 iff .  We 
construct a doubly-exponential automaton 
that captures  .  
First, using the tableau construction for ,
we construct an exponential-size automaton  
that captures nested words that satisfy .
Intuitively, every time a proposition  is encountered,
we want to start a new copy of , and a state of  keeps track of
states of multiple copies of . 
At a call,  guesses whether the call has a matching return or not.
In the latter case, 
as in case of determinization
construction for nested word automata~\cite{nested}, 
we need to 
maintain pairs of states of  so that the join at return positions
can be done correctly.
A state of , then, is either a set of states of  or a set of pairs
of states of . We explain the latter case.
The intended meaning is that a
pair  belongs to the state of , while reading position 
of a nested word , if the subword from  to the first unmatched return
can take the automaton  from state  to state . 
When reading an internal symbol , a summary  in the current state
can be updated to , provided  has an internal transition from  to
 on symbol . Let  read a call symbol .
Consider a summary  in the current state, and a call-transition 
 of . Then  guesses the return transition  that will
be used by  at the matching return, and sends the summary
 along the call edge and the triple  along the nesting edge.
While processing a return symbol , the current state of  must contain
summaries only of the form  where the two states match, and
for each summary  retrieved from the state along the nesting edge,
the new state contains .
Finally,  must enforce that  holds when  is read.
Only a call symbol  can contain 
the proposition 
, and when reading
such a symbol,  guesses a call transition , where  is the initial
state of , and a return transition , 
where  is an accepting state of ,
and sends the summary  along the call edge and 
the symbol  along the nesting edge.




\begin{lemma}
For every formula  of , there is a nested word automaton
that accepts the language  and has size doubly-exponential
in .
\end{lemma}


Consider a formula  of .
For every within-subformula  of
,   
let  be obtained from  by
substituting each top-level subformula  in  by the
proposition .  
Each of these primed
formulas is a formula of .  Then, if we take the product of the
nested word automata accepting  corresponding to all the
within-subformulas , together with the nested word automaton
, the resulting language captures the set of
models of .  Intuitively, the automaton for  is
ensuring that the truth of the proposition  reflects the truth
of the subformula .  If  itself has a within-subformula
, then the automaton for  treats it as an
atomic proposition , and the automaton checking ,
running in parallel, makes sure that the truth of  correctly
reflects the truth of .

For the lower bound, the decision problem for LTL games can be reduced 
to the satisfiability problem for formulas with linear untils and within
operators~\cite{Madhu04}, and this shows that
for   extended with the within operator,
the satisfiability problem is 2\EXPTIME-hard.
We thus obtain:
\begin{theorem}
For the logic  extended with the within operator 
the satisfiability problem and the model checking problem with respect to
Boolean programs, are both 2\EXPTIME-complete.
\end{theorem}

\paragraph{Remark: checking  for finite nested words} For finite
nested words, one evaluates the 
complexity of checking whether the given word satisfies a formula,
 in terms of the length  of the word and the size of the formula. 
A straightforward recursion on
subformulas shows that for  formulas the complexity of
this check is , and for both logics with
{\em within} operators,  and , it is 
. 




\subsection{On {\em within} and succinctness} We saw that adding
within operators to  increases the complexity of
model-checking by one exponent. Thus there is no
polynomial-time translation from  to . We now
prove a stronger result that gives a space bound as well: while
 has the same power as , its formulae can be
exponentially more succinct than formulas of . That is, there
is a sequence , , of  formulas such that
 is of size , and the smallest formula of 
equivalent to  is of size .  For this result,
we require nested -words to be over the alphabet .


\begin{theorem}\label{succinct-theo}
 is exponentially more succinct than .
\end{theorem}

{\em Proof}. 
The proof is based upon succinctness results in \cite{EVW02,LMS}, by
adapting their examples to nested words. 

From the FO completeness of , we have that  can be
translated into . We show that at least an exponential blow-up
is necessary for such translation. More precisely, we construct a
sequence  of  formulas of size
, such that the shortest  formula that is equivalent to
 is of size . Our proof is a modification of
similar proofs given in \cite{EVW02,LMS}.  Assume , and let  be the following 
formula (here,  and  are
abbreviations for  and ,
respectively):

It is not hard to see that  iff for all positions
 in  such that  holds, if position  in
 coincides with  on , then  also
coincides with  on .

It is shown in Theorem \ref{exp-buchi} that for each 
formula , the language 

is recognized by a nondeterministic nested word automaton of size
. Thus, to prove the theorem, it is enough to show
that every such automaton for  is of size
.  Let  be a nondeterministic nested word
automaton for .  Assume that  is
an enumeration of the symbols in . For every  let  be the word  over
alphabet , where for each :

It is not hard to see that for each ,
the nested -word , where , is such that
. Let  and
 be pairs of states such that (1) there
exists an accepting run of  on  such that  is
in state  and has hierarchical symbol  in call position
, and  is in state  in internal position ;
(2) there exists an accepting run of  on  such
that  is in state  and has hierarchical symbol 
in call position , and  is in state  in internal
position . Next we show that  if . On the contrary, assume
that . Then  accepts
, which leads to a contradiction since . Given that the number
of different 's is , the latter implies that the number of
different triples of states and hierarchical symbols of  is at
least . Thus, if  is equal to the number of states of 
plus the number of hierarchical symbols of , then  and, hence, . Therefore, the size of 
is . This concludes the proof of the theorem.
\qed




\section{Finite-Variable Fragments}
\label{fv-sec}

\noindent We have already seen that \FO\ formulas in one free variable over
nested words can be written using just three distinct variables, as in
the case of the usual, unnested, words. For finite nested words this
is a consequence of a tree representation of nested words and the
three-variable property for \FO\ over finite trees \cite{marx-tods},
and for infinite nested words this is a consequence Theorem
\ref{nwtl-thm}. 

In this section we prove two results. First, we give a model-theoretic
proof that \FO\ formulas with zero, one, or two free variables over
nested words (finite or infinite) are equivalent to  formulas.
Given the  collapse, we ask whether there is
a temporal logic expressively complete for , the two-variable
fragment. We adapt techniques from \cite{EVW02}
to find a temporal logic that has the same expressiveness as 
over nested words (in a vocabulary that has successor relations
corresponding to the ``next'' temporal operators).

\subsection{The three-variable property}

\newcommand{\sland}{\;\land\;}
\newcommand{\abs}[1]{ \vert #1 \vert }

We give a model-theoretic, rather than a syntactic,
argument, that uses 
Ehrenfeucht-Fra\"{\i}ss\'e games and shows that over nested words, 
formulas with at most two free variables are equivalent to
 formulas. Note that for finite nested words, the translation
into trees, already used in the proof of Theorem \ref{nwtl-thm}, can
be done using at most three variables. This means that the result of
\cite{marx-tods} establishing the 3-variable property for finite
ordered unranked trees gives us the 3-variable property for finite
nested words. We prove that  over arbitrary
nested words.

\begin{theorem}\label{3var th}
Over finite or infinite nested words, every \FO\ formula with at most
 free variables is equivalent to an  formula.
\end{theorem}


{\em Proof}.
As we mentioned already, in the finite case this is a direct
consequence of \cite{marx-tods} so we concentrate on the infinite
case.  
It is more convenient for us to prove the result for ordered
unranked forests in which a subtree rooted at every node is
finite. The way to translate a nested -word into such a
forest is as follows: when a 
matched call  with  is encountered,
it defines a subtree with  as its root, and  as the next
sibling (note that this is different from the translation into binary
trees we used before). 
If  is an internal position, or a pending call or a pending
return position, then it has no descendants and its next sibling is .
Matched returns do not have next sibling, nor do they have any descendants.
The nodes in the forest are labeled with , ,
and the propositions in , as in the original nested word.


It is routine to define, in \FO, relations  and  for 
descendant and younger sibling in such a forest. Furthermore, from
these relations, we can define the usual  and  in nested
words using at most  variables as follows. For , the
definition is given by

and for , by
 
Thus, it suffices to prove the three-variable property for such
ordered forests, which will be referred to as , , etc.
We shall use pebble games. Let 
 be the -move, -pebble game on structures 
and  where initially pebbles  are placed on  in  and
 in .  \dupl\ has a winning strategy for  iff  and  agree on all
formulas with at most  variables and quantifier-depth .  
We know from \cite{IK}
that to prove Theorem \ref{3var th}, it suffices to show
the following,

\begin{claim}
For all , if \dupl\ has a winning strategy for the game
 , then she also has a winning
strategy for the game .
\end{claim}

We will show how \dupl\ can win the -pebble game by maintaining a
set of 3-pebble sub-games on which she will copy \spoiler's
moves and decide on good responses using her winning strategy for
these smaller 3-pebble games.   The choice of these sub-games will
partition the universe  so that each play by
\spoiler\ in the -pebble game will be answered in one -pebble
game.  This is similar to the proof that linear orderings have the
3-variable property \cite{IK}.

The subgames, , that \dupl\
maintains will all be {\em vertical} in which  and
 hold, or {\em horizontal} in which  and
 hold.

The following lemma gives the beginning strategy of \dupl\ in which she
replaces an arbitrary game configuration with a set of configurations
each of which is vertical or horizontal.

\begin{lemma}\label{Rajeev le}
If \dupl\ wins . Then there are
points  from  and  from  
such that \dupl\ wins the horizontal game
 and the vertical games
 for .
\end{lemma}

\proof
For this proof since  and  are fixed, we will 
describe a game only by listing the chosen points, 
e.g., .  We simulate two moves of the
  game, , in which we choose
  \spoiler's moves and then \dupl\ answers according to her winning
  strategy.  Let  denote the least common ancestor of  and
  . First, we have \spoiler\ place pebble  on , the
  unique child of  that is an ancestor of .  (Note that
  if  then this move can be skipped and similarly for the
  second move if .)  \dupl\ answers by placing  on
  some point .  Second, \spoiler\ should move pebble  from 
  to , the unique child of  that is an ancestor of
  .  \dupl\ moves  to some point .

Since \dupl\ has
moved according to her winning strategy, we have that she still has a
winning strategy for the three games in the statement of the lemma.
Furthermore, since  and  are siblings and we have two
remaining moves,  and  must be siblings as well.
\qed 

Using Lemma \ref{Rajeev le} we initially partition the universe
according to four subgames:
\begin{enumerate}[]
\item   with domain everything not below  or
  . Here , i.e., the parent of ,
  , i.e., the parent of  and  and  are
  the roots of  and , (the roots are not necessary but then
  the subgames are all on horizontal or vertical pairs), or
\item   with domain everything below  or ,
\item  , with domain everything below  or
  , 
\item  , with the remaining domain.
\end{enumerate}

We now have to explain, inductively, how all moves of \spoiler\ in the
-pebble game are answered by \dupl\ and how, in the process, the
universe is further partitioned.  We inductively assume that \dupl\
has a winning strategy for each of the 3-pebble, m-move sub-games.
There are two cases:

{\bf Vertical:}  \spoiler\ places a new pebble on a point  that is 
in the domain of a vertical game: .  We thus know that  is a proper
ancestor of .  The interesting case is where
neither of  and  is above the other so, without loss of generality,
assume that .  We place  on , the child of 
  that is above .  Let \dupl\
  move according to her winning strategy, placing  on some point
  .  We split the
  original game into  and  
 
so \dupl\ has a winning strategy for these 3-pebble, 
  move sub-games.  Next, in the   game we place
   on , the parent of  and we let \dupl\ answer
  according to her winning strategy, placing  on some point,
  .  We then split off the game .

Returning to the game ,  we have \spoiler\ place  on ,
the sibling of   above , and let \dupl\ answer according to her
winning strategy, placing  on some point, .  

Finally, we let \spoiler\ move  to , and let \dupl\ reply with 
on some point .  

The sub-games are thus:  , ,
, and  and \dupl\ has winning
strategies for the  game on all of them.  

{\bf Horizontal:}
In this case, we have the configuration, ,
consisting of a pair of siblings.  The only interesting case occurs
when \spoiler\ puts a new pebble on some vertex, , s.t. .  In this case, we have \spoiler\ place pebble  on , the
sibling of  above .  \dupl\ will place pebble  on some
vertex, , which must be a sibling of  and .  

Next, in the game below  and , we let \spoiler\ place pebble 
on  and we let \dupl\ answer according to her winning strategy in
this game, placing  on some vertex, .  The domain of the
original configuration is thus split into domains for three sub-games:  
,
, and
.  On each of these, \dupl\ has a winning strategy
for the 3-pebble,  move game.  

We now complete the proof that \dupl\ wins .
Whenever \spoiler\ places a new pebble on some point, say , in the
original game, \dupl\ will answer as described above, i.e., in one of
the little games we will have \dupl\ wins  where
there are  moves remaining in the big game.

\dupl\ then answers in the big game by placing the corresponding
pebble on .  To see that the resulting moves are a win for \dupl,
we must just consider  any two pebbled points, , and
.  If they came from the same sub-game, then they agree
on relations  because \dupl\ wins the sub-game.  Otherwise,
 came from one sub-game, , and 
 came from another sub-game, .  By our choice of the
domains and transitivity of , it thus follows that 
stand in the same relation with respect to  as  do.





\subsection{The two-variable fragment}
In this section, we construct a temporal logic that captures the two-variable
fragment of \FO\ over nested words. 
Note that for finite unranked trees, a navigational
logic capturing  is known \cite{marx-twovars,marx-tods}: it
corresponds to a fragment of XPath. However, translating the basic
predicates over trees into 
the vocabulary of nested words requires  variables, and thus we
cannot apply existing results even in the finite case. 

Our temporal logic will be based on several next and eventually
operators. 
Since  over a linear ordering cannot define the
successor relation but temporal logics have next operators, we
explicitly introduce successors into the vocabulary of
.  
These successor relations in effect partition the linear edges into three 
disjoint types; {\em interior} edges, {\em call} edges, and {\em return} edges,
and the nesting edges
(except those from a position to its linear successor) into two disjoint types; 
{\em call-return\/} summaries, and {\em call-interior-return\/} summaries.


\begin{enumerate}[]
\item  holds iff  and either  or 
  is not a call and  is not a   return.
\item  holds iff  is a call and  is not a return;
\item  holds iff  is not a call and  is a return.
\item  holds iff  and there is a path from  to  using only
call and return edges.
\item  holds iff  and neither  nor .
\end{enumerate} 

Let  denote the set  of all edge types.
In addition to the built-in predicates  for , we
add the {\em transitive closure} of all unions of subsets 
of these relations.
That is, for each non-empty set  of 
edge types,  let  stand for the union ,
and let  be the reflexive-transitive closure of .
Now when we refer to  over nested words, we mean  in the
 vocabulary of the unary predicates plus all the 's,
the five successor relations, and the built-in unary  and 
predicates. 

We define a temporal logic   that has
future and past versions of next operators parameterized by edge types,
and eventually operators parameterized
by a set of edge types. 
For example,  means eventually along
a path containing only call edges.
Its formulas are given by:

where  ranges over ,  ranges over ,  and  ranges over non-empty subsets of 
. 
The semantics is defined in the obvious way.  For example,
 iff 
for some position ,   and 
;  
iff for some position ,   and ;
and  iff  holds in .


For an  formula  with one free variable , let
 be its quantifier depth,
and for a  formula ,  let  
be its operator depth.

\begin{theorem} 
  \label{translation theorem}\hfil
\begin{enumerate}[\em(1)]
\item  {} is expressively complete for  over nested words.

\item If formulas are viewed as DAGs (i.e identical subformulas are shared), then
every  formula  can be converted to an equivalent
  {} formula 
of size  and .
  The translation is computable in time polynomial in
  the size of .
\item Model checking of  can be carried out with the
same worst case complexity as for NWTL.
\end{enumerate}
\end{theorem}

{\em Proof}.
The translation from   into  is standard and can be
done with negligible blow-up in the size of the formula, so we
concentrate on the other direction.
The proof generalizes the proof of an analogous result
 for unary temporal logic over words from \cite{EVW02}. 

Given an  formula  the translation procedure works
a follows. When  is atomic, \ie, of the form , it
outputs .  When  is of the form 
or ---we say that  is \emph{composite}---it
recursively computes  and , or  and outputs
 or .  The two cases that remain are
when  is of the form  or . In both cases, we say that  is
\emph{existential}. In the first case,  is equivalent to
 and, viewing  as a dummy free variable in
, this reduces to the second case.
  
In the second case, we can rewrite  in the form

where  is a propositional formula, each formula  is an
atomic order formula, each formula  is an atomic or existential
 formula with , and each formula
 is an atomic or existential  formula with
.
  
In order to be able to recurse on subformulas of  we have to
separate the 's from the 's. We first introduce a case
distinction on which of the subformulas  hold or not. We obtain
the following equivalent formulation for :

We proceed by a case distinction on which order relation holds between
 and , where . 
We consider  mutually exclusive cases, determined by
the following formulas, which we call \emph{order types}.
 
\begin{enumerate}[]
\item  is .
\item For each ,   is  .
\item For each ,   is
.
\item Let   be a sequence over  such that
, all 's are distinct, and a call never appears before return
(that is, if  then  for .
Then  stands for
{\small
}\noindent
where for , the set  equals the set ,
but with  removed if both  and  belong to this set.
\end{enumerate}

\noindent We claim  that these order types are
mutually exclusive and complete, and are expressible in  (and hence, in 
). First, let us show that the order types form a disjoint partition, 
meaning for all pairs 
such that ,  we
have exactly one of these relationships holding true. 
To see this, suppose . Then either   holds for some type 
(and the successor relations  are disjoint, for distinct 's), 
or there is a path from  to 
that uses at least two edges. 
The key observation is that a path from  to  is a summary path iff
the path does not contain a call edge followed later by a return edge.
Also, there is a unique summary path from  to .
We can now classify the paths by the edge types that this unique summary
path contains, and the order in which they first appear in the path.
For example,  holds when there is a path from  to  using 2 or more
call edges;  holds when there is a path from  to 
which begins with a call edge, uses at least one call-interior-return summary edge, 
and uses only these two types of edges; 
 holds when there is a path from  to  that can be split into
three consecutive parts:
a part containing only return edges, a part containing at least one internal 
and only internal and return edges, 
and a part containing at least one call and only call and internal edges.
Note that some of these order types are empty: for example, two summary edges can never
follow one another, and hence  can never hold. 
Emptiness of some of the order types is not relevant to the proof.



When we assume that one of these order types is true,
each atomic order formula evaluates to either  or , in
particular, each of the 's evaluates to either  or
; we will denote this truth value by . 
For example, when  holds then
(1)  is true for  and false for , and
(2)  is true if  contains  or if  contains both  and ,
and false otherwise.

We can
finally rewrite  as follows, where  stands for the
set of all order types:

If  is an order type,  an
 formula, and  an equivalent  formula, there is
a way to obtain a  formula 
equivalent to , as follows.
Assume that .
\begin{enumerate}[]
\item
For the order type ,  is  itself.
\item For each ,  
for the order type ,  is .
\item For each ,  
for the order type ,  is .
\item 
For order type , where   is a sequence over , 
 is 
 ,
where for , the set  equals the set ,
but with  removed if both  and  belong to this set.
\end{enumerate}
The case corresponding to past operators is analogous.
Our procedure will therefore recursively compute  for 
and  for  and output



Now we verify that  and  are bounded as stated
in the theorem. 
Note that the size  is measured by viewing the 
formula as a DAG, i.e., sharing identical subformulas.
That  is easily
seen from the operator depth in the translation table above. 
The proof that  for
some constant  is inductive on the quantifier depth of . The
base case is trivial, and the only interesting case in the inductive
step is when  is of the form  as above.
In this case, we have to estimate the length of (\ref{eq:translation}).
There are  possibilities for 
in (\ref{eq:translation}), and each disjunct in (\ref{eq:translation}) has
length at most 
for some constant . By induction hypothesis, the latter is bounded
by , which implies the claim,
provided  is chosen large enough.

It is straightforward to verify that our translation to  can
be computed in time polynomial in .

Model checking of  can be achieved with the same complexity
as for NWTL using a variant of the tableaux construction in Section
\ref{mc-sec}.
\qed

\section{Conclusion}

\noindent We have provided several new temporal logics over nested words
and shown that they are first-order expressively complete. 
We have furthermore shown that first-order logic over nested
words has the three-variable property, and we have also
provided a temporal logic over nested words that is complete
for two-variable first-order logic.
We have
shown, via an automata-theoretic approach based on 
nested word automata, 
that satisfiability for 
the logic  is
EXPTIME-complete,
and that model checking runs in time polynomial in the size of the
RSM model and exponential in the size of the formula.
When the within modality is added to , the complexity 
of model checking 
becomes doubly exponential.
We note that it remains open whether the original temporal logic \caret,
proposed for nested words 
in \cite{AEM04}, is first-order complete, but we conjecture that it is
not. 


\section*{Acknowledgments}
\noindent The authors were supported by: Alur -- NSF CPA award 0541149; Arenas
-- \mbox{FONDECYT} grants 1050701, 7060172 and 1070732; Arenas and Barcel\'o
-- grant P04-067-F from the Millennium Nucleus Centre for Web
Research; Immerman -- NSF grants CCF-0541018 and CCF-0830174; Libkin
-- EC grant MEXC-CT-2005-024502 and EPSRC grant E005039.

\begin{thebibliography}{99}



\bibitem{RSM}
R.~Alur, M.~Benedikt, K.~Etessami, P.~Godefroid, T.~Reps, M.~Yannakakis.
\newblock Analysis of recursive state machines. 
\newblock {\em ACM
TOPLAS} 27(4): 786--818 (2005). 

\bibitem{AEM04} 
R. Alur, K. Etessami and P. Madhusudan. 
\newblock A temporal logic of nested calls and returns.  
\newblock In {\em TACAS'04}, pages 467--481.  

\bibitem{VPL} 
R. Alur and P. Madhusudan. 
\newblock Visibly pushdown languages.  
\newblock In {\em STOC'04}, pages 202--211. 

\bibitem{nested} 
R. Alur and P. Madhusudan. 
\newblock Adding nesting structure to words.  
\newblock In {\em DLT'06}, pages 1--13.

\bibitem{BallRajamani}
T. Ball and S. Rajamani.
\newblock Bebop: A symbolic model checker for boolean programs.
\newblock In {\em SPIN'00}, pages 113--130.

\bibitem{Baranystacs}
V.~B\'ar\'any, C.~L\'oding, O.~Serre.
\newblock  Regularity problems for visibly pushdown languages. 
\newblock {\em STACS 2006}, pages 420--431. 

\bibitem{dom}
Document Object Model DOM.
\newblock {http://www.w3.org/DOM}.

\bibitem{moped}
J. Esparza and S. Schwoon.
\newblock A BDD-based model checker for recursive programs.
\newblock In {\em CAV'01},
pages {324--336}. 


\bibitem{EVW02} 
K. Etessami, M. Vardi, and T. Wilke. 
\newblock First-order logic with two variables and unary temporal
logic.  
\newblock {\em Information and Computation} 179(2): 279--295, 2002.   

\bibitem{FG02} 
M.~Frick, M.~Grohe.
\newblock  The complexity of first-order and monadic second-order
logic revisited. 
\newblock {\em LICS 2002}, 215--224. 


\bibitem{GK-jacm}
G.~Gottlob, C.~Koch.
\newblock Monadic datalog and the expressive power of languages for
web information extraction. 
\newblock {\em Journal of the ACM} 51 (2004), 74--113. 

\bibitem{I}
N.~Immerman.
\newblock {\it Descriptive Complexity}. \newblock Springer, 1999.

\bibitem{IK}
N. Immerman and D. Kozen.
\newblock Definability with bounded number
    of bound variables. \newblock {\it Information and
    Computation,} 83 (1989), 121-139. 

\bibitem{Kamp} 
H.~Kamp.
\newblock Tense Logic and the Theory of Linear Order.
\newblock   PhD thesis, UCLA, 1968.

\bibitem{KSS03}
N.~Klarlund, T.~Schwentick and D.~Suciu.
\newblock XML: model, schemas, types, logics, and queries.
\newblock In {\em Logics for Emerging Applications of Databases},
Springer, 2003, pages 1--41.






\bibitem{Lib05}
L.~Libkin.
\newblock Logics for unranked trees: an overview.
\newblock In {\em ICALP 2005}, pages 35-50. 

\bibitem{LMS04}
C.~L\"oding, P.~Madhusudan, O.~Serre.
\newblock Visibly pushdown games. 
\newblock In {\em FSTTCS 2004}, pages 408--420. 


\bibitem{Madhu04}

 P. Madhusudan, personal communication.

\bibitem{marx-pods04}
M. Marx.
\newblock Conditional XPath, the first order complete XPath dialect.
\newblock In {\em PODS'04}, pages 13--22.

\bibitem{marx-tods}
M. Marx.
\newblock Conditional XPath. 
\newblock TODS 30(4): 929--959, 2005.

\bibitem{marx-twovars}
M. Marx and M. de Rijke. 
\newblock 
Semantic characterizations of navigational XPath.
\newblock  In {\em TDM'04}, pages 67--73. 


\bibitem{neven00}
F.~Neven, T.~Schwentick.
\newblock Expressive and efficient pattern languages for
tree-structured data. 
\newblock {\em PODS'00}, pages 145-156. 


\bibitem{LMS} 
F. Laroussinie, N. Markey, and P. Schnoebelen. 
\newblock Temporal logic with forgettable past. 
\newblock In {\em LICS'02}, pages 383--392. 

\bibitem{QA} 
F. Neven and T. Schwentick.
\newblock Query automata over finite trees. 
\newblock {\em Theor. Comput. Sci.} 275(1-2): 633--674, 2002.

\bibitem{sax}
SAX: A Simple API for XML.
\newblock {\tt http://www.saxproject.org}. 

\bibitem{Schl92}
B.-H. Schlingloff. 
\newblock Expressive completeness of temporal logic of trees. 
\newblock {\em J. Appl. Non-Classical Log.} 2: 157-180, 1992.

\bibitem{luc-pods03}
L.~Segoufin.
\newblock  Typing and querying XML documents: some complexity bounds. 
\newblock In {\em PODS'03}, pages 167--178. 

\bibitem{SV02} 
L.~Segoufin, V.~Vianu.
\newblock Validating streaming XML documents. 
\newblock In {\em PODS'02},
pages 53--64. 

\bibitem{vianu-pods}
V.~Vianu.
\newblock {A web Odyssey: from Codd to XML}.
\newblock In {\em ACM PODS'01}, 
pages 1--15.
\end{thebibliography}

\appendix
\section{Proof of Lemma \ref{nwtl-lemma-one}}
\noindent
For translating each  formula  into an equivalent
 formula , we need to consider only the case of
until/since operators. The formula  is translated
into
{\small

}
where  is a formula defined as follows:
{\small

}
The proof that the translation is correct is by induction on the
structure of  formulas. Again we need to consider only the
case of until/since operators. Assume that ,  are
equivalent to  and , respectively. We need
to prove that  is equivalent to (\ref{trans-eq-app}).
\\
\\
() We first show that if 
 satisfies (\ref{trans-eq-app}), then . Given that 
satisfies (\ref{trans-eq-app}), either  or
 satisfies the second disjunct of
(\ref{trans-eq-app}). Since  and  are assumed to be
equivalent, in the former case . Thus, assume that the latter case holds. Then , since  and  are equivalent, and there
exists a summary path  such that:
{\small
}\noindent
We consider three cases. 
\begin{enumerate}[(a)]
\item[(I)] Assume that there exists a position  () such that  is a matched call position and , and let  () be
the first such position. Then only one semi-strict path with
endpoints  and  can be obtained from the sequence
 by removing all positions 
(with ) such that  is a matched call position and
; let 
be that semi-strict path. Next we show that: 

from which we conclude that . 

Given that ,  and we assume that  and  are
equivalent, we have that . Next we show
that  for every . If , then the property holds since  and we assume
that  and  are equivalent. Assume that . If  is not a return position, then  since  (recall
that  is a position in the summary path  since ). If  is a return position, then we have to
consider two cases. If , then we have that  is
not a call position since  is a return position,  is a semi-strict path and . Given that  is a position in the summary path
, we conclude that . Thus, from the fact that  is
not a call position, we conclude that . Hence, . Otherwise, , and we conclude that  is a matched call position and
. Thus, since  is the smallest one
satisfying  and , 
and we know from  (\ref{gamma-eq-one}) that
, we see that 
  and, since   is a
matched call, we conclude that  and,
therefore, .


\item[(II)] Assume that condition (I) does not hold, and also assume
that either  is not a matched call position or  is a matched
call position and . Then given that , we have that there exists a position
 
such that  and  is
either  or . Only one
semi-strict path with endpoints  and  can be
obtained from the sequence  by
removing all positions  (with ) such that 
is a matched call position and ; let  be that semi-strict path. Next we
show that:

from which we conclude that . 

Given that  and the hypothesis that
 and  are equivalent, we have that . Next we show that  for every
. If , then the property holds since .
Assume that . If  is not a return
position, then  since  (recall that  is a position in the summary
path ). If  is a return position, then we have
to consider two cases. If , then we have that 
is not a call position since  is a
semi-strict path and . Thus, given that
 is a position in the summary path , we have that , from which we conclude that
. Hence, . Otherwise, , and we conclude that 
is a matched call position and . Thus, given
that condition (I) does not hold, we have that  (since  is a position in the
summary path  and 
). Thus, given that
 is a matched call, we conclude from (\ref{gamma-eq-one}) that  and, therefore, .  

\item[(III)] We now look at the remaining cases, that is,  condition
  (I) does not hold,  is a matched call, and 
. By
  (\ref{gamma-eq-two}), this implies 
.  
{From} , we see that there exists a summary path
 such that:
{\small
}\noindent
We first show that . Assume to the contrary that . Since the first position on the path is inside the call
, there exists  such that . Given that  is not a return position (since
), we have that  and, therefore,  is also a position in the summary path . But given that  is the matching
return of  and , we have that  is not a
call position. Thus, ,
which contradicts the fact that 
witnesses formula . Therefore indeed .

Given that , we conclude
that there exists a position  such that  and  is either  or . Only one
semi-strict path with endpoints  and  can be
obtained from the sequence  by
removing all positions  (with ) such that 
is a matched call position and ; let  be that semi-strict path. Next we
show that:

from which we conclude that . 

Given that ,
we conclude that that . Next we show that  for every
. If , then the property holds since  and we assume that  and  are
equivalent.  Assume that . If  is not a return
position, then  since  (recall that  is a position in the
sequence ). If  is a return position,
then we need 
to consider two cases. If , then we have that 
is not a call position since  is a
semi-strict path and . Thus, given that
 is a position in the sequence  and  (since  is a call position), we
have that , from which we conclude that
. Hence, . If , then we have that  is
a matched call position and . Moreover, in this
case we also have that . Indeed, to see this, assume to the
contrary that . Then given that , we know that . Thus, given that  is a call position,  and , we conclude that . Therefore, given that  is a return position and  is a summary path, there exists
 such that  is a call position with matching
return . But since  and  are both positions in
the summary path  and , we
conclude that this path 
contains three positions ,  and  such that  and
 is the matching return of call position , which contradicts the
definition of summary path. So we proved  . Now we have that , from which we
conclude that  since condition (I) does
not hold and . Hence, .
\end{enumerate}

\noindent
() We now show that if , then   satisfies (\ref{trans-eq-app}). Given that , there exists a semi-strict path
 such that: 

Notice that if , then  and, therefore,
 satisfies the first disjunct of (\ref{trans-eq-app}) since
 and  are assumed to be equivalent. Thus, we
suppose that , and we consider two cases.
\begin{enumerate}[(a)]
\item[(I)] Assume that there exists  such that 
is a matched call position,  and  is not a
return position, and let  be the first such position. Then only
one summary path with endpoints  and  can be obtained
from the semi-strict path  by adding
positions  for every  such that  is a
matched call position and ; let  be that summary path. Next we show that:
\begin{center}
{\small
\begin{tabular}{l}
 \ \ \ \ \
,\\ 
,
\end{tabular}}
\end{center}
from which we conclude that  satisfies (\ref{trans-eq-app}).

We start by showing that the first condition above holds.  Let . If  is a return position, then we have that . Otherwise, by definition of
, we have that  is a position in the
semi-strict path . Thus, from (\ref{m-eq1}) we
conclude that  and, hence,  since  and  are assumed to
be equivalent. It only remains to show that . If
 is a matched call position, then by definition of  we have
that  and  are both positions in the semi-strict
path . Thus, from (\ref{m-eq1}) we
conclude that  and, therefore, . If  is not a matched call position, then we have
that  is a position in the semi-strict path . Thus, from (\ref{m-eq1}) we conclude that  and, therefore, .  

We now show that the second condition above also holds. Given that
 is a matched call position, we have to prove that . Given that  and we assume that  and  are
equivalent, we have that . If , then given that  and we assume that
 and  are equivalent, we conclude that . Thus, assume that . Next we
show that  in this case. Given that  and  is
not a return position, we have , and it only
remains to prove that . Given that , only one summary
path with endpoints  and  can be obtained from the
sequence  by adding
positions  for every  such that  is a
call position and ; let  be that summary path. Next we show that:
{\small
}\noindent
from which we conclude that .

We start by showing that the first condition above holds.  Let . If  is a return position, then we have that . Otherwise, by definition of , we have that  is a position in the semi-strict
path . Thus, from
(\ref{m-eq1}) we conclude that  and, hence,
 since  and
 are assumed to be equivalent. It only remains to show
that:

If  is a matched call position, then  is a
position in semi-strict path  and either (a)  and  is a position in
the semi-strict path ,
or (b)  and  is a position in the
semi-strict path . In
the former case, from (\ref{m-eq1}) we conclude that  and, therefore, . In the latter case, from (\ref{m-eq1}) we conclude
that  and, therefore, . Thus, if  is a matched
call position, then . Assume now that  is not a
matched call position. Given that  is a semi-strict path,  is a matched call
position,  and  is not a return position, we
have that . Thus, given that , we have
that , which implies that  is either an
internal position or a return position. Therefore,  is
a position in the semi-strict path  and, thus, from (\ref{m-eq1}) we conclude that . Hence, , and it only remains to prove
that  . On the contrary,
assume that  and . Given that  is not a call position and , we have that  is a position in the semi-strict
path . Thus, given that , we conclude that there exists a return position in
the sequence . But this leads to a
contradiction since from the fact that , we can
conclude that none of the elements , ,  is a
return position. 

To conclude this part of the proof, we need to show that the second
condition above holds, that is, . Given that , we have that  and, therefore, . It remains to show that . Given that 
, we know that  is not a return
position. If  is an internal position, then 
and, thus,  since . If  is a call
position, then  has a matching return and either  or . In the former case, we have that
 since . In the latter case,
we have that 
since . Hence, we conclude that .

\item[(II)] Assume that condition (I) does not hold, that is, assume
that there is no  such that  is a matched call
position,  and  is not a return
position. Then only one summary path with endpoints  and
 can be obtained from the semi-strict path  by adding positions  for every 
such that  is a matched call position and ;
let  be that summary
path. Next we show that: 
{\small
\begin{tabular}{l}
\hspace{-2mm} \ \ \
,\\ 
\hspace{-2mm},
\end{tabular}}

\noindent
from which we conclude that  satisfies (\ref{trans-eq-app}).

We start by showing that the first condition above holds.  Let . If  is a return position, then we have that . Otherwise, by definition of
, we have that  is a position in the
semi-strict path . Thus, from
(\ref{m-eq1}) we conclude that  and, hence,
 since  and
 are assumed to be equivalent. It only remains to show
that . If
 is a matched call position and , then given that
 is a semi-strict path and condition
(I) does not hold, we have that  and  are both
positions in the semi-strict path . Thus, from (\ref{m-eq1}) we conclude that  and, therefore, . If  is a matched call position and ,
then given that  is a semi-strict
path and condition (I) does not hold, we have that  and . Thus, given that , we conclude that . Finally, if  is not a matched
call position, then we have that  is a position in the
semi-strict path  (since ). Thus, from
(\ref{m-eq1}) we conclude that  and,
therefore, .   

To conclude the proof of the lemma, we show that the second condition
above also holds, that is, . If  is a return position, we immediately
conclude that . Thus, assume that  is not a return position. But
in this case we conclude that  is a position in the
semi-strict path  and, thus,
 since  and we assume that  and  are
equivalent. It only remains to show that:

If  is a matched call position, then given that condition
(I) does not hold, we have that . Thus, given that  and we assume that  and  are
equivalent, we conclude that  and, therefore, . If  is not a matched call position, then we
have that . Thus, given that , we have that  and, therefore, . This concludes the proof of Lemma \ref{nwtl-lemma-one}.\qed
\end{enumerate}

\end{document} 
