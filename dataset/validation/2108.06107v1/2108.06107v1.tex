





\pdfoutput=1

\documentclass[sigconf]{acmart}


\usepackage{soul}
\usepackage{adjustbox}
\usepackage{pgfplots}

\AtBeginDocument{\providecommand\BibTeX{{\normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

\copyrightyear{2021}
\acmYear{2021}
\setcopyright{acmcopyright}
\acmConference[CIKM '21] {Proceedings of the 30th ACM International Conference on Information and Knowledge Management}{November 1--5, 2021}{Virtual Event, Australia.}
\acmBooktitle{Proceedings of the 30th ACM Int'l Conf. on Information and Knowledge Management (CIKM '21), November 1--5, 2021, Virtual Event, Australia}
\acmPrice{15.00}
\acmISBN{978-1-4503-8446-9/21/11}
\acmDOI{10.1145/XXXXXX.XXXXXX}


\settopmatter{printacmref=true}

\usepackage{microtype}




\begin{document}
\fancyhead{}

\title{Aspect Sentiment Triplet Extraction Using\\ Reinforcement Learning}

\settopmatter{authorsperrow=4}

\author{Samson Yu Bai Jian}
\affiliation{\institution{SUTD, Singapore}
  \streetaddress{8 Somapah Road}
\country{}
}
\email{samson_yu@sutd.edu.sg}

\author{Tapas Nayak}
\affiliation{\institution{IIT KGP, India}
  \streetaddress{}
\country{}
}
\email{tnk02.05@gmail.com}

\author{Navonil Majumder}
\affiliation{\institution{SUTD, Singapore}
\country{}
}
\email{navonil_majumder@sutd.edu.sg}

\author{Soujanya Poria}
\affiliation{\institution{SUTD, Singapore}
\country{}
}
\email{sporia@sutd.edu.sg}
\renewcommand{\shortauthors}{Yu et al.}
\newcommand{\mymodel}{ASTE-RL}

\begin{abstract}
Aspect Sentiment Triplet Extraction (ASTE) is the task of extracting triplets of aspect terms, their associated sentiments, and the opinion terms that provide evidence for the expressed sentiments. Previous approaches to ASTE usually simultaneously extract all three components or first identify the aspect and opinion terms, then pair them up to predict their sentiment polarities. In this work, we present a novel paradigm, \textbf{\mymodel{}}, by regarding the aspect and opinion terms as arguments of the expressed sentiment in a hierarchical reinforcement learning (RL) framework. We first focus on sentiments expressed in a sentence, then identify the target aspect and opinion terms for that sentiment. This takes into account the mutual interactions among the triplet's components while improving exploration and sample efficiency. Furthermore, this hierarchical RL setup enables us to deal with multiple and overlapping triplets. In our experiments, we evaluate our model on existing datasets from laptop and restaurant domains and show that it achieves state-of-the-art performance. The implementation of this work is publicly available at \url{https://github.com/declare-lab/ASTE-RL}.
\end{abstract}







\maketitle

\section{Introduction}







Aspect-based sentiment analysis (ABSA) or target-based sentiment analysis (TBSA) is an important research area in natural language processing (NLP)~\cite{poria2020beneath, duan2021survey}. It consists of various fine-grained sentiment analysis tasks \cite{nasukawa2003sentiment, liu2010sentiment, liu2012sentiment}, with the three most fundamental being aspect/target term extraction, opinion term extraction and aspect/target term sentiment classification. Aspect Sentiment Triplet Extraction (ASTE) is a relatively new subtask of ABSA introduced by \citet{Li2019Unified,peng2020knowing}. In ASTE, the task is to extract triplets containing aspect terms, their associated sentiment polarities, and the opinion terms that express those sentiments. A sentence may contain multiple such triplets where the aspect terms or opinion terms across triplets may overlap with each other. We include an example of such triplets in Table \ref{tab:example}.







\begin{table}[ht!]
\centering
\small
\caption{An Example of ASTE Triplets Present in a Sentence}
\label{tab:example}
\resizebox{0.8\linewidth}{!}{
\begin{tabular}{|l|l|}
\hline
Sentence & \begin{tabular}[c]{@{}l@{}} Appetizers are excellent ; you can make a great \
\mathrm{\textbf{s}}_t^u = f^{u}_{s}(\mathrm{\textbf{W}}_s^u[\mathrm{\textbf{h}}_t;\mathrm{\textbf{p}}_t;\mathrm{\textbf{v}}_t^c; \mathrm{\textbf{s}}_{t-1}^{u}]),

\mathrm{\textbf{o}}_t \sim \pi_u (\mathrm{\textbf{o}}_t|\mathrm{\textbf{s}}_t^u) = softmax(\mathrm{\textbf{W}}_{\pi}^{u}\mathrm{\textbf{s}}_t^u).

\mathrm{\textbf{r}}_{t}^u =
\begin{cases}
1,\quad\ \ \ \mathrm{if\ \textbf{o}_t\ in}\ X \\
0,\quad\ \ \ \mathrm{if\ \textbf{o}_t} = \mathrm{none} \\
-1,\quad\mathrm{if\ \textbf{o}_t\ not\ in}\ X.
\end{cases}

\mathrm{\textbf{v}}_{t'}^{ctx} = g^{ctx}(\mathrm{\textbf{W}}^{ctx}_{v_{t'}}\mathrm{\textbf{s}}_{t'}^{u}).

\mathrm{\textbf{s}}_t^l = f^{l}_{s}(\mathrm{\textbf{W}}_s^l[\mathrm{\textbf{h}}_t;\mathrm{\textbf{p}}_t;\mathrm{\textbf{v}}_t^{O,A}; \mathrm{\textbf{s}}_{t-1}^{l}; \mathrm{\textbf{v}}_{t'}^{ctx};\mathrm{\textbf{h}}_t^{CLS}]).

\mathrm{\textbf{a}}_t \sim \pi_l (\mathrm{\textbf{a}}_t|\mathrm{\textbf{s}}_t^l;\mathrm{\textbf{o}}_{t'}) = softmax(\mathrm{\textbf{W}}_{\pi}^{l}[\mathrm{\textbf{o}}_{t'}]\mathrm{\textbf{s}}_t^l).

r^l_t = \begin{cases}
\lambda,\quad\ \ \ \ \ \ \mathrm{if\ tag} \ y_t\mathrm{\ is\ predicted\ correctly} \\
-0.5,\quad\mathrm{otherwise},
\end{cases}

r^l_{final} = \begin{cases}
1,\quad\ \ \ \mathrm{if\ all\ tags\ are\ predicted\ correctly} \\
-1,\quad\mathrm{otherwise}.
\end{cases}

}There will also be negative rewards in the cases where the low-level processes produce impossible predictions, namely cases where there are no or more than one  tag present, and no or more than one opinion/aspect term identified for each predicted triplet. Note that the low-level rewards are non-zero only in the case where the option  from the high-level process is correctly predicted.

\subsection{Hierarchical Policy Learning}
We learn the high-level policy by maximizing the expected total reward at each time step  as the agent samples trajectories following the high-level policies . Likewise, we learn the low-level policies by maximizing the expected total reward at each time step  as the agent samples trajectories following the low-level policies . We then optimize all policies using policy gradient methods \citep{sutton1999policy} with the REINFORCE algorithm \citep{williams1992simple, takanobu2019hierarchical}.

\subsection{Training Procedure}

We pre-train our \mymodel{} models for 40 epochs with a learning rate of 2e-5. During pre-training, we give our model the ground-truth options or actions at every time step to limit the exploration of the agent due to the high-dimensional state space in our setup. This prevents the agent from exploring too many unreasonable cases, e.g. an I tag preceding a B tag, and learning too slowly. We then fine-tune the best model (chosen based on the Dev  score) with RL policy for 15 epochs with a learning rate of 5e-6. We sample 5 trajectories for each data point during RL fine-tuning. 

We initialize the BERT parameters from pre-trained weights \citep{devlin2018bert} and update them during training for this task. We set the dimension of sentiment polarity and opinion/aspect tag embeddings at 300. For POS embeddings, we set the dimension at 25. We randomly initialize these embeddings and update them during training. We set the state vector dimension for  and  at 300. We apply dropout \cite{srivastava2014dropout} after the non-linear activations in  and  during training and set the dropout rate at 0.5. We train our models in mini-batches of size 16 and optimize the model parameters using the Adam optimizer \cite{kingma2014adam}.

\section{Experiments and Analysis}

\subsection{Datasets \& Evaluation Metrics}

\begin{table}[ht]
\caption{ASTE-Data-V2 Dataset Statistics}
\label{tab:dataset_stat}
\centering
\resizebox{0.9\linewidth}{!}{
\begin{tabular}{l|ccc|ccc|ccc|ccc}
\toprule
           & \multicolumn{3}{c|}{\texttt{14Lap}} & \multicolumn{3}{c|}{\texttt{14Rest}} &
           \multicolumn{3}{c|}{\texttt{15Rest}} &
           \multicolumn{3}{c}{\texttt{16Rest}} \\ \hline
           & Train    & Dev    & Test   & Train    & Dev    & Test  
           & Train    & Dev    & Test   & Train    & Dev    & Test    \\
           \midrule
\#sentence & 906      & 219    & 328    & 1266     & 310    & 492  & 605	& 148	& 322 & 857	& 210	& 326  \\ 
\#positive & 817      & 169    & 364    & 1692     & 404    & 773   & 783	& 185	& 317	& 1015	& 252	& 407  \\ 
\#negative & 517      & 141    & 116    & 480      & 119    & 155  & 205	& 53	& 143	& 329	& 76	& 78   \\ 
\#neutral  & 126      & 36     & 63     & 166      & 54     & 66    & 25	& 11	& 25	& 50	& 11	& 29  \\
\bottomrule
\end{tabular}
}
\vspace{-1em}
\end{table}

We use the ASTE-Data-V2 dataset\footnote{https://github.com/xuuuluuu/SemEval-Triplet-data} curated by \citet{xu2020position} to show the effectiveness of \mymodel{} in two different domains of English reviews, namely the laptop and restaurant domains. \texttt{14Rest}, \texttt{15Rest}, \texttt{16Rest} are the datasets of the restaurant domain and \texttt{14Lap} is of the laptop domain. We include the statistics of the four datasets in ASTE-Data-V2 in Table \ref{tab:dataset_stat}, where \#sentence represents the number of sentences, and \#positive, \#negative, and \#neutral represent the numbers of triplets with positive, negative, and neutral sentiment polarities respectively.

We process the sentences with BERT's WordPiece tokenizer \cite{wu2016google} to make them work for \mymodel{}. Since the WordPiece tokenization may break down the tokens in the original dataset into subwords, we need to align the opinion/aspect term annotations and our BIO tagging scheme. We tag every token that corresponds to the opinion/aspect term tokens in the original annotations with , except for the first token, which we tag with . 

We follow the evaluation metrics of \citet{xu2020position} for our experiments. An extracted triplet is correct if the entire aspect term, opinion term, and sentiment polarity match with a ground-truth triplet. We report \textbf{precision}, \textbf{recall} and  score based on this.








\begin{table*}[ht!]
\small
\caption{Results of \mymodel{} and Previous Methods on the ASTE-Data-V2 Dataset}
\resizebox{0.8\linewidth}{!}
{
\label{tab:main_results}
\centering
\begin{tabular}{l|cccc|cccc|cccc|cccc}
\toprule
     & \multicolumn{4}{c|}{\texttt{14Lap}}                & \multicolumn{4}{c|}{\texttt{14Rest}}         
     & \multicolumn{4}{c|}{\texttt{15Rest}} 
     & \multicolumn{4}{c}{\texttt{16Rest}} \\ \hline
Model            & Dev                 & Prec                 & Rec                  &                     & Dev                 & Prec                 & Rec                  &              & Dev                 & Prec                 & Rec                  &        & Dev                 & Prec                 & Rec                  &               \\ \midrule
WhatHowWhy \cite{peng2020knowing} &            -           & 37.38                 & 50.38                 & 42.87                 &           -            & 43.24                 & 63.66                 & 51.46                 & - & 48.07	& 57.51	& 52.32 & - & 46.96	& 64.24	& 54.21\\
OTE-MTL \cite{zhang2020multi} & - & 54.26 & 41.07 & 46.75 & - & 63.07 & 58.25 & 60.56 & - & 60.88 & 42.68 & 50.18 & - & 65.65 & 54.28 & 59.42 \\
 \cite{wu2020grid} & - & 58.02 & 40.11 & 47.43 & - & 71.41 & 53.00 & 60.84 & - & 64.57 & 44.33 & 52.57 & - & 70.17 & 55.95 & 62.26 \\
 \cite{xu2020position}             &  48.26  & 54.84                  & 34.44                 & 42.31                 & 53.14 & 66.76                 & 49.09                 & 56.58      & 55.06 & 59.77 & 42.27 & 49.52         & 58.45 & 63.59 & 50.97 & 56.59 \\ 
 \cite{xu2020position}             &  45.83  & 55.98                  & 35.36                 & 43.34                 & 53.54 & 61.50                 & 55.13                 & 58.14   & 60.97   & 64.37	& 44.33	& 52.50       & 60.90  & 70.94	& 57.00	& 63.21 \\
\hline
 \cite{wu2020grid} & - & 57.12 & 53.42 & 55.21 & - & 71.76 & 59.09 & 64.81 & - & 54.71 & 55.05 & 54.88 & - & 65.89 & 66.27 & 66.08 \\
 \cite{xu2020position} & 50.40 & 53.53 & 43.28 & 47.86 & 56.00 & 63.44 & 54.12 & 58.41 & 59.86 & 68.20 & 42.89 & 52.66 & 60.67 & 65.28 & 51.95 & 57.85 \\
 \cite{xu2020position} & 48.84 & 55.39 & 47.33 & 51.04 & 56.89 & 70.56 & 55.94 & 62.40 & 64.78 & 64.45 & 51.96 & 57.53 & 63.75 & 70.42 & 58.37 & 63.83 \\
TOP \cite{huang2021first} & - & 57.84 & 59.33 & 58.58 & - & 63.59 & 73.44 & 68.16 & - & 54.53 & 63.30 & 58.59 & - & 63.57 & 71.98 & 67.52 \\
BMRC \cite{chen2021bidirectional} & 56.08 & 65.91 & 52.15 & 58.18 & 62.83 & 72.17 & 65.43 & 68.64 & 72.47 & 62.48 & 55.55 & 58.79 & 70.91 & 69.87 & 65.68 & 67.35 \\
\hline
\textbf{\mymodel{}}   & 58.14 & 64.80  & 54.99 &  \textbf{59.50}   &  64.40  & 70.60   & 68.65 &  \textbf{69.61}  & 74.01 & 65.45 & 60.29 &  \textbf{62.72}  & 72.11 & 67.21 & 69.69 &  \textbf{68.41} \\
 \hspace{6mm} - Pre-training only        & 57.35  & 62.00 & 55.84 &  58.73 &  64.50 & 69.70 & 69.23 & 69.47 & 72.84 & 63.31 & 61.61 & 62.44 & 71.50 & 64.76 & 70.74 & 67.57  \\
\bottomrule
\end{tabular}
}
\end{table*}



\subsection{Baselines}



We compare the performance of \mymodel{} against the following baselines: (i) \textbf{WhatHowWhy}: \citet{peng2020knowing} proposed a multi-layer LSTM neural architecture for co-extraction of aspect terms with sentiments, and opinion terms, with a Graph Convolutional Network \cite{kipf2016semi} component to capture dependency information to enhance the co-extraction. (ii) \textbf{OTE-MTL}: \citet{zhang2020multi} proposed a multi-task learning framework to jointly extract aspect and opinion terms while parsing word-level sentiment dependencies, before conducting a triplet decoding process. We use results from \citet{huang2021first} for OTE-MTL's performance on ASTE-Data-V2. (iii) \textbf{GTS}: \citet{wu2020grid} proposed an end-to-end grid tagging framework and a grid inference strategy to exploit mutual indication between opinion factors. We use results from \citet{huang2021first} for GTS' performance on ASTE-Data-V2, and report them for two variants: bidirectional LSTM (BiLSTM) and BERT. (iv) \textbf{JET}: \citet{xu2020position} proposed a position-aware tagging scheme for triplet extraction. They encode information about sentiment polarities and distances between the start position of aspect term and the opinion term's start and end positions () or vice versa (). We report the results for two variants: BiLSTM and BERT. (v) \textbf{TOP}: \citet{huang2021first} proposed a two-stage method to enhance correlations between aspect and opinion terms. Aspect and opinion terms are first extracted with sequence labeling, and artificial tags are added to each pair to establish correlation. A sentiment polarity is then identified for each pair using the resulting representations. (vi) \textbf{BMRC}: \citet{chen2021bidirectional} proposed a transformation of the ASTE task into a multi-turn MRC task and a bidirectional MRC framework to address it. They use non-restrictive, restrictive and sentiment classification queries in a three-turn process to extract triplets. We train and test BMRC on ASTE-Data-V2 over 5 runs with different random seeds.







\begin{table}[ht!]
\caption{ Scores for Multiple and Overlapping Triplets}
\small
\label{tab:multiple_triplets}
\centering
\resizebox{0.9\linewidth}{!}{
\begin{tabular}{l|cc|cc|cc|cc}
\toprule
           & \multicolumn{2}{c|}{\texttt{14Lap}} & \multicolumn{2}{c|}{\texttt{14Rest}} &
           \multicolumn{2}{c|}{\texttt{15Rest}} &
           \multicolumn{2}{c}{\texttt{16Rest}} \\ \hline
           & ASTE-RL & BMRC & ASTE-RL & BMRC & ASTE-RL & BMRC & ASTE-RL & BMRC
           \\
           \midrule
Single & 62.46  & 63.04 & 67.44   & 66.51 & 61.33  & 59.59 & 66.31 & 67.83 \\
Multiple & 57.70 & 53.77 & 70.23 & 69.17 & 63.95 & 56.37 & 69.84 & 64.11 \\ \hline
No Overlap & 62.24  & 62.80 & 72.16   & 70.81 & 62.17  & 59.75 & 70.13 & 69.23 \\
Overlap & 55.94  & 50.18 & 67.23    & 63.96 & 63.83  & 55.48 & 65.20 &  58.59\\
\bottomrule
\end{tabular}
}
\vspace{-2.4em}
\end{table}
\subsection{Experimental Results}

The experimental results are shown in Table \ref{tab:main_results}. We observe that BERT-based models (their results are in the row above \mymodel{}'s results in Table \ref{tab:main_results}) generally perform better than the non-BERT models. Hence, we only experiment with BERT for our \mymodel{} model. We select our best model for each dataset based on its Dev  score. For reproducibility, we report the testing results averaged over 5 runs with different random seeds. \mymodel{} outperforms existing baselines on all four datasets, and significantly outperforms existing baselines on the \texttt{15Rest} dataset. When compared to the second-best performance for each dataset, we observe an average improvement of 1.68\%  score across all four datasets, and an improvement of 3.93\% on \texttt{15Rest}. We also observe that our model strikes a balance between the TOP and BMRC models in terms of precision and recall, and hypothesize that this balance can be flexibly shifted depending on  to fit dataset requirements, if we generalize , where  is the weighted harmonic mean of precision and recall.


\subsection{Effect of RL Fine-tuning}

In Table \ref{tab:main_results}, we report our results for \mymodel{} without the RL fine tuning step. In this setting, we pre-train our \mymodel{} for 40 epochs as usual and after that we run for another 15 epochs with a learning rate of 5e-6 (as used in RL fine-tuning step). As compared to the RL fine-tuning setting with multinomial sampling, this setting has lower  scores with an average decrease of 0.51\% over 5 runs with different random seeds. In this setting, our model achieves slightly higher recall, but precision is significantly lower across all four datasets. This might be because multinomial sampling encourages more exploration after the initial pre-training of 40 epochs.

\vspace{-1em}
\subsection{Analysis on Multiple \& Overlapping Triplet Extraction}



We show the results of \mymodel{} and BMRC in complex situations where there are multiple and overlapping triplets in a sentence in Table \ref{tab:multiple_triplets}. For the multiple triplet scenario, we observe that there is a performance increase for \texttt{14Rest}, \texttt{15Rest} and \texttt{16Rest} and a decrease for \texttt{14Lap} as compared to the case where only one triplet is present in a sentence. For the overlapping triplet scenario, we observe a performance increase for for \texttt{15Rest} and a decrease for \texttt{14Lap}, \texttt{14Rest} and \texttt{16Rest}.

In general, we observe that \mymodel{} can handle multiple and overlapping triplets in a sentence consistently well due to its hierarchical RL setup, as compared to BMRC. There is a total  decrease of 4.76\% for multiple triplet extraction for \mymodel{} across all four datasets as compared to 16.21\% for BMRC, and a total  decrease for overlapping triplet extraction of 16.16\% for \mymodel{} as compared to 34.38\% for BMRC. 

\vspace{-0.7em}
\section{Conclusion}
In this work, we propose a novel \mymodel{} model based on hierarchical reinforcement learning (RL) paradigm for aspect sentiment triplet extraction (ASTE). In this paradigm, we treat the aspect and opinion terms as arguments of the sentiment polarities. We decompose the ASTE task into a hierarchy of three subtasks: high-level sentiment polarity extraction, and low-level opinion and aspect term extractions. This approach is good at modeling the interactions between the three tasks and handling multiple and overlapping triplets. We incorporate the multi-turn MRC elements in our model to further improve these interactions. Our proposed model achieves state-of-the-art performance on four challenging datasets for the ASTE task.

\section*{Acknowledgments}


This project is supported by the DSO grant no. RTDST190702  awarded to SUTD titled Complex Question Answering.



















































































\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}












\end{document}
