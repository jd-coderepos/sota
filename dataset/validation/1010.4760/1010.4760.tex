\documentclass[12pt]{article}

\usepackage{a4wide}


\usepackage{amssymb}

\sloppy





\usepackage{pj-arx-dpda-macros}

\title{A Short Decidability Proof for DPDA Language Equivalence 
via First-Order Grammars
}

\author{Petr Jan\v{c}ar\\
{\small Techn. Univ. Ostrava, Czech Republic,}\\
{\small http://www.cs.vsb.cz/jancar/,
 email:petr.jancar@vsb.cz}
}


\date{}

\begin{document}

\maketitle


\begin{abstract}
\noindent
The main aim of the paper is to give a short 
self-contained proof of the decidability of
language equivalence for deterministic pushdown automata, 
which is the famous problem 
solved by G. S\'enizergues, for which  C. Stirling has 
derived a primitive recursive complexity upper bound.
The proof here is given in 
the framework of first-order grammars,
which seems to be particularly apt for the aim.
\end{abstract}

\noindent
\textbf{Keywords:} pushdown automaton, deterministic context-free
language, first-order grammar, language equivalence, trace
equivalence,
decidability 



\section{Introduction}
\label{sec:intro}


The decidability question for language equivalence of two
deterministic pushdown automata (dpda) is  a famous problem in language
theory. The question was explicitly stated in the 1960s 
\cite{Ginsburg66} (when language inclusion was found undecidable);
then a series of works solving various subcases followed,
until the question was answered positively
by S\'enizergues in 1997 
(a full version appeared in~\cite{Senizergues:TCS2001}).
G. S\'enizergues was
awarded G\"odel prize in 2002 for this significant achievement. 
Later Stirling~\cite{Stirling:TCS2001},
and also S\'enizergues~\cite{Senizergues:TCS2001_simple},
provided simpler proofs than the original long
technical proof. A modified version, which 
showed a primitive recursive complexity upper bound, appeared as a conference
paper by Stirling in 2002~\cite{Stir:DPDA:prim}.  


Nevertheless, even the above mentioned simplified proofs are rather
technical, and they seem not well understood in the (theoretical)
computer science community.
One reason might be that the frameworks like that of strict deterministic
grammars, which were chosen by S\'enizergues and Stirling, are not
ideal for presenting this topic to a broader audience. 

From some (older) works by Courcelle,
Harrison and others we know that the dpda-framework
and strict-deterministic grammar framework are equivalent 
 to the
framework of first-order schemes, or first-order grammars. 
In this paper, a proof in the framework of first-order grammars is
presented.

\emph{Author's remark.}
I have been reminded that J.~R.~B\"uchi in his book 
``Finite automata, their algebras and grammars: towards a theory of
formal expressions'' (1989)
argues that using terms
is the way proofs on context-free grammars should be done. 
I have not managed to verify myself, but this can be an indication that
the framework of first-order terms might be ``inherently more
suitable'' here.

In fact, the proof here shows
the decidability of trace equivalence (a variant of
language equivalence, coinciding with  bisimulation equivalence on 
deterministic labelled transition systems) for deterministic first-order
grammars; the states (configurations) are first-order terms which can
change by performing actions according to the root-rewriting rules.
To make the paper self-contained, a reduction from 
the dpda language equivalence problem to the above trace equivalence
problem is given in an appendix.

In principle, the proof is lead in a similar manner as the proofs of
S\'enizergues and Stirling, being based on the same abstract ideas.
Nevertheless, the framework of the first-order terms seems to allow to
highlight the basic ideas in a more
clear way and to provide
a shorter proof in the form of
a sequence of relatively simple observations.
Though the proof is the ``same'' as the previous ones on an abstract
level, and each particular idea used here might be embedded somewhere in the
previous proofs, it is by no means a ``mechanical translation'' of a
proof (or proofs) from one framework to another.
Another appendix then shows that the framework
chosen here also has a potential to concisely comprise
and slightly strengthen the previous
knowledge of the complexity of the problem, though the proofs in that
part are not so detailed as in the decidability part.

\emph{Author's remarks.}
I hope that the presentation here should significantly extend the number of
people in the community who will 
understand
the problem which seems to belong to fundamental ones; this might also
trigger new attempts regarding the research of complexity. 
Another remark concerns
the previous version(s) of this arxiv-paper where I also claimed to
provide a smooth generalization of the decidability proof to the case
of bisimilarity for nondeterministic first-order grammars.
G\'eraud S\'enizergues was present at my talk at 
http://www.lsv.ens-cachan.fr/Events/Pavas/ (20 January, 2011) and he
later put a counterexample on arxiv: http://arxiv.org/abs/1101.5046.
(My mistake was, in fact, embarrassingly simple, mixing the
absolute equivalence levels with the eq-levels relative to fixed
strategies. At the moment, I do not speculate how this can be
corrected.)

In the rest of this section, the main ideas are sketched.
A GNF (Greibach Normal Form) grammar , with finite sets
 of nonterminals and  of terminals, 
has the rewriting rules 
 where  and .
Such a rewrite rule can be written as  , for a
formal variable , and read as follows: 
any sequence  (a `state', or a `configuration') can perform
action  while changing into  \,;
this includes the case  when  and thus , the
empty word.
The language  is the set of words  such that 
. 

In a first-order grammar , each nonterminal 
has a finite arity (not only arity 1 like in the GNF grammar), 
and the (root rewriting) rules are 
where  and  is a finite term over  where all
occurring variables are from the set .
When  are terms then 
  where 
 denotes the result of substitution
.
Grammar  is \emph{deterministic} if for each pair ,
 there is at most one rule of the type .
We note that states (configurations) are no longer strings (as in the
case of GNF grammars) but
\emph{terms}, naturally represented as \emph{trees}. 

It is a routine to reduce dpda language equivalence 
to deterministic first-order grammar \emph{trace equivalence}:
two terms  are equivalent, ,
iff the words (traces)  enabled in 
( for some ) are the same as those enabled in .
It is natural to define the equivalence-level
  as the maximal  for which we have 
, which means that 
 enable the same words upto length ; 
we put  iff , i.e. iff  
 for all .

Given a deterministic first-order grammar
 and an initial pair of terms ,  the first idea for
deciding  
is to use the (breadth-first) search for a
shortest 
word  which is enabled in just one of .
We call such a
\emph{word} as \emph{offending} (adopting the viewpoint of a
defender of the claim ).

To get a
terminating algorithm in the case of ,
we can think of some \emph{sound system} enabling to establish for certain words
 that they are not \emph{offending prefixes}, i.e.
prefixes of offending words for  ; e.g., if 
and  then  cannot be an offending prefix.
We aim at \emph{completeness},
i.e., look for some means which enable to recognize sufficiently many
nonoffending prefixes, finally showing that  is not
offending, which means  .

We use a simple observation that
the eq-level of a pair  can drop by at most  when both sides
perform the same
action, 
and it 
really \emph{drops by  in each step} when we follow an offending
word.
It is also easy to observe a \emph{congruence property} of
\emph{subterm replacement}; in particular, given terms  with 
 and  with  
where  has a subterm , i.e. ,
by replacing  with  we get for the arising  
that ; 
the eq-level has been unaffected, and moreover, even the offending words for
 
are
the same as the offending words for . 

The above simple observations allow to build a (sound and) 
complete system,
when we add the notion of a \emph{basis}, a finite set of pairs of `equivalent heads'
(tree-tops, tree-prefixes)
, for which 
we have  for every instance.
To enable a smooth completeness proof, showing
even the existence of a fixed sufficient basis
 for each grammar  (not depending on the initial pair),
it is helpful
to start immediately in a more general setting of
\emph{regular terms}, 
which are finite or infinite terms with only finitely many
subterms (where a subterm can possibly have an infinite number of
occurrences); such terms have natural finite graph presentations.


The structure of the paper is clear from (sub)section titles.
There are also two (above mentioned) appendices.




\section{Basic definitions and simple facts}
\label{sec:definitions}

In this section we introduce the basic definitions and observe 
some simple facts on which the main proof is based. 
\\
By  we denote the 
set  of natural numbers; symbol  
is taken as the first infinite ordinal number,
which satisfies  and  for any
.
\\
For a set , by  
we denote the set of finite sequences, i.e. words, of
elements of ; the length of  is denoted 
,
and we use  for the empty sequence,
so .
By  we denote the set of infinite
sequences of
elements of  (i.e., the mappings ).
\\
Given 

and , by  we mean the
\emph{left quotient} of  by , i.e. the set
. 
By  for some
 we denote the set of (finite) prefixes of the words in .

\subsubsection*{(Deterministic) labelled transition systems and 
(stratified) trace
equivalence}


A \emph{labelled transition system (LTS)} is a tuple

where  is the set of \emph{states},  the set of
\emph{actions} 
and  is the set of
\emph{transitions labelled with} .
\\
We extend  to relations  for all  inductively:
; if  and  then
. We say that  is \emph{reachable 
from}  \emph{by
a word}  if .
A \emph{state}  \emph{enables (a trace)}
, denoted , if there is  such that 
 . An infinite sequence 
  
is enabled in , written , if there are
 such that  
for all .
The \emph{trace-set} of a state  is defined as
\begin{center}
. 
\end{center}
For , 
we define
 and ;
we also put
.
On the set , we define the \emph{(trace) equivalence} , and the \emph{family  
of equivalences} , , as follows:
\begin{center}
   
\ and 
\   .
\end{center}

\begin{observ}\label{prop:basicstratif}
.
.
.


\end{observ}
The \emph{equivalence level}, or the \emph{eq-level},
of a pair of states is defined as follows:
\begin{quote}
 if  and \,;
 if .
\end{quote}
The shortest words 
showing nonequivalence for a pair  (if )
are called \emph{offending words}:
 is a shortest word in 
. 
The elements of  are called \emph{offending
prefixes} for the pair .
We now note some trivial facts, point  being of particular 
interest:

\begin{observ}\label{prop:basicoffwords}
(1.)  iff  iff .
\\
(2.) If  then  for any
.
\\
(3.) If  and  then 
\\
\hspace*{3em} and . 
\end{observ}
An \emph{LTS}   is 
\emph{deterministic} 
if each  is a partial
function, i.e.:
if  and  then
. (Recall now the left quotient operation .)

\begin{observ}\label{prop:basicquottraces}
In any \emph{deterministic} LTS,
if  then 
, and
.
Moreover,  implies  
.
\end{observ}
We use notation  as a shorthand meaning
 and . 

\begin{prop}\label{prop:basiceqleveldrop}
Assume a \emph{deterministic} LTS, and suppose
. Then:
\\
1.  
(in particular,  implies
);
\\
2. if  then 
 iff 
; 
\\
3. if  then 
.
\end{prop}

\begin{proof}
This follows almost trivially from 
Observation~\ref{prop:basicquottraces}. 
E.g., for Point 3. it is sufficient to note:
if  then 
 iff
.  
\qed
\end{proof}



\subsubsection*{Finite and infinite regular terms and their
finite graph presentations} 

We now give (a variant of) standard definitions of first-order terms,
including infinite terms;
we fix a countable set 
 of (first-order) \emph{variables}.

Let us now assume  a given \emph{finite} set  of 
ranked symbols, called \emph{nonterminals}
(though we can also view them as function symbols).
Each  thus has  ; we use  to range
over elements of .

A (general) \emph{term}  over  (and ) is defined as a
partial mapping 
\\
where  
the domain  is prefix-closed,
i.e. , and nonempty ();
moreover, for  we have 
 iff  where the arity of variables  is viewed as
.

For each , by  we denote
\emph{the subterm occurring} at  in  where
 for each 
;
this \emph{occurrence of subterm}  has \emph{depth}
 in . 

For  and terms , where 
, by  we denote the term  for which
 and  for each length-1 sequence 
where ;  is the \emph{root nonterminal} of this term
. Each variable  is also viewed as
the term  for which  
(and thus ). 

A \emph{term}  is \emph{finite} (\emph{infinite})
if  is finite (infinite).
The \emph{depth-size} of a finite term , denoted ,
is the maximal  for 
(i.e., the maximal depth of a subterm-occurrence in ).
A \emph{term} is \emph{regular} if the set of its subterms
is finite 
(though the subterms can have infinitely many occurrences).

By  we denote the set of all
(finite and infinite) \emph{regular} terms, since we will not consider
nonregular terms anymore.
Hence from now on, when saying ``term'' we mean ``regular term''. 
 denotes the set of all (regular)
\emph{ground terms}, i.e. the terms  in which no  variables 
occur.
We use symbols  (possibly with sub- and
superscripts) for ranging over ;
symbols  
are used more generally, they range over .





Regular terms can be infinite but they have natural finite
presentations, since they can be viewed as the unfoldings of finite
graphs: 

\begin{defn}
A \emph{graph presentation} of a regular term is 
a finite labelled (multi)graph , where each node  has a label
 and   outgoing edges
labelled with  where  
(and where different edges can have the same target); 
moreover, one node is selected  as the root. 
Graph  represents term  as follows:  
consists of sequences of edge-labels of
finite paths in   starting in the root; 

where  is the end-vertex of the path with the edge-label sequence
.
\end{defn}
(Given ,) 
we can naturally define a notion of the \emph{size of a graph
presentation} , e.g., as the number of nodes of , or, to be
pedantic, as the length of a standard bit-string representation of 
(thus also handling the descriptions of indexes of variables ).
We define the
\emph{presentation size} of a term , denoted 
, as the size of the least graph
presentation of . 
By  for a pair  we mean the sum 
, say. 
On our level of reasoning, we do not need further technical details,
since the facts like the following one are sufficient for us.

\begin{observ}\label{prop:boundpressize}\hfill
\\
For any , there are only finitely many pairs  with
.
\end{observ}
We will also use some facts concerning an effective (algorithmic)
work with finite
presentations of regular terms. The next observation is an example of
such a fact. Further we often leave such facts implicit.

\begin{observ}\label{prop:algorgraphequality}
There is an algorithm which, given ( and) 
graph presentations , , decides if .
\end{observ}


\subsubsection*{Substitutions, 
ground instances of a pair
, a limit substitution}

By a \emph{substitution}
we mean a mapping .
The term  arises from  by 
replacing each occurrence  in  with .
(Since  and  are regular,  is regular.)
By writing 
we mean that  if  and 
 otherwise. Substitutions can be naturally composed;
associativity allows to omit the parentheses:
, etc.
\\
 is an \emph{instance} of  if there is 
a substitution  such that . 

As usual, we sometimes write 
to denote the fact
that all variables occurring in   
are from the set
.
In fact, we only use the special case ;
note that even a ground term  
can be viewed
as , for any .
(We ignore the slight notational collision with 
the previous use , since this should cause no problems.)

\smallskip
\noindent
\textbf{Convention.} When writing , we implicitly
assume , and we take 
  as a
shorthand for . In particular
we note that .

\smallskip

\noindent
A ground term  which is an instance of  is called
a \emph{ground instance} of .
We will in particular use the notion
of a \emph{ground instance of a pair} 
: it is any 
pair 
where  is a substitution  
where  are ground terms.
We usually write  instead of 
 .



By writing  we mean ;  
() means .
We need just a  special case of substitutions
 for which  
is well-defined; we use the graph presentations for the definition
(which also shows another aspect of the effective work with these
finite presentations).

\begin{defn}
Given (a regular term)  we define , denoted as
, as follows: given a graph presentation  where
, then  where  arises from 
by redirecting each edge leading to a node labelled
with  (in ) to the root (in ).
(Hence if  or 
does not occur in  then 
.)
\end{defn}





\subsubsection*{Head-tails presentations of terms,
the -prefix form of terms}

If  then we say that 
the (regular) \emph{head}  and the (regular)
\emph{tails}   constitute a 
\emph{head-tails presentation} of . 
We can also note that
the head  itself can be presented by a head-tails
presentation , say, etc. 
\\
A particular head-tails presentation of a term is its 
-prefix form; it suffices when we restrict ourselves to ground terms:

\begin{defn}\label{def:dprefix}
For a ground term  and , the
\emph{-prefix
form of}  arises as follows:
we take all (ordered) occurrences of subterms of  with depth  (if
any), say , 
and replace them with variables ,
respectively. We thus get a \emph{finite} term
, 
the \emph{-prefix of}
. 
The head  and the tails  constitute the
\emph{-prefix form} of . 
( when  is a finite term with .)
\end{defn}
\begin{observ}\label{prop:boundtails}
If  is the maximal arity of nonterminals in 
then the number  of tails in the
-prefix form is bounded by .
\end{observ}

We also note the next obvious fact.

\begin{observ}\label{prop:limdprefform}
If  then  is a ground term, and for
any  we
have  where 
.
\end{observ}








\subsubsection*{First-order grammars as generators
of LTSs}

\begin{defn}
A \emph{first-order grammar} is a structure 
 where  is a finite set of 
ranked \emph{nonterminals}, 
 is a finite set of \emph{actions} (or terminals), 
and  
a finite set of \emph{(root rewriting) rules} of the form

where , , 
,
,
and  is a
\emph{finite}  term over  (and ) 
 in which all occurring
variables are from the set
.
( is a particular example.)
\emph{Grammar}  is \emph{deterministic}, a \emph{det-first-order
grammar},
if for each pair ,  
there is at most one rule of the form~(\ref{eq:rewrule}). 
\end{defn}

\smallskip

\noindent
\emph{Remark.}
Context-free grammars  in Greibach normal form
can be seen as  a special case,
where each nonterminal has arity .
Classical rules like ,  can be presented as 
,
.

\begin{center}
We view 
as a generator of the 

\end{center}
where each (root) rewriting rule

is a ``schema''
(a~``template'') of a set of transitions:
for every substitution 
(including  with  for all )
we have 
, 
i.e.
\begin{center}
.
\end{center}
\begin{observ}
When  is deterministic then   is deterministic.
\end{observ}
Though the main result applies to deterministic grammars, we will also 
note some properties holding in the general (nondeterministic) case.

The notions and notation like  ( is enabled by ),
 (for words ), 
 (for ),
, , ,
trace equivalence , etc.,
are inherited from . 
(Note that the term  enables no actions; nevertheless,
it is technically convenient to have also
nonground terms as states in  .)
\\
We will be interested in comparing ground terms,
so we will use , , 
, , 
mainly for
.
We note (now explicitly)
another fact about the effective work with graph presentations:

\begin{observ}
Given ( and) a graph presentation  (of term ), we can effectively 
find all rewriting rules in  (of type~(\ref{eq:rewrule})) which
can be applied to  and for each such rule yielding 
 we can effectively construct some  such that . 
\end{observ}


\subsubsection*{Root-locality of action performing, 
words exposing subterm occurrences}

Assuming a given first-order grammar ,
we observe some consequences of
the fact that the root nonterminal of  
determines if  is enabled, and when a transition is performed
then the subterms  play no role other than being copied
(or ``lost'')
appropriately.



\begin{observ}\label{prop:basictraceperform}
For   and  ,  
we have  iff 
there is a rule  in
 such that  or  where 
 and  (for some ).
\end{observ}
We say that 
 \emph{exposes the -th successor} of 
if  .

\begin{observ}\label{prop:basicsubtermexpos}
Viewing a (regular) term  as a partial mapping
, we note that there is  such that 
 iff there is  where  and
for each  prefix  of
 there is some  exposing the -th successor of
. 
\end{observ}

\begin{observ}\label{prop:segmenttraces}

\\

 and .
\end{observ}
We now look at some simple algorithmic consequences 
of the above observations.

\begin{prop}\label{prop:computwXi}
There is an algorithm which, given 
, computes (and fixes) a word 
for each pair , where
 , , so that 
 is a shortest word exposing the -th
successor of  if any such word exists and
 otherwise.
\end{prop}

\begin{proof}
Recalling Observations~\ref{prop:basictraceperform}
and~\ref{prop:basicsubtermexpos},
a brute-force systematic search of all  is
sufficient:
we finish when
finding that the remaining pairs , i.e. those
for which  have not been
computed, are mutually dependent, i.e., the existence of an exposing 
  for any of the 
 remaining pairs depends on the existence of exposing
 words for some remaining pairs. 
\qed
\end{proof}

\noindent
For later use we note that we can compute a bound bigger than any
, say

We also note the bounded increase of the depth-size of finite terms, 
given by the fact that the right-hand sides of 
the (finitely many) rules~(\ref{eq:rewrule}) in  are finite terms.


\begin{observ}\label{prop:binc}
(For ,) there is a (linear) nondecreasing function
  such that:
if \mbox{} for a finite term  
then .
\end{observ}
Generally we cannot provide a similar \emph{lower} 
bound for , 
since some  might not occur in  in (\ref{eq:rewrule}).
But we can 
recall the -prefix form from Definition~\ref{def:dprefix}
(defined for ground terms) and note the following obvious fact.

\begin{observ}\label{prop:prefixchange}
If  and    then

iff there is some (finite)   such that 
 
and
 (where ). 
Hence if  then  .
\end{observ}


\subsubsection*{Congruence property of  and }


\begin{prop}\label{prop:congrproperty}
If  then . 
( implies .)
\end{prop}

\begin{proof}
The claim follows from Observation~\ref{prop:segmenttraces}:
 consists of traces  
and of traces of the form
 where  and .
\qed
\end{proof}

\noindent


\begin{prop}\label{prop:congrlim}
If  where  then 
.
\\
Hence  implies .
\end{prop}

\begin{proof}
If 
then by repeated use of Proposition~\ref{prop:congrproperty} we get
 where . 
By Observation~\ref{prop:limdprefform} we get
 and
thus 
(by Observation~\ref{prop:prefixchange}), which implies
.
\qed
\end{proof}

\begin{cor}\label{prop:corcongrlimequat}
If  where  then
 (with no occurrence of  in 
). In particular, 
if  where   then  
.
\end{cor}

\subsubsection*{A normal form for first-order grammars}


\begin{observ}\label{prop:noexposeequiv}\hfill
\\
If there is no  such that  then 
 for any .
\end{observ}

\begin{defn}\label{def:grammarnormalform}
 is in \emph{normal form} 
if for each   and   there 
is (a shortest)  exposing the -th
successor of .
\end{defn}

\begin{prop}\label{prop:transinnormal}
Any  can be effectively transformed
to   in normal form, yielding also an
effective mapping 
such that
 (in the disjoint union of  and
). 
\end{prop}

\begin{proof}
For each , by  (Exposable
Successors of )
we denote the subsequence 
of  where  iff there is 
exposing the -th successor of ;
by  we denote a fresh nonterminal with
.
We put  and 
.
Each rule  in  is transformed to 
the rule 
where ; thus
 arises.
This guarantees that 
iff  .
The claim now follows from
Proposition~\ref{prop:computwXi} and
Observation~\ref{prop:noexposeequiv}.
\qed
\end{proof}


\subsubsection*
{Exposing equations for pairs  in deterministic }

We now note an important notion 
and make some 
observations.

\begin{defn}
We say that \mbox{} 
\emph{exposes an equation for 
the pair} 
\\
 
if 
, 
,
or vice versa, where  (but might be  for ).
\\
Formally we write this exposed equation 
as {\modr{}}.
\end{defn}

\begin{prop}\label{prop:exposing}
For deterministic ,
if 
and  
then
an offending prefix for   exposes an equation for .
\end{prop}

\begin{proof}
There is surely no 

such that . If there is 
 
(where )
such that 
 where none of  is a variable and
 then 
 witnesses that
 -- a
contradiction.
\qed
\end{proof}


\noindent
We recall that Observation~\ref{prop:basicquottraces} 
and Proposition~\ref{prop:basiceqleveldrop} apply
to   when 
 is deterministic, and observe the following:

\begin{observ}
For deterministic , 
if  exposes an equation  for 
 then 

(for any ). 
Thus if  then
; 
otherwise (at least)
 for 
.
\end{observ}




\section{A ``word-labelling predicate''  and its soundness}\label{subsec:dersystem}

\begin{defn}
(Given ,)
a \emph{pair}
 is \emph{sound} if we
have   
for all ground instances 
 (i.e., ) 
of the pair .
A \emph{set}  \emph{of pairs}  is \emph{sound} if each
element is sound. 
\\
By  we mean the set of all
ground instances of pairs in .
\end{defn}
Let us now assume a given \emph{deterministic}
first-order grammar 
  in normal form, and
a \emph{finite} set , called
a \emph{basis}, 
of pairs (of regular terms) , supposedly sound;
we 
always 
assume  contains the pair 
which is obviously sound.


The derivation (or deduction) system in
Figure~\ref{fig:dersystem1}, assuming  and ,
provides
an inductive definition of the predicate 
\begin{center}
.
\end{center}
So it is in fact a family of predicates, parametrized with the initial
pair  of regular \emph{ground} terms. We write just
\modr{} instead of 
 when  is  clear from context. 


We can see that Axiom,
Basic transition rule (1.) and Rejection rule (6.) guarantee that 
if  and  is an offending word for 
, which implies  where ,
then  , which can be read as `` can be labelled
with the pair '', and thus ; as
expected, 
  is intended to mean .
 
In the case    we are guaranteed that 
if  then  but it is not clear
how to use this to conclude that .
To this aim we introduce another ``label'': 
 
(read `` can be (also) labelled with '')
is intended
to imply
that 
\fial{ is \cerv{N}ot an \cerv{O}ffending \cerv{P}refix 
for 
if  is sound}. Thus  
is intended to imply
\,\, if  is sound.
Having this in mind, Basis rule (4.) is clear;
 we will later
realize the reason for the condition .
Bottom-up progression rule (5.) is clear as well;
we note in particular that it enables 
to derive
 when  and
 do not enable any action. 

The most interesting is the 
Limit subterm replacement rule (2.),
with its particular case of Subterm replacement rule.
It allows to label  also with other pairs than those derived just
by Basic transition; so one  can get many pairs of terms as
``labels''.
This is meant to help
to create instances of the
basis and label the respective words with .
The condition  is important for soundness of 
the predicate  (wrt its intended meaning).
The symmetry rule 
(3.) could be dropped if we included 
all symmetric cases in the Limit subterm replacement rule.

As usual, we write 
, or ,
if the predicate is true (i.e., derivable) for the triple
, or not true (not derivable), 
respectively; similarly for  and .

\begin{figure}[t]
\begin{itemize}
\item
(Axiom) 
\item
(Primary derivation (deduction) rules, determining when )
\begin{enumerate}
\item (Basic transition) 
\\
If ,  , 
then .
\item (Limit subterm replacement) 
\\
If  , ,
  ,  
then .
\\
(A particular case is Subterm replacement:
if  then .)

\item (Symmetry)
If   then  .
\end{enumerate}
\item
(Secondary derivation rules, determining when  and/or
 )
\begin{enumerate}
\setcounter{enumi}{3}
\item (Basis)
If , 
 and  then 
.
\item
(Bottom-up progression)
If , ,
and 
for all  enabled by  (and )
then
.
\item (Rejection)
If    where  then 
.
\end{enumerate}
\end{itemize}
\caption{Inductive definition of 
(for given )
}\label{fig:dersystem1}
\end{figure}

We now recall Observation~\ref{prop:basicquottraces}
and Proposition~\ref{prop:basiceqleveldrop}, 
and show the following generalization  
in our case of det-first-order grammars.
This is the crucial point for showing
soundness (Proposition~\ref{prop:infsoundness}).
(In fact, Point 3. is used later 
 in the 
 completeness proof.)

\begin{prop}\label{prop:indsound}
Given (a det-first-order grammar  and) an initial pair :
\\
1. If   then 
.
( implies .)
\\
2. If   and  where 
 
then
\\
\hspace*{2em}
and
.
\\
3.
If  and  then
\,.
\end{prop}
\begin{proof}
We proceed by induction on the length of derivations.
The axiom  trivially satisfies the
conditions. Suppose that the conditions are satisfied for 
all  derived by derivations upto length , and
consider a derivation deriving   by  applications
of the derivation rules. 

If the last rule was 1. (Basic transition),
using  and , 
then  satisfies the conditions by (the induction
hypothesis and) 
Propositions~\ref{prop:basicquottraces},~\ref{prop:basiceqleveldrop}:
We have . If  
 then ,
hence  and thus
;
this implies

and thus .

If the last rule was Limit subterm replacement (2.),
so from , ,
  ,  we have derived
,
then
the conditions 1. and 3. (for  ) 
follow from (the induction hypothesis and)
Propositions~\ref{prop:congrlim} 
and~\ref{prop:congrproperty};  the condition 2. follows
from Point 3. of Observation~\ref{prop:basicoffwords}.

Rule 3. (Symmetry) obviously preserves the conditions. 
\qed
\end{proof}


\begin{cor}
 iff .
\end{cor}



\begin{prop}\label{prop:infsoundness}(Soundness)
\\
If  for all

then  is sound and .
\end{prop}

\begin{proof}
By contradiction.
\\
Suppose the assumption holds but there is some

with the {\fial{least finite eq-level}}.
Take the {\fial{longest (offending) prefix}}  
of some  such that 
. 
The rule deriving 
could not be the Basis rule since
this supposes  and 
where  but 
 Point 2. of Proposition~\ref{prop:indsound} implies that
 is smaller than the eq-level of any pair in
.
The same Point 2. also implies that 
the deriving rule could not be Bottom-up
progression since this presupposes 
for 
a longer prefix  of the above .
\qed
\end{proof}

\noindent
So we have a sound system, on condition  is sound.
But we note that an algorithm surely cannot process infinitely many
pairs   (to show 
 for each of them).
Fortunately, it suffices to consider a ``critical instance'' for each pair
 in
 which has the least eq-level among
the ground instances of :

\begin{defn}
The \emph{critical instance} of a pair 
  is the pair 
   where 
for fresh 
nullary nonterminals  (extending ) such that 
 for any ; e.g.,  gets its own
special action  and a rule .
By  we mean the set of the critical instances of
the pairs in . 
\end{defn}


\begin{prop}\label{prop:worstinstance}
For any , , and any ,
\\

\\
if 
do not occur in .
\end{prop}

\begin{proof}
Proposition~\ref{prop:exposing} shows that if we had
 then there were an offending prefix
 for   exposing an equation
 for
, which also means ; but then  where ,
and thus

(a contradiction).
\qed
\end{proof}


\noindent
The next lemma summarizes some important ingredients for the decidability
of trace equivalence for det-first-order grammars, showing that it
is now sufficient to
prove
the completeness of .

\begin{lemma}
For a det-first-order grammar  and a finite set
 of pairs of
terms, if

then  is sound and .
Moreover, the condition~\mbox{\textnormal{(\ref{eq:sound})}} 
is semidecidable.
\end{lemma}


\section{Completeness of the predicate }
\label{subsec:completeness}



\begin{defn}
Given a det-first-order grammar , a finite set  of pairs 
of regular terms is
a \emph{sufficient basis} if  is sound and 
we have:
if  are regular ground terms where 
then  (wrt ).
\end{defn}
We now aim to prove that any det-first-order grammar (in normal form)
has a sufficient basis.
We use implicitly the fact that if 
then  implies 
, 
,
and 

(recall Propositions~\ref{prop:indsound} and~\ref{prop:basicquottraces}).
We start with a simple observation:

\begin{prop}\label{prop:infininter}
Given a det-first-order grammar  
and a sound basis , 
if for every triple  where
 and  () there is
a prefix  of  such that  then
 is a sufficient basis.
\end{prop}

\begin{proof}
Suppose .
For every maximal  
(for which there is no )
we have  by using 
Basic transition 
and Bottom-up progression. 
Thus the assumption that each 
 has a prefix  
for which  implies that 
, by repeated use of Bottom-up
progression.
\qed
\end{proof}

\noindent
We now show 
a  sufficient condition for the existence
of a sufficient basis (Proposition~\ref{prop:secondsuf}), 
first introducing  some auxiliary notions to this aim.



\begin{defn}
We assume a det-first-order grammar . 
Given  where  
, an infinite trace   
is \emph{-bounded} (for )
if it has a nonempty
prefix  such that
 
where 
the pair  is sound and 
.  
\\
\emph{Grammar}  is \emph{-bounded} 
if for each
 all   are -bounded.
\\
Grammar  \emph{has a stair-base of width}
 
if 
there is a function  such that: 
for every  
and every 
either  is -bounded or there are 
some (unspecified) terms 
and infinitely
many nonempty, increasing prefixes  of  such
that 
for some (regular)  with
, for all .
\end{defn}
For illustration and later use, we
first note a particular example of -bounded traces where
; then we show
that the stair-base property is indeed sufficient.

\begin{defn}\label{def:repeat}
Given  and an initial pair ,

\emph{has a repeat} if there are two
different prefixes , , of   and some  such that 
, .  
(By Subterm replacement we then derive
, where  for
; so if  then
.)
\end{defn}

\begin{prop}\label{prop:suffi}
A det-first-order grammar  has a stair-base of width  
iff  is -bounded for some .
If  is -bounded then it has a sufficient
basis.  
\end{prop}

\begin{proof}
The first part follows directly from the definitions (if the width is  
then  is -bounded).
For the second part it suffices to define  as
the set of all sound pairs  with
 (recalling Proposition~\ref{prop:infininter}).
\qed
\end{proof}



\begin{prop}\label{prop:secondsuf}
If  a det-first-order grammar  has a stair-base (of some width)
then it is -bounded (for some )
and thus
has a sufficient basis.
\end{prop}


\begin{proof}
Assume a fixed  which has a stair-base of width
, for a fixed function .
By Proposition~\ref{prop:suffi}, we are done
once we show
that  has also  a stair-base of width .

So let us consider an arbitrary pair 
and some  which is not -bounded (for
);
there are prefixes  of  such
that 

where . 
 is not sound (since  is not -bounded)
but  
(Proposition~\ref{prop:indsound}, Point 1.).
There is thus a
shortest  exposing an equation for  
(recall Proposition~\ref{prop:exposing}); w.l.o.g. we can assume that
the equation is  (where ), and thus
.
Since there are only finitely many pairs  with
, there is some  determined by 
 and  (independent of ) 
such that  and .

By Limit subterm replacement we get

for , where
, 

and
.
So defining , for some trivial function 
(e.g. , depending on the definition of the size of graph presentations), 
shows that   has a stair-base of width 
(since our reasoning was independent of ).
\qed
\end{proof}



\noindent
Now we aim to show that any det-first-order
 (in normal form)
has a stair-base (of some width).
We use further auxiliary notions,
recalling 
,
, , and the -prefix form ( in our case).
 
 \begin{defn}\label{def:exposing}
Given  and ,  \emph{exposes a
subterm} of  \emph{in depth}  if there is a prefix  of  such that 
 for some . ( is the -prefix of .)
\\
For  , , 
 \emph{sinks by}  if 
 exposes a subterm of  in depth ; hence if  
 \emph{does not sink by} 
 then
 where
 is the root nonterminal of .
\end{defn}
Now we introduce a key ingredient,
the notions of left- and right-balancing segments, with the right- and
left-balancing pivots; we also use  for ranging over ground terms
(which serve as balancing pivots). We assume that
the \emph{underlying}
 \emph{is in normal form} (discussing this issue afterwards).

\begin{defn}\label{def:balanc}
A triple  where  is an \emph{-balancing
segment} if ,  and 
 does not sink by a proper prefix of .  is called the
\emph{(balancing) pivot} of this segment, an \emph{-pivot}
in this case. 
The \emph{-bal-result}  
of this segment 
is defined
as follows: if ,
, and 
 then 
 is the pair  where
  
and
 where 
for .

can be also presented as 
 where
.

An \emph{-balancing segment} , with the \emph{-pivot} 
and , is
defined symmetrically. We say just ``\emph{pivot}'' and
``\emph{bal-result}'' when
the side ( or ) follows from context.
\end{defn}
Informally, Proposition~\ref{prop:balancelabel} 
captures the following simple idea:
if the ``left-hand side'' (lhs-) term does not sink 
by a segment of length
, so it misses the opportunity to expose
a depth-1 subterm by a shortest word, 
then we can balance, i.e., replace its subterms (in depth 
originally) by using the
rhs-term (-pivot), achieving
a pair with bounded finite heads and the
same tails, inherited from the -pivot.
By symmetry the same holds for the case of
a non-sinking rhs-term and an -pivot.
In what follows we sometimes 
leave implicit the parts of the claims which follow by
symmetry. 

\emph{Remark.}
The normal form assumption on  is technically convenient
(though not really crucial). 
Definition~\ref{def:balanc} makes good sense also for
 (recall Proposition~\ref{prop:computwXi}),
but Proposition~\ref{prop:balancelabel} and some later reasoning
would be slightly more complicated. An alternative to the normal
form assumption would 
be adding
a (harmless)
derivation rule in Figure~\ref{fig:dersystem1} 
enabling to replace
an unexposable subterm arbitrarily.


\begin{prop}\label{prop:balancelabel}
Given 
an initial pair ,
if  is an -balancing segment and
 then 
 implies
. 
\end{prop}

\begin{proof}
Suppose the notation from Definition~\ref{def:balanc}. If  
 then by Basic transition rule we get

and  
 where
, for .
Since , by repeated Subterm replacement 
we get
.
\qed
\end{proof}

\noindent
Recalling Observations~\ref{prop:prefixchange}
and~\ref{prop:boundtails}, 
we easily observe the following facts.


\begin{observ}\label{prop:balbounds}
\hfill
\\
(1.) The bal-result of an -balancing segment  is determined
by the pivot , the word  (of length ) and by
the root nonterminal of .
\\
(2.) The depth-size of (finite) terms
 in the bal-result as in 
Definition~\ref{def:balanc} 
is bounded by . 
\\
(3.) The number  of tails in the bal-result 

has an upper bound determined by  (since  is determined by
).
\\
(4.)
If 
where  as in 
Definition~\ref{def:balanc},  
and  where  exposes a subterm of  in depth 
 then  necessarily exposes a
subterm of  (of the form ) 
which is reachable from  by some  (of length
).
\end{observ}
We now try to use the possibility of balancing along
an infinite , for a pair ,
to show that 
 allows
a stair-base of width , with a function , 
which are independent of 
(i.e., with  and  determined just by grammar ).
We first observe that if there are only
finitely many balancing opportunities then
 allows a repeat (recall Definition~\ref{def:repeat})
and the condition is trivial:

\begin{defn}\label{def:nextbal}
Assume an initial pair  and a fixed 
. 
\\
For (the triple  such that)
,  being a prefix of
, we define the 
\emph{next -segment} as the -balancing segment  
for the shortest  (if there is some)
such that  is a prefix of  and . 
The \emph{distance of} this next -segment is defined as . 
Similarly we define the 
\emph{next -balancing segment} for  .
\end{defn}

\begin{prop}
Given   as in Definition~\ref{def:nextbal},
if there is no next -segment and no next -segment for some
,  being a prefix of ,
then  has a repeat.
\end{prop}

\begin{proof}
Consider performing  from ;
let .
If there were a (first) segment  where  is a subterm of  but none of 
 is a subterm of  (of , in
fact) then we had an -balancing segment. Hence each  is
reachable from a subterm of  by a word of length , which
means that there are only finitely many different . Similarly for
 on the rhs. This guarantees a repeat.
\qed
\end{proof}



\begin{prop}~\label{prop:ghasstairbase}\hfill
\\
Any det-first-order grammar  in normal form
has
a stair-base (of some width).
\end{prop}

\begin{proof}
We assume a det-first-order grammar  in
normal form,
a pair  and a fixed ; 
we further write
 instead of . 
Assuming that  has no repeat, we show that it has
a stair-base of
width , with function , where  are independent of
.

We will present  as  where ,
attaching to each  a triple  and a pair 

such that
,  is a -balancing
segment,  ,
 and
 for .
Hence   and
 .
We note that each  has the corresponding pivot
, i.e. one of , depending on .

 is defined as the next -segment
or the next -segment for ; if both
exist, the one with the 
smaller distance is chosen
(recall Definition~\ref{def:nextbal}), and  we prefer
, say, to break ties. This also induces  
(where ). 

Suppose  
have been
defined, and assume that  is an -segment 
(so  is an -pivot; the other case is symmetrical). 
If for 
there is the next -segment
with the distance at most

then we use 
this segment to define  etc.; there was no switch, we
have .
If there is no such ``close'' 
-segment (since the -side terms keep sinking),
we note
that a subterm of  in depth  has been
exposed by  where  and 
 is a prefix of ;
let . 
Point 4. in Observation~\ref{prop:balbounds} implies that 
 is reachable from , by a word arising from  by
replacing a prefix  with some .
Here we define 
 as the 
next - or -segment
with the least distance for 
 (so  is a
prefix of ).
This might, but also might not, mean a switch of the pivot side.

Anyway,
 is reachable from  by  where either  
or  arises from  by replacing a prefix

of length 
by a (shorter) word .
We thus get a \emph{pivot-path}

We note that if some  is longer than , 
where , then the ``pivot-path sinks''
in any segment of  of length , i.e.:
for any partition , , we have 
 where 
 sinks by .


This implies for any 
 where 
that there is a nonempty prefix  of  of length at most

such that
 (for some ) or
 sinks by . (Informally: any segment 
of the pivot path  with length 
either contains a pivot  or sinks.)
Hence if  exposes subterms of  in all depths
then infinitely many pivots  are
equal (since reachable from subterms of  by words of length
);
Point 1. in Observation~\ref{prop:balbounds}  shows 
that  would then have a repeat.

So there is the maximal depth  such that  exposes
a (unique) subterm  of  in depth ; hence
 where  and 
 does not sink by .
Let   be the -prefix form of
, and let  be the least such that 

( being a prefix of ).

Then pivots , , are of the form 
  where  are finite terms in which
 each occurrence 
 of a variable has depth 
 at least. Moreover,  (by the above ``contains a pivot or sinks'' fact).
 
 Hence
the bal-results  for , 
are of the form
 
where  are finite terms with the depth-size bounded by
 for some  determined by
the grammar  (recall Definition~\ref{def:balanc}, Point 2. in
Observation~\ref{prop:balbounds}, and the fact that 
 are determined by
).
There is thus 
(independent of ) such that 
, for . 

Point 3. in
Observation~\ref{prop:balbounds} thus
implies that  has a
stair-base (of some width).
\qed
\end{proof}

\noindent
In fact, we have thus shown the next completeness
lemma, and the main theorem.

\begin{lemma}\label{lem:completeness1} (Completeness)
\\
For each det-first-order grammar  in normal form
there is a sufficient (sound) basis .
\end{lemma}





\begin{theorem}\label{th:tracedecid}
Trace
equivalence for deterministic
first-order grammars 
is decidable. 
\end{theorem}
For deciding \,, 
an algorithm based on soundness and completeness is clear
(using the effective manipulations with graph 
presentations of regular terms): when we
are allowed to generate any finite basis for a given initial pair
 then both questions ``~?'', 
``~?'' are semidecidable; when verifying ,
we have to verify all (critical instances of) pairs included in the basis as well.

\emph{Remark.} By inspecting the proofs we could note that a sufficient
basis for a det-first-order grammar (in normal form) is, in fact,
computable (since we now know that
the value  determined by  and  in
the proof of Proposition~\ref{prop:secondsuf} is computable) 
but this
computability does not seem much helpful.


\subsection*{Conclusions}


The presented proof of the decidability of trace equivalence for
det-first-order grammars routinely applies 
to the dpda language equivalence, as also shown in Appendix 1. 
The novelty here is the presentation in the framework of first order terms,
resulting in a proof which seems technically simpler than the previous
ones. 


Appendix 2. gives another look at the complexity result by 
Stirling~\cite{Stir:DPDA:prim}, showing that the
framework of first-order terms can be useful there as well.  









\bibliographystyle{plain}
\bibliography{root}




\noindent
\textbf{Appendix 1.}


\section{DPDA 
language
equivalence problem presented via
trace equivalence for det-first-order grammars}

A \emph{deterministic pushdown automaton} (\emph{dpda})
is a tuple 
 consisting of
finite sets  of (control) states, 
 of actions (or terminals),
 of stack symbols, and  of transition rules.
For each pair , , , and each 
,  contains at most one rule
of the type  , where , .
Moreover, any pair  is (exclusively) either \emph{stable}, 
i.e. 
having no rule 
, or
\emph{unstable}, in which case there
is (one rule  and) no rule
 with .

A dpda  generates a labelled transition system

where the states are
configurations   (, ).
Having our grammars in mind, we view a rule 
as  (for a formal variable ), inducing
 for every . 
The transition relation is extended to words  
as usual; we note that  
can comprise more than   basic steps, due
to possible ``silent'' -moves.
Each configuration 
has its associated \emph{language}

for some .
The \emph{dpda language equivalence problem} is:  
given a dpda  and two configurations
, ,
is ~?

\emph{Remark.}
It is straightforward to observe that this setting is
equivalent to the classical problem of language equivalence 
between deterministic pushdown automata with 
accepting states.
First, the disjoint
union of two dpda's is a dpda. Second, for languages
 we have 
 iff
\}=L_2\cdot\{\, for an endmarker \not\in\SigmaM\varepsilonpA\gt{\varepsilon}qL(pA\alpha)pApA\gt{\varepsilon}qB\alphaqB\gt{a_1}q_1\beta_1\dotsqB\gt{a_k}q_k\beta_kpA\gt{a_j}q_j\beta_j\alphapA\varepsilonpAa\in\actpA\gt{a}q\alphaq_dq_dA\gt{a}q_dAA\in \Gamma, a\in\actpA\gt{a}..pA\gt{a}q_dAL(p\alpha)w\in \act^*p\alphaw=uvp\alpha\gt{u}q\varepsilonqu\in L(p\alpha)v\neq\varepsilonL(p\alpha)=L(q\beta)\forall w\in\act^*:p\alpha\gt{w}\,\Leftrightarrow\,q\beta\gt{w}\varepsilonM=(Q,\act,\Gamma,\Delta)\calG_M=(\calN,\act,\calR)\calN=\{pA\mid pA \}\cup\{\bot\}X=pAm=|Q|\botp \alpha\calT(p \alpha)Q=\{q_1,q_2,\dots,q_m\}\calT(q\varepsilon)=\botqA\gt{\varepsilon}q_iqA\calT(qA\beta)=\calT(q_i\beta)qA\calT(qA\beta)=X\,\calT(q_1\beta) \dots \calT(q_m\beta)X=qA\calT(q_ix)=x_ipA\gt{a}q\alphaa\in\actpAx\gt{a}q\alpha x\calG_M\calT(pAx)\gt{a} \calT(q\alpha x)Xx_1\dots x_m\gt{a} \calT(q\alpha x)X=pA\calR\calG_M\varepsilonp A\alpha \gt{\varepsilon} q \alpha\varepsilon\calT(pA\alpha)=\calT(q \alpha)p A\alpha \gt{a} q \beta\alphaa\in\actpA\calT(pA\alpha)\gt{a}\calT(q \beta\alpha)p\alpha\gt{w}q\varepsilon\calT(p\alpha)\gt{w}\botL(p\alpha)=L(q\beta)\big(\forall
w\in\act^*:p\alpha\gt{w}\,\Leftrightarrow\,q\beta\gt{w}\big)\calT(p\alpha)\sim \calT(q\beta)\calT(q\alpha)1+m+m^2+m^3+\cdots +m^{|\alpha|}\calT(q\alpha)1+m(|\alpha|-1)+1B_1\gt{w_1} B_2\gt{w_2}B_3\gt{w_3}\cdotsV_1B_1\calG(T_0,U_0)\Nat^k\rightarrow \Nat+, -,\times, \div\uparrowa\uparrow n=a^n\calGM_0,M_1,M_2M_0\uparrow\uparrowa\uparrow\uparrow n= 
a\uparrow (a\uparrow (a\uparrow ( \dots a \uparrow a )\dots ))\uparrown\calGT_0,U_0\inputsize\calG(T_0,U_0)T_0\not\sim U_0T_0, U_02\uparrow\uparrow f(\inputsize)f\calGT_0, U_0O(2\uparrow\uparrow g(\inputsize))g\calG=(\calN,\act,\calR)(T_0,U_0)T_0\not\sim U_0\alpha\in\act^*(T_0,U_0)\alpha\alpha\alpha\alpha\modelsu\models  (E(U_1\dots U_n),F(U_1\dots U_n))v\models (E(V_1\dots V_n),F(V_1\dots V_n))|u|<|v|v(E(V'_1\dots V'_n),F(V'_1\dots V'_n))V'_jV_jU_nH\limtreen(U_1,\dots,U_{n-1})(E(x_1,\dots,x_n), F(x_1,\dots,x_n))w\in\act^*x_n\symbeq H(x_1,\dots,x_n)H\neq x_n(E(U_1\dots U_n),F(U_1\dots U_n))(E(V_1\dots V_n),F(V_1\dots V_n))(E(V'_1\dots V'_n),F(V'_1\dots V'_n))k_1,k_2,k_3V_j=G_j(U_n)V'_j=G_j(H\limtreen(U_1,\dots,U_{n-1}))j=1,2,\dots,nk_3\geq \min\{k_1,k_2\}k_3=k_2k_1>k_2U_n\sim_{k} H(U_1,\dots, U_{n})\sim_{k} 
H\limtreen(U_1,\dots, U_{n-1})k=max\{k_1{-}|w|,0 \}V_j\sim_{k} V'_jj=1,2,\dots,nk_3<\min\{k_1,k_2\}w'E,F|w'|\geq |w|(E(V'_1,\dots,V'_n),F(V'_1,\dots,V'_n))\gt{w'} 
(V'_i,G(V'_1,\dots,V'_n))iG\eqlevel(V'_i,G(V'_1,\dots,V'_n))= k_3-|w'|=k'\eqlevel(V_i,G(V_1,\dots,V_n))\geq
k_2{-}|w'|\geq k'{+}1V_i\sim_{k'+1}V'_ik=k_1{-}|w|>k'k_2<\min\{k_1,k_3\}u\models (E(T),F(T))v\models (E(e(T)),F(e(T)))e=e(x_1)1|u|<|v|v(T_0,U_0)\eqlevel(E(e(T)),F(e(T)))T\eqlevel(E(e(T)),F(e(T)))=\eqlevel(E(e(H\limtreeone)),F(e(H\limtreeone)))Hu'\models (E(T'),F(T'))v'\models (E(e(T')),F(e(T')))|u'|<|v'|<|v|v,v'(T_0,U_0)E\sigma_1\sigma_2\cdots\sigma_r\sigma_j=[e^{i_j}_1/x_1,\dots, e^{i_j}_n/x_n]\{x_1,\dots,x_n\}(E(x_1,\dots,x_n), F(x_1,\dots,x_n))n(e^1_1,\dots,e^1_n)(e^2_1,\dots,e^2_n)\dots(e^n_1,\dots,e^n_n)E,Fe^i_j= e^i_j(x_1,\dots,x_n)(E',F')0\leq r\leq n1\leq i_1<i_2<\cdots < i_r\leq n2^n(E'_{max},F'_{max})r=ni_1=1, i_2=2, \dots, i_n=nEe^{i_1}_1 \dots e^{i_1}_ne^{i_2}_1 \dots e^{i_2}_n\dotse^{i_r}_1 \dots e^{i_r}_nFe^{i_1}_1 \dots e^{i_1}_ne^{i_2}_1 \dots e^{i_2}_n\dotse^{i_r}_1 \dots e^{i_r}_n(E(x_1,\dots,x_n), F(x_1,\dots,x_n))(e^1_1,\dots,e^1_n)(e^2_1,\dots,e^2_n)\dots(e^n_1,\dots,e^n_n)T_1,\dots,T_nk=\eqlevel(E'_{max}(T_1,\dots,T_n),F'_{max}(T_1,\dots,T_n))\eqlevel(E'(T_1,\dots,T_n),F'(T_1,\dots,T_n))(E',F')kT_1,\dots,T_nn=0n > 0n{-}1w\in\act^*E,F\eqlevel(E(U_1,\dots,U_n),F(U_1,\dots,U_n))U_1,\dots,U_nU_1,\dots,U_nw\in\act^*E,Fx_n\symbeq H(x_1,\dots,x_n)E'(T_1,\dots,T_n), F'(T_1,\dots,T_n)E',F'i_1=1e^{i_j}_{\ell}(x_1,\dots,x_n)\bar{e}^{i_j}_{\ell}(x_1,\dots,x_{n-1})=
{e}^{i_j}_{\ell}[H\limtreen/x_n]T_ne^{i_j}_ni_j\neq 1T_1,\dots,T_nE\bar{e}^{1}_1 \dots \bar{e}^{1}_n\bar{e}^{i_2}_1 \dots \bar{e}^{i_2}_{n-1}\dots\bar{e}^{i_r}_1 \dots \bar{e}^{i_r}_{n-1}T_1 \dots T_{n-1}F\bar{e}^{1}_1 \dots \bar{e}^{1}_n\bar{e}^{i_2}_1 \dots \bar{e}^{i_2}_{n-1}\dots\bar{e}^{i_r}_1 \dots \bar{e}^{i_r}_{n-1}T_1 \dots T_{n-1}2^{n-1}(\bar{E},\bar{F})=
(E(\bar{e}^{1}_1 \dots \bar{e}^{1}_n),
F(\bar{e}^{1}_1 \dots \bar{e}^{1}_n))(\bar{e}^{2}_1, \dots, \bar{e}^{2}_{n-1})(\bar{e}^{3}_1, \dots, \bar{e}^{3}_{n-1})\dots(\bar{e}^{n}_1, \dots, \bar{e}^{n}_{n-1})E\bar{e}^{i_{\ell+1}}_1 .. \bar{e}^{i_{\ell+1}}_n\dots\bar{e}^{i_r}_1 \dots \bar{e}^{i_r}_{n}T_1 \dots T_{n}F\bar{e}^{i_{\ell+1}}_1 .. \bar{e}^{i_{\ell+1}}_n\dots\bar{e}^{i_r}_1 \dots \bar{e}^{i_r}_{n}T_1 \dots T_{n}E{e}^{i_1}_1 \dots {e}^{i_1}_n\dots{e}^{i_{\ell-1}}_1 .. {e}^{i_{\ell-1}}_n{e}^{i_{\ell}}_1 \dots {e}^{i_{\ell}}_n\bar{e}^{i_{\ell+1}}_1 .. \bar{e}^{i_{\ell+1}}_n\dots\bar{e}^{i_r}_1 \dots \bar{e}^{i_r}_{n}T_1 \dots T_{n}F{e}^{i_1}_1 \dots {e}^{i_1}_n\dots{e}^{i_{\ell-1}}_1 .. {e}^{i_{\ell-1}}_n{e}^{i_{\ell}}_1 \dots {e}^{i_{\ell}}_n\bar{e}^{i_{\ell+1}}_1 .. \bar{e}^{i_{\ell+1}}_n\dots\bar{e}^{i_r}_1 \dots \bar{e}^{i_r}_{n}T_1 \dots T_{n}E{e}^{i_1}_1 \dots {e}^{i_1}_n\dots{e}^{i_{\ell-1}}_1 .. {e}^{i_{\ell-1}}_n\bar{e}^{i_{\ell}}_1 \dots \bar{e}^{i_{\ell}}_n\bar{e}^{i_{\ell+1}}_1 .. \bar{e}^{i_{\ell+1}}_n\dots\bar{e}^{i_r}_1 \dots \bar{e}^{i_r}_{n}T_1 \dots T_{n}F{e}^{i_1}_1 \dots {e}^{i_1}_n\dots{e}^{i_{\ell-1}}_1 .. {e}^{i_{\ell-1}}_n\bar{e}^{i_{\ell}}_1 \dots \bar{e}^{i_{\ell}}_n\bar{e}^{i_{\ell+1}}_1 .. \bar{e}^{i_{\ell+1}}_n\dots\bar{e}^{i_r}_1 \dots \bar{e}^{i_r}_{n}T_1 \dots T_{n}2^{n-1}2^n\calG, T_0,U_0E(x_1,\dots,x_n),F(x_1,\dots,x_n)(e^1_1,\dots,e^1_n)\dots(e^n_1,\dots,e^n_n)T_1,\dots,T_n(E'_{max}(T_1,\dots,T_n),F'_{max}(T_1,\dots,T_n))m\in\Nat(E',F')u|u|<mu\models (E'(T_1,\dots,T_n),F'(T_1,\dots,T_n))u\models (U,U')u(T_0,U_0)(U,U')(E'_{max}(T_1,\dots,T_n),F'_{max}(T_1,\dots,T_n))|u|v|v|\neq |u|T'_1,\dots,T'_nv\models (V,V')(V,V')(E'_{max}(T'_1,\dots,T'_n),F'_{max}(T'_1,\dots,T'_n))|v|E,FT_0,U_0T_0\not\sim U_0\alpha\in\offpl(T_0,U_0)\alpha\alpha\alphau_1v_1u_2v_2\dots\alphau\models (T,U)u\alpha\eqlevel(T,U)=\eqlevel(T_0,U_0)-|u|B_1\gt{w_1} B_2\gt{w_2}\cdots\gt{w_{k-1}}B_kk=0V\gt{w}|w|=M_2V\gt{u}B_iuwVwB_ii=1,2,\dots, k{-}1V_iV_i=B_iw_iw_{i1}w_{i2}|w_{i2}|\leq M_2V_i\gt{w_{i2}} B_{i+1}\gt{w_{i+1,1}}V_{i+1}V_i{w_{i2}}{w_{i+1,1}}V_{i+1}V_i(i_0, i_1, \dots , i_r)(1,2,\dots,k{-}1)j\in\{0,1,\dots,r{-}1\}V_{i_j}{w}V_{i_j}\gt{w}V_{i_{j+1}}w=w_{(i_j,2)}w_{i_j+1}\dots
w_{i_{j+1}-1}w_{(i_{j+1},1)}(i_0, i_1, \dots , i_r)V_{i_0},V_{i_1},V_{i_2},\dots, V_{i_r}V_{i_0}=G_0T_1  \dots T_nV_{i_1}=G_1e^1_1  \dots e^1_nT_1  \dots T_nV_{i_2}=G_2e^2_1  \dots e^2_ne^1_1  \dots e^1_nT_1  \dots T_n\dotsV_{i_r}=G_re^r_1  \dots e^r_n\dotse^2_1  \dots e^2_ne^1_1  \dots e^1_nT_1  \dots T_nG_jM_0n\depthsize(e^i_j)\leq \boundinc(M_2)V_{i_{j+1}}V_{i_{j}+1}\ell\geq 1i_{j}+\ell<i_{j+1}V_{i_{j}+\ell}w'V_{i_{j}+\ell}\gt{w'}V_{i_{j+1}}\ell'i_{j}+\ell<i_{j}+\ell'\leq i_{j+1}V_{i_{j}+\ell'}V_{i_{j}+\ell}V_{i_j}\gt{w}V_{i_{j+1}}Yx_1\dots
x_m\gt{w}F(x_1,\dots,x_m)YV_{i_j}FV_{i_{j+1}}V_{i_{j}+1}1\leq\depthsize(F)\leq 1+\boundinc(M_2)e^i_jT_je^i_jg\calG,
T_0,U_0,\alpha|\alpha|\leq g(\inputsize,\ell)\ellVV=F(W_1,\dots,W_m)FW_iT_0U_0size(V)\depthsize(F)V'Vsize(V')\leq size(V)T_0\gt{u_1}B_1U_0\gt{u_1}B_1sizeB_iV_isize(V_{i+1})\leq  size(V_{i})+M_3M_3=1+\boundinc(M_2)size(V_{i})> p M_3p\in\Nat(i_0,i_1,\dots,i_p)i_p=iV_iipp\geq 1V_1B_1B_1T_0U_0M_0size(V_1)\leq M_3i>1size(V_{i-1})> (p{-}1)M_3V_{i}V_{i-1}V_{i-1}p-1V_{i-1}\gt{w}V_isize(V_{i-1})> p M_3i{-}1>1size(V_{i-2})> (p{-}1)M_3V_iV_{i-2}size(V_{i-2})> p M_3\ellsize(B_i)\leq (\ell+2)M_3B_i\inputsize\ell|\alpha|\Sigma\varepsilon0n\geq 1w\in\Sigma^*nw=vuvvn{-}1u|u|\geq 1wn>0nv_1,v_2,\dots,v_nw_1,w_2,\dots,w_nw_iiw_1=v_1w_2=w_1v_2w_1=v_1v_2v_1w_3=w_2v_3w_2=v_1v_2v_1v_3v_1v_2v_1\dotsw_n=w_{n-1}v_nw_{n-1}w_n=w(n{+}1)w\in\Sigma^*v_1,v_2,\dots,v_{n+1}u_1,u_2,\dots,u_nv_1u_{i_1}u_{i_2}\dots u_{i_r}w/v_11\leq r\leq n1\leq i_1<i_2<\cdots < i_r\leq nv_1,v_2,\dots,v_{n+1}w_1,w_2,\dots,w_{n+1}w'_i=w_i/v_1u_i=v_1v_{i+1}w'_ii=1,2,\dots,nw'_{i+1}=w'_iu_i=w'_iv_1v_{i+1}w'_iu_3=v_1v_4v_1v_2v_1v_3v_1v_2w'_1=\varepsilonw'_2=v_1v_2w'_3=v_1v_2v_1v_3v_1v_2\dotsu_3=v_1v_4v_1v_2v_1v_3v_1v_2u_1=v_1v_2u_2=v_1v_3v_1v_2u_3=v_1v_4v_1v_2v_1v_3v_1v_2\dotsw'_iw'_jj>iu_{i_1}u_{i_2}\dots u_{i_r}w'_{i_r+1}w'_{i_r+1}=w'_{i_r}u_{i_r}u_{i_1}u_{i_2}\dots u_{i_{r-1}}w'_{i_{r-1}+1}w'_{i_r}h\in\Natf_h:\Nat\rightarrow\Nat|\Sigma|=hw\in \Sigma^*|w|\geq f_h(n)nn=0wf_h(n+1)uf_h(n)w=v_1uv_2uv_3|v_2|\geq 1u=u_1u_2u_3u_2nu_2u_3v_2u_1u_2n+1g\calG, T_0, U_0, \alpha2\uparrow\uparrow g(size(\calG))(i_0, i_1, \dots , i_r)V_{i_0},V_{i_1},V_{i_2},\dots, V_{i_r}B_{i_0+1},\dots, B_{i_{r-1}+1}B_{i_j+1}V_{i_{j}}B_{i_0+1},\dots, B_{i_{r-1}+1}E_0T_1  \dots T_nF_0T_1  \dots T_nE_1e^1_1 \dots e^1_nT_1  \dots T_nF_1e^1_1 \dots e^1_nT_1  \dots T_n\dotsE_{r-1}e^{r-1}_1 \dots e^{r-1}_n\dotse^2_1 \dots e^2_ne^1_1 \dots e^1_nT_1  \dots T_nF_{r-1}e^{r-1}_1 \dots e^{r-1}_n\dotse^2_1 \dots e^2_ne^1_1 \dots e^1_nT_1  \dots T_nE_i,F_i,e^i_1 \dots e^i_n(E_i,F_i,e^i_1, \dots, e^i_n)hhsize(\calG)r{-}1\geq f_h(n{+}2)(E_{r-1},F_{r-1},e^{r-1}_1,\dots,e^{r-1}_n)(E_{r-2},F_{r-2},e^{r-2}_1,\dots,e^{r-2}_n)\dots(E_1,F_1,e^1_1,\dots,e^1_n)n{+}1E,Fv_1nu_1,\dots,u_n(\bar{e}^1_1, \dots, \bar{e}^1_n)(\bar{e}^2_1, \dots, \bar{e}^2_n)\dots(\bar{e}^n_1, \dots, \bar{e}^n_n)(\bar{e}^j_1, \dots, \bar{e}^j_n)e^{k+\ell}_1 \dots e^{k+\ell}_n\dotse^k_1 \dots e^k_nU_1,U_2\dots,U_nn{+}11\leq i_1<i_2<\cdots < i_r\leq nE\bar{e}^{i_1}_1 \dots \bar{e}^{i_1}_n\dots\bar{e}^{i_r}_1 \dots \bar{e}^{i_r}_nU_1  \dots U_nF\bar{e}^{i_1}_1 \dots \bar{e}^{i_1}_n\dots\bar{e}^{i_r}_1 \dots \bar{e}^{i_r}_nU_1  \dots U_n(E'_{max}(U_1,\dots,U_n),F'_{max}(U_1,\dots,U_n))V_1,V_2,\dots,V_nn{+}1r-1<f_h(n+2)f_hf_h(n+2)\leq h \uparrow\uparrow g_1(n)g_1hnsize(\calG)$,
the claim follows.
\qed
\end{proof}


\end{document}
