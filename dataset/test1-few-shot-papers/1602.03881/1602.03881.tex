\section{Experimental Analysis}
\label{sec:exp}

This section empirically investigates how the settings of  and , and
the choice of shortcutting heuristics affect the number of shortcut edges added,
as well as the number of steps that \AlgName{} requires.  These
quantities provide an indication of how well a well-engineered implementation
would perform in practice.






\subsection{Experiment Setup}
We use graphs of various types from the SNAP datasets~\cite{leskovec2014snap},
including the road networks in Pennsylvania and Texas (real-world planer graphs)
and the web graphs of the University of Notre Dame and Stanford University
(real-world networks).  In the case of web graphs, each edge represents a
hyperlink between two web pages.  We also use synthetic graphs of 2D and 3D
grids (structured and unstructured grids).

In practical applications, such graphs are used both in the weighted and
unweighted settings.  In the weighted setting, for instance, the distances in
road networks and grids can represent real distances, while the edge weights in
network graphs (e.g., social networks) also have real-world meanings, such as
the time required to pass a message between two users, or (the logarithm of) the
probability to pass a message.  In our experiments, if a graph does not come
equipped with weights, we assign to every edge a random integer between  and
.

We construct \ourstructure{k}{\rho}s using the heuristics described in
Section~\ref{sec:heuristics} except the implementation has the following
modifications: instead of breaking ties arbitrarily and taking exactly 
neighbors, we continue until all vertices with distance  are
visited.  This has the same implementation complexity as the theoretical
description but is more deterministic.  Using this, our results are a
pessimistic estimate of the original heuristics as more than  edges may be
found for some sources.  However, in all our experiments, we found the
difference to be negligible in most instances.

To improve our confidence in the results, two of the authors have independently
implemented and conducted the experiments, and arrived at the same results, even
without introducing a tie-breaker.






\subsection{The Number of Shortcut Edges}

Section~\ref{sec:heuristics} described heuristics that put in a small number of
edges to make the input graph a \ourgraph{k}{\rho}.  \emph{How many extra edges
  are generated by each heuristic?}  To answer this question, we use 3
representative graphs in our analysis: (1) road networks in Pennsylvania, (2) a
webgraph of Stanford University, and (3) a synthetic -by- 2D grid.
All these graphs have about  million vertices, and between  and 
million edges.  We show experimental results for unweighted graphs since the
performance of the heuristics is independent of edge weights.



Figure~\ref{fig:addingedges} shows the number of added edges in terms of the
fraction of the original edges for  as the value of  is varied
between  and .  More detailed results are given in
Tables~\ref{tab:addingedgegreedy} and \ref{tab:addingedgedp} in the appendix.
Evidently, both heuristics achieve similar results on the road map and 2D
grid. This is because road maps and grids are relatively regular, in fact
almost planar.  Thus, even the na\"ive shortcuts to the -hop performs
well. As  becomes larger, the gap between the greedy and the DP heuristic
increases.  When  reaches , both DP and greedy add more than x
edges compared to the original graph. This is because in road maps and grids the
degree of a vertex is usually a small constant, which makes the shortest-path tree very
deep.

On webgraphs, which is less regular, DP only adds x the number of original
edges even when  is as large as  while greedy still adds x the
original edges. This is because webgraphs not only are far more irregular but
also have a very skewed degree distribution.  As a known scale-free network
\cite{barabasi1999emergence}, it has some ``super stars'' (or more precisely,
the ``hubs'') in the network.  In this case, the bad example in
Section~\ref{sec:heuristics} occurs frequently when these hubs are not at the
exact -th layer in the shortest-path tree, while the DP heuristic can
discover the hubs accurately.  This also explains the phenomena that only a few
edges are added on webgraphs by the DP heuristic even when  is large,
since the hubs already significantly reduce the depth of the shortest path tree,
and it only takes a few edges to shortcut to the hubs.  This property holds for
many kinds of real-world graphs such as social networks, airline networks,
protein networks, and so on.  In such graphs, a relatively optimal heuristic is
necessary to construct the enclosed balls; a na\"ive method often leads to bad
performance.  As can be seen, the DP solution achieves satisfactory performance
on webgraphs, where it only adds about 10\% more edges with  and
.


\hide{
\kanat{Do we really want to mention the following? It seems very subtle and may
  muddle the point.}  Note that to efficiently implement it is important to
break the ties and create \emph{no more than}  shortcuts. In that case the
number of added edges is at most .  From Table \ref{tab:addingedgedp} we
can see that even ties are not broken, the number of edges created by DP is
still much less than .
}

\begin{figure}[!t!h]
\begin{center}
    \begin{minipage}[t]{0.45\textwidth}
        \includegraphics[width=\textwidth]{figures/road-edge}\\ \centering{\small \bf (a) Road map of Pennsylvania}
    \end{minipage}
    \begin{minipage}[t]{0.45\textwidth}
        \includegraphics[width=\textwidth]{figures/web-edge}\\ \centering{\small \bf (b) Webgraph of Stanford}
    \end{minipage}
    \begin{minipage}[t]{0.45\textwidth}
        \includegraphics[width=\textwidth]{figures/grid-edge}\\ \centering{\small \bf (c) 2D-grid}
    \end{minipage}
    \caption{The fraction of additional edges added to generate
      \ourgraph{k=3}{\rho} using greedy vs. dynamic programming (DP) for different
      types of graphs.}\label{fig:addingedges}
\end{center}
\end{figure}

\subsection{The Number of Steps}
\label{sec:expreduce}

\emph{How many steps does \AlgName{} take for each setting of ?}  We ran
our \AlgName{} on both weighted and unweighted graphs and counted the number of
steps as we change .  Notice that the number of steps is independent of
 and is only affected by . (The value of  only affects the number of
substeps within a step.)  We discuss the performance of our algorithm on all six
graphs.  Since the cost of \sssp potentially varies with the source and we
cannot afford to try it from all possible sources, we take 1000 random sample
sources for each graph.  We use the same  sources for all our experiments
for both the weighted and unweighted cases.  We report the arithmetic means over
all sample sources.






\medskip

\noindent
\textbf{Unweighted Graphs (BFS):} Figure~\ref{fig:numerofrounds} shows, for the
unweighted case, the average number of steps taken by \AlgName{} as  is
varied.  More results appear in Tables~\ref{tab:stepunweighted} and
\ref{tab:stepreducedunweighted} in the appendix, which compare the number of
steps taken by \AlgName with that of a conventional BFS implementation.

Several things are clear: on a log-log scale\footnote{The vertical axis is drawn
  on a log scale and the horizontal axis closely approximates a log scale.}, the
trends are downward linear as  increases except for the Notre Dame
webgraph (not completely regular but shows a similar trend).  This suggests that
the average number of steps is inversely proportional to , which is
consistent with our theoretical analysis.

The webgraph has a relatively smoother slope. The reason is that once the
``super stars'' are included in the enclosed balls, which usually only need a few
hops, then most of the vertices will be visited in a few steps (--
steps vs. -- steps on the other graphs when ).  However, we
will later see that in the weighted case, the performances on these graphs are
even better than other graphs.  For the road maps and grids, the number of steps
reduces steadily. Furthermore, the number of steps shown in the experiments is
much less than the theoretical upper bound () because
most real-world graphs tend to have a hop radius that is smaller than .







On all the graphs studied,  can be as small as  to reduce the number
of steps by x.  When , the reduction factor is about x.  As the
results show, we can achieve a reduction factor of more than x when thousands of
vertices are in the balls.
The experiment results verified our theoretical analysis of the \AlgName{} algorithm.

\emph{What should an unweighted graph look like so that \AlgName{} reduces the
  steps much when adding no more than  edges?}  At first thought, the answer
might be a grid or a road map with a large diameter, so that there is more space
to be reduced.  However, our experiments give the opposite answer: \AlgName{},
in fact, performs better on webgraphs with smaller diameters.  On webgraphs,
\AlgName{} can reduce the number of steps by x by adding no more than 
edges (choosing  and ), while on road maps and grids, a
5x reduction in steps requires  to  edges. Even though the number
of rounds reduces more steadily and quickly on road maps and grids with
larger , the number of added edges in turn increases more rapidly
(100x times more edges added to achieve 20x reduction on the number of steps).
On scale-free networks, however, \AlgName{} improves standard BFS by more than
10x in time without adding much extra edges, and an efficient implementation of
\AlgName{} on these networks might be worthwhile in the future.  \hide{ Along
  with the result on the number of edges we need to add to construct a
  \ourgraph{k}{\rho}, we can analyze the tradeoff between the number of added
  edges (the space efficiency) and the number of steps (the time efficiency). On
  webgraphs \AlgName{} can reduce the number of steps by 15 times by adding no
  more than  edges (choosing  and ), while on road maps and
  grids, reducing the number of steps by about 5 times already requires  to
   edges. Even though on road maps and grids the number of rounds reduces
  more steadily and quickly with  increases, the number of added edges in
  turn increases more rapidly (100x times more edges added to achieve 20x
  reduction on the number of steps).  Considering the diameter of real-world
  graphs is usually not that large, and the standard parallel BFS can finish in
  the number of steps to be about half the diameter, which already provides much
  parallelism, our \AlgName{} does not have much improvement on standard BFS on
  very sparse or regular graphs limited by storage. However on the scale-free
  networks it still improves standard BFS by more than 10x in time without
  introducing much extra required space.  } \hide{ However, we do not recommend
  to actually use our algorithm to replace existing highly-optimized parallel
  BFS implementations on real-world graphs, since the diameter of real-world
  graphs is usually not that large, and the standard parallel BFS can finish in
  the number of steps to be about half the diameter, and this already provides
  much parallelism.  If one wants to have a try, we recommend to pick  no
  more than 20, so the number of shortcuts is relatively small comparing to the
  edges in the original graph, which provide a reduction of steps for a factor
  of 3--5. } \hide{ \yihan{Rewrite: good performance on webgraph since we can
    afford a large , with 20x less depth with adding about 
    edges. On planar or near-planar graphs, we can reduce depth by increasing
    , but the number of added edges in turn increases more rapidly. If we
    can afford the storage our algorithm is still very good, otherwise for those
    graphs in which vertices have constant degrees, we do not recommend our
    algorithm to replace conventional BFS. }}

\begin{figure*}[t]
\begin{center}
    \begin{minipage}[t]{0.45\textwidth}
\begin{center}
    \begin{minipage}[t]{\textwidth}
        \includegraphics[width=\textwidth]{figures/roadmap-round}\\ \centering{\small \bf (a) Road maps}
    \end{minipage}
    \begin{minipage}[t]{\textwidth}
        \includegraphics[width=\textwidth]{figures/webgraph-round}\\ \centering{\small \bf (b) Webgraphs}
    \end{minipage}
    \begin{minipage}[t]{\textwidth}
        \includegraphics[width=\textwidth]{figures/grid-round}\\ \centering{\small \bf (c) Grids}
    \end{minipage}
  \caption{Unweighted graphs---the number of \AlgName{} steps as  is varied.}\label{fig:numerofrounds}
\end{center}
    \end{minipage}  ~~~~~
    \begin{minipage}[t]{0.45\textwidth}
\begin{center}
    \begin{minipage}[t]{\textwidth}
        \includegraphics[width=\textwidth]{figures/roadmap-round-weighted}\\ \centering{\small \bf (a) Road maps}
    \end{minipage}
    \begin{minipage}[t]{\textwidth}
        \includegraphics[width=\textwidth]{figures/webgraph-round-weighted}\\ \centering{\small \bf (b) Webgraphs}
    \end{minipage}
    \begin{minipage}[t]{\textwidth}
        \includegraphics[width=\textwidth]{figures/grid-round-weighted}\\ \centering{\small \bf (c) Grids}
    \end{minipage}
    \caption{Weighted graphs---the number of \AlgName{} steps as  is
      varied.}\label{fig:numerofroundsw}
\end{center}
    \end{minipage}
\end{center}
  \vspace{-2.5em}
\end{figure*}



\medskip

\noindent\textbf{Weighted Graphs:}
Figure~\ref{fig:numerofroundsw} shows, for the weighted case, the average number
of steps taken by \AlgName{} as  is varied.  More results appear in
Tables~\ref{tab:stepweighted} and \ref{tab:stepreducedweighted} in the appendix,
which compare the number of steps taken by \AlgName to when .  Notice
that when , \AlgName{} becomes essentially Dijkstra's except vertices with the same distance are extracted together.



Similar to the unweighted case, the trends in Figure \ref{fig:numerofroundsw}
are also nearly-linear, indicating an inverse-proportion relationship between
the number of steps and , which is consistent with our theory.  In the
weighted case, however, we can visit much fewer vertices in each step than those
in the unweighted case because most vertices have different distances to the
source.  Thus, Dijkstra's algorithm (or when ) requires almost 
steps to finish.  As a result, considering the inverse-proportion relationship,
even a small  can reduce greatly the number
of steps.  Indeed, the number of steps taken by \AlgName is far fewer than the
predicted theoretical upper bound ( with 
here).  We also notice that the number of steps decreases much faster when
 is small compared to larger values of .



The reduction in the number of steps is significant. Even  leads to
about x fewer steps on road maps and grids, and about --x on the
webgraphs. When , we only need a few hundreds of steps on all graphs, which
can already provide considerable parallelism.  The number of steps further
decreases to -- when .  This provides some evidence that the
algorithm has the potential to deliver substantial speedups when many more cores
on a shared-memory machine are made available.

Another trend is that the reduction factors on the webgraphs are always less
than the other two types of graphs.  The reason is that the webgraphs are
scale-free, and even when we do not use enclosed balls to traverse the graph,
not many steps are required. The ``hubs'' substantially bring down the diameter
of the graph.  For more uniformly distributed graphs, such as the road maps and
grids, increasing  to a big value reduces the number of steps required to
perform \sssp{} more rapidly.


\subsection{How to choose the parameters?}

\emph{What is the best combination of  and ?}  The choice of  and
 offers a tradeoff between the number of added edges (hence additional
space and work) and the parallelism of the algorithm.  In general, we do not
want to increase the number of edges substantially; the total number of edges
should be around .  On every graph tested,  or  works reasonably
well whereas  in the range -- for weighted graph
yields the best bang for the buck.  A larger  can reduce
the number of steps in \AlgName{} but in turn, increases the preprocessing time
and the number of edges required to be added. A larger  will reduce the
number of added edges but at the same time, increases the number of visited
edges, as well as the overall depth\footnote{As mentioned at the beginning of
  Section~\ref{sec:expreduce}, a larger  will not increase the number of
  steps, but the number of the overall substeps, which is the inner loop of
  \AlgName{}, hence an increase in the overall depth.}.

On unweighted graphs, \AlgName{} performs better on webgraphs, but less efficient on grids and road maps.
Finally, since
preprocessing is only run once, if \sssp will be run from multiple sources, we
suggest increasing  and decreasing : the cost for preprocessing is
amortized over more sources.

