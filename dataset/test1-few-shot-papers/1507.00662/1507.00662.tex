\documentclass[oribibl]{llncs}

\title{On the Approximability of Digraph Ordering}
\author{Sreyash Kenkre\inst{1}
	\and Vinayaka Pandit\inst{1}
        \and Manish Purohit\inst{2}\thanks{Partially supported by NSF grants CCF-1217890 and IIS-1451430.}
	\and Rishi Saket\inst{1}}

	\institute{IBM Research, Bangalore, Karnataka 560045, India \\ {\tt
		\{srekenkr, pvinayak, rissaket\}@in.ibm.com}  \and 
		University of Maryland, College Park, MD 20742, USA \\ {\tt
	manishp@cs.umd.edu}}

\usepackage{amssymb, amsmath, mathrsfs}
\usepackage{graphicx}
\usepackage[lined,boxed,commentsnumbered,linesnumbered]{algorithm2e}
\usepackage{algpseudocode}
\usepackage{color}
\usepackage{enumerate}
\usepackage{footmisc}
\usepackage{xspace}
\usepackage{url}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\from}[2]{{\bf From #1 :{ #2}}}
\newcommand{\todo}[1]{{\color{red} Todo: #1}}
\newcommand{\hide}[1]{{}}

\newcommand{\eps}{\varepsilon}

\newcommand{\mas}{{\sc MAS}\xspace}
\newcommand{\maxk}{{\sc Max--Ordering}\xspace}
\newcommand{\maxdi}{{\sc Max-DiCut}\xspace}
\newcommand{\mink}{{\sc DED}\xspace}
\newcommand{\rmas}{{\sc RMAS}\xspace}
\newcommand{\rmasoff}{{\sc OffsetRMAS}\xspace}
\newcommand{\off}{{\theta}}

\newcommand{\slfrac}[2]{\left.#1\middle/#2\right.}
\newcommand{\mc}[1]{\ensuremath{\mathcal{#1}}\xspace}

\spnewtheorem{cl}{Claim}{\bfseries}{\itshape}

\usepackage{thmtools}
\usepackage{thm-restate}
\usepackage[margin=1.5in]{geometry}
\pagestyle{plain}
\begin{document}

\maketitle

\begin{abstract}
	Given an -vertex digraph  the 
	\maxk problem is to compute a labeling  
	maximizing the number of forward edges, i.e. edges 
	 such that . For
	different values of , this reduces to
	\emph{maximum acyclic subgraph} (),
	and \maxdi (). This work studies the approximability
	of \maxk and its generalizations, motivated by their
	applications to job scheduling with \emph{soft} precedence
	constraints. 
	We give an LP rounding based
	-approximation algorithm for \maxk for any ,
	improving on the known -approximation
	obtained via
	random assignment.
	The tightness of this
	rounding is shown by proving that for any  and
	constant , 
	\maxk has an
	LP integrality gap of  for
	 rounds of
	the Sherali-Adams hierarchy.

	\smallskip
	A further generalization of \maxk is the \emph{restricted
	maximum acyclic subgraph} problem or \rmas, where each vertex
	 has a finite set of allowable labels . We prove an LP rounding based
	
	approximation for it, improving on the  approximation recently given by Grandoni et
	al.~\cite{grandoni2015lp}. In fact, our approximation algorithm also works for a
	general version where the objective counts the edges which go
	forward by at least a positive \emph{offset} specific to each
	edge. 
	
	\smallskip
	The minimization formulation of digraph
	ordering is \emph{DAG edge deletion} or \mink, which
	requires deleting the minimum number of edges from an
	-vertex directed
	acyclic graph (DAG) to remove all paths of length .
	We show that both, the LP relaxation
	and a local ratio approach for \mink yield -approximation 
	for any
	.
	A vertex deletion
	version was studied earlier by Paik et al.~\cite{paik1994deleting}, 
	and
	Svensson~\cite{svensson2012hardness}. 
\end{abstract}

\section{Introduction}
\label{sec:introduction}
One of the most well studied combinatorial problems on directed graphs
(digraphs)
is the \emph{Maximum Acyclic Subgraph} problem (\mas): given an -vertex digraph,
find a subgraph\footnote{Unless specified, throughout this
paper a \emph{subgraph} is not necessarily induced.} of maximum number 
of edges 
containing no directed cycles. 
 An equivalent formulation of \mas is to
obtain a linear ordering of the vertices which maximizes the number of directed
edges going forward. A natural generalization is \maxk
where the goal is to compute the best \emph{-ordering}, i.e. a labeling of
the vertices from  (), which
maximizes the number of directed edges going forward in this ordering.
It can be seen -- and we show this formally -- that \maxk is
equivalent to finding the maximum subgraph which has no directed
cycles, and no directed paths\footnote{The length of a directed path is
the number of directed edges it contains.} of length . Note that \mas is
the special case of \maxk when , and for  \maxk reduces to the
well known \maxdi problem. 

A related problem is the \emph{Restricted Maximum Acyclic Subgraph} problem or
\rmas, 
in which each vertex  of the digraph has
to be assigned a label from a finite set 
 to maximize the number of edges
going forward in this assignment. 
Khandekar et al.~\cite{khandekar2009hardness} 
introduced \rmas in the context of \emph{graph
pricing} problems and its approximability has recently 
been studied by Grandoni et al.~\cite{grandoni2015lp}. A further
generalization is \rmasoff where each edge  has an offset
 and is satisfied by a labeling  if
. Note that
when all offsets are unit \rmasoff reduces to \rmas, which in turn
reduces to \maxk when  for all vertices .

This study focuses on the approximability of \maxk and its
generalizations  and 
is motivated by their applicability
in scheduling jobs with \emph{soft} precedences under a hard deadline. 
Consider the following simple case
of discrete time scheduling: given  unit length jobs with precedence
constraints and an infinite capacity machine, find a schedule so that all the jobs
are completed by timestep . Since it may not be feasible to satisfy all
the precedence constraints, the goal is to satisfy the maximum number.
This is equivalent to \maxk on the corresponding precedence digraph.
One can generalize this setting to each job having a
set of allowable timesteps when it can be
scheduled. This can be abstracted as \rmas and a further
generalization to each
precedence having an associated lag between the start-times yields
\rmasoff as the underlying optimization problem.  

Also of interest is the minimization version of \maxk on directed
\emph{acyclic} graphs (DAGs). We refer to it as \emph{DAG edge
deletion} or \mink where the goal is to
delete the minimum number of directed edges from a DAG so that the
remaining digraph does not contain any path of length . Note that
the problem for arbitrary  does not admit any approximation factor on
general digraphs since even detecting whether a digraph has a 
path of length  is the well studied NP-hard longest path problem. â€¦
A vertex deletion formulation of
\mink was introduced as an abstraction of
certain VLSI design and communication problems by Paik et
al.~\cite{paik1994deleting} who gave efficient algorithms for it on special
cases of DAGs, and proved it to be NP-complete in general. More recently,
its connection to project scheduling was noted 
by Svensson~\cite{svensson2012hardness} who proved 
inapproximability results for
the vertex deletion version. 
  
The rest of this section gives a background of previous related work,
describes our results, and provides an overview of the techniques
used.

\subsection{Related Work}
It is easy to see that \mas admits a trivial -approximation, by
taking any linear ordering or its reverse, and this is also obtained by a random
ordering.
For \maxk the random -ordering yields a
-approximation for any . For
, which is \maxdi, the semidefinite programming (SDP) 
relaxation is shown to yield a -approximation in \cite{lewin2002improved}, improving upon previous analyses of
\cite{matuura20010},  \cite{zwick2000analyzing}, and \cite{FeigeGoemans}. 
As mentioned above, \rmas is a generalization
of \maxk, and a -approximation for it
based on linear programming (LP) 
rounding was shown recently by Grandoni et al.~\cite{grandoni2015lp}
which is also the best approximation for \maxk for . 
For , to the best of our knowledge the proven
approximation factor for \maxk remains . 

On the hardness side, Newman~\cite{newman2000approximating} showed that 
\mas is NP-hard to
approximate within a factor of . Assuming
Khot's~\cite{khot2002power} Unique
Games Conjecture (UGC), Guruswami et al.~\cite{guruswami2008beating} gave a
-inapproximability for any .
Note that \maxdi is at least as hard as {\sc Max-Cut}. Thus, 
for , \maxk is NP-hard to
approximate within factor ~\cite{hastad2001some},
and within factor   assuming the UGC~\cite{khot2007optimal}. 
For larger constants , the
result of Guruswami et al.~\cite{guruswami2008beating} implicitly shows a
-inapproximability for \maxk, assuming the UGC.

For the vertex deletion version of 
\mink, Paik et al.~\cite{paik1994deleting} gave linear time and quadratic time 
algorithms for rooted trees and series-parallel
graphs respectively. 
The problem reduces to vertex cover on -uniform hypergraphs
for any constant  thereby admitting a -approximation, and a
matching -inapproximability assuming the UGC was obtained by
Svensson~\cite{svensson2012hardness}. 


\subsection{Our Results}
The main algorithmic result of this paper is the following improved
approximation guarantee for \maxk.
\begin{theorem}\label{thm:main1}
	There exists a polynomial time -approximation algorithm for \maxk on
	-vertex weighted digraphs for any .
\end{theorem}
The above approximation is obtained by appropriately rounding the
standard LP relaxation of the CSP formulation of \maxk. For small values of 
this yields significant improvement on
the previously known approximation factors:  for 
 (implicit in \cite{grandoni2015lp}),  for , 
and  for . The latter two factors follow from the previous best 
-approximation given by a random -ordering
for . The detailed proof of Theorem \ref{thm:main1} 
is given in
Section \ref{sec:lp-rounding}.

Using an LP rounding approach similar to Theorem \ref{thm:main1}, in
Section \ref{sec:generalizations} we
show the following improved approximation for \rmasoff which implies
the same for \rmas. Our result improves the 
previous -approximation for \rmas 
obtained by Grandoni et al.~\cite{grandoni2015lp}.
\begin{theorem}\label{thm:rmasoff}
	There exists a polynomial time
	 approximation algorithm 
	for \rmasoff on weighted digraphs. 
\end{theorem}

Our next result gives a lower bound that matches the approximation
obtained in Theorem \ref{thm:main1}. In Section \ref{sec:integrality-gaps}, we show that even after
strengthening the LP relaxation of \maxk with a large number of rounds of the
Sherali-Adams hierarchy, its integrality gap remains close to , and
hence Theorem \ref{thm:main1} is tight. 
\begin{theorem}\label{thm:main2}
	For any small enough constant , there exists  such that for \maxk on -vertex weighted digraphs and
	any , 
	the LP relaxation with  
	rounds of
	Sherali-Adams constraints has a  integrality gap.
\end{theorem}

For \mink on DAGs we prove in Section \ref{sec:mink} 
the following approximation for any ,
not necessarily a constant.
\begin{theorem}\label{thm:deletion1}
	The standard LP relaxation for \mink on -vertex DAGs can be
	solved in polynomial time for  and yields
	a -approximation. The same approximation factor is also
	obtained by a combinatorial algorithm.
\end{theorem}
We complement the above by showing in Section \ref{sec:mink-hardness} a
 hardness factor for \mink via a
 simple gadget reduction from
Svensson's~\cite{svensson2012hardness} -inapproximability 
for the vertex deletion version for constant , assuming the
UGC.

\subsection{Overview of Techniques}

The approximation algorithms we obtain for \maxk and its
generalizations are based on rounding the standard LP relaxation for
the instance. \maxk is viewed as a constraint satisfaction problem (CSP) 
over alphabet
, and the corresponding LP relaxation has -valued variables 
 for each vertex  and label , and  for
each edge  and pairs of labels  and  to  and 
respectively. We show that a generalization of the 
rounding algorithm used by Trevisan~\cite{trevisan1998parallel} for approximating 
-ary boolean CSPs yields a
-approximation in our setting. The key
ingredient in the analysis is a lower bound
on a certain product of the  variables 
corresponding to the end points of an edge 
in terms of the  variables for that edge. This improves 
a weaker bound shown by Grandoni et al.~\cite{grandoni2015lp}.
For \rmasoff, a
modification of this rounding algorithm yields the improved
approximation. 

The construction of the integrality gap for the LP
augmented with  Sherali-Adams constraints for \maxk begins
with a simple integrality gap instance for the basic LP
relaxation. This instance is appropriately sparsified  to ensure
that subgraphs of polynomially 
large (but bounded) size are \emph{tree-like}.
On trees, it is easy to construct a distribution over  
labelings from 
to the vertices (thought of as -orderings), 
such that the marginal distribution on each vertex is uniform
over  and a large fraction of edges are satisfied in expectation.
Using this along with the sparsification allows us to construct 
distributions for each bounded subgraph, i.e. good local distributions.
Finally a geometric 
\emph{embedding} of the marginals of these distributions
followed by Gaussian 
rounding yields modified local distributions which are
\emph{consistent} on the common vertex sets. These distributions
correspond to an LP solution with a high objective value,  
for large number of rounds of Sherali-Adams constraints. Our
construction follows the approach in a recent work of
Lee~\cite{lee2014hardness} which is based on earlier works of Arora et
al.~\cite{arora2002proving} and Charikar et al.~\cite{charikar2009integrality}.

For the \mink problem, the approximation algorithms stated in Theorem
\ref{thm:deletion1} are obtained using the acyclicity of the input
DAG. In particular, we show that both, the LP rounding and the
local ratio approach, can be implemented in polynomial time on DAGs 
yielding  -approximate solutions.

\section{Preliminaries} \label{sec:prelims}
This section formally defines the problems studied in this paper. We
begin with \maxk.
\begin{definition}\label{def:maxk} \maxk: Given an -vertex digraph  with a non-negative weight function , 
	and an integer , find a labeling to the
	vertices  that maximizes the weighted 
	fraction of edges  such that , i.e. forward edges.
\end{definition}
It can be seen that \maxk is equivalent to the problem of computing
the maximum weighted subgraph of  which is acyclic and does not
contain any directed path of length . The
following lemma implies this equivalence.
\begin{restatable}{lemma}{equivalence}\label{lem:equiv}
	Given a digraph , there exists a labeling
	 with each edge  satisfying
	, if and only if  is acyclic and does not
	contain any directed path of length .
\end{restatable}

\begin{proof}
	If such a labeling  exists then every edge is directed
	from a lower labeled vertex to a higher labeled one. Thus, 
	there are no
	directed cycles in . Furthermore, any directed path in  has
	at most  vertices on it, and is of length at most . On
	the other hand, if  satisfies the second condition in the
	lemma, then
	choose  for any vertex  to be , where
	 is the length of the
	longest path from any source to . It is easy to see that
	 and for each edge , . \qed
\end{proof}

The generalizations of \maxk studied in this work, viz. 
\rmas and \rmasoff, are defined as
follows.
\begin{definition}\label{def:rmasoff}\rmasoff: 
	The input is a digraph  with a
	finite subset  of labels for each
	vertex , a non-negative weight function , and offsets  for each
	edge . A labeling  to  s.t.  satisfies an edge  if . The goal is to compute a labeling that maximizes the
	weighted fraction of satisfied edges. \rmas is the special
	case when each offset is unit.
\end{definition}

As mentioned earlier, \mink is not approximable on general digraphs. 
Therefore, we define it only on DAGs.
\begin{definition}\mink:  Given a DAG  with a non-negative weight function , 
	and an integer , find a minimum weight set
	of edges  such that  does not
	contain any path of length .
\end{definition}
The rest of this section describes the LP relaxations for \maxk and
\rmasoff studied in this paper. 

\subsection{LP Relaxation for \maxk}
From Definition \ref{def:maxk}, an instance  of 
\maxk is given by , , and . 
Viewing it as a CSP over label set , the standard LP
relaxation given in Figure \ref{fig:LPmaxk} is defined over 
variables  for each vertex  and
label , and  for each edge  and labels 
to  and  to .
\begin{figure}[h]
\setlength{\fboxsep}{10pt}
\begin{center}
\fbox{
\begin{minipage}[c]{4.3in}

subject to,

\caption{LP Relaxation for instance  of \maxk.}
\label{fig:LPmaxk}
\end{minipage}
}
\end{center}
\end{figure}

\noindent
{\bf Sherali-Adams Constraints.} Let  
be a variable corresponding
to a subset  of vertices, and a labeling 
. The LP relaxation in Figure
\ref{fig:LPmaxk} can augmented with  rounds of Sherali-Adams
constraints which are 
defined over the variables . The additional constraints are given in Figure \ref{fig:SAmaxk}. The
Sherali-Adams variables define, for each subset  of at most
 vertices, a distribution over the possible labelings from
 to the vertices in . The constraints given by Equation 
\eqref{eqn:SAcons}  ensure that these
distributions are consistent across subsets. Additionally, 
Equations \eqref{eqn:SAxcons} and \eqref{eqn:SAycons} ensure the
consistency of these distributions with the variables of the
standard LP relaxation given in Figure \ref{fig:LPmaxk}.
\begin{figure}[h]
\setlength{\fboxsep}{10pt}
\begin{center}
\fbox{
\begin{minipage}[c]{4.3in}

\caption{-round Sherali-Adams constraints for LP relaxation in
Figure \ref{fig:LPmaxk}.}
\label{fig:SAmaxk}
\end{minipage}
}\end{center}
\end{figure}

\smallskip
\noindent
{\bf LP Relaxation for \rmas and \rmasoff.} 
The LP relaxation for \rmas is
a generalization of the one in Figure
\ref{fig:LPmaxk} for \maxk and we omit a detailed definition. Let  denote the set of all labels.
For convenience, we define variables  and  and force the infeasible assignments to be zero, i.e.  for . The other constraints
are modified accordingly.  For \rmasoff, an additional change is
that the contribution to the objective from each edge  is
. 

\section{A 2-Approximation for \maxk}
\label{sec:lp-rounding}

This section proves the following theorem that implies 
Theorem \ref{thm:main1}.
\begin{theorem}
\label{thm:2-approx} Let  denote an optimal solution
to the LP in Figure \ref{fig:LPmaxk}. Let  
be a randomized labeling
obtained by independently assigning to each vertex  
label   with probability
. Then, for any edge ,
 
\end{theorem}
To analyze the rounding given above, we  need the following key 
lemma that bounds the sum of
products of row and column sums of a matrix in terms of the matrix
entries. It improves a weaker bound shown by Grandoni
et al.~\cite{grandoni2015lp} and also generalizes to arbitrary
offsets.
\begin{lemma}
\label{lem:psd}
Let  be a  matrix with non-negative entries.
Let  and  denote the sum
of entries in the  row and  column
respectively, and let  be an integer offset . 
Then,

\end{lemma}
\begin{proof} The LHS of the above is simplified as,

where all the indices above are in . Note that \eqref{eqn:RHS2}
follows from \eqref{eqn:RHS1} because: \newline
      (i) For any ,  appears in
      the RHS of \eqref{eqn:RHS1} when  and .\newline
      (ii) For  and ,
       appears in the RHS of \eqref{eqn:RHS1} both,
      when , and when .\newline
      (iii) For any  and  (say
      ), it must be that , and hence
       appears in the RHS of \eqref{eqn:RHS1}
      when  and .\newline
      Thus, we obtain,
      
Therefore, it is sufficient to show that

Substituting, 

and simplifying, inequality \eqref{eqn:squared1} can be rewritten as,

  where ,
   with 
  , and  
  is a symmetric matrix defined as follows: 

To complete the proof of the lemma we show that  is positive
semidefinite. Consider the set of unit vectors
 given by the normalized corner
points of the -dimensional simplex centered at the origin. 
It is easy to see
(for e.g. in Lemma 3 of \cite{frieze1997improved}) that,  if . 
Thus, , where  is a matrix whose columns are
indexed by  such that 
the  column is . 
Therefore,  is positive 
semidefinite.
\qed
\end{proof}
\begin{proof}[of Theorem \ref{thm:2-approx}]
For brevity, let  denote the contribution
of the edge  to the LP objective. From the definition of the
rounding procedure we have, 

For ,  appears  times in the RHS of the above
inequality when , and  times when . Since , we obtain that RHS of Equation \eqref{eqn:expanded} is 
lower bounded by . Substituting back into Equation
\eqref{eq:A} and simplifying gives us that  is at least,

where we use  for .
\qed
\end{proof}

\section{Approximation for \rmasoff}
\label{sec:generalizations}
Let , , , and  
constitute an instance of \rmasoff
as given in Definition \ref{def:rmasoff}.
Without loss of generality, one can assume that for each edge ,  , otherwise
no feasible solution can satisfy  and that edge can be removed. 
A simple randomized
strategy that independently assigns each vertex  either 
or 
with equal probability is a -approximation. The
recent work of Grandoni et al.~\cite{grandoni2015lp} show that
combining this randomized scheme with an appropriate LP-rounding
yields a  approximation algorithm for
\rmas.

We show that a variant of the rounding scheme
developed in Section \ref{sec:lp-rounding} yields an improved
approximation factor for \rmasoff. 
In particular, we prove the following theorem which
implies Theorem \ref{thm:rmasoff}.
\begin{theorem}
\label{thm:rmasapprox}
Let  
denote an optimal solution to the linear programming relaxation of
\rmasoff described in Section \ref{sec:prelims}. Let  be a
randomized labeling obtained by independently assigning labels to
each vertex  with the following probabilities:
  
Then, for any edge  we have

\end{theorem}
\begin{proof}
Let  denote the set of all labels
and let 
denote the contribution of the edge  to the LP objective. We have,
  
  Substituting the assignment probabilities from \eqref{eqn:rmasoffprobs}
  into the above and simplifying we obtain,
  
Note that we allow  in the above sums instead of
 and . This does not affect the analysis as the LP forces  for  and similarly for .  Now, consider the
 matrix . Since
 and  are equal to the row sums and column sums of this
matrix respectively, Lemma \ref{lem:psd} guarantees that,

We thus have, 

where the last inequality uses 
 for .
\qed
\end{proof}

\section{Sherali-Adams Integrality Gap for \maxk}
\label{sec:integrality-gaps}
For convenience, in the construction of the integrality gaps presented
in this section the
integral optimum and the LP objective shall count the weighted
fraction of edges satisfied.
We begin with a simple construction of an -vertex digraph which is
a  integrality gap
for the standard LP relaxation for \maxk in Figure \ref{fig:LPmaxk},
for . 
\begin{cl}\label{claim:int}
Let  be the complete digraph on  vertices, i.e. having
a directed edge for every ordered pair  of distinct vertices
 and . Thus, . Let
. Then,
\begin{itemize}
	\item The optimum of \maxk on  is at most 
		. 
	\item There is a solution to the standard LP relaxation for
		\maxk on  with value . 
\end{itemize}
In particular, the above implies a  
integrality gap
for the LP relaxation in Figure \ref{fig:LPmaxk}.
\end{cl}
\begin{proof}
The number of forward edges is simply the number of ordered pairs of vertices
 with distinct labels.
By Turan's Theorem, 
the optimal integral solution is to partition the vertices into 
subsets whose sizes differ by at most , giving each subset a distinct 
label from . This implies that there are at most 
 forward edges. Hence, the optimal integral solution
has value, 

On the other
hand, consider an  LP solution that assigns  for all
 and , and  for all
 and . Each edge  
contributes,

to the objective. \qed
\end{proof}
The above integrality gap is essentially 
retained even after near polynomial rounds of the Sherali-Adams constraints
given in Figure \ref{fig:SAmaxk}. In particular, we prove the
following that implies Theorem \ref{thm:main2}.
\begin{theorem}\label{thm:main2restated}
	For any constant , there is  such that
	for large enough  and any , 
	there is a weighted digraph 
	satisfying,
	\begin{itemize}
		\item The optimum of \maxk on  is at most 
		.
		\item The LP relaxation for \maxk augmented with
			 
			rounds of Sherali-Adams constraints
			has objective value at least 
	\end{itemize}
\end{theorem}
The rest of this section is devoted to proving the above theorem.  Our
construction of the integrality gap uses the techniques of 
Lee~\cite{lee2014hardness} who proved a similar gap for a variant of the 
\emph{graph pricing} problem. We begin by 
showing that a sparse, random subgraph ,
of the complete digraph  mentioned above,
also has a low optimum solution. For this, we require the following
result on \emph{-samples}~\cite{VC} for finite set systems that
follows from Hoeffding's bound. The reader is referred 
to Theorem 3.2 in \cite{lect} for a proof.
\begin{theorem}
\label{thm:epsilonsample}
  Let  denote a finite set system\footnote{A set system  consists of a
	  ground set  and a collection of its subsets
	  . It is called finite
  if  is finite.}. Suppose
   is a multi-set obtained by sampling
  from  independently and uniformly  times where . Then
  with probability at least ,
   
   is referred to as an -sample for
  .
\end{theorem}
In order to construct a solution that satisfies Sherali-Adams
constraints for a large number of rounds, 
we require the instance to be \emph{locally sparse}, i.e. the
underlying undirected graph is
almost a tree on subgraphs induced by large (but bounded) 
vertex sets. We use the notion of \emph{path decomposability} 
as defined by 
Charikar et al.~\cite{charikar2009integrality} as a measure of local
sparsity.
\begin{definition}\textnormal{[Path Decomposability]} A graph  is
	-path decomposable if every 2-connected subgraph  of 
	contains a path of length  such that every 
	vertex of the path has degree 2 in .  
\end{definition}
We proceed to show that the sparse graph  obtained as above can be
further processed so that it is locally sparse. Applying the
techniques in \cite{charikar2009integrality} and 
\cite{lee2014hardness} yields a solution with high value that
satisfies the Sherali-Adams constraints.

\subsection{Constructing a Sparse Instance}
\label{sec:constr-sparse-inst}

\begin{lemma} \label{lem:lowopt} Let  be the complete
	digraph on  vertices, let  and
	 be a small constant. The weighted 
	digraph 
	obtained by sampling  edges
	uniformly at random satisfies  
	with high probability, where 
	denotes the optimum of \maxk.
\end{lemma}
\begin{proof} Let  and  denote the
	vertices and edges of the digraph . Let  denote some labeling of the vertices.
	Let 
	denote the subset of edges that are satisfied by
	, and  denote the collection of such subsets
	induced by all feasible labelings. Since the number of
	distinct labelings is , we have that . 

	We now construct an -sample for the set system  by randomly sampling edges (with replacement) as per
Theorem \ref{thm:epsilonsample}. Let  denote the bag of
randomly chosen  
edges. Substituting , we get that  and with probability at least  we have,
 
In order to avoid multi-edges in the construction, we define the
weight of an edge  to be the number of times that edge is
sampled in  and let  denote the set of thus weighted 
edges obtained
from . Equation
\eqref{eq:lowobjective} along with Claim \ref{claim:int}
guarantees that the optimum integral
solution of the weighted graph  induced by the edges  is
bounded by  as desired.
\qed
\end{proof}
Given a digraph, let its corresponding undirected multigraph be
obtained by replacing every directed edge by the corresponding
undirected one. Note that if the digraph contains both  and
 edge for some pair of vertices, then the undirected multigraph 
contains two parallel edges between  and . 

We now show that  
obtained in Lemma \ref{lem:lowopt} 
can be slightly modified 
so that its corresponding underlying multigraph is almost
regular, has high girth, and is locally sparse i.e. all small enough
subgraphs are -path decomposable for an appropriate choice of
parameters. 

\begin{lemma}
	\label{lem:girth} Let  and  be
	a small enough constant. Given the complete digraph 
	 on  vertices, let  
	be obtained by sampling (with replacement) 
   edges uniformly at random. 
  Then, with high probability there exists 
  a subgraph  of  obtained 
  by removing at most  edges, such that the undirected 
  multigraph  underlying  satisfies the following
  properties: 
  \begin{enumerate}
  \item \emph{Bounded Degree:} The maximum degree of any vertex is 
	  at most  and  has  edges,
	  where .
  \item \emph{High Girth:}  has girth at least .
  \end{enumerate}
\end{lemma}

\begin{proof}
Since  is obtained by sampling  edges
uniformly, the probability that any given edge is selected is . In addition, these events are negatively
correlated. Therefore given any set of edges , the probability that all
the edges in  are sampled is upper bounded by .

\emph{Bounded Degree:} As the maximum degree of any vertex in  is
at most , the expected degree of any vertex  in  is
at most . Call a vertex  \emph{bad} if it has degree more than  in , and
call and edge  bad if either  or  is bad. Now, for
any edge , the probability that  is bad given that
 is at most  by Chernoff
bound. Hence, the expected number of bad edges is at most
. Finally, by Markov's inequality, with
probability at least , the number of bad edges is at most
. Deleting all bad edges guarantees that
the maximum degree of  is at most  and with probability
at least half, we only delete  edges which
is much smaller than  since .

\emph{Girth Control:} Let  denote the undirected multigraph underlying . Since the degree of any vertex in  is at most , we have


Summing up over all  in , we get that the expected number of cycles of length up to  is at most  and hence it is less than  with high probability. We can then remove one edge from each such cycle (i.e.  edges) to ensure that the graph  so obtained has girth at least . In particular, note that the corresponding digraph  has no 2-cycles.
\qed  
\end{proof}


\subsubsection{Ensuring Local Sparsity}
\label{sec:ensur-local-spars}
Using Lemma \ref{lem:girth} 
we ensure that the subgraph of  induced by any subset of 
 vertices is -path decomposable for some constant .
The following lemma shows that -connected subgraphs of  of
polynomially bounded size are sparse.
\begin{lemma} \label{lem:local-sparsity} The undirected multigraph
	 underlying the digraph  satisfies the following p,
	i.e., there exists  such that every 2-connected
	subgraph  of  containing 
vertices has only  edges where .
\end{lemma}

\begin{proof} Let  denote the undirected multigraph underlying the
	graph  that was used as a starting point for Lemma
	\ref{lem:girth}. The proof proceeds by counting the number of
	possible ``dense'' subgraphs of  and showing that the
	probability that any of them exist in  after the previous
	sparsification steps is bounded by .  We consider two
	cases based on the value of . 

\emph{Case 1: }. We first bound the
total number of 2-connected subgraphs of  with  vertices and
 edges. It is easy to verify that the only possible degree
sequences for such subgraphs are  or
. Suppose it is  and let  be the
vertex with degree 4. Now, there must be a sequence of  vertices
 that represents an Eulerian tour. But the
number of such sequences is upper bounded by  ( for guessing ,  for guessing the position of 
in the middle, and  to guess the other  vertices).
Now assume that the degree sequence is  and  be
the vertices with degree 3. Now, there must a sequence of 
vertices  that represents an
Eulerian path from  to . By a similar argument, the number of
such sequences is bounded by .  Hence, we are guaranteed
that the total number of 2-connected subgraphs of  with 
vertices and  edges is at most .

Therefore, the probability that there exists a subgraph of  with
 vertices and  edges for  is at most  	
where  is an appropriate constant. 
For , we have that
.

\emph{Case 2: .} In this case,
we count the number of subgraphs of  with  vertices and
 edges. As shown by Lee~\cite{lee2014hardness}, the number
of such subgraphs is bounded by  for some constants
 and .

Therefore, the probability that such a subgraph exists in  is at most

where  and  are appropriate constants. We choose  and , such that
above quantity is less than . Summing up over all , we still have that probability such a subgraph
exists is bounded by . \qed \end{proof}

Finally, we need the following lemma proved by Arora 
et al.~\cite{arora2002proving} regarding the existence of long paths in
sparse, 2-connected graphs.  
\begin{lemma}[Arora et al.~\cite{arora2002proving}] 
	\label{lem:arora} Let
	 be an integer and , and
	let  be a 2-connected graph with  vertices and at most
	 edges and  is not a cycle. Then  contains a
	path of length at least  whose internal vertices have
	degree 2 in .  
\end{lemma}

\begin{corollary} \label{cor:path-decomposable} Every subgraph
 of  that is induced on at most 
vertices is -path decomposable.  
\end{corollary} 
\begin{proof}
	Consider any 2-connected subgraph  of . If 
	is not a cycle, then Lemma \ref{lem:local-sparsity} and Lemma
	\ref{lem:arora} together guarantee that  contains a path of
	length at least  such that all internal vertices have
	degree  in , which gives us a path of length 
	with all vertices of degree  in . 
	On the other hand, if  is a cycle, then Lemma
	\ref{lem:girth} guarantees that  has at least 
	vertices and hence again the required path exists.  \qed
\end{proof}
For convenience we replace  in Corollary
\ref{cor:path-decomposable} with , and since , this does not change any parameter noticeably.

\subsubsection{Final Instance}

\begin{theorem} 
	\label{thm:instance} Given 
	and constants , there exists a constant , and parameters ,
	and  such that there
	is an instance  (with underlying undirected 
	graph ) of \maxk with the following properties 
	\begin{itemize} 
		\item Low Integral Optimum: . 
		\item Almost Regularity: Maximum Degree of , and  has 
			 edges.  
		\item Local Sparsity: For , every
			induced subgraph of  on  
			vertices is -path decomposable.  
		\item Large Noise: For , 
			. 
	\end{itemize}
	Note that . 
\end{theorem}
\begin{proof}
	Let  be the digraph obtained from Lemma \ref{lem:girth}.  
	Lemmas \ref{lem:lowopt} and \ref{lem:girth} imply that  
the digraph  so obtained
(i) has low integral optimum, (ii) is almost regular, and (iii) has
girth . 

The large noise condition is satisfied by  for an appropriate constant . 

Corollary \ref{cor:path-decomposable} guarantees that the local
sparsity condition is satisfied if , i.e.
 for another constant . Hence,
by selecting a small enough constant  and an appropriate , 
the instance  obtained in Lemma \ref{lem:girth}
satisfies all the required properties. \qed 
\end{proof}

\subsection{Constructing Local Distributions}
\label{sec:constr-local-distr}

Let  be the instance of \maxk constructed in Theorem
\ref{thm:instance} and let  be the underlying undirected
graph. We now show that there exists a solution to the LP after  
rounds of the Sherali-Adams hierarchy whose objective is at
least . Our proof for the existence of
such a solution essentially follows the approach of 
Lee~\cite{lee2014hardness}.  
Given a set of  vertices , our goal is to give a distribution on
events .

Let  be the shortest distance between  and  in the
(undirected) graph . Let  be the set of vertices that
are at most  distance away from  and let  be the subgraph
induced by  on . Since the maximum degree of vertices is
bounded by , we have  and hence 
is -path decomposable by Theorem \ref{thm:instance}.

The first step of the construction relies on the following theorem by
Charikar et al.~\cite{charikar2010local} that shows that if a graph
 is -path decomposable, then there exists a distribution on
partitions of  such that close vertices are likely to remain in the
same partition while distant vertices are likely to be separated. 

\begin{theorem}[Charikar et al.~\cite{charikar2010local}]
\label{thm:cmmmulticut}
Suppose  is an -path decomposable graph. Let
 be the shortest path distance on  , and ; . Then there exists a
probabilistic distribution of multicuts of  (or in other words
random partition of  into pieces) such that the following
properties hold. For every two vertices  and , 
\begin{enumerate}
	\item If , then the probability that  and
		 are separated by the multicut (i.e. lie in
		different parts) equals ;
		moreover, if  and  lie in the same part, then
		the unique shortest path between  and  also lies
		in that part.  
	\item If , then the probability that  and 
		 are separated by the multicut is at least 
		.  
	\item Every piece of the multicut partition is a tree.  
\end{enumerate} 
\end{theorem}
Based on this random partitioning, we define a distribution on the
vertices in  (actually in ). As each piece of the above
partition is a tree, given some vertex  with an arbitrary label
, we can extend it to a labeling  for 
every other vertex in that piece such that every
directed edge  in the piece satisfies .

For vertices  and  with , we say that label 
for  and  for  \emph{match} if the labeling  can be extended so that for every directed edge  on the
unique shortest path between  and , . Note
that there are exactly  such matching pairs for every  and .
We can now use Theorem \ref{thm:cmmmulticut} to obtain a random
labeling as follows.
\begin{corollary} \label{cor:tree} Suppose  is an
	-path decomposable graph. Let . Then there exists a random labeling  such that 
	\begin{enumerate} 
		\item If , then 
			\\ ii'
		\item If , then
			\\  for any 
			 
	\end{enumerate}
\end{corollary}
\begin{proof}
We first sample from the distribution of multicuts given by Theorem
\ref{thm:cmmmulticut}. For every piece obtained, we pick an arbitrary
vertex  and assign  to be a uniformly random label from
. Now, since each piece is a tree, we can propagate this label
along the tree so that for every directed edge  we have . Note that the final distribution obtained
does not depend on the choice of the initial vertex .

Consider any two vertices  and . If , then if  and  are in the same piece, then the path connecting  and  in the piece is the shortest path. If  and  are matching labels, then

On the other hand, if  and  are not matching,

Similarly, if , then  is lower
bounded by u,v and upper
bounded by u,vu,v.  Substituting the
separation probabilities in Theorem \ref{thm:cmmmulticut} proves the
desired result. \qed \end{proof}

The above random labeling defines a distribution  over labels of pairs of vertices as follows.
\begin{definition} Let  be a fixed set
	of vertices. For any two vertices  and , let  in the local distribution on  defined by  in Corollary \ref{cor:tree}.
\end{definition}

We now define another distribution  over labels for pairs of
vertices that is independent of the choice of the set  as follows.
\begin{definition} For any vertices  and , let
	 if , and  otherwise. Also define  and  for . Since the shortest path between  and  is unique
	when ,  is uniquely defined by  and
	 and is independent of the choice of set .
\end{definition}
Lee~\cite{lee2014hardness} shows that it is possible to use the 
and  distributions defined above to produce consistent
distributions over events of the form . Further, these distributions
need to be consistent, i.e., the marginal distribution on 
does not depend on the choice of its superset ( or ) that is
used to obtained the larger local distribution. The key idea here as
shown by Charikar et al.~\cite{charikar2009integrality} is to embed
 into Euclidean space 
with a small error to obtain  vectors  such that . This uses the large noise property in Theorem
\ref{thm:instance}. The following lemma appears as Lemma 5.7 in
\cite{lee2014hardness}.
\begin{lemma}[Lee~\cite{lee2014hardness}]
There exist  vectors  such that  and .
\end{lemma}
Given such  vectors, one can use a geometric rounding scheme to
define the consistent local distributions. Note that the local
distribution is completely defined by the pairwise inner products of
the vectors which, for any two vectors, is independent of the
subset . Lee~\cite{lee2014hardness} 
shows that the
following simple rounding scheme suffices to obtain a good
distribution: choose a random Gaussian vector , and for each vertex
, let .  
\begin{lemma}[Lee \cite{lee2014hardness} \footnote{The lemma follows
	from the proof of Lemma 5.8 of Lee \cite{lee2014hardness} by
	substituting .}] \label{lem:lee-obj} There
	exists a  depending on  and  such that, in
	the above rounding scheme, for any edge  and any label
	 the probability that  and k is at least .  
\end{lemma}
	Consider the solution to  
	rounds of the Sherali-Adams hierarchy obtained by the 
	above rounding process. 
	For any edge , its contribution 
	to the objective is 
	
The last inequality follows due to  Lemma \ref{lem:lee-obj}. Thus we have 
a fractional solution with  value at least .
This, along with the low optimum of the instance from Theorem
\ref{thm:instance} completes the proof of Theorem
\ref{thm:main2restated}.

\section{The \mink Problem}
\label{sec:mink}

Recall that the \mink problem is to remove the minimum weight subset 
of edges from a given DAG
so that the remaining digraph
does not contain any path of length . 

\subsection{Combinatorial -Approximation}
\label{sec:greedy-k-appr}

In the unweighted case (i.e. all edges have unit weight), 
the following simple
scheme is a -approximation algorithm. As long as the DAG
contains a directed path   of length , delete \emph{all} edges
of that path. It is easy to see that the above scheme guarantees a
-approximation as the optimal solution must delete at least one
edge from the path  while the algorithm deletes exactly  edges.

The following slightly modified scheme that uses the 
local ratio technique yields a -approximation for weighted DAGs.

\vspace{2mm}
{\bf Algorithm {\sf LocalRatio}}:
\vspace{-2mm}
\begin{enumerate}
\item 
\item While  contains a path  of length 
  \begin{enumerate}
  \item 
  \item 
  \item 
  \end{enumerate}
\end{enumerate}

\begin{theorem}
	{\sf LocalRatio} 
	is a polynomial time -approximation to the 
	\mink problem on weighted DAGs. 
\end{theorem}
\begin{proof}
	We note that the {\sf LocalRatio} 
	terminates in at most  iterations as
the weight of at least one edge reduces to 0 in each iteration. Also,
since one can check if there exists a path of length  in DAG via a
dynamic programming, it follows that {\sf LocalRatio} runs in polynomial
time.

Let  be an optimal solution and  be the
solution returned by {\sf LocalRatio}.
Note that an edge is in  if its
weight is reduced to  in some iteration of the algorithm. 
Thus, the weight of  is upper
bounded by the total reduction in the weight of the edges. 
At each iteration, for a path  of
length , the reduction is at most
 times the minimum weight edge (according to the current weights)
on in . Since there is at least one edge  in  which is in
, we charge this reduction to the weight of . Then
the weight of  decreases by at least  factor of what is charged to
it, and it cannot decrease beyond . Thus, the weight of  is
at most the  times the weight of . \qed
\end{proof}

\subsection{-Approximation via LP Rounding}
\label{sec:ded-lp}

The natural LP relaxation for \mink on an -vertex DAG  
is given in Figure \ref{fig:LPmink}.
\begin{figure}[h]
\setlength{\fboxsep}{10pt}
\begin{center}
\fbox{
\begin{minipage}[c]{4.3in}

subject to,

\caption{LP Relaxation for instance  of \mink.}
\label{fig:LPmink}
\end{minipage}
}\end{center}
\end{figure}
This relaxation has  constraints. 
However, when the input graph is a DAG, it admits the following 
polynomial time 
separation oracle for any .

\subsubsection{Separation Oracle and Rounding.}
\label{sec:separation}
For each vertex  and integer , 
define  
where  is a path of length  that ends at vertex . 
Once we compute all these  values, then a constraint is 
violated if and only if there is a vertex  such that .

On a DAG the  can be computed 
by dynamic programming. First assume that the vertices are arranged in 
a topological order. For any vertex  with no predecessors, set 
. Otherwise, we have the following recurrence,

It is easy to see that the above recurrence leads to a dynamic program
on a DAG.
Once we obtain an optimal solution to the LP relaxation, a simple threshold based rounding using  a threshold of  yields a -approximation.
\begin{theorem}
	The standard LP relaxation for \mink on -vertex DAGs can be
	solved in polynomial time for  and yields
	a -approximation. 
\end{theorem}

\subsection{Hardness of Approximation}
\label{sec:mink-hardness}

For fixed integer  and arbitrarily small constant ,
Svensson~\cite{svensson2012hardness} showed factor 
UGC-hardness of
the \emph{vertex deletion} version of \mink, which requires deleting
the minimum number of vertices from a given DAG to remove all paths
with  vertices. 
In particular, 
\cite{svensson2012hardness} proves
the following structural hardness result.
\begin{theorem}[Svensson~\cite{svensson2012hardness}]
	\label{thm:svensson} For any fixed integer  and arbitrary
	constant , assuming the UGC the following is NP-hard: 
	Given a DAG
	, distinguish between the following cases:
	\begin{itemize} 
		\item \textnormal{(Completeness):} 
			There exist  disjoint subsets
			 satisfying  and such that a
			subgraph induced by any  of these subsets
			has no directed path of  vertices.  
		\item \textnormal{(Soundness):} 
			Every induced subgraph on 
			vertices has a path with  vertices.  
	\end{itemize}
\end{theorem}
The following theorem provides a simple gadget reduction from the
above theorem to a hardness for \mink on DAGs.
\begin{theorem}
  \label{thm:ded-hardness}
  Assuming the UGC, for any constant 
  and , 
  the \mink problem on weighted DAGs is NP-hard to approximate with a
  factor better than .
\end{theorem}
\begin{proof}
Fix . Let  be a hard
instance from Theorem \ref{thm:svensson} for the parameter  and
small enough . 
The following simple reduction yields a weighted DAG  as an instance of \mink. 
Assign  to every edge . Split
every vertex  into  and  and add a directed edge
 of weight . Also every edge entering  now
enters  while edges leaving  now leave . It is
easy to see that removing all edges of weight  from  eliminates
all paths with  edges, implying that the optimum solution has
weight at most . Thus, we may assume that the optimum solution
does not delete any edge of weight . 

We now show that Theorem \ref{thm:svensson} implies that it is
-hard to distinguish whether: (Completeness)  has a
solution of cost , or (Soundness)  
has no solution of cost . This immediately implies the
desired 
UGC-hardness for \mink.
\begin{itemize} 
	\item (Completeness) There exists a subset  of
			size at most , such
			that removing  eliminates all paths in 
			of  vertices. Let  denote
			the set of edges in  corresponding to the
			vertices in . It is easy to observe that
		 	
			has no paths of length (number of edges) .
			Thus,  is a feasible solution to the \mink
			problem of cost .
		
	\item (Soundness) Assume for the sake of contradiction, that
		we have an optimal solution  of cost at
		most . Since  is an optimal
		solution it only has edges of weight , each
		of which correspond to a vertex in .
		Let  denote this set of vertices in . By
		construction, since  has no paths with  edges, 
		has no induced paths with  vertices. 
		Further,
		since , we have . Thus, we have a set of size
		 that has no induced paths of length .
		This is a contradiction since every induced subgraph
		of  vertices has a path of length
		.  
\end{itemize} 
\qed 
\end{proof}


\bibliographystyle{plain}
\bibliography{bibfile}

\end{document} 
