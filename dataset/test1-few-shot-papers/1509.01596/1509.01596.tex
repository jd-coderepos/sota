\documentclass[journal,twocolumn,10pt,twoside]{IEEEtranTCOM}







\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{subfigure}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{subfigure}
\usepackage{graphicx,amssymb,amsmath,cite,subfigure,hyperref,calc}
\usepackage{graphicx,amssymb,amsmath,cite}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\usepackage{cite}
\usepackage[]{algorithm2e}
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}
\theoremstyle{plain}
\newtheorem{prop}[thm]{\protect\propositionname}
\theoremstyle{remark}
\newtheorem{rem}[thm]{\protect\remarkname}
\newtheorem{remark}{Remark}





\usepackage{cite}
\begin{document}




\title{Inter-Layer Per-Mobile Optimization of Cloud Mobile Computing: \protect\\ A Message-Passing Approach}


\author{Shahrouz Khalili, \emph{Student Member, IEEE} and\thanks{This work was partially supported by the U.S. NSF through grant no. 1525629.}\thanks{S. Khalili and  O. Simeone are with CWCSPR, ECE Dept, NJIT, Newark, USA. E-mail: \{sk669, osvaldo.simeone\}@njit.edu.} Osvaldo Simeone, \emph{Senior Member, IEEE}}

\maketitle
\vspace{-1in}

\begin{abstract}
Cloud mobile computing enables the offloading of computation-intensive applications from a mobile device to a cloud processor via a wireless interface. In light of the strong interplay between offloading decisions at the application layer and physical-layer parameters, which determine the energy and latency associated with the mobile-cloud communication, this paper investigates the inter-layer optimization of fine-grained task offloading across both layers. In prior art, this problem was formulated, under a serial implementation of processing and communication, as a mixed integer program, entailing a complexity that is exponential in the number of tasks. In this work, instead, algorithmic solutions are proposed that leverage the structure of the call graphs of typical applications by means of message passing on the call graph, under both serial and parallel implementations of processing and communication. For call trees, the proposed solutions have a linear complexity in the number of tasks, and efficient extensions are presented for more general call graphs that include "map" and "reduce"-type tasks. Moreover, the proposed schemes are optimal for the serial implementation, and provide principled heuristics for the parallel implementation. Extensive numerical results yield insights into the impact of inter-layer optimization and on the comparison of the two implementations.
\end{abstract}

\begin{IEEEkeywords}
Cloud mobile computing, Message passing, Inter-layer optimization, Dynamic programming.
\end{IEEEkeywords}





\section{Introduction}
\label{sec:intro}
With the current widespread use of smart phones, there is an increasing
demand on the users' part for applications that require heavy computations
to be run on battery-powered mobile devices, such as video processing,
gaming, automatic translation, object recognition and medical monitoring. Offloading energy-consuming tasks from a mobile
device to a cloud server -- known in the literature as cyber foraging, computation offloading \cite{kumar} and, more commonly, cloud mobile
computing \cite{fern} -- provides a viable solution to this problem, as attested to by systems such as Google Voice Search, Apple Siri and
Shazam and by implementations such as MAUI \cite{maui} and ThinkAir \cite{kosta}.

A mobile application can be partitioned into its component tasks via
profiling, producing a \emph{call graph }for the program \cite{cal}. The call graph describes the functional dependence between the different tasks (see Fig. \ref{graph2} for an example). Offloading can either take place at the coarser
granularity of entire applications, as in, e.g., \cite{sat}, or at the finer scale of individual tasks, see \cite{maui}. In the latter case, each task may be either offloaded to the cloud
or performed locally. Moreover, processing and communication processes can either be implemented one after another in a serial fashion, as assumed in most prior art, or may be parallelized in the case of non-conflicting tasks as in \cite{no}\cite{hermp}.

\begin{figure}
\centering
\includegraphics[scale=.35]{graph_hermp.png}
\caption{An example of a call graph  \cite{hermp}.}\label{graph2}\vspace{-1.5em}
\end{figure}
\textbf{State of the Art}: The large majority of prior works on the subject of optimal fine-grained
offloading tackles the problem on a per-mobile basis, and assumes a \emph{fixed physical layer}, which provides given
information rate and latency. Examples of this approach for the serial implementation include \cite{yang}, which uses a graph
partitioning formulation; \cite{odessa}, which presents a heuristic on-line approach to task
partitioning to improve latency; and \cite{sub} and \cite{cll}, which assume a time-varying channel and propose
adaptive solutions based on Lyapunov optimization and a constrained
shortest path problem, respectively. Instead, for the parallel implementation, references \cite{no}\cite{hermp} propose a dynamic programming solution, again with a fixed physical layer.


While the assumption of a fixed physical layer made in all reviewed works simplifies the problem
formulation, there is an evident interplay between decisions at the
physical layer and offloading decisions at the application layer.
Most fundamentally, the choice of the physical layer mode, e.g., of
the transmission power and information rate, determines
the mobile energy consumption, as well as the corresponding latency, for mobile-cloud communication. Therefore, a proper adaptation of the physical layer is instrumental in making cloud mobile computing viable.


Recognizing this critical interplay, more
recent work has tackled the \textit{inter-layer optimization of the physical
and of the application layers}. Specifically, references \cite{barba}\cite{stef}
 studied this problem for a general network of interfering
mobile devices by assuming \textit{coarse-grained offloading}. Fine-grained offloading is instead studied in \cite{bar}, where the authors focus on a per-mobile formulation under a serial implementation. To reduce the complexity of the resulting mixed integer program in \cite{bar}, a method is proposed that limits the exponential number of alternative offloading decisions based on feasibility arguments. Furthermore, for fixed offloading decisions, the problem is shown to have useful convexity properties. A similar problem formulation is also studied in \cite{holis}.


\textbf{Main Contributions}: In this paper, we investigate the per-mobile inter-layer fine-grained optimization of offloading decisions at the application layer and of the transmission powers at the physical layer, with the aim of minimizing energy and latency for \textit{both} serial and parallel implementations. As discussed, prior works, including \cite{bar}\cite{holis}, formulate the problem as a mixed integer program, whose complexity is exponential in the size of the call graph. Here, instead, we start from the observation that most call graphs have specific structures that can be leveraged to reduce the computational complexity. For instance, Fig. \ref{graph2} shows a typical example of an application that is composed of ``map'' tasks, which perform operations such as filtering, features extraction or sorting, and allow the successive tasks to be decomposed into independent operations (see tasks , , ); along with ``reduce'' tasks, which perform summary operations such as classification or regression (see tasks ,  and ). This paper shows that, for structured graphs, solutions based on message passing can be developed for the both standard \textit{serial} implementation, (see Sec. \ref{sec:ser}), as well as the \textit{parallel} implementation (see Sec. \ref{sec:par}).

In particular, for applications with a tree structure, such as the subtrees  and  in Fig. \ref{graph2}, we develop optimal efficient message passing algorithm for the serial implementation, whose complexity is of the order , where  is the number of nodes of the call graph and  is the maximum in-degree. For the more challenging parallel implementation, the proposed method yields a principled suboptimal scheme whose complexity is of the same order as for the serial case. The performance of this scheme is evaluated by means of a dynamic model also introduced here. For more general call graphs, such as the one in Fig. \ref{graph2}, we generalize the proposed solutions to yield a complexity of the order , where  is the number of nodes that, if removed, decompose the graph into subtrees (such as ,  and  in Fig. \ref{graph2}, so that  for this call graph). With reference to prior work, we note that the proposed approach for parallel case generalizes the schemes in \cite{no} and \cite{hermp} by encompassing also the optimization of the physical layer. Extensive simulation results, presented in Sec. \ref{sec:simu}, bring insight into the impact of inter-layer optimization and of the call graph structure on the performance of the cloud mobile computing.


\emph{Notation}: Throughout, we use the graph terminology of, e.g., \cite{koller}. Accordingly, for a graph , a node  with an incoming edge from another node  is referred to as a \textit{child} of the \textit{parent} node .  and  are the sets containing parents and children, respectively, of a node . Given a set , where  is the set of integers and variables  with ,  is the set defined as ; similarly, for variables  with  ,  is the set defined as .
\section{System Model}
\label{sys:mod}
We consider a per-mobile problem formulation in which a mobile aims at running a given application with  minimal energy expenditure and latency. For this purpose, the mobile may offload some of the computing tasks to a cloud processor, also referred to as server. We consider a configuration with a single processor both at mobile and cloud. We start in this section by introducing the key quantities at the \textit{application layer} and then at the \textit{physical layer}.
\subsection{Application Layer}
A computer application can be described by its call graph \cite{cal}. A call graph  is a \textit{directed acyclic graph}  which is used to represent the casual relation among the tasks in which a program can be partitioned. An example is shown in Fig. \ref{graph2}. Each vertex, or node, in  represents a particular task to be carried out within the application, e.g., data preparation, edge recognition or transform coding. We denote the task nodes as . However, we will also use the shortcut notation  in lieu of , where no confusion can arise. In the call graph , a directed edge  with  and  denotes the invocation of a ``child'' task   by a ``parent'' task .



Each task node  is characterized by a parameter , which is the number of CPU cycles required for task  to be completed. Let us define as  and  the number of CPU cycles/sec that can be run at the mobile (i.e., locally) and the cloud (i.e., remotely), respectively. The latency   is then the time required to compute task  locally and  is the latency to run that task remotely in the case the respective processors are devoted only to the completion of task . Each edge  is instead labeled by the number of bits  that must be transferred by the parent task  in order to allow the computation of the child task .



To complete the description of the quantities of interest at the application layer, we introduce the \textit{offloading decision variables}. Specifically, we define  as the indicator variable that determines whether task  should be executed locally or remotely, where  indicates the local execution of the task and  represents the offloading of the task to the remote server. Not all the tasks may be eligible for offloading. In particular, a mobile application typically operates on input data, e.g., images or videos, that reside in the mobile device. This can be accounted for by identifying a subset  of task nodes that represent input data preparation processes, such that for every task  we have , i.e., local processing. These nodes are assumed to have no parents and have the role of initializing the application (see, e.g., \cite{no}\cite{hermp}). For instance, in Fig. \ref{graph2}, we may have . Moreover, for any graph, we assume, without loss of generality, that there is a final task to be carried out at the mobile that has no children and completes the application by, e.g., showing the results on the mobile screen. An example is task  in Fig. \ref{graph2} for which we then have .


\subsection{Physical Layer}
\label{sec:intro:phy}
We now describe the parameters and the optimization variables relative to the \textit{physical layer}. The parameter  represents the local processing power of the mobile and  is the power required to keep the mobile's RF circuits active during both transmission and reception, while  is the power needed to process the received baseband signal for decoding at the mobile. All powers are measured in Watts. The parameter  (bits/s) is the downlink capacity available to transfer the information bits from the server to the mobile. Uplink and downlink are assumed to be operated over orthogonal spectral resources.

The optimization variable  is the uplink power used by the mobile to transfer the necessary  bits in case a parent task  is run locally  () and a child task  is performed remotely () for all . Note that we allow the uplink transmit powers  to be different for every edge in , hence enabling a more flexible joint optimization of application and physical layers as in \cite{bar}. Given an uplink power , we denote as

the uplink rate (bits/s) between the mobile and the server, where  accounts for the channel gain between mobile and the server,  is the available bandwidth and  (Watts/Hz) is noise power spectral density.





\section{Problem Formulation}
\label{sec:prob}
In this work, we aim at optimizing the application layer variables , with  for  and for the root node, and the physical layer variables . We consider separately serial and parallel implementations.
\subsection{Serial Implementation}
\label{sec:ser}
In this section, as in most prior work, we assume that at any time, only one operation, either computation or communication, may take place, either at the mobile or at the server. Therefore, the operations needed to run a given application are performed in a serial fashion one after another. Note that the order in which these operations are scheduled is arbitrary as long as it is consistent with the procedures encoded in the call graph. For instance, for the tree  in Fig. \ref{graph2} if  and , tasks  and  can be first carried out in any order at the mobile; then,  and  bits are transferred in the uplink in any order; then, node  is processed at the cloud; and finally  bits are downloaded by the mobile, which performers task .

Under a serial implementation, the overall latency is the sum of all the latencies required to communicate and compute across all task nodes, which can be written as (see also \cite{bar})

where  denotes the delay required to perform the computations associated with task  either locally or remotely;  accounts for the delay caused by the transfer of  bits to the server if task  is offloaded () but  is not ();  represents the latency caused by the transfer of  bits at the mobile if  is offloaded () and  is run locally ().

The energy spent by the mobile for given variables is similarly given as the sum (see also \cite{bar})

where the term  measures the energy consumed by the mobile to perform each task  locally if ; the term  is the energy required, for a task  with , to transfer information from all the parent tasks  that are performed locally, namely with ; and finally  is the energy consumed, for a task  with , to transfer and decode the information in the downlink from parent tasks  with .


\subsection{Parallel Operation}
\label{sec:par:op}
As an alternative to the serial operation discussed above, we now consider an implementation that allows to potentially reduce the latency by parallelizing computing and communication. This implementation was implicitly assumed in \cite{no}\cite{hermp} but without consideration for the optimization of the physical layer. According to this implementation, tasks are processed as soon as they receive the necessary information from their parents. It is then possible for uplink transmissions, downlink transmissions, local and remote computations to  occur at the same time.

As an example, consider the call tree  in Fig. \ref{graph2} with  and .
\begin{figure}
\centering
\includegraphics[scale=.4]{timeline2.png}
\caption{An example of a timeline for the parallel implementation of the call tree  in Fig. \ref{graph2} with  and .}\label{time_line}
\vspace{-1.5em}
\end{figure}
An illustrative timeline is shown in Fig. \ref{time_line}, where   denotes local computing and  denotes remote computing;  indicates that the task is uploading information bits in the uplink; and  means that the task is receiving information from one or more of its parent task nodes  in the downlink. It can be seen that, for instance,  task  can be processed remotely as soon as the information from tasks  and  has been received by the server at time , while uplink transmission for task  may be still ongoing. Observe that, whenever multiple concurrent uplink/downlink transfers take place at the same time, the uplink/downlink spectral resources have to be properly divided (e.g., for tasks ,  and  at time ). This requires an adequate allocation of the spectral resources, such as time-frequency resource blocks in LTE. An analogous discussion applies to the computational resources.

Assuming the feasibility of allocating communication and computation resources as discussed above, the Appendix details a dynamic model that enables the evaluation of the energy and latency of the parallel implementation for given physical- and application-layer variables  and . This framework will be used in Sec. \ref{sec:sim} to evaluate the performance of the parallel implementation using numerical results. However, the framework in the Appendix does not lend itself  to the development of efficient optimization algorithms due to the complexity of accounting for the mentioned reallocation of the communication and computation resources. In Sec \ref{sec:par}, we develop useful heuristics for this purpose.
\subsection{Problem Formulation}
In order to optimize physician and application layer variables, we consider two different standard approaches (see, e.g, \cite{boyd}). In the first problem formulation, a weighted sum of energy and latency is minimized via the problem

where  is a non-negative constant that determines the trade-off between energy and latency and can be interpreted as a Lagrange multiplier. By varying , one can explore the trade-off between latency and energy \cite{boyd}. An alternative problem formulation is to minimize the energy (\ref{cost2}) with a latency constraint as

where  is the maximum allowed delay. Note that, in (\ref{opt2}) and (\ref{opt}), the domains of variables  and  are implicit. As it will be illustrated in the next sections, it is analytically convenient to tackle problem  for the serial implementation and problem  for the parallel implementation.



\begin{remark} References \cite{no}\cite{hermp} tackled problem   for the parallel implementation under the assumption that the call graph is a tree or a parallel/serial combination of trees, and assuming that the physical-layer parameters  are not subject to optimization. Moreover, the papers \cite{no}\cite{hermp} implicitly assume that parallel communication and computation do not entail a division of the available resources, hence bypassing the issue discussed above. Under these assumptions, it is shown  that the problem can be efficiently, albeit approximately, solved via dynamic programming by quantizing the set of possible delays. Reference \cite{bar} studied instead problem  for the serial implementation. The solution given in \cite{bar} prescribes a properly pruned exhaustive search over the variables , and leverages the fact that, for a fixed , the problem of optimization over , upon a proper change of variables, is convex.
\end{remark}




\section{Optimal Task Offloading for Serial Processing}
\label{sec:ser}
In this section, we tackle problem  for serial processing. The key idea of the proposed approach is to leverage the factorization of the objective function in  in order to apply the min-sum message passing algorithm. We first detail the mentioned factorization in Sec. \ref{sec:ser:gen}. Then, in Sec. \ref{sec:ser:tree}, we discuss the proposed efficient optimal method based on min-sum message passing \cite{koller} for the special case of a call tree. Then, in Sec. \ref{sec:ser:graph}, we extend the proposed algorithm to call graphs with more general structure.
\subsection{Factorization of the Cost Function}
\label{sec:ser:gen}
The objective function for problem  can be factorized over the task nodes as follows:

where the factor  accounts for the weighted sum of energy and latency associated with the local or the remote computation of node  and with the transmissions in uplink and/or downlink related to the edges connecting the parents of node  to node . This function is given, from (\ref{ser}) and (\ref{cost2}), as





We now show that the optimization in  over the transmission powers  can be carried out analytically, yielding new factors that are independent of the powers. In fact, given that each power  appears separately in the factors of (\ref{p2}), the optimization of all powers can be carried out independently. In particular, the optimum power  for all edges  is given by the solution of the problem


As discussed in \cite{bar}, the optimization problem in (\ref{p_ser}) becomes strictly convex with the change of variables  and hence its unique solution can be easily found. Note that the optimum values  for all  are equal.

Substituting the optimum powers from (\ref{p_ser}) into (\ref{p2}), the problem  can be rewritten as

where we have defined the factors

\subsection{Message Passing for a Call Tree}
\label{sec:ser:tree}
 \begin{figure}
\centering
\includegraphics[scale=.23]{call-blue.png}
\caption{The clique tree  corresponding to the call tree  in Fig. \ref{graph2}.}\label{cluster}
\end{figure}
For a given call tree , as for  and  in Fig. \ref{graph2}, the problem  in (\ref{p22}) can be solved exactly via the \textit{min-sum message passing} algorithm with a complexity of the order , where  is the maximum in-degree in the call graph. We refer to \cite{koller} for an introduction to message passing algorithms.

The algorithm operates on a clique tree  that is associated with the call tree . The clique tree  can be constructed from  as follows: (\textit{i}) replace the directed edges in  with undirected ones; and (\textit{ii}) substitute each task node  in  with a node of , which we label as the th cluster node. Each cluster node  is assigned the factors  in (\ref{phi_1}). Each edge that connects clusters  and  is labeled with the variable  that appears in both clusters  and .  An example of a call tree and its corresponding clique tree is illustrated in Fig. \ref{cluster}.

Once the clique tree is constructed, the min-sum message passing algorithm can be directly obtained following the standard rules as detailed in \cite[Ch. 10]{koller}. To elaborate, we define  as the message  sent by the th cluster node on the edge labeled by , to its child cluster, where  is the value of the message corresponding to  (local processing) and  is the value of the message for  (remote processing). Note that the definition of the parents and children nodes follows that used for the call tree . The messages of the clusters that are not leaves can be calculated recursively as

and

In order to keep track of the optimal decision , for each cluster  and parent cluster , we also define the functions  and , where we have  if the first argument in the min operation in (\ref{ser_up}) is smaller and  otherwise; and  is defined analogously with respect to (\ref{ser_up2}).
\begin{table}
 \caption{Message Passing Algorithm for the Serial Implementation}\label{tab2}
\begin{tabular}{l}
\hline
1: Calculate the powers  for all\\
~~~ using (\ref{p_ser}).\\
2: Build the corresponding clique tree as explained in Sec. \ref{sec:ser:tree} (see \\
~~~Fig. \ref{cluster}).\\
3:  \textbf{for} : \textbf{do}\\
~~~~~\textbf{if}  is a leaf cluster\\
\\
\\
~~~~~\textbf{else}\\
~~~~~~~~~Update  and   by using (\ref{ser_up}) and (\ref{ser_up2}) and calculate\\
~~~~~~~~~ and  for all \\
~~~~~~~~~as explained in Sec. \ref{sec:ser:tree}.\\
4: Trace back the optimum decisions.\\
\hline
\end{tabular}
\end{table}


As detailed in Table \ref{tab2}, the messages are first sent by the leaf clusters, and then each cluster transmits its message  to its child cluster as soon as it has received the message from all its parents. The message passing algorithm is detailed in Table \ref{tab2}. The optimum decisions are finally obtained via backtracking, starting from the root node  so that for any node  and every parent , we set  if  and  otherwise. From (\ref{ser_up}) and (\ref{ser_up2}), the complexity of serial implementation is of order , since every node needs to sum at most  metrics, each of which only requires two sums and a binary comparison.

\subsection{Message Passing for a General Graph}
\label{sec:ser:graph}

In the case of a more general call graph , it is not possible to directly convert the call graph to a clique tree as done above for a call tree.

We outline here two solutions to this problem. First, assume that the call graph is such that by removing a small number subset  of nodes, one can partition the graph into subtrees. This is the case for typical graphs, such as that in Fig. \ref{graph2}, with a small number of ``map'' and ``reduce'' nodes (see Sec. \ref{sec:intro}). For such graphs, similar to the observation in \cite{hermp}, one can apply message passing scheme introduced above on each subtree for all possible instantiations of the offloading decisions for the mentioned fixed nodes. Then, the minimum value of the function in (\ref{p22}) is calculated over all such instantiations. The complexity of this approach is of the order  .

For graphs with an even more general structure, the junction tree algorithm can be applied to obtain a clique tree \cite[Ch. 10]{koller}. Once the clique tree is obtained, message passing can be implemented by extending the approach described in the previous subsection. The complexity of this scheme depends on the treewidth of the graph \cite{koller}. In general, unless  is prohibitively large, the previous approach is to be preferred due to the possibility to reuse efficient algorithm in Table \ref{tab2}.



\section{Optimization of Task Offloading for Parallel Processing}
\label{sec:par}
In this section, we tackle the problem  in the presence of parallel processing. As for the serial case, we concentrate on call trees  in Sec. \ref{sec:par:tree}, and in Sec. \ref{sec:par:gen} we discuss the extensions to more general call graphs.

As explained in Sec. \ref{sec:prob}, in order to evaluate energy and latency of a parallel implementation, one needs to keep track of the number of concurrent processes that use the local and remote CPUs as well as the uplink and downlink bandwidth. While the dynamic model presented in the Appendix is able to do so, its use for optimization appears challenging. Hence, in this section, in order to develop a useful optimization heuristic, we assume that the number of concurrent uploads, downloads, local computations and remote computations are fixed. Under this simplifying assumption, we propose an algorithm that solves problem  to any arbitrary precision with linear complexity via message passing, and, specifically, via dynamic programming. The performance of the obtained heuristic solution is then evaluated by means of the dynamic model described in the Appendix.

To elaborate, we fix the number of concurrent upload and download transmissions to  and , respectively, and, the number of concurrently computed tasks locally or remotely as  and , respectively. The fixed values of , ,  and  define parameters that can be set by the designer, yielding different optimization solutions that can be evaluated via the dynamic model in the Appendix. More discussion on the selection of these parameters can be found in Sec. \ref{sec:sim}.

Having fixed the mentioned parameters, the optimization proceeds as follows. To start, the available uplink and downlink capacities are obtained as
 
&C^{ul}_{par}(P^{ul}_{m,n})=\frac{C^{ul}(N^{ul}P^{ul}_{m,n})}{N^{ul}}\\
&\mathrm{and}~C^{dl}_{par}=\frac{\log_2\left(1+(2^{C^{dl}}-1)N^{dl}\right)}{N^{dl}},

which correspond to the rates achievable when the spectral resources, either in the time or in the frequency, are equally divided into  and  parts, respectively. Similarly, the frequency of the local and the remote processors can be obtained by



Following \cite{no}, we start by observing that, for each task , the delay required to complete the tasks of the subtree in  rooted at any task node  can be calculated recursively, given that the completion of task  requires completion of all the parent tasks. Specifically the time  by which the subtree rooted at  is completed, given the decisions , can be written in terms of the same quantities for its parents as

where the  is the latency of the subtree rooted at the parent node  and the latency terms are defined as in (\ref{ser}). Note that since  for the leaf nodes in , we have  for . The expression (\ref{par}) can be then calculated recursively starting from the leaf nodes, and the final delay is given by . \subsection{Message Passing for a Call Tree}
\label{sec:par:tree}
In order to develop an approximate solution to problem  under the said assumptions (see (\ref{cap})-(\ref{far})), as in \cite{no}, we partition the set of possible delays into  intervals by means of the quantization function

where  are given predefined latency values. We take for simplicity  for a given quantization step . The algorithm presented below provides  an approximation of the optimal solution of the program at hand, which, following the same arguments as in \cite{no}\cite{hermp}, become increasingly accurate as  becomes smaller.

We define  as the subtree  that is rooted at the task . Moreover, we let  denote the minimum energy needed to run the the tasks in   if node  is executed locally and under the constraint that the latency is less than . Note that the energy  is minimized with respect to the offloading variables in vector  corresponding to the task nodes in the mentioned subtree except , as well as over the uplink powers in vector  corresponding to all the edges within the subtree. Similarly, we define   as the minimum energy cost for  if  is performed remotely and under the delay constraint . We also correspondingly define the set  that  contains the optimum offloading decisions for the parent nodes   of node  if the latter is performed locally under the latency  for the subtree rooted at . Similarly, we define  as the set containing the optimum decisions for the parent nodes  of node , if the latter is performed remotely with the latency constraint .

The proposed dynamic programming algorithm computes the cost functions  and   and the sets  and  recursively from the energy cost functions  and  of all the parent nodes  under all the delay constraints  with . Specifically, we set  and   for  . We can then obtain the recursive relationship

where the function  is defined as .

Equation (\ref{update}) accounts for the fact that the minimum energy cost required to run the task in the subtree  within a latency  if  is run locally is given by the sum of the local processing energy  (see  in (\ref{cost2})) and of the energies required to run all the subtrees  with . For the latter, each parent node  can be run either locally, requiring energy  , or remotely, with an energy . We observe that, if node  is performed locally, the latency allowed for the subtree  is  and hence the corresponding minimum energy is , and similarly for the case in which  is carried out remotely the energy can be calculated as in (\ref{update}). In (\ref{update}), the  operation accounts for the choice of whether node  should be performed locally or remotely. Accordingly, the set  can be evaluated during calculation of  in (\ref{update}) by observing which term in the function   is smaller. Specifically, we can write  if the first term is smaller and  otherwise.



Similar to (\ref{update}), we can also write

where uplink  is selected as detailed below. The two arguments of the  operator measures the energy cost of the subtree  in the case that the parent node  is performed locally or remotely, respectively, and are explained in an analogous fashion as for (\ref{update}). Furthermore, the set  can be evaluated during calculation of  in analogous fashion as .


Once equations (\ref{update})-(\ref{opt_c}) are evaluated starting from the leaf nodes  of  to the root, the optimum powers  and offloading decisions  are obtained via backtracking from the root to the leaves of . Specifically, since the root node must be performed locally  within the delay constraint , the optimum solution (,) can be found starting from the optimal decisions associated with  by keeping track  of  the maximum allowed delay  for each subtree . The complete dynamic complete programming algorithm is presented in Table \ref{al} and the backtracking method is explained in Table \ref{trace}.
\begin{table}
 \caption{Dynamic Programming Solution for Parallel Implementation}\label{al}
\begin{tabular}{l}
\hline
1:  \textbf{for} : \textbf{do}\\
~~~~~\textbf{if} \\
\\
\\
~~~~~\textbf{else}\\
~~~~~~~\textbf{for} ,  \textbf{do}\\
~~~~~~~~~Calculate the powers  for all  using (\ref{p_u2}).\\
~~~~~~~~~Update , ,  and  by using\\
~~~~~~~~~~(\ref{update})-(\ref{opt_c}).  \\
2: Trace back the optimum decisions from  using the\\
~~~algorithm in Table \ref{trace}.\\
\hline
\end{tabular}
\end{table}

Optimization of the powers is carried out by observing that, thanks to the decomposition made possible by dynamic programming, the powers   appear in separate terms in (\ref{opt_c}). Therefore, without loss of optimality, the powers  can be optimized separately from each term in (\ref{opt_c}). This optimization is complicated by the presence of the non-differentiable term  . To address this issue, for each  and each  we calculate

where

by solving  convex subproblems. To this end, we note that the equality  holds as long as the inclusion  is satisfied with
 
where we defined . We can then calculate  in (\ref{p_u2}) by first solving the problems

for all  and then set

Each problem (\ref{opt_p}) becomes convex by means of the change of variable  \cite{bar}.

Since the maximum number of convex optimizations that need to be solved at each time instant for each node can be upper bounded by , and  is proportional to , the complexity of the proposed algorithm in Table \ref{al} is given by .
\begin{table}
 \caption{Backtracking algorithm for Table \ref{al}}\label{trace}
\begin{tabular}{l}
\hline
1: Set  and \\
2:~~~\textbf{for}  \textbf{do} \\
~~~~~~~~~~\textbf{for} all  \textbf{do} \\
~~~~~~~~~~~~~\textbf{if} \\
~~~~~~~~~~~~~~~~~~\textbf{if} \\
~~~~~~~~~~~~~~~~~~~~~~Set  and  .\\
~~~~~~~~~~~~~~~~~~\textbf{else}\\
~~~~~~~~~~~~~~~~~~~~~~Set  and  .\\
~~~~~~~~~~~~~\textbf{else}\\
~~~~~~~~~~~~~~~~~~\textbf{if} \\
~~~~~~~~~~~~~~~~~~~~~~Set , \\
~~~~~~~~~~~~~~~~~~~~~~and   .\\
~~~~~~~~~~~~~~~~~~\textbf{else}\\
~~~~~~~~~~~~~~~~~~~~~~Set  and  .\\
\hline
\end{tabular}
\end{table}
\subsection{Message Passing for a General Call Graph}
\label{sec:par:gen}
Similar to Sec. \ref{sec:ser:graph}, for a graph with the structure discussed in Sec. \ref{sec:intro}, the problem  can be solved, for fixed parameters , ,  and , by means of an exhaustive search over the offloading decisions of the nodes that, when removed, decompose the graph into disjoint trees. Following the discussion in Sec. \ref{sec:ser:graph}, the resulting solution has a complexity of order .

\section{Simulation Results}
\label{sec:simu}
\label{sec:sim}
In this section, we provide some numerical example based on the analysis developed in the previous sections. We start by considering the call tree in Fig. \ref{g_ex} in order to simplify the interpretation of the results and gain an insight into the performance of the considered techniques. In this example,  process input data present at the mobile device, represented by nodes , e.g., to extract some features, and then root node  performs a ``reduce'' operation, such as classification, on the extracted features at the mobile (). We set   Watts, which is a common for smart phones \cite{no,cpu_url,cpu_url2};  CPU cycles/s (e.g., Apple iPhone 6 processor has maximum clock rate of 1.4 Ghz);  CPU cycles/s (e.g., AMD FX-9590 has a clock rate of 5 Ghz \cite{amd});  dB,  W,  W,  MHz,   Mbits/s unless stated otherwise. For both the serial implementation (solid lines) and the parallel implementation (dashed lines), optimization is performed according to the algorithms described in Sec. \ref{sec:ser} and Sec. \ref{sec:par}, respectively, and, for the parallel implementation, the performance is evaluated using the dynamic model presented in the Appendix with step size . For parallel optimization, we set  in (\ref{cap}) and (\ref{far}) to an optimized value in the range  and we have . Note that the performance of the optimization was found not to be significantly improved with smaller values of  and not to be increased by choosing larger values for .

In Fig. \ref{res1}, the mobile energy cost for the serial and the parallel implementations are plotted versus the latency, along with their communication and computation components for the graph in Fig. \ref{g_ex} with the selection of parameters marked as case (a) in the caption of Fig. \ref{g_ex}. The parameters of the graph are chosen to yield the same range of latencies and energy consumptions as in \cite{maui} and \cite{hermp}. With the selected parameters, performing the application locally requires an energy equal to  J and has a latency of  s (outside the range of Fig. \ref{res1}). Fig. \ref{res1} shows that significantly smaller latencies and energy expenditures can be obtained by properly optimizing the offloading decisions and the communication strategy. For instance, with an energy expenditure of  J, an optimized parallel implementation yields a latency of around  s, while an optimized serial implementation requires a latency of around  s.

The parallel implementation is shown here to have the potential to strictly outperform the serial implementation and to enable the operation at latencies that are unattainable with the serial implementation. Moreover, as the latency increases, the energy can be seen to decrease mostly due to the fact that the communication powers can be reduced. An exception to this trend is observed for the serial implementation around the latency  s, due to the fact that the optimum application layer decisions prescribe more tasks to be offloaded for  s.

In order to provide a further reference performance for inter-layer optimization, we consider a conventional \textit{separate design} strategy, whereby: (\textit{i}) the uplink transmission power for each task is obtained by imposing the constraint that transmitting in the uplink require a time no larger than that necessary to perform that task locally (see \cite[Sec. 3]{bar} for a similar approach); (\textit{ii}) the optimization of the offloading decisions is carried out by following the proposed algorithms with a fixed physical layer, which amount to the schemes in \cite{no}\cite{hermp} for the parallel implementations. For the serial implementation, this separate approach yields a latency of  s and an energy expenditure of  J, which is outside the range of Fig. \ref{res1}, while for parallel processing the observed energy-latency power is illustrated in this figure. Note that separate optimization does not attempt to adapt the physical layer to the application layer requirements and hence it yields a single energy-latency point in the considered latency range.
\begin{figure}
\centering
\includegraphics[scale=.3]{g_ex.png}
\caption{The call tree graph used for the examples in Fig. \ref{res1}-\ref{time}. The numbers shown next to the edges that are connected to the input task nodes represent the sizes of input bits  in Mbits and the numbers in the task nodes (circles) represent the number of CPU cycles  normalized by  CPU cycles (empty circles with ). The remaining values for case (a) are: , , ,  bits,  , ,  and . In case (b), all the parameters are the same as case (a) except for  Mbits,  bits,  bits and ,  and  CPU cycles.}\label{g_ex}
\vspace{-1.5em}
\end{figure}

Fig. \ref{no-gain} shows the energy-latency trade-off for the call graph in Fig. \ref{g_ex} for both case (a) and case (b) as detailed in the caption of Fig. \ref{g_ex}. Note that the separate optimization for case (b) with the parallel implementation yields  J for , which is out of the range of Fig. \ref{no-gain}. The results in Fig. \ref{no-gain} suggest that the gains offered by the parallel implementation over the serial implementation depend strongly on the chosen call graph.

To gain more insight into this point, Fig. \ref{time} illustrates the timeline corresponding to the parallel implementation for case (a) and case (b) for  s. Here, we use the same definition for  as in Fig. \ref{time}. It can be seen that in case (a), several communication and computation operations take place in parallel for a significant  fraction of the time, and hence the parallel implementation is advantageous as compared to the serial implementation. Instead, for case (b) most of the time is spent for uplink transmissions and hence the opportunities for parallel processing are much reduced.

In order to complement the insight obtained from the study of the call graph in Fig. \ref{res1}, here we elaborate on the impact of the structure of the call graph by considering the graph in Fig. \ref{graph2}. We plot the performance of the serial and parallel implementations for the call graph  as well as for the subtrees  and  in Fig. \ref{dep}. The relative values of the parameters in the call graph  is obtained from \cite{hermp}, and their exact values are defined in the caption of this figure. As expected, the energy required to run the application for a given latency increases as one considers a larger call graph. More importantly, the opportunities for concurrent computations and communications are enhanced on larger subgraphs, and, as a result, for  and , parallel processing provides more substantial gain over the serial implementation than in .


\begin{figure}
\centering
\includegraphics[scale=.33]{sim2.png}
\caption{Energy and latency trade-off for the call graph  in Fig. \ref{g_ex} (case (a)). The program can be completely performed locally with  J and  s. Moreover, separate optimization for serial implementation yields   J and  s.}\label{res1}
\end{figure}








\section{Concluding Remarks}

In this paper, we studied the inter-layer optimization of cloud mobile computing systems over the power  allocation at the physical layer and offloading decisions at the application layer with the aim of exploring the achievable trade-offs between the mobile energy expenditure and latency. Unlike prior work in which the problem is formulated as a mixed integer program, here we proposed a message-passing framework that leverage the typical structure of call graphs to drastically reduce complexity. In particular, we focused on call graphs that can be decomposed into combination of a small number of subtrees when fixing the decisions of a subset of nodes, obtaining a complexity that grows exponentially only in the size of such set of nodes rather the size of the call graph. Moreover, unlike prior art, the framework is applied to both the conventional serial implementation and a parallel implementation that enables the concurrent schedule of communication and computation. Via simulation results, we demonstrated the impact of the call graph structure on the relative performance of the parallel and serial implementations, and shed light on the impact of inter-layer optimization.
\label{sec:con}


\section{Acknowledgements}

The authors would like to thank Gesualdo Scutari from University of
Buffalo for interesting discussions.


\appendix
\setcounter{secnumdepth}{-1}
\section{Evaluating Energy and Latency For the Parallel Implementation}
\setcounter{secnumdepth}{-1}
\label{app:eva}
In Sec. \ref{sec:par}, we proposed an analytically convenient approximation for the energy and latency of the parallel implementation. Here, we develop a dynamic model that enables the evaluation of upper bounds on the energy and latency of the parallel implementation for a fixed set of variables , by tracking the state of each task over time. To this end, we quantize the time axis similar to (\ref{time_q}) with a generally different time step . By construction, the upper bounds calculated here become increasingly tighter as the quantization step  decreases.

\begin{figure}
\centering
\includegraphics[scale=.27]{comm2.png}
\caption{Energy and latency trade-off for the call graph  in Fig. \ref{g_ex} for case (a) and case (b). Separate optimization for the parallel implementation yields  J and   s for case (b) (not shown).}\label{no-gain}
\end{figure}
Define as  the state of task node  at time instant . The state of each node remains constant in the time range  and may take any value in the set , where  indicates that a task is idle in the sense that it has not started processing yet. Instead,  indicates that a task is completed in terms of processing and uplink/downlink communication and other state are defined in Sec. \ref{sec:par:op}. For all , we initialize the state as .

To keep track of the state of the uplink and downlink transmissions, we define the following variables. The variable  indicates the remaining information bits that task  still needs to send in the uplink at time . For , we have  for all tasks  that are not directly connected to a leaf node with  and ; instead, if  and , we set ; and we have  otherwise. Similarly, the variable  for  represents the remaining output bits of task  that task  needs to receive in the downlink at time . For , we have  for all pairs  such that  and , and  otherwise.

In order to track the state of the tasks in terms of computations, we define as  the number of CPU cycles that are left at time  to finish a task  with , while  denotes the corresponding number of remaining CPU cycles for a task  with . Thus, we have   if  and  if , while we set  otherwise.



Let us define  as the number of tasks that are running locally and   as the number of tasks that are running remotely at time . Similarly, we define   and   as the number of concurrent uplink  and downlink transmissions at time , respectively. In the proposed approach, as described below, we update the state  of each task node by making the assumption that the quantities , ,  and  remain constant through the time interval  . As argued below, this lead to the desired upper bounds on energy and latency. In the following, we treat separately the state update of each task  in any interval  depending on the state  at time .


If ,  the amount of information that can be transmitted to the server in the time slot   should be calculated in order to update the variable . If  we have   due to the uploading of information from the connected leaf node, where  is equal to  if  and  is equal to  otherwise. Instead, if , we have  ,  due to the uploading of information to the  child task . As a result, the state of the node changes as

since when , the task is completed, and when , the task  needs to be computed remotely.

\begin{figure}
\centering
\begin{minipage}{.8\linewidth}
\includegraphics[width=6.38cm,height=4.95cm]{stat1_2.png}
\end{minipage}
\begin{minipage}{.8\linewidth}
\includegraphics[width=6.38cm,height=4.95cm]{stat2_2.png}
\end{minipage}
\caption{Timeline for the parallel implementation corresponding to the optimum solution for  s for the call graph in Fig. \ref{g_ex} (see Fig. \ref{no-gain}).}\label{time}
\vspace{-1.5em}
\end{figure}
Following similar consideration, if , the state of the task node  can be updated as

Moreover, if , we have

and, if , we can write

where  is calculated as . If , we always have  and,
if , we have



Based on the discussion above, the values , ,  and  are calculated at each time  according to the states of nodes as
, ,  and ,
where  is the indicator function.

\begin{figure}
\centering
\includegraphics[scale=.3]{herms2.png}
\caption{Energy and latency trade-off for call graph  in Fig. \ref{graph2} and the subtrees  and  with , , , , , , , ,   CPU cycles, , , , , , , ,  and  bits.}\label{dep}
\vspace{-1.5em}
\end{figure}
Finally, at the end of each time interval  the energy consumed by the mobile is updated as

The latency is instead given by the smallest value  such that  for the root node . We observe that (\ref{ene_end}) assumes that transmissions and computations last for the period of duration  even if the task completed at some time within the interval. This implies that (\ref{ene_end}) and the corresponding latency are upper bounds on the actual energy and latency that become increasingly tight as  become smaller.


\bibliographystyle{IEEEtran}
\bibliography{refrences2}

\end{document}
