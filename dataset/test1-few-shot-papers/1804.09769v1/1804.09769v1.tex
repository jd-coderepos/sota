

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{naaclhlt2018}
\usepackage{times}
\usepackage{latexsym}
\usepackage{graphicx}
\graphicspath{{fig/}}
\usepackage{url}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{adjustbox}

\aclfinalcopy \def\aclpaperid{878} 



\newcommand\BibTeX{B{\sc ib}\TeX}
\newcommand{\newvec}[1]{\mathbf{#1}}
\DeclareMathOperator{\softmax}{\textbf{softmax}}

\title{TypeSQL: Knowledge-based Type-Aware Neural Text-to-SQL Generation}

\author{Tao Yu \\
  Yale University \\
  {\tt tao.yu@yale.edu} \\\And
  Zifan Li \\
  Yale University \\
  {\tt zifan.li@yale.edu} \\ \And
  Zilin Zhang \\
  Yale University \\
  {\tt zilin.zhang@yale.edu} \\ \AND
  Rui Zhang \\
  Yale University \\
  {\tt r.zhang@yale.edu} \\ \And
  Dragomir Radev \\
  Yale University \\
  {\tt dragomir.radev@yale.edu} \\}

\date{}

\begin{document}
\maketitle

\begin{abstract}
Interacting with relational databases through natural language helps users of any background easily query and analyze a vast amount of data. This requires a system that understands users' questions and converts them to SQL queries automatically.
In this paper we present a novel approach, \textsc{TypeSQL}, which views this problem as a slot filling task.
Additionally, \textsc{TypeSQL} utilizes type information to better understand rare entities and numbers in natural language questions.
We test this idea on the WikiSQL dataset and outperform the prior state-of-the-art by 5.5\% in much less time. We also show that accessing the content of databases can significantly improve the performance when users' queries are not well-formed. \textsc{TypeSQL} gets 82.6\% accuracy, a 17.5\% absolute improvement compared to the previous content-sensitive model.
\end{abstract}


\section{Introduction}

Building natural language interfaces to relational databases is an important and challenging problem \cite{li2014constructing,pasupat2015compositional,Yin15,Zhong2017,Yaghmazadeh17,Xu2017,Wang2017}.
It requires a system that is able to understand natural language questions and generate corresponding SQL queries.
In this paper, we consider the WikiSQL task proposed by \newcite{Zhong2017}, a large scale benchmark dataset for the text-to-SQL problem. Given a natural language question for a table and the table's schema, the system needs to produce a SQL query corresponding to the question.

\begin{figure*}[th!]
\centering
\includegraphics[width=\textwidth]{typesql.png}

\caption{\textsc{TypeSQL} consists of three slot-filling models on the right. We only show \textsc{model\_col} on the left for brevity. \textsc{model\_agg} and \textsc{model\_opval} have the similar pipelines.}
\label{fig:model}

\end{figure*}

We introduce a knowledge-based type-aware text-to-SQL generator, \textsc{TypeSQL}. Based on the prior state-of-the-art SQLNet \cite{Xu2017}, \textsc{TypeSQL} employs a sketch-based approach and views the task as a slot filling problem (Figure \ref{fig:sql_sketch}). By grouping different slots in a reasonable way and capturing relationships between attributes, \textsc{TypeSQL} outperforms SQLNet by about 3.5\% in half of the original training time.

Furthermore, natural language questions often contain rare entities and numbers specific to the underlying database. Some previous work \cite{agrawal03} already shows those words are crucial to many downstream tasks, such as infering column names and condition values in the SQL query. However, most of such key words lack accurate embeddings in popular pre-trained word embedding models. In order to solve this problem, \textsc{TypeSQL} assigns each word a type as an entity from either the knowledge graph, a column or a number. For example, for the question in Figure \ref{fig:model}, we label ``mort drucker" as \textsc{person} according to our knowledge graph; ``spoofed title," ``artist" and ``issue" as \textsc{column} since they are column names; and ``88.5" as \textsc{float}. Incorporating this type information, \textsc{TypeSQL} further improves the state-of-the-art performance by about another 2\% on the WikiSQL dataset, resulting in a final 5.5\% improvement in total. 

Moreover, most previous work assumes that user queries contain exact column names and entries. However, it is unrealistic that users always formulate their questions with exact column names and string entries in the table. To tackle this issue, when scaleability and privacy are not of a concern, the system needs to search databases to better understand what the user is querying.
Our content-sensitive model \textsc{TypeSQL + TC} gains roughly 9\% improvement compared to the content-insensitive model, and outperforms the previous content-sensitive model by 17.5\%.


\section{Related Work}
\label{sec:rel}

Semantic parsing maps natural language to meaningful executable programs. The programs could be a range of representations such as logic forms \cite{zelle96,Zettlemoyer05,wong07,Das10,Liang11,banarescu13,artzi13,Reddy14,Berant14,pasupat2015compositional}. Another area close to our task is code generation. This task parses natural language descriptions into a more general-purpose programming language such as Python \cite{Allamanis15,ling16, RabinovichSK17,Yin17}.

As a sub-task of semantic parsing, the text-to-SQL problem has been studied for decades \cite{warren1982efficient,popescu2003towards,popescu2004modern,li2006constructing,giordani2012translating,wang2017synthesizing}. The methods of the Database community \cite{li2014constructing, Yaghmazadeh17} involve more hand feature engineering and user interactions with the systems. In this work, we focus on recent neural network based approaches \cite{Yin15,Zhong2017,Xu2017,Wang2017,iyer17}. \newcite{dong16} introduce a sequence-to-sequence approach to converting text to logical forms. Most of previous work focus on specific table schemas, which means they use a single database in both train and test. Thus, they don't generalize to new databases.
\newcite{Zhong2017} publish the WikiSQL dataset and propose a sequence-to-sequence model with reinforcement learning to generate SQL queries. In the problem definition of the WikiSQL task, the databases in the test set do not appear in the train and development sets. Also, the task needs to take different table schemas into account. \newcite{Xu2017} further improve the results by using a SQL sketch based approach employing a sequence-to-set model.

\section{Methodology}
\label{sec:methods}

Like SQLNet, we employ a sketch-based approach and format the task as a slot filling problem. Figure \ref{fig:sql_sketch} shows the SQL sketch. Our model needs to predict all slots that begin with \texttt{\AGG} \texttt{\COND\_COL} \texttt{\COND\_VAL}}
    \adjustbox{}{(\textbf{AND} \texttt{\OP \texttt{\" are slots to fill. ``*" indicates zero or more \textbf{AND} clauses.}
    \label{fig:sql_sketch}
\end{figure}

Figure \ref{fig:model} illustrates the architecture of \textsc{TypeSQL} on the right and a detailed overview of one of three main models \textsc{model\_col} on the left. We first preprocess question inputs by type recognition (Section \ref{sec:type}). Then we use two bi-directional LSTMs to encode words in the question with their types and the column names separately (Section \ref{sec:inputenc}). The output hidden states of LSTMs are then used to predict the values for the slots in the SQL sketch (Section \ref{sec:slot-filling}).


\subsection{Type Recognition for Input Preprocessing}
\label{sec:type}

In order to create one-to-one type input for each question, we, first, tokenize each question into -grams of length 2 to 6, and use them to search over the table schema and label any column name appears in the question as \textsc{column}. Then, we assign numbers and dates in the question into four self-explanatory categories: \textsc{integer}, \textsc{float}, \textsc{date}, and \textsc{year}.
\urlstyle{same}
To identify named entities, we search for five types of entities: \textsc{person}, \textsc{place}, \textsc{country},  \textsc{organization}, and \textsc{sport}, on Freebase\footnote{\url{https://developers.google.com/freebase/}} using grams as keyword queries. The five categories cover a majority of entities in the dataset. Thus, we do not use other entity types provided by Freebase. Domain-specific knowledge graphs can be used for other applications.

In the case where the content of databases is available, we match words in the question with both the table schema and the content and labels of the columns as \textsc{column} and match the entry values as the corresponding column names. For example, the type in the Figure \ref{fig:model} would be [none, column, column, none, artist, artist, none, none, column, none, column, issue, none] in this case. Other parts in the Figure \ref{fig:model} keep the same as the content-insensitive approach.

\subsection{Input Encoder}
\label{sec:inputenc}

As shown in the Figure \ref{fig:model}, our input encoder consists of two bi-directional LSTMs, \textsc{bi-LSTM} and \textsc{bi-LSTM}. To encode word and type pairs of the question, we concatenate embeddings of words and their corresponding types and input them to \textsc{bi-LSTM}.
Then the output hidden states are  and , respectively.


For encoding column names, SQLNet runs a bi-directional LSTM over each column name. We first average the embeddings of words in the column name. Then, we run a single \textsc{bi-LSTM} between column names. This encoding method improves the result by 1.5\% and cuts the training time by half. Even though the order of column names does not matter, we attribute this improvement to the fact that the LSTM can capture their occurrences and relationships.

\subsection{Slot-Filling Model}
\label{sec:slot-filling}

Next, we predict values for the slots in the SQL sketch. For the slots in Figure \ref{fig:sql_sketch}, SQLNet has a separate model for each of them which do not share their trainable parameters. This creates five models for the five slots and one model for \texttt{\SELECT\_COL}, \texttt{\COND\#} are similar, we combine them into a single model. Additionally, \texttt{\SELECT\_COL}, which reduces errors of predicting the same column in these two slots \texttt{\OP} and \texttt{\COND\_COL}. Furthermore, we use one model for \texttt{\AGG} model converges much faster and suffers from overfitting when combined with other models.
Finally, \textsc{TypeSQL} consists of three models (Figure \ref{fig:model} right):
\begin{itemize}
    \item \textsc{model\_col} for \texttt{\COND\#} and \texttt{\AGG}
    \item \textsc{model\_opval} for \texttt{\COND\_VAL}
\end{itemize}
where the parameters of \textsc{bi-LSTM} and \textsc{bi-LSTM} are shared in each model (6 \textsc{bi-LSTM}s in total).



Since all three models use the same way to compute the weighted question and type representation  using the column attention mechanism proposed in SQLNet, we first introduce the following step in all three models:


where  applies the softmax operator over each row of the input matrix,  is a matrix of attention scores, and  is the weighted question and type representation. In our equations, we use  and  to represent all trainable parameter matrices and vectors, respectively.


\paragraph{\textsc{model\_col}-\texttt{\\newvec{H}_{\textsc{qt/col}}SELECT\_COL}:

\begin{table*}[!ht]
\small
\centering
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multirow{2}{*}{} & \multicolumn{3}{c|}{Dev}  & \multicolumn{3}{c|}{Test} \\ \cline{2-7} 
& Acc\textsubscript{lf} & Acc\textsubscript{qm} & Acc\textsubscript{ex} & Acc\textsubscript{lf} & Acc\textsubscript{qm} & Acc\textsubscript{ex} \\ \hline
\multicolumn{7}{|c|}{Content Insensitive} \\ \hline
\newcite{dong16}  & 23.3\%  & \multicolumn{1}{c|}{-} & 37.0\% & 23.4\% & \multicolumn{1}{c|}{-} & 35.9\% \\ \hline
Augmented Pointer Network \cite{Zhong2017}  & 44.1\%  & \multicolumn{1}{c|}{-} & 53.8\%  & 42.8\% & \multicolumn{1}{c|}{-} & 52.8\% \\ \hline
Seq2SQL \cite{Zhong2017}  & 49.5\%  & \multicolumn{1}{c|}{-} & 60.8\%  & 48.3\% & \multicolumn{1}{c|}{-} & 59.4\% \\ \hline
SQLNet \cite{Xu2017}  & \multicolumn{1}{c|}{-} & 63.2\%  & 69.8\% & \multicolumn{1}{c|}{-} & 61.3\%  & 68.0\%  \\ \hline
TypeSQL w/o type-awareness (ours)  & \multicolumn{1}{c|}{-} & 66.5\% & 72.8\% & \multicolumn{1}{c|}{-} & 64.9\% & 71.7\% \\ \hline
TypeSQL (ours)  & \multicolumn{1}{c|}{-} & \textbf{68.0\%} & \textbf{74.5\%} & \multicolumn{1}{c|}{-} & \textbf{66.7\%} & \textbf{73.5\%} \\ \hline
\multicolumn{7}{|c|}{Content Sensitive} \\ \hline
\newcite{Wang2017} & 59.6\% & \multicolumn{1}{c|}{-} & 65.2\%  & 59.5\% & \multicolumn{1}{c|}{-} & 65.1\% \\ \hline
TypeSQL+TC (ours) & \multicolumn{1}{c|}{-} & \textbf{79.2\%} & \textbf{85.5\%}  &   \multicolumn{1}{c|}{-} & \textbf{75.4\%} & \textbf{82.6\%} \\ \hline
\end{tabular}
\caption{Overall results on WikiSQL. Acc\textsubscript{lf}, Acc\textsubscript{qm}, and Acc\textsubscript{ex} denote the accuracies of exact string, canonical representation, and  execute result matches between the synthesized SQL with the ground truth respectively. The top six results are content-insensitive, which means only the question and table schema are used as inputs. The bottom two are content-sensitive, where the models use the question, the table schema, and the content of databases.}
\label{tb:ova_results}
\end{table*}

\begin{table*}[!ht]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multirow{2}{*}{} & \multicolumn{3}{c|}{Dev} & \multicolumn{3}{c|}{Test} \\ \cline{2-7} 
                  & Acc\textsubscript{agg} & Acc\textsubscript{sel} & Acc\textsubscript{where} & Acc\textsubscript{agg} & Acc\textsubscript{sel} & Acc\textsubscript{where} \\ \hline
Seq2SQL \cite{Zhong2017} & 90.0\% & 89.6\% & 62.1\% & 90.1\% & 88.9\% & 60.2\% \\ \hline
SQLNet \cite{Xu2017} & 90.1\% & 91.5\% & 74.1\% & 90.3\% & 90.9\% & 71.9\% \\ \hline
TypeSQL (ours) & 90.3\% & \textbf{93.1\%} & \textbf{78.5\%} & 90.5\% & \textbf{92.2\%} & \textbf{77.8\%} \\ \hline
\hline
TypeSQL+TC (ours) & 90.3\% & \textbf{93.5\%} & \textbf{92.8\%} & 90.5\% & \textbf{92.1\%} & \textbf{87.9\%} \\ \hline
\end{tabular}
\caption{Breakdown results on WikiSQL. Acc\textsubscript{agg}, Acc\textsubscript{sel}, and Acc\textsubscript{where} are the accuracies of canonical representation matches on \textsc{aggregator}, \textsc{select column}, and \textsc{where} clauses between the synthesized SQL and the ground truth respectively.}
\label{tb:bkd_results}
\end{table*}



%
 \paragraph{\textsc{model\_col}-\texttt{\
P_{num}= \softmax \left(\newvec{V}^{num} \textbf{tanh} (\newvec{W}_{qt}^{num} \sum_{i} \newvec{H}^\top_{\textsc{qt/col}_i})\right)
COND\_COL}}
We find that SQLNet often selects the same column name in the \texttt{\SELECT\_COL}, which is incorrect in most cases. To avoid this problem, we pass the weighted sum of question and type hidden states conditioned on the column chosen in \texttt{\\newvec{H}_{\textsc{qt/scol}}\newvec{H}_{\textsc{qt/col}}
c = \newvec{V}^{col} \textbf{tanh} (\newvec{W}_{c}^{col} \newvec{H}_{\textsc{col}}^\top + \newvec{W}_{qt}^{col} \newvec{H}_{\textsc{qt/col}}^\top + \newvec{W}_{qt}^{scol} \newvec{H}_{\textsc{qt/scol}}^\top)AGG}}
Given the weighted sum of question and type hidden states conditioned on the column chosen in \texttt{\\newvec{H}_{\textsc{qt/scol}}AGG} is chosen from \{\textsc{null}, \textsc{max}, \textsc{min}, \textsc{count}, \textsc{sum}, \textsc{avg}\} in the same way as SQLNet:

\vspace{-3mm}


\paragraph{\textsc{model\_opval}-\texttt{\OP} from  by:


\paragraph{\textsc{model\_opval}-\texttt{\iw_iv = \newvec{V}_{t}^{val}\textbf{tanh}(\newvec{W}_{qt}^{val}\newvec{H}^{i}_{\textsc{qt}} + \newvec{W}_{c}^{val}\newvec{H}_{\textsc{col}} + \newvec{W}_{h}^{val}\newvec{h})\newvec{h}\langle\rangle$ token is the most probable next token of the substring.

\section{Experiments}

\paragraph{Dataset}
We use the WikiSQL dataset \cite{Zhong2017}, a collection of 87,673 examples of questions, queries, and database tables built from 26,521 tables. It provides train/dev/test splits such that each table is only in one split. This requires model to generalize to not only new questions but new table schemas as well. 
\paragraph{Implementation Details}
We implement our model based on SQLNet \cite{Xu2017} in PyTorch \cite{paszke2017automatic}. We concatenate pre-trained Glove \cite{pennington14} and paraphrase \cite{Wieting17} embeddings. The dimensions and dropout rates of all hidden layers are set to 120 and 0.3 respectively. We use Adam \cite{Kingma15} with the default hyperparameters for optimization. The batch size is set to 64. The same loss functions in \cite{Xu2017} are used. Our code is available at \url{https://github.com/taoyds/typesql}.

\paragraph{Results and Discussion}
Table \ref{tb:ova_results} shows the main results on the WikiSQL task.
We compare our work with previous results using the three evaluation metrics used in \cite{Xu2017}.
Table \ref{tb:bkd_results} provides the breakdown results on \textsc{aggregation}, \textsc{selection}, and \textsc{where} clauses.

Without looking at the content of databases, our model outperforms the previous best work by 5.5\% on execute accuracy. According to Table \ref{tb:bkd_results}, \textsc{TypeSQL} improves the accuracy of \textsc{SELECT} by 1.3\% and \textsc{WHERE} clause by 5.9\%. By encoding column names and grouping model components in a simpler but reasonable way, \textsc{TypeSQL} achieves a much higher result on the most challenging sub-task \textsc{where} clause. Also, the further improvement of integrating word types shows that \textsc{TypeSQL} could encode the rare entities and numbers in a better way.

Also, if complete access to the database is allowed, \textsc{TypeSQL} can achieve 82.6\% on execute accuracy, and improves the performance of the previous content-aware system by 17.5\%. Although \cite{Zhong2017} enforced some limitations when creating the WikiSQL dataset, there are still many questions that do not have any column name and entity indicator. This makes generating the right SQLs without searching the database content in such cases impossible. This is not a critical problem for  WikiSQL but is so for most real-world tasks.

\section{Conclusion and Future Work}
\label{sec:conclusion}

We propose \textsc{TypeSQL} for text-to-SQL which views the problem as a slot filling task and uses type information to better understand rare entities and numbers in the input. \textsc{TypeSQL} can use the database content to better understand the user query if it is not well-formed. \textsc{TypeSQL} significantly improves upon the previous state-of-the-art on the WikiSQL dataset.

Although, unlike most of the previous work, the WikiSQL task requires model to generalize to new databases, the dataset does not cover some important SQL operators such as JOIN and GROUP BY. This limits the generalization of the task to other SQL components. In the future, we plan to advance this work by exploring other more complex datasets under the database-split setting. In this way, we can study the performance of a generalized model on a more realistic text-to-SQL task which includes many complex SQL and different databases.

\section*{Acknowledgement}
We thank Alexander Fabbri for his help in reviewing.

\bibliography{naaclhlt2018}
\bibliographystyle{acl_natbib}
\end{document}
