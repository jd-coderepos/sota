
\documentclass [11pt]{article}



\usepackage{graphicx,amsmath,amssymb,latexsym,epsfig,epstopdf, cite}
\usepackage{flushend}
\usepackage{color}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{lmodern,textcomp}
\usepackage{dblfloatfix}

\newtheorem{theo}{Theorem}
\newtheorem{prop}{Proposition}
\newtheorem{proposition}{Proposition}
\newtheorem{assumption}{Assumption}  
\newtheorem{coro}{Corollary}
\newtheorem{definition}{Definition}  
\newtheorem{lemma}{Lemma}
\newtheorem{rem}{Remark}

\def\bp{\noindent{\it Proof.}\ } 
\def\ep{\hfill }  
\def\sumi{\sum_{i=1}^N} 
\def\sumk{\sum_{k=1}^K} 
\def\summ{\sum_{m=1}^{M_k}}
\def\Y{{\cal Y}} 
\def\E{{\rm E}} 

\def\N{{\mathbb N}}
\def\et{{\quad \mbox{and}\quad }}
\def\etal{{\em et al. }}


\begin{document}

\title{Exploring the Memory-Bandwidth Tradeoff in an Information-Centric Network}


\author{
{James Roberts (Inria and SystemX, France)}
\and
{Nada Sbihi (Inria, France)}
}

\date{}

\maketitle    


\begin{abstract}
An information-centric network should realize significant economies by exploiting a favourable memory-bandwidth tradeoff: it is cheaper to store copies of popular content close to users than to fetch them repeatedly over the Internet. We evaluate this tradeoff for some simple cache network structures under realistic assumptions concerning the size of the content catalogue and its popularity distribution. Derived cost formulas reveal the relative impact of various cost, traffic and capacity parameters, allowing an appraisal of possible future network architectures. Our results suggest it probably makes more sense to envisage the future Internet as a loosely interconnected set of local data centers than a network like today's with routers augmented by limited capacity content stores.
\end{abstract}





\section{Introduction}
It has become a commonplace to observe that the Internet has become information-centric, with more than 90\% of its traffic resulting from content retrieval\footnote{See Cisco Visual Network Index, for example.}. There is broad agreement that the network should make more extensive use of caching in order to exploit an increasingly favourable memory-bandwidth tradeoff: it is cheaper to store copies of content items close to users than to repeatedly fetch them from some remote server. This tradeoff determines the optimal cache size, number and location and therefore has a strong impact on the structure of the future Internet. Our objective in this paper is to derive quantitative tradeoff results that reveal the structurally determinant parameters of an information-centric network (ICN).

Most currently proposed novel ICN architectures would systematically equip routers with caches in order to reduce the volume of content-retrieval traffic \cite{ADIKO12}. However, the effectiveness of such universal caching has recently been called into question \cite{Ghodsi2011}. We agree with the authors of this paper that the in-network caching assumption needs closer analysis, though not for the same reasons. The arguments in  \cite{Ghodsi2011} are based on models where cache size is assumed infinite, effectively supposing storage costs are negligible. Our own doubts stem rather from the observation formulated in \cite{FRRS12} that, to be effective in significantly reducing traffic volumes, cache sizes need to be very large, orders of magnitude larger than the storage that could reasonably be added to a router  \cite{PV11}. Rather than a network of content routers equipped with caches, the future Internet might more realistically be seen as a network of data centers that, among other applications, also do routing. 

The memory-bandwidth tradeoff depends on the cache hit rate that determines the proportion of download traffic that is saved by a cache of given size. We use the ``Che approximation'' to evaluate the hit rate of a cache assuming least recently used (LRU) replacement under the independent reference model (IRM) \cite{CTW02,FRR12}. The hit rate depends crucially on the size and popularity distribution of the considered content catalogue. To derive a realistic characterization we have used data recorded by Dan and Carlsson \cite{DC10} for content retrieved using BitTorrent. These data allow us to directly derive the relative torrent request rates, as required for the IRM. In the absence of comparable measurement results for other types of content, we use this as a generic popularity law with characteristic head, body and tail behaviour. 
 
To more clearly identify structural properties we consider simple symmetrical cache networks. The base case is a simple 2-level hierarchy where users first address requests to their local level-1 cache. In case of a miss, requests are redirected to a single central cache at level-2. The tradeoff is determined by the total cost of storage compared to the cost of the bandwidth needed to handle peak traffic flowing between the two levels. We use simple cost formulas that allow straightforward understanding of the impact of key parameters. This is important since assumed parameter values are necessarily imprecise and subject to quite rapid change as costs tend to decrease while demand and content catalogues grow. 

Results for the simple 2-level hierarchy highlight structural issues but costs might be further reduced by using some form of inter-cache cooperation. We therefore extend the tradeoff analysis to account for two generalizations drawn from the literature. First, we suppose level-1 caches perform load sharing by specializing the content they store. A hash of the chunk name determines to which level-1 cache the request must be sent. In the second generalization, users send all requests to their local cache but in case of a miss, a request is sent to another level-1 cache that, as for load sharing, is designated by a hash of the chunk name.  
These schemes require less storage than the basic hierarchy but incur additional bandwidth costs leading to a modified tradeoff. 

The rest of the paper is organized as follows. We begin in the next section by situating our approach with respect to related work. In Section \ref{sec:Chepop} we recall the Che approximation and use it to derive some useful properties of the model. This section also derives the BitTorrent popularity law used to evaluate the memory-bandwidth tradeoff. The memory-bandwidth tradeoff is evaluated in detail for the 2-level cache hierarchy in Section \ref{sec:hierarchy}. Generalizations of this analysis to more sophisticated cooperative cache networks are described in Section \ref{sec:alternatives}.


 
\section{Related work}
\label{sec:related}
There is a vast literature on how to place content items in order to optimize the memory-bandwidth tradeoff under various constraints. The papers cited below are a small sample meant to illustrate of the approaches that are most relevant to the present objective.

A paper by Nussbaumer \etal \cite{NPSS95} adopts a similar approach to ours in directly comparing the costs of storage and bandwidth. The authors envisage caches at different levels of a symmetric tree hierarchy and study cost as a function of cache size. Their results are not directly applicable, however, mainly because we have quite different cost assumptions. Cidon \etal  \cite{CKS2002 } propose a method for minimizing the sum of bandwidth and storage costs under general assumptions but provide no numerical results or qualitative analysis. 

A number of papers seek to minimize bandwidth usage when demand is assumed known for each object. Kangasharju \etal \cite{KRR01} supposes cache locations and capacities are given while Laoutaris \etal \cite{LZS05} proposes heuristics to jointly optimize storage allocation and content placement under a constraint on overall storage capacity. In both cases, the storage cost is replaced by capacity constraints and the analysis therefore brings little insight concerning the memory-bandwidth tradeoff.

Two recent papers revisit the issue of optimal content placement for video-on-demand. Borst \etal \cite{BGW10} seeks to minimize bandwidth usage under given cache capacities and known demand. This work is similar to ours in that the authors characterize the nature of the optimal solution for a simple symmetric 2-level cache hierarchy. Applegate \etal \cite{Applegate2010} optimally places video content in a given network where both storage capacity and link bandwidths are fixed. Again, since capacity is fixed \emph{a priori}, the results of these papers cannot be used to evaluate the memory-bandwidth tradeoff. 
  
In the large body of current work on a future information-centric Internet, we have found little of direct use in our evaluation. Most papers follow Jacobson \etal \cite{JSTP09} in assuming caching is performed by routers equipped with a content store. Since such a store is limited in capacity for technological reasons, the aim is to optimally exploit overall storage capacity by various selective and cooperative caching strategies (e.g., \cite{LS11, RR12, CHPP12}).  In order to avoid very poor performance under the assumed capacity constraints, it appears necessary either to assume the content catalogue is unrealistically small or that demand is unreasonably concentrated on the most popular items. In our work we do not pre-suppose in-router caching and use a realistic content retrieval model derived from measurements. 



\section{Cache performance and popularity laws}
\label{sec:Chepop}

We recall the Che approximation and derive a popularity law from measurements of BitTorrent activity.
\subsection{The Che approximation}
\label{sec:Che}
Cache hit rates are derived using the approximation introduced by Che \etal \cite{CTW02} and shown by Fricker \etal \cite{FRR12} to be extremely accurate, especially for the large cache sizes considered here. 
The ``Che approximation'' uses the independent reference model (IRM) where users request objects from a fixed catalogue of size , the probability a request is for some object  being fixed and independent of all prior requests. Let the latter probability be proportional to a ``popularity law''  for . Under the IRM, the  can be interpreted as rates of independent Poisson processes. 

The probability  that a request for object  can be satisfied by an LRU cache of size  is

where the ``characteristic time''  is the unique solution to the equation 

The overall hit rate is . Note that performance depends on the relative values of the  and not their absolute values: under the IRM, hit rates do not depend on traffic intensity. It is usual to order the  in decreasing order (object 1 is the most popular, object  the least) but the approximation does not depend on this.  

The approximation extends to objects of variable size. Let object  be of size  and assume  for all . The hit rate is still given by (\ref{eq:hn}) where  now solves 



Suppose  is measured in chunks of constant size and that objects are downloaded as a sequence of chunks. First assume all chunks are always requested whenever the object is requested so that each chunk inherits the object's popularity. The per-object hit rate is still given by (\ref{eq:hn}) and (\ref{eq:identitysize}) and is clearly identical to the hit rate for each of the object's chunks. Note, however, that equations (\ref{eq:hn}) and (\ref{eq:identitysize}) would also apply had we assumed the IRM applied to chunks, ignoring therefore the obvious correlation between successive requests for chunks of the same object. We conclude that, under condition  for , the hit rate can be accurately evaluated assuming the IRM also applies to chunks.

Assume now users do not necessarily request every chunk of an object, as is common when the objects in question are streamed videos, for instance. The popularity law per chunk will be different,  say for . However, under the condition   we expect the chunk hit rates to still be well-approximated as above by assuming the IRM at chunk level. Moreover, under quite severe user impatience, we observe empirically in Section \ref{sec:impatience} below that the popularity law under impatience is practically the same (after reordering and to within a multiplicative constant) as the per-chunk law assuming no impatience. The Che approximation thus applies even when users are impatient and the overall hit rate  is largely independent of the characteristics of this impatience.



 
\subsection{A three part popularity law}
While we believe the IRM is a valid model for our purposes, it remains very difficult in general to estimate the popularity law . For example, it is not possible to directly infer the instantaneous popularity of a given object from a measurement of the number of requests for that object over a period of one week, say. While request rates can be assumed constant, as in the IRM, for a short periods, it is clear that an object's popularity can vary significantly over periods of hours and days.  Fortunately, one type of content does allow an estimation of its popularity law. This is the set of torrents advertised by a BitTorrent search engine like \emph{mininova.org}. 

Dan and Carlsson and co-authors have analyzed a large data set obtained for torrents referenced by \emph{mininova} \cite{DC10,CDMA12}. They kindly provided us with some of their raw data that we have used to derive a per-chunk popularity law.

A first data set allows us to classify some  active torrents according to the number of leechers they had at the time of capture, namely 8pm GMT on 15 Sept. 2008. We retained  torrents that had at least one leecher (the others were active because they had at least one seed). The number of leechers is a measure of instantaneous popularity but does not immediately give the required request rates. By Little's law, the request rate  for torrent  is the expected number of leechers divided by the expected download time. Estimating the former by the measured number of leechers  and assuming the latter is proportional to the torrent size in chunks , we have . 


Unfortunately, the leecher file does not include torrent size data. However, a second data set provides torrent size for another set of torrents, as described in \cite{CDMA12}. The torrents in both data sets are identified by the usual content hash and we were able to match leechers and size for some 330~000 of the  torrents. We filled in the blanks by preserving as far as possible the size distribution of the torrents of known size for every fixed number of leechers.

\begin{figure}[tp]
 \centering
 \includegraphics[scale=.8]{popularity.eps}
 \caption{Popularity law for torrents; number of leechers , revised torrent popularity , derived chunk popularity}
 \label{fig:popularity}
\end{figure}

Figure \ref{fig:popularity} shows three popularity plots. The top one is the original leechers against rank plot and is identical to the corresponding curve in Figure 2 of \cite{DC10}. The bottom curve is normalized torrent popularity  plotted against rank. Finally, the middle curve plots the popularity of 1 MB chunks against rank. It is derived by stretching the second curve by counting  equal popularity chunks for torrent  for . The average torrent size is around 1 GB so the total number of chunks is  for a total of 1.6 PB.  Note that the last two curves coincide for the 300 most popular torrents since these are all just 1 chunk in size (the actual size is rounded up to 1 MB for cache occupancy though the intensity  is derived using the actual value of  in bytes).

\begin{figure}[tp]
 \centering
 \includegraphics[scale=.8]{popularityFit2.eps}
 \caption{Popularity law for torrents; fit }
 \label{fig:popularityfit}
\end{figure}

We use the per-chunk popularity law below for our evaluations of the memory-bandwidth tradeoff. More precisely, we fit a sequence of power law segments to represent this law, as shown in Figure \ref{fig:popularityfit}. This law has three main components that we label ``head'', ``body'' and ``tail''. The head is flat and roughly parallel to a power law . In the following, we refer to such a power law with exponent  as Zipf(). The body is somewhat steeper and parallel to Zipf(.8). Lastly, popularity drops rapidly in the tail and we fit it by a sequence of Zipf segments with exponent increasing from 1 to 15.  

Given the number of chunks in each segment and their individual popularities, we can apportion download traffic as follows: the head represents roughly 10\% (for  chunks), the body 59\% ( chunks) and the tail 31\% ( chunks). Note the significant volume contributed by the tail despite the very low popularity of the torrents from which it is composed. 


\subsection{Hit rate as function of cache size}
\label{sec:hitvcache}

\begin{figure}[tp]
 \centering
 \includegraphics[scale=.8]{newDanpop.eps}
 \caption{Hit rate as function of cache size for different popularity laws: real from Figure \ref{fig:popularityfit}, head + body, body alone, body + tail, head + Zipf(1.2) body.}
 \label{fig:Danpop}
\end{figure}

We evaluate the sensitivity of hit rate estimates to the degree of approximation in representing the popularity law. Numerical results derived using the Che approximation are presented in Figure \ref{fig:Danpop}. The hit rate for the ``real'' 3-component law of Figure \ref{fig:popularityfit} is given by the bold line. The simple expedient of assuming popularity is Zipf(.8) for  is inaccurate for both small and large caches. The other two curves show how the head and tail are important to accurately predict hit rates of small and large caches, respectively (when head or tail is missing, the body is extended to ranks 1 or , respectively). 

Lastly, we recall the impact of supposing the popularity is more accentuated than measurements suggest. Specifically, we suppose  follows the head up to  and then decreases rapidly as Zipf(1.2).  It is clear from Figure \ref{fig:Danpop} that such an assumption would lead to widely inaccurate hit rate estimations.

 \begin{figure}[h]
                \centering
                        \fontsize{12}{12}\selectfont 
                \resizebox{!}{7.2cm}{\begingroup
  \makeatletter
  \providecommand\color[2][]{\GenericError{(gnuplot) \space\space\space\@spaces}{Package color not loaded in conjunction with
      terminal option `colourtext'}{See the gnuplot documentation for explanation.}{Either use 'blacktext' in gnuplot or load the package
      color.sty in LaTeX.}\renewcommand\color[2][]{}}\providecommand\includegraphics[2][]{\GenericError{(gnuplot) \space\space\space\@spaces}{Package graphicx or graphics not loaded}{See the gnuplot documentation for explanation.}{The gnuplot epslatex terminal needs graphicx.sty or graphics.sty.}\renewcommand\includegraphics[2][]{}}\providecommand\rotatebox[2]{#2}\@ifundefined{ifGPcolor}{\newif\ifGPcolor
    \GPcolorfalse
  }{}\@ifundefined{ifGPblacktext}{\newif\ifGPblacktext
    \GPblacktexttrue
  }{}\let\gplgaddtomacro\g@addto@macro
\gdef\gplbacktext{}\gdef\gplfronttext{}\makeatother
  \ifGPblacktext
\def\colorrgb#1{}\def\colorgray#1{}\else
\ifGPcolor
      \def\colorrgb#1{\color[rgb]{#1}}\def\colorgray#1{\color[gray]{#1}}\expandafter\def\csname LTw\endcsname{\color{white}}\expandafter\def\csname LTb\endcsname{\color{black}}\expandafter\def\csname LTa\endcsname{\color{black}}\expandafter\def\csname LT0\endcsname{\color[rgb]{1,0,0}}\expandafter\def\csname LT1\endcsname{\color[rgb]{0,1,0}}\expandafter\def\csname LT2\endcsname{\color[rgb]{0,0,1}}\expandafter\def\csname LT3\endcsname{\color[rgb]{1,0,1}}\expandafter\def\csname LT4\endcsname{\color[rgb]{0,1,1}}\expandafter\def\csname LT5\endcsname{\color[rgb]{1,1,0}}\expandafter\def\csname LT6\endcsname{\color[rgb]{0,0,0}}\expandafter\def\csname LT7\endcsname{\color[rgb]{1,0.3,0}}\expandafter\def\csname LT8\endcsname{\color[rgb]{0.5,0.5,0.5}}\else
\def\colorrgb#1{\color{black}}\def\colorgray#1{\color[gray]{#1}}\expandafter\def\csname LTw\endcsname{\color{white}}\expandafter\def\csname LTb\endcsname{\color{black}}\expandafter\def\csname LTa\endcsname{\color{black}}\expandafter\def\csname LT0\endcsname{\color{black}}\expandafter\def\csname LT1\endcsname{\color{black}}\expandafter\def\csname LT2\endcsname{\color{black}}\expandafter\def\csname LT3\endcsname{\color{black}}\expandafter\def\csname LT4\endcsname{\color{black}}\expandafter\def\csname LT5\endcsname{\color{black}}\expandafter\def\csname LT6\endcsname{\color{black}}\expandafter\def\csname LT7\endcsname{\color{black}}\expandafter\def\csname LT8\endcsname{\color{black}}\fi
  \fi
  \setlength{\unitlength}{0.0500bp}\begin{picture}(7200.00,5040.00)\gplgaddtomacro\gplbacktext{\csname LTb\endcsname \put(946,1022){\makebox(0,0)[r]{\strut{} 0}}\put(946,1709){\makebox(0,0)[r]{\strut{} 0.2}}\put(946,2396){\makebox(0,0)[r]{\strut{} 0.4}}\put(946,3083){\makebox(0,0)[r]{\strut{} 0.6}}\put(946,3770){\makebox(0,0)[r]{\strut{} 0.8}}\put(946,4457){\makebox(0,0)[r]{\strut{} 1}}\put(1078,802){\makebox(0,0){\strut{} 1e-05}}\put(2223,802){\makebox(0,0){\strut{} 0.0001}}\put(3368,802){\makebox(0,0){\strut{} 0.001}}\put(4513,802){\makebox(0,0){\strut{} 0.01}}\put(5658,802){\makebox(0,0){\strut{} 0.1}}\put(6803,802){\makebox(0,0){\strut{} 1}}\put(176,2739){\rotatebox{-270}{\makebox(0,0){\strut{}hit rate}}}\put(3940,472){\makebox(0,0){\strut{}normalized cache size}}}\gplgaddtomacro\gplfronttext{\csname LTb\endcsname \put(3454,4284){\makebox(0,0)[r]{\strut{}}}\csname LTb\endcsname \put(3454,4064){\makebox(0,0)[r]{\strut{}}}\csname LTb\endcsname \put(3454,3844){\makebox(0,0)[r]{\strut{}}}\csname LTb\endcsname \put(3454,3624){\makebox(0,0)[r]{\strut{}}}}\gplbacktext
    \put(0,0){\includegraphics{catalogue}}\gplfronttext
  \end{picture}\endgroup
 }
\setlength{\belowcaptionskip}{-3pt}
                \caption{Hit rate as function of  for different values of  using the empirical popularity law. }
                \label{fig:convergence}
 \end{figure}

Consider now the impact of the catalogue size. We assume the shape of the popularity law is retained while scaling the rank in proportion to catalogue size. We refer below to this scaled function as the ``empirical popularity law'', for whatever catalogue size  is appropriate. For example, a catalogue of  chunks has components delimited by  and  with the same slopes on the loglog plots. It is known that for Zipf() popularity with , the hit rate for cache size  and catalogue  tends to a limit function  as  \cite{Fill96}. Unsurprisingly, the hit rate for the empirical law of Figure \ref{fig:popularityfit} has the same behaviour, as illustrated in Figure \ref{fig:convergence}. The hit rate  expressed as a function of  is practically the same for . 

\subsection{Impact of decreasing chunk popularities}
\label{sec:impatience}
In the absence of more precise real data, we use the popularity law of Figure \ref{fig:popularityfit} as if it were universal for all content. One possible objection is that, while torrents are useful only when their download is complete, other forms of content retrieval suffer from user impatience so that it is not correct to assume all chunks of the same object have equal popularity. To evaluate the impact of users interrupting a streaming video, say, we take the empirical data of Figure \ref{fig:popularity} and modify it as follows.

We retain torrents of size  satisfying 10 MB  1 GB, both to limit the data set volume and because this range would be typical of video content. For each torrent with  leechers and size , we assume the popularity of chunks decreases linearly from  to  implying that only 30\% of objects are downloaded to the end. The chunks are then resorted in order of decreasing popularity. 

\begin{figure}[tp]
 \centering
 \includegraphics[scale=.8]{impatience.eps}
 \caption{Popularity law of chunks assuming either all chunks inherit object popularity (flat) or chunk popularity decreases linearly to 30\% of initial value}
 \label{fig:impatience}
\end{figure}

Figure \ref{fig:impatience} compares the popularity laws of this model and that of the original where all chunks have popularity . Except for the most popular chunks on the left, the impact of impatience is to reduce popularity by a factor of about 1/3 while preserving the slope of the law. Since hit rates in the IRM are determined by the relative values of the , we conclude that the hit rate is hardly changed by the assumed downloader impatience (see Sec. \ref{sec:Che}). This is so because the difference in popularity between distinct objects largely outweighs the difference in popularity between chunks of the same object.

In the following we use the derived empirical popularity law as if it applies to all content and not just torrents. We might vary the catalogue size but we assume the shape of the law, its head, body and tail, remain the same. The justification is that this law is derived from the best popularity measurements we have and that no published measurements for other types of content suggest the shape would be radically different. Popularity against rank has consistently been shown to exhibit  power law behaviour for the body with an exponent less than 1 and not too different to .8. Moreover, the petabyte catalogue size is also representative of other types of content like web pages or user-generated content \cite{FRRS12}.

\section{A two-level cache hierarchy}
\label{sec:hierarchy}

        \begin{figure}[h]
                       \centering
                \includegraphics[scale=.8]{hierarchy.eps}
\caption{Two-level cache hierarchy with  level-1 sites and 1 level-2 site}
                \label{fig:hierarchy}
        \end{figure}

We use the Che approximation and the empirical popularity law to quantify the memory-bandwidth tradeoff for a simple, symmetrical 2-level cache hierarchy (Fig. \ref{fig:hierarchy}). Level-1 caches serve distinct sets of local users and have identical demand characteristics. If a requested chunk is absent at the local level-1 cache, the request is forwarded to the single level-2 cache. Replacement is LRU at each level. Level-1 caches occupy  sites. They have capacity for  chunks while the level-2 cache has capacity . Users generate a total busy period download traffic of  bit/sec. The entire content catalogue consists of  chunks with the empirical popularity law of Figure \ref{fig:popularityfit}.

\subsection{Cost difference}
To evaluate the memory-bandwidth tradeoff we consider the cost of the considered network as a function of , excluding fixed costs. We refer to this as the \emph{cost difference}. In particular, we fix , and therefore ignore the cost of the access network, and fix an overall network hit rate target  , and therefore ignore the cost of retrieving content from beyond the considered network. Fixing  implies  is a function of  and can be calculated using the Che approximation, on assuming cache occupancies are independent \cite{FRRS12}. Denote the level-1 hit rate by . It is a function of  and  but not of .

We assume bandwidth costs are proportional to the traffic flowing between level-2 and level-1 with a constant of proportionality . Bandwidth thus costs . 

We assume the cost of caching is due to two factors: the cost of memory, supposed proportional to capacity, and the cost of serving content, supposed proportional to peak demand in bit/sec. Denoting the constants of proportionality by  and , respectively, total caching costs are . The last  term sums all traffic served by level-1 and the fraction   also served by level-2.

Excluding the constant service cost , the memory-bandwidth tradeoff is characterized by the cost difference,




\subsection{Cost estimates}
\label{sec:costs}

To progress we need plausible estimates for the constants ,  and . 

We set 15k_b5 in 2010 and declining fast. The Ethernet alliance states the price of Ethernet bandwidth needs to decrease at an annual rate of 20\% to meet demand forecasts\footnote{http://www.networkworld.com/news/tech/2012/041012-ethernet-alliance-258118.html?page=1}.

We set the nominal monthly unit cost of memory to 0.15k_sk_b.10 per GB or roughly \k_b+k_s \approx k_b = \ per Mbps per month.


\subsection{Evaluation}

 \begin{figure}[h]
                \centering
                \fontsize{12}{12}\selectfont 
                \resizebox{!}{7.5cm}{\begingroup
  \makeatletter
  \providecommand\color[2][]{\GenericError{(gnuplot) \space\space\space\@spaces}{Package color not loaded in conjunction with
      terminal option `colourtext'}{See the gnuplot documentation for explanation.}{Either use 'blacktext' in gnuplot or load the package
      color.sty in LaTeX.}\renewcommand\color[2][]{}}\providecommand\includegraphics[2][]{\GenericError{(gnuplot) \space\space\space\@spaces}{Package graphicx or graphics not loaded}{See the gnuplot documentation for explanation.}{The gnuplot epslatex terminal needs graphicx.sty or graphics.sty.}\renewcommand\includegraphics[2][]{}}\providecommand\rotatebox[2]{#2}\@ifundefined{ifGPcolor}{\newif\ifGPcolor
    \GPcolorfalse
  }{}\@ifundefined{ifGPblacktext}{\newif\ifGPblacktext
    \GPblacktexttrue
  }{}\let\gplgaddtomacro\g@addto@macro
\gdef\gplbacktext{}\gdef\gplfronttext{}\makeatother
  \ifGPblacktext
\def\colorrgb#1{}\def\colorgray#1{}\else
\ifGPcolor
      \def\colorrgb#1{\color[rgb]{#1}}\def\colorgray#1{\color[gray]{#1}}\expandafter\def\csname LTw\endcsname{\color{white}}\expandafter\def\csname LTb\endcsname{\color{black}}\expandafter\def\csname LTa\endcsname{\color{black}}\expandafter\def\csname LT0\endcsname{\color[rgb]{1,0,0}}\expandafter\def\csname LT1\endcsname{\color[rgb]{0,1,0}}\expandafter\def\csname LT2\endcsname{\color[rgb]{0,0,1}}\expandafter\def\csname LT3\endcsname{\color[rgb]{1,0,1}}\expandafter\def\csname LT4\endcsname{\color[rgb]{0,1,1}}\expandafter\def\csname LT5\endcsname{\color[rgb]{1,1,0}}\expandafter\def\csname LT6\endcsname{\color[rgb]{0,0,0}}\expandafter\def\csname LT7\endcsname{\color[rgb]{1,0.3,0}}\expandafter\def\csname LT8\endcsname{\color[rgb]{0.5,0.5,0.5}}\else
\def\colorrgb#1{\color{black}}\def\colorgray#1{\color[gray]{#1}}\expandafter\def\csname LTw\endcsname{\color{white}}\expandafter\def\csname LTb\endcsname{\color{black}}\expandafter\def\csname LTa\endcsname{\color{black}}\expandafter\def\csname LT0\endcsname{\color{black}}\expandafter\def\csname LT1\endcsname{\color{black}}\expandafter\def\csname LT2\endcsname{\color{black}}\expandafter\def\csname LT3\endcsname{\color{black}}\expandafter\def\csname LT4\endcsname{\color{black}}\expandafter\def\csname LT5\endcsname{\color{black}}\expandafter\def\csname LT6\endcsname{\color{black}}\expandafter\def\csname LT7\endcsname{\color{black}}\expandafter\def\csname LT8\endcsname{\color{black}}\fi
  \fi
  \setlength{\unitlength}{0.0500bp}\begin{picture}(7200.00,5040.00)\gplgaddtomacro\gplbacktext{\csname LTb\endcsname \put(1342,1141){\makebox(0,0)[r]{\strut{} 100000}}\put(1342,1940){\makebox(0,0)[r]{\strut{} 1e+06}}\put(1342,2740){\makebox(0,0)[r]{\strut{} 1e+07}}\put(1342,3539){\makebox(0,0)[r]{\strut{} 1e+08}}\put(1342,4338){\makebox(0,0)[r]{\strut{} 1e+09}}\put(1474,921){\makebox(0,0){\strut{} 0}}\put(2806,921){\makebox(0,0){\strut{} 4e+14}}\put(4139,921){\makebox(0,0){\strut{} 8e+14}}\put(5471,921){\makebox(0,0){\strut{} 1.2e+15}}\put(176,2739){\rotatebox{-270}{\makebox(0,0){\strut{}cost difference (\h=.7.8.9.99k_b \times 10k_b / 10) against cache size (bytes) for the data of Section \ref{sec:costs} (nominal), for bandwidth cost  multiplied by 10, and for  divided by 10; overall hit rate  is 100\%. }
                \label{fig:deltacost}
 \end{figure}


\begin{figure}[h]
        \centering
        \fontsize{12}{12}\selectfont 
                \resizebox{!}{7cm}{\begingroup
  \makeatletter
  \providecommand\color[2][]{\GenericError{(gnuplot) \space\space\space\@spaces}{Package color not loaded in conjunction with
      terminal option `colourtext'}{See the gnuplot documentation for explanation.}{Either use 'blacktext' in gnuplot or load the package
      color.sty in LaTeX.}\renewcommand\color[2][]{}}\providecommand\includegraphics[2][]{\GenericError{(gnuplot) \space\space\space\@spaces}{Package graphicx or graphics not loaded}{See the gnuplot documentation for explanation.}{The gnuplot epslatex terminal needs graphicx.sty or graphics.sty.}\renewcommand\includegraphics[2][]{}}\providecommand\rotatebox[2]{#2}\@ifundefined{ifGPcolor}{\newif\ifGPcolor
    \GPcolorfalse
  }{}\@ifundefined{ifGPblacktext}{\newif\ifGPblacktext
    \GPblacktexttrue
  }{}\let\gplgaddtomacro\g@addto@macro
\gdef\gplbacktext{}\gdef\gplfronttext{}\makeatother
  \ifGPblacktext
\def\colorrgb#1{}\def\colorgray#1{}\else
\ifGPcolor
      \def\colorrgb#1{\color[rgb]{#1}}\def\colorgray#1{\color[gray]{#1}}\expandafter\def\csname LTw\endcsname{\color{white}}\expandafter\def\csname LTb\endcsname{\color{black}}\expandafter\def\csname LTa\endcsname{\color{black}}\expandafter\def\csname LT0\endcsname{\color[rgb]{1,0,0}}\expandafter\def\csname LT1\endcsname{\color[rgb]{0,1,0}}\expandafter\def\csname LT2\endcsname{\color[rgb]{0,0,1}}\expandafter\def\csname LT3\endcsname{\color[rgb]{1,0,1}}\expandafter\def\csname LT4\endcsname{\color[rgb]{0,1,1}}\expandafter\def\csname LT5\endcsname{\color[rgb]{1,1,0}}\expandafter\def\csname LT6\endcsname{\color[rgb]{0,0,0}}\expandafter\def\csname LT7\endcsname{\color[rgb]{1,0.3,0}}\expandafter\def\csname LT8\endcsname{\color[rgb]{0.5,0.5,0.5}}\else
\def\colorrgb#1{\color{black}}\def\colorgray#1{\color[gray]{#1}}\expandafter\def\csname LTw\endcsname{\color{white}}\expandafter\def\csname LTb\endcsname{\color{black}}\expandafter\def\csname LTa\endcsname{\color{black}}\expandafter\def\csname LT0\endcsname{\color{black}}\expandafter\def\csname LT1\endcsname{\color{black}}\expandafter\def\csname LT2\endcsname{\color{black}}\expandafter\def\csname LT3\endcsname{\color{black}}\expandafter\def\csname LT4\endcsname{\color{black}}\expandafter\def\csname LT5\endcsname{\color{black}}\expandafter\def\csname LT6\endcsname{\color{black}}\expandafter\def\csname LT7\endcsname{\color{black}}\expandafter\def\csname LT8\endcsname{\color{black}}\fi
  \fi
  \setlength{\unitlength}{0.0500bp}\begin{picture}(7200.00,5040.00)\gplgaddtomacro\gplbacktext{\csname LTb\endcsname \put(858,864){\makebox(0,0)[r]{\strut{} 0.01}}\put(858,1736){\makebox(0,0)[r]{\strut{} 0.1}}\put(858,2608){\makebox(0,0)[r]{\strut{} 1}}\put(858,3479){\makebox(0,0)[r]{\strut{} 10}}\put(858,4351){\makebox(0,0)[r]{\strut{} 100}}\put(990,644){\makebox(0,0){\strut{} 0}}\put(2153,644){\makebox(0,0){\strut{} 0.2}}\put(3315,644){\makebox(0,0){\strut{} 0.4}}\put(4478,644){\makebox(0,0){\strut{} 0.6}}\put(5640,644){\makebox(0,0){\strut{} 0.8}}\put(6803,644){\makebox(0,0){\strut{} 1}}\put(932,4574){\makebox(0,0)[l]{\strut{}.3}}\put(1164,4574){\makebox(0,0)[l]{\strut{}.5}}\put(1629,4574){\makebox(0,0)[l]{\strut{}.7}}\put(2094,4574){\makebox(0,0)[l]{\strut{}.8}}\put(2850,4574){\makebox(0,0)[l]{\strut{}.9}}\put(3664,4574){\makebox(0,0)[l]{\strut{}.95}}\put(4943,4574){\makebox(0,0)[l]{\strut{}.99}}}\gplgaddtomacro\gplfronttext{}\gplbacktext
    \put(0,0){\includegraphics{delta-norm}}\gplfronttext
  \end{picture}\endgroup
 }
		\setlength{\abovecaptionskip}{-9pt}
               \caption{Normalized cost difference  against normailized cache size  for empirical popularity law: five curves for each graph correspond to different values of   ranging from .01 to 100; vertical lines indicate level-1 hit rates.  , b/w cost  traffic.}
                \label{fig:basedelta}
        \end{figure}

\begin{figure}[h]
        \centering
        \fontsize{12}{12}\selectfont 
                \resizebox{!}{7cm}{\begingroup
  \makeatletter
  \providecommand\color[2][]{\GenericError{(gnuplot) \space\space\space\@spaces}{Package color not loaded in conjunction with
      terminal option `colourtext'}{See the gnuplot documentation for explanation.}{Either use 'blacktext' in gnuplot or load the package
      color.sty in LaTeX.}\renewcommand\color[2][]{}}\providecommand\includegraphics[2][]{\GenericError{(gnuplot) \space\space\space\@spaces}{Package graphicx or graphics not loaded}{See the gnuplot documentation for explanation.}{The gnuplot epslatex terminal needs graphicx.sty or graphics.sty.}\renewcommand\includegraphics[2][]{}}\providecommand\rotatebox[2]{#2}\@ifundefined{ifGPcolor}{\newif\ifGPcolor
    \GPcolorfalse
  }{}\@ifundefined{ifGPblacktext}{\newif\ifGPblacktext
    \GPblacktexttrue
  }{}\let\gplgaddtomacro\g@addto@macro
\gdef\gplbacktext{}\gdef\gplfronttext{}\makeatother
  \ifGPblacktext
\def\colorrgb#1{}\def\colorgray#1{}\else
\ifGPcolor
      \def\colorrgb#1{\color[rgb]{#1}}\def\colorgray#1{\color[gray]{#1}}\expandafter\def\csname LTw\endcsname{\color{white}}\expandafter\def\csname LTb\endcsname{\color{black}}\expandafter\def\csname LTa\endcsname{\color{black}}\expandafter\def\csname LT0\endcsname{\color[rgb]{1,0,0}}\expandafter\def\csname LT1\endcsname{\color[rgb]{0,1,0}}\expandafter\def\csname LT2\endcsname{\color[rgb]{0,0,1}}\expandafter\def\csname LT3\endcsname{\color[rgb]{1,0,1}}\expandafter\def\csname LT4\endcsname{\color[rgb]{0,1,1}}\expandafter\def\csname LT5\endcsname{\color[rgb]{1,1,0}}\expandafter\def\csname LT6\endcsname{\color[rgb]{0,0,0}}\expandafter\def\csname LT7\endcsname{\color[rgb]{1,0.3,0}}\expandafter\def\csname LT8\endcsname{\color[rgb]{0.5,0.5,0.5}}\else
\def\colorrgb#1{\color{black}}\def\colorgray#1{\color[gray]{#1}}\expandafter\def\csname LTw\endcsname{\color{white}}\expandafter\def\csname LTb\endcsname{\color{black}}\expandafter\def\csname LTa\endcsname{\color{black}}\expandafter\def\csname LT0\endcsname{\color{black}}\expandafter\def\csname LT1\endcsname{\color{black}}\expandafter\def\csname LT2\endcsname{\color{black}}\expandafter\def\csname LT3\endcsname{\color{black}}\expandafter\def\csname LT4\endcsname{\color{black}}\expandafter\def\csname LT5\endcsname{\color{black}}\expandafter\def\csname LT6\endcsname{\color{black}}\expandafter\def\csname LT7\endcsname{\color{black}}\expandafter\def\csname LT8\endcsname{\color{black}}\fi
  \fi
  \setlength{\unitlength}{0.0500bp}\begin{picture}(7200.00,5040.00)\gplgaddtomacro\gplbacktext{\csname LTb\endcsname \put(858,864){\makebox(0,0)[r]{\strut{} 0.01}}\put(858,1736){\makebox(0,0)[r]{\strut{} 0.1}}\put(858,2608){\makebox(0,0)[r]{\strut{} 1}}\put(858,3479){\makebox(0,0)[r]{\strut{} 10}}\put(858,4351){\makebox(0,0)[r]{\strut{} 100}}\put(990,644){\makebox(0,0){\strut{} 0}}\put(2153,644){\makebox(0,0){\strut{} 0.2}}\put(3315,644){\makebox(0,0){\strut{} 0.4}}\put(4478,644){\makebox(0,0){\strut{} 0.6}}\put(5640,644){\makebox(0,0){\strut{} 0.8}}\put(6803,644){\makebox(0,0){\strut{} 1}}\put(932,4574){\makebox(0,0)[l]{\strut{}.3}}\put(1164,4574){\makebox(0,0)[l]{\strut{}.5}}\put(1629,4574){\makebox(0,0)[l]{\strut{}.7}}\put(2094,4574){\makebox(0,0)[l]{\strut{}.8}}\put(2850,4574){\makebox(0,0)[l]{\strut{}.9}}\put(3664,4574){\makebox(0,0)[l]{\strut{}.95}}\put(4943,4574){\makebox(0,0)[l]{\strut{}.99}}}\gplgaddtomacro\gplfronttext{}\gplbacktext
    \put(0,0){\includegraphics{delta-norm-90}}\gplfronttext
  \end{picture}\endgroup
 }
		\setlength{\abovecaptionskip}{-9pt}
               \caption{Normalized cost difference  against normailized cache size  for empirical popularity law: five curves for each graph correspond to different values of   ranging from .01 to 100; vertical lines indicate level-1 hit rates.  , b/w cost  traffic.}
                \label{fig:hit90delta}
        \end{figure}

\begin{figure}[h]
        \centering
        \fontsize{12}{12}\selectfont 

		\resizebox{!}{7cm}{\begingroup
  \makeatletter
  \providecommand\color[2][]{\GenericError{(gnuplot) \space\space\space\@spaces}{Package color not loaded in conjunction with
      terminal option `colourtext'}{See the gnuplot documentation for explanation.}{Either use 'blacktext' in gnuplot or load the package
      color.sty in LaTeX.}\renewcommand\color[2][]{}}\providecommand\includegraphics[2][]{\GenericError{(gnuplot) \space\space\space\@spaces}{Package graphicx or graphics not loaded}{See the gnuplot documentation for explanation.}{The gnuplot epslatex terminal needs graphicx.sty or graphics.sty.}\renewcommand\includegraphics[2][]{}}\providecommand\rotatebox[2]{#2}\@ifundefined{ifGPcolor}{\newif\ifGPcolor
    \GPcolorfalse
  }{}\@ifundefined{ifGPblacktext}{\newif\ifGPblacktext
    \GPblacktexttrue
  }{}\let\gplgaddtomacro\g@addto@macro
\gdef\gplbacktext{}\gdef\gplfronttext{}\makeatother
  \ifGPblacktext
\def\colorrgb#1{}\def\colorgray#1{}\else
\ifGPcolor
      \def\colorrgb#1{\color[rgb]{#1}}\def\colorgray#1{\color[gray]{#1}}\expandafter\def\csname LTw\endcsname{\color{white}}\expandafter\def\csname LTb\endcsname{\color{black}}\expandafter\def\csname LTa\endcsname{\color{black}}\expandafter\def\csname LT0\endcsname{\color[rgb]{1,0,0}}\expandafter\def\csname LT1\endcsname{\color[rgb]{0,1,0}}\expandafter\def\csname LT2\endcsname{\color[rgb]{0,0,1}}\expandafter\def\csname LT3\endcsname{\color[rgb]{1,0,1}}\expandafter\def\csname LT4\endcsname{\color[rgb]{0,1,1}}\expandafter\def\csname LT5\endcsname{\color[rgb]{1,1,0}}\expandafter\def\csname LT6\endcsname{\color[rgb]{0,0,0}}\expandafter\def\csname LT7\endcsname{\color[rgb]{1,0.3,0}}\expandafter\def\csname LT8\endcsname{\color[rgb]{0.5,0.5,0.5}}\else
\def\colorrgb#1{\color{black}}\def\colorgray#1{\color[gray]{#1}}\expandafter\def\csname LTw\endcsname{\color{white}}\expandafter\def\csname LTb\endcsname{\color{black}}\expandafter\def\csname LTa\endcsname{\color{black}}\expandafter\def\csname LT0\endcsname{\color{black}}\expandafter\def\csname LT1\endcsname{\color{black}}\expandafter\def\csname LT2\endcsname{\color{black}}\expandafter\def\csname LT3\endcsname{\color{black}}\expandafter\def\csname LT4\endcsname{\color{black}}\expandafter\def\csname LT5\endcsname{\color{black}}\expandafter\def\csname LT6\endcsname{\color{black}}\expandafter\def\csname LT7\endcsname{\color{black}}\expandafter\def\csname LT8\endcsname{\color{black}}\fi
  \fi
  \setlength{\unitlength}{0.0500bp}\begin{picture}(7200.00,5040.00)\gplgaddtomacro\gplbacktext{\csname LTb\endcsname \put(858,864){\makebox(0,0)[r]{\strut{} 0.01}}\put(858,1736){\makebox(0,0)[r]{\strut{} 0.1}}\put(858,2608){\makebox(0,0)[r]{\strut{} 1}}\put(858,3479){\makebox(0,0)[r]{\strut{} 10}}\put(858,4351){\makebox(0,0)[r]{\strut{} 100}}\put(990,644){\makebox(0,0){\strut{} 0}}\put(2153,644){\makebox(0,0){\strut{} 0.2}}\put(3315,644){\makebox(0,0){\strut{} 0.4}}\put(4478,644){\makebox(0,0){\strut{} 0.6}}\put(5640,644){\makebox(0,0){\strut{} 0.8}}\put(6803,644){\makebox(0,0){\strut{} 1}}\put(932,4574){\makebox(0,0)[l]{\strut{}.3}}\put(1164,4574){\makebox(0,0)[l]{\strut{}.5}}\put(1629,4574){\makebox(0,0)[l]{\strut{}.7}}\put(2094,4574){\makebox(0,0)[l]{\strut{}.8}}\put(2850,4574){\makebox(0,0)[l]{\strut{}.9}}\put(3664,4574){\makebox(0,0)[l]{\strut{}.95}}\put(4943,4574){\makebox(0,0)[l]{\strut{}.99}}}\gplgaddtomacro\gplfronttext{}\gplbacktext
    \put(0,0){\includegraphics{delta-norm-scale}}\gplfronttext
  \end{picture}\endgroup
 }
		 \setlength{\abovecaptionskip}{-9pt}
                \caption{Normalized cost difference  against normailized cache size  for empirical popularity law: five curves for each graph correspond to different values of   ranging from .01 to 100; vertical lines indicate level-1 hit rates. , b/w cost  (traffic).}
                \label{fig:scaledelta}
        \end{figure}     




Figure \ref{fig:deltacost} plots  as a function of  with parameter values  Tbps, , and , corresponding to an overall hit rate . These data are intended to be representative of a national ISP network in a country like France. We use the empirical popularity law with a total catalogue size  chunks of 1 MB. The impact of varying these parameters is considered later.

The middle curve is plotted using the constants  and  given in Section \ref{sec:costs}. The maximum monthly cost of bandwidth (for ) is \C=N24M. Cost is minimized at \C=200k_bk_mk_bk_mC=NC=0\Theta=1\bar{C}\equiv N \bar{C}k_sk_b\Gamma\thetaCN\theta(c)c=C/N\delta\Gammac\delta(c)\Gamma\GammaSTNNSk_bk_m40\%T\Gamma\Gamma>10\bar{C} < N\theta(c)\le .9\Gamma\ge 10\Gamma = T^{.75}k_b/(SNk_m)\Gamma\alpha\alpha > 1\alpha>1SS=12P=3PN/PC/P\theta(c)c=C/N\delta_{\textsc{ls}}(c)k'_b\delta(c)P\Gamma k'_b/k_b> ck'_bP\Gamma \ge 10k'_b < k_b/10N=10000P=10P=5\theta\theta'CP=5\theta\theta'PCnq'(n)=q(n)(1+(P-1)e^{-q(n)t_c})t_ct_c\theta'\theta1.6 \times 10^9\theta'\thetaCPCP\theta'CP\thetaPCP\theta(PC,N)\theta(C,N)P\thetaS/P\theta\tilde{C}\tilde{h}k_mk_bk'_b\tilde{C} > C/P\theta'(\tilde{C},N) \approx h(C/N)\tilde{\theta} \lesssim \theta'\tilde{\theta}(\tilde{C}, N) \lesssim \tilde{\theta}(c/P) \lesssim \theta(c/P)\lesssim$

As for load sharing, it is impossible to make a definitive statement about the value of this type of cooperation. However, if we are correct to believe the cost of bandwidth increasingly outweighs that of memory, the simple duplication of large caches at a suitably chosen level in the network is unlikely to be far from optimal for the future Internet.


\section{Conclusions}
The ICN memory-bandwidth tradeoff depends crucially on the hit rate realized by a cache of given capacity. To evaluate this we have used the Che approximation with a realistic traffic model derived from measurements of the popularity law of BitTorrent content retrieval. We showed that this approximation remains accurate when applied to chunks, despite the correlated request process and even accounting for decreasing chunk popularity due to frequent incomplete downloads.

Our analysis is based on the performance of symmetric cache networks assuming linear dependence of cost on capacity. These simplifications reveal quite robust structural properties that are unlikely to be disproved by more detailed models. We note also that such refinements would still be very hard to correctly parameterize. 

Under our best guess cost and traffic assumptions, a 2-level cache hierarchy realizing the optimal tradeoff would equip level-1 caches to capture around 70\% of download traffic with a capacity equivalent to 10\% of the entire catalogue (i.e., caches of around 100 TB). However, accounting for cost and traffic trends, it will soon (within 4 years, say) be optimal to achieve a hit rate of 99\% by caching up to 75\% of the catalogue. 

The above figures apply to a choice of traffic and network parameters that is meant to be representative of a country like France. More general understanding is derived from normalized cost formulas where the critical quantity is shown to be the ratio of the total cost of bandwidth without caching to the total cost of storing the entire catalogue in each level-1 cache. The normalized tradeoff formulas can be used to determine the optimal siting of caches for given costs and traffic volumes. We can, for instance, evaluate the advantage of isolating popular content (e.g., a particular VoD catalogue) to be cached very close to end-users, while storing the petabytes of general content (web, UGC, file sharing) somewhere much closer to the network core.  

Cooperation between level-1 caches may lead to cost reduction but this again depends on relative costs of memory and bandwidth. We have considered two cooperative strategies and derived cost formulas that characterize the tradeoff. Under our best assumptions about unit costs and their evolution, the formulas suggest cooperation brings little cost advantage over the simple cache hierarchy.

Our deduction from the above is that the future Internet is less likely to be a network of content store augmented routers than a loosely interconnected network of local data centers. Since these data centers should be equipped to cater for the large majority of content downloads, and these count for the majority of Internet demand, traffic circulating above them would be reduced by an order of magnitude. A further advantage is that a data center would be better able to perform the necessary higher level functions of a content distribution network.  

\section*{Acknowledgment}
This work was partially funded by French ANR project CONNECT under grant ANR-10-VERS-001.

\bibliographystyle{abbrv}
\bibliography{cache}

\end{document}
