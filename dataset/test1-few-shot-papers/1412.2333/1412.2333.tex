\pdfpagewidth=8.5in
\pdfpageheight=11in
\pdfoutput=1

\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[newenum]{paralist}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[noend]{algorithmic}
\usepackage{algorithm}
\usepackage[T1]{fontenc}
\usepackage{verbatim}
\usepackage[bottom]{footmisc}
\usepackage{calligra}
\usepackage{setspace} 
\usepackage{boxedminipage}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{hyperref}
\bibliographystyle{plain}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\renewcommand{\algorithmiccomment}[1]{// \textit{#1}}
\algsetup{linenodelimiter=.}
\algsetup{indent=2em}
\newlength\myindent
\setlength\myindent{4em}
\newcommand\bindent{\begingroup
    \setlength{\itemindent}{\myindent}
    \addtolength{\algorithmicindent}{\myindent}
}
\newcommand\eindent{\endgroup}

 \makeatletter
 \newtheorem*{rep@theorem}{\rep@title}
 \newcommand{\newreptheorem}[2]{\newenvironment{rep#1}[1]{\def\rep@title{#2 \ref{##1}}\begin{rep@theorem}}{\end{rep@theorem}}}
 \makeatother

 \newtheorem{theorem}{Theorem}
 \newtheorem{lemma}[theorem]{Lemma}
 \newtheorem{corollary}[theorem]{Corollary}
 \newtheorem{proposition}[theorem]{Proposition}
 \newtheorem{definition}[theorem]{Definition}
\newtheorem{operation}[theorem]{Operation}
 \newtheorem{problem}[theorem]{Problem}
 \newtheorem{claim}[theorem]{Claim}
 \newtheorem{observation}[theorem]{Observation}
 \newreptheorem{theorem}{Theorem}
 \newreptheorem{lemma}{Lemma}
 \newreptheorem{corollary}{Corollary}
\hypersetup{colorlinks,linkcolor=blue,filecolor=blue,citecolor=blue, urlcolor=blue,pdfstartview=FitH}

\DeclareMathOperator{\poly}{poly}
\DeclareMathOperator{\degree}{degree}
\DeclareMathOperator*{\E}{\mathbf{E}}
\newcommand{\lra}{Lenzen's routing algorithm}

\begin{document}
\title{Minimum-weight Spanning Tree Construction in  Rounds on the Congested Clique
  \thanks{This work is supported in part by National Science Foundation grant CCF-1318166.
  }}
\author{Sriram V. Pemmaraju \hspace{3em} Vivek B. Sardeshmukh\\ \small{Department of Computer Science, The University of Iowa, Iowa City, IA 52242}\\ 
\texttt{\{sriram-pemmaraju, vivek-sardeshmukh\}@uiowa.edu}}
\maketitle
\begin{abstract}
  This paper considers the \textit{minimum spanning tree (MST)} problem in the Congested Clique model and presents an algorithm that runs in  rounds, with high probability. 
  Prior to this, the fastest MST algorithm in this model was a deterministic algorithm due to Lotker et al.~(SIAM J on Comp, 2005) from about a decade ago.
  A key step along the way to designing this MST algorithm is a \textit{connectivity verification} algorithm that not only runs in  rounds with high probability, but also has low message complexity. 
  This allows the fast computation of an MST by running multiple instances of the connectivity verification algorithm in parallel.

  These results depend on a new edge-sampling theorem, developed in the paper, 
  that says that if each edge  is sampled independently with probability  (for a large enough constant ) then
  all cuts of size at least  are approximated in the sampled graph. 
  This sampling theorem is inspired by series of papers on graph sparsification via random edge sampling due to Karger~(STOC 1994),
  Bencz\'{u}r and Karger~(STOC 1996, arxiv 2002), and Fung et al.~(STOC 2011).
  The edge sampling techniques in these papers use probabilities that are functions of edge-connectivity or a related measure called edge-strength.
  For the purposes of this paper, these edge-connectivity measures seem too costly to compute and the main technical contribution of this paper is to
  show that degree-based edge-sampling suffices to approximate large cuts.
\end{abstract}

\section{Introduction}
The  model is a synchronous, message-passing model of distributed
computation in which the amount of information that a node can transmit along
an incident communication link in one round is restricted to  bits, where
 is the size of the network \cite{peleg2000distributed}. As the name suggests, the
 model focuses on congestion as an obstacle to distributed computation. 
In this paper, we focus on the design of distributed algorithms in the
 model on a clique communication network; we call this the
\textit{Congested Clique} model. In the Congested Clique model, all information is nearby, i.e., 
at most one hop away, and so any difficulty in solving a problem is due to congestion alone
In this paper we focus on the \textit{minimum spanning tree (MST)} problem in the Congested
Clique model and show how to solve it in  rounds with high probability.
Prior to this, the fastest MST algorithm in the Congested Clique was a deterministic algorithm 
due to Lotker et al.~\cite{lotker2005mstJournal} from about a decade ago.

The MST problem has a long history in distributed computing~\cite{gallager1983ghs, awerbuch1987optimal,garay1998sublinear, KhanTheoreticalCS2007}.
After a long sequence of results on MST through the 80's and 90's, Kutten and Peleg 
\cite{KuttenPeleg1998} showed how to compute an MST in the  model in  
rounds on -vertex diameter- graphs.
The near-optimality of this result was established by lower bounds on MST construction in the 
 model due to Peleg and Rubinovich \cite{PelegRubinovich2000}, Elkin \cite{Elkin2006}, and most recently
Das Sarma et al.~\cite{DasSarmaSICOMP2011}.
In the latter paper \cite{DasSarmaSICOMP2011}, a lower bound of  is shown for 
.
Lower bounds are known for smaller  as well; for example, for , Das Sarma et al.~\cite{DasSarmaSICOMP2011}
show a lower bound of .
Note that there are no lower bounds known for  or , which is the setting we are 
interested in.
For diameter-1 graphs, i.e., cliques, the -round deterministic algorithm of 
Lotker et al.~\cite{lotker2005mstJournal} has been the fastest known for more than a decade.
The lack of lower bounds in the Congested Clique model has kept open the possibility that faster
MST algorithms are possible and we show that this in indeed the case by presenting an exponentially
faster algorithm.

A key step along the way to designing the above-mentioned MST algorithm is a 
\textit{connectivity verification} algorithm in the Congested Clique model that not only 
runs in  rounds with high probability, but also has low message complexity. 
The low message complexity allows the fast computation of an MST by running multiple instances 
of the connectivity verification algorithm in parallel.
These results depend on a new edge-sampling theorem, developed in the paper, 
that says that if each edge  is sampled independently with probability  (for a large enough constant ) then
all cuts of size at least  are approximated in the sampled graph.
This sampling theorem is inspired by series of papers on graph sparsification via random edge 
sampling due to Karger~\cite{karger1994stoc}, Bencz\'{u}r and Karger~\cite{benczurKarger2002arxiv, benczurKarger1996stoc}, and Fung et al.~\cite{fung2011stoc}.
The edge sampling techniques in these papers use probabilities that are functions of 
edge-connectivity or a related measure called edge-strength.
For the purposes of this paper, these edge-connectivity measures seem too costly to compute 
and the main technical contribution of this paper is to
show that degree-based edge-sampling suffices to approximate large cuts.

\subsection{Main Results}
\label{section:mainResults}
In this paper, we achieve the following results:
\begin{itemize}
  \item We show how to solve the Connectivity Verification problem in  rounds  on a Congested Clique w.h.p.\footnote{We say an event occurs with high probability (w.h.p.), if the probability of that event is at least  for a constant .} on an input graph .
It has the following implication.

\item We show how to use this Connectivity Verification algorithm solve the MST problem in  rounds w.h.p. on a Congested Clique. 
\end{itemize}
In order to achieve our results, we use a variety of techniques that balance bandwidth constraints with the need to make rapid progress. 
One of the key technique we use is random edge sampling. 
In the next subsection we describes these sampling techniques at a high level. 
We believe that our techniques will have independent utility in any distributed setting in which congestion is a bottleneck. 

\subsection{Random Sampling in the Congested Clique Model}
\paragraph{Random graph sampling.} 
Randomly sampling vertices or edges to obtain a reduced-sized subgraph of the input graph has been studied in various computational models for a variety of problems. 
For example, in the sequential setting (RAM model) cut, flow, and network design problems can be solved faster on the sampled subgraph than on the input graph and 
more importantly, due to properties of the random sample, the solution on the sampled subgraph can be efficiently translated into a solution of the original graph~\cite{karger1994stoc, benczurKarger1996stoc, fung2011stoc}. 
Having a reduced-sized subgraph also enables solving problems efficiently in the streaming model~\cite{ahn2009streaming}.
Recently, applications of random vertex- and edge-sampling to solve problems in MapReduce model~\cite{KarloffSuriVassilvitskii} have been shown~\cite{lattanzi2011filtering}. 


\paragraph{Random sampling in the Congested Clique model.}
The Congested Clique model has high bandwidth availability over the entire network, but congestion at individual nodes.
Each node can communicate  messages in each round and hence a total of  messages are exchanged in a round over the entire network. 
Hence, an -vertex graph can be fully communicated across the network in one round, but only a linear-sized subgraph can reach a single node. 
Given this situation, a general approach would be to use the outcome of local processing of a linear-sized subgraph to compute the solution to the original problem.  
Of course, the key challenge of such an approach is showing that a linear-sized subgraph with the appropriate properties can be quickly sampled. 
The question is how to set the probabilities of sampling such that (i) we get a linear-size subgraph and (ii) processing this subgraph enables efficient computation of the solution to the original problem. 
One can produce this linear-sized subgraph in a variety of ways - 
by randomly sampling vertices independently with probability , where  is the average degree of  or 
by sampling each edge independently with probability  , etc. 
But for many cases, the sampling-probabilities based on these ``local'' quantities such as degree, max-degree, average degree, etc are not adequate to obtain a subgraph with the appropriate properties. 
On the other hand, computing sampling probabilities which are based on ``global'' properties of the graph may be as hard as solving the problem on the original graph itself. 
In summary, the challenges of random sampling in the Congested Clique are two-fold - 
(i) how to set the sampling probabilities so that we a get a linear-sized subgraph with the appropriate properties and (ii) how to compute these probabilities quickly on the Congested Clique model. 


In this paper, we describe our edge-sampling technique to solve the Connectivity Verification problem. 
Random edge-sampling has been shown to be useful in the context of cut-approximation in the sequential setting (RAM model)~\cite{karger1994stoc, benczurKarger1996stoc, fung2011stoc}. 
For example, Fung et al.~\cite{fung2011stoc} showed that edge-connectivity-based probabilities produce a -size subgraph which approximates all the cuts in the original graph w.h.p..  
Hence, the Connectivity Verification problem can be solved on this reduced-size sampled graph obtained in this way.
The problem with this approach is the probability function depends on the edge-connectivity which is a global-property and hence it might be difficult to compute quickly in the Congested Clique model. 
On the other hand, for the Connectivity Verification problem we don't need such a strong result on the cut-approximation similar to the result of Fung et al.~\cite{fung2011stoc}. 
In this report, we show that degree-based edge-sampling probabilities are sufficient to solve the Connectivity Verification problem. 
Specifically, we show the following result: 
\begin{itemize}
  \item If each edge  is independently sampled with probability based on the degrees of its end-points then the set of sampled edges  has the following properties w.h.p.:
    (i)  and (ii) the number of inter-component\footnote{Refer to Subsection~\ref{sub:tech} for the definition of inter-component edges}  edges between components induced by  is . 
    (For the precise statement of this, see Theorem~\ref{thm:sample}).
\end{itemize}


\subsection{Preliminaries}
\label{sub:tech}
\paragraph{Maximal spanning forest and component graph.}
A \textit{maximal spanning forest} of a graph  is a spanning forest of  which has exactly as many trees as the number of components in .    
  For a given graph  and a given subset of edges , let  be the set of connected components of graph . 
  The \textit{component graph} ``induced'' by edges in  is the graph  whose vertices are components  and whose edges are 
 \textit{inter-component edges} defined as  
 
where  is the minimum of ID of nodes in component . 
The minimum ID node in a component  is also referred as the \textit{leader} of  and denoted as .
For the convenience we \textit{label} a component  by the ID of  and 
let  denote the label of the component of a node . 
Refer to Figure~\ref{fig:componentGraph} for an illustration of a component graph. 
We can extend the concept of the component graph to weighted graphs as well by defining weights of inter-component edges as follows:

\begin{figure}
  \begin{boxedminipage}{\textwidth}
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
     \includegraphics[scale=0.6]{componentGraph1} 
      \caption{Edges in \label{subfig:edges}}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
     \includegraphics[scale=0.6]{componentGraph} 
     \caption{Components induced by \label{subfig:component}}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
     \includegraphics[scale=0.6]{componentGraph3}
      \caption{Component graph\label{subfig:cg}} 
    \end{subfigure}
  \end{boxedminipage}
  \caption{(a) The solid lines are the edges in  and the dashed lines are the edges in  (b) The circles are the components induced by edges in  (c) The component graph induced by edges in  and the solid lines are the inter-component edges. 
  \label{fig:componentGraph}}
\end{figure}
\paragraph{Connectivity Verification problem.}
The input to the Connectivity Verification problem is a graph  and the goal is to decide whether  is connected or not. 
Initially, each node  knows incident edges in . 
When the algorithm ends, all nodes in  are required to know a maximal spanning forest of  and hence can decide whether  is connected or not.

\paragraph{MST problem.}
The input to MST problem is a weighted clique graph . 
(This can be generalized to any non-clique graph where weights of non-edges is set to .)
Initially, each node  knows weights  to all nodes . 
When the algorithm ends, all nodes in  are required to know a spanning tree  of  of minimum weight.
We assume that weights can be represented in  bits. 

\paragraph{Lenzen's routing protocol.}
A key algorithmic tool that allows us to design near-constant-time round 
algorithms is a recent deterministic routing protocol by Lenzen 
\cite{lenzen2013routing} that disseminates a large volume of information 
on a Congested Clique in constant rounds.
The specific routing problem, called an \textit{Information Distribution Task},
solved by Lenzen's protocol is the following.
Each node  is given a set of  messages, each of size , ,
with destinations , .
Messages are globally lexicographically ordered by their source , destination , and .
Each node is also the destination of at most  messages.
Lenzen's routing protocol solves the Information Distribution Task in  rounds.

\section{Large-Cut-Preserving Random Edge-Sampling}
\label{sec:cut}
In this section, we describe how to sparsify the given graph  by sampling edges such that ``large'' cuts of  have approximately the same value in  as in the sampled graph. 
The problem of approximating every cut of  arbitrarily well in the sampled graph first introduced by Karger~\cite{karger1994stoc}. 
He showed that if the graph has minimum cut-size , then sampling edges with probability roughly  yields a graph with cuts that are all, with high probability, within  of their expected values. 
However if  has  edges, then the sampled graph has  edges so this scheme may not sparsify the graph effectively when  is small. 
Bencz\'{u}r and Karger~\cite{benczurKarger2002arxiv, benczurKarger1996stoc} later showed that one can obtain a weighted graph with  edges which approximates all the cuts in the original graph. 
This was achieved by sampling edges with non-uniform probabilities which are based on \textit{edge-strengths} (a measure of edge-connectivity). 
Fung et al.~\cite{fung2011stoc} simplified the computation of these probabilities based on standard edge-connectivity and showed that one can obtain a weighted graph graph with  edges which approximates all the cuts in the original graph.  
The motivation behind the work of Bencz\'{u}r-Karger~\cite{benczurKarger1996stoc, benczurKarger2002arxiv} and Fung et al.~\cite{fung2011stoc} was to speed-up the computation of max-flow approximation, since the sampled graph has fewer edges, minimum cuts can be found in it faster than in the original graph. 
We are interested in ``preserving'' only large cuts, i.e., cuts of size  as opposed to arbitrary cuts and hence a special case of above problems. 
In this section, we show that simple degree-based sampling probabilities are good enough to obtain a sparse graph with  edges which has at least one edge from every -size cuts in  when . 
We start with defining few terms which will enable us to state the sampling probabilities.  

\begin{definition}[rounded-degree, -degree edge]
  The rounded-degree of a vertex  is defined as . 
  The rounded-degree of an edge  is defined as . 
  An edge  is called a -degree edge if its rounded-degree . 
\end{definition}

An edge  is independently sampled with probability . 
When edges of  are sampled in this manner, we obtain a graph , such that w.h.p. (i)  has  edges and (ii) every cut of size at least  in  contains at least one edge in .
We can obtain approximate cuts in the sampled graph for large cuts in  if we assign weights  to the sampled edges in the sampled graph, but for our purpose it is sufficient to show that at least one edge from every large cut is sampled. 
More formally, we'll prove the following theorem:
\begin{theorem}
  For a given undirected graph , if we sample each edge  independently with probabilities  to obtain the sampled graph  then the following properties hold with high probability: 
  (i) Number of edges in  and (ii) from every cut of size at least  in  at least one edge is sampled. 
\end{theorem}
\noindent We prove this theorem in a similar manner as Fung et al.~\cite{fung2011stoc} proved for edge-connectivity based probabilities. 
We first define -projection of a cut and then count distinct -projections of cuts of sizes . 
Then we show that ``bad events'' happen with low probability for a single projection and then use the counting result to apply a union bound. 
\subsection{The Projection Counting Theorem}
\begin{definition}[-projection]
  For a cut  the subset  of -degree edges is called -projection of . 
\end{definition}
It is worth mentioning that this definition of -projection is different from the definition of -projection in Fung et al.~\cite{fung2011stoc}. 
They defined -projection of a cut  to be subset  of edges whose edge-connectivity is at least . 
We are sampling edges based on degrees as opposed to edge-connectivities and hence the definition of -projection is also based on degrees. 

\noindent To count the number of distinct -projections of cuts of size , consider the following two operations.
\begin{operation}[splitting-off]
  \textit{`Splitting-off a pair of edges'} refers to replacing the pair of edges  and  in an undirected multigraph by a single edge . 
  The operation \textit{`splitting-off a vertex'} with even degree in an undirected graph refers to splitting-off all arbitrary pairs of incident edges on this vertex.  
\end{operation}
This splitting-off operation was first introduced by Lov\'{a}z in~\cite{lovasz1993book}. 
Various properties of splitting-off operations have been studied in the past~\cite{mader1978reduction, babai1986complexity}. 
Mader~\cite{mader1978reduction} showed that there exists a pair of edges incident on an even-degree vertex such that splitting off this pair does not decrease connectivity of the rest of the edges in the resulting graph. 
We need a very simple property:
\begin{proposition} 
Splitting-off an even-degree vertex preserves vertex degrees of the rest of the vertices in the resulting graph. 
\end{proposition}

\noindent The following operation was introduced by Karger~\cite{karger1993soda}. 
\begin{operation}[edge-contraction]
  Contraction of an edge  in an undirected multigraph is defined as merging  and  into a single vertex.
  Any self-loops produced by edges between  and  are discarded. 
  We call undoing contracted edge  as \textit{expanding} the vertex formed by contracting . 
\end{operation}

\noindent We now present the -projection counting theorem.
The proof of this theorem is similar to the celebrated cut-counting result of Karger~\cite{karger1993soda} 
and the use of of the ``splitting-off'' operation is inspired by Fung et al.~\cite{fung2011stoc}.
We first describe a randomized algorithm which outputs a random cut.
This algorithm establishes a probability distribution over -projections. 
We bound the probability of this random cut being the cut under inception and use this to bound number of distinct -projections.
\begin{lemma}[-projection counting] \label{lemma:projectionCount}
  Let  be an undirected size- graph. 
  For any  that is power of~ and  the number of distinct -projections of cuts of size at most  is at most .
\end{lemma}
\begin{proof}
  We construct a multigraph  by adding two copies of , i.e., for each edge  in  we have two copies of  in . 
  There is a bijection between size- cuts in  and size- cuts in . 
  Further, there is a bijection between -projections of size- cuts in  and -projections of size- cuts in .
  Hence, it suffices to prove above lemma for -projections of size- cuts in .
  To avoid carrying the ``2'' through the rest of the proof we prove the lemma for -projections of size- cuts in  where  and  is even.

  \noindent We run the following randomized algorithm on .
We want this algorithm to output a -projection and thereby establish a probability distribution on -projections.
  \begin{enumerate}
    \item Split-off all vertices  whose rounded degree .
    \item Contract an edge chosen uniformly at random in the resulting graph.
    \item If the contraction operation produces a vertex  with , split it off. 
    \item If at most  vertices are left, generate a random cut and output -degree edges from the cut (where the degrees are with respect to ); otherwise, go to Step 2.  
  \end{enumerate}
  Fix a cut  of size at most . 
  Let  be its -projection. 
  Since rounded degree of all the edges in  is , none of the edges in  are split-off by Step~1. 
  We argue below that the probability that none of the edges in  are contracted in the above algorithm is at least  and therefore, there can be at most  such different -projections. 

  Observe that splitting-off vertices with rounded-degree  does not affect the degrees of the rest of the vertices. 
  Therefore, in the splitting-off process no edge from  is split-off. 
  If no edge in  is contracted then no edge from  is contracted.
  We now bound the probability that an edge from  is contracted. 
  Let  be the multigraph and  be the remaining vertices at the beginning of iteration  of the contraction algorithm. 
Note that  is the number of vertices in  with . 
  At the start of iteration , there are at least  edges in the current multigraph .
  The size of cut  does not increase during the splitting-off process. 
  Hence the probability that no edge in  is selected to contract in Step 2 of iteration  is at least . 
  Therefore, the probability that no edge in  is selected in the entire execution of the algorithm is at least
  
  Once the number of vertices reaches , the algorithm generates a random cut. 
  Since there are at most  distinct cuts in a graph with  vertices, the probability that the random cut generated by the algorithm contains only edges in  is at least 
  . 
  Let the random cut generated by the algorithm is . 
  We now backtrack the execution of the algorithm to ``expand'' vertices, i.e. we obtain the multigraph  from the multigraph  by expanding the vertex that was formed by the edge chosen for contraction in iteration . 
  After expansion let  becomes  in  (i.e. multigraph at the beginning of the contraction algorithm) and  becomes  in . 
  We report the -degree edges from the cut  and the degrees are with respect to . 
  (Note that the degree of a vertex in  is the same as its degree in  since splitting-off is degree-preserving operation). 
  Observe that if none of the edges in  are contracted in the process then it means none of the edges in  are contracted (some of the edges in  might have split-off but edges in  does not split-off). 
  Therefore,  is exactly the set of -degree edges in  output by the algorithm. 
  This is true for every distinct -projection of cuts having at most  edges. 
  Hence the lemma follows. 
\end{proof}

\subsection{Sampling Large Cuts}
In this subsection, we show that our choice of degree-based sampling probabilities ``preserves''  -projections given that these are large enough. 
The upper bound on the number of -projections proved in Lemma~\ref{lemma:projectionCount} allows us to apply a union bound.
After showing that large -projections survive in the sampled graph we show at least one edge from large cuts is sampled with high probability.
\begin{definition}[-good -projection]
  The -projection  of a cut  of size  is a -good -projection if .
\end{definition}

\begin{lemma} \label{lemma:goodProjection}
  Let  be an -vertex graph and let  be the set of edges obtained by independently sampling each edge  with probability . 
  For any  and any  that is power of~, with probability at least  every -good -projection contains an edge in . 
\end{lemma}
\begin{proof}
  Fix a size  and . 
  Consider a -good -projection , i.e.,  is a -projection of size at least  of size- cut.
  Since all edges in  are -degree edges, the probability that an edge is sampled from  is .
  If  then we are done, therefore assume that . 
  Let  be the number of edges sampled from .
  Then . 
  Since edges are sampled independently, by Chernoff's bound we have 
  
  By Lemma~\ref{lemma:projectionCount}, for a fixed  and  there are at most  distinct -projections. 
  Applying a union bound over all -good -projections the probability that 
  the there exists a -good -projection from which fewer than  edges are sampled is at most 
     
  The last inequality is due to the fact that  and the assumption that . 
  Again applying a union bound over at most  different values of  and at most  different values of , for any  and any ,
  the probability that there exists a -good -projection with fewer than  edges sampled is at most 
  
  Hence the lemma follows. 
\end{proof}

\begin{theorem}\label{thm:cut} 
  Let  be an -vertex graph and let  be the set of edges obtained by independently sampling each edge  with probability . 
  Then with probability at least  every cut of size at least  contains an edge in . 
\end{theorem}
\begin{proof}
  Let  be the set of all cuts of size . 
  If for some  we can show there exists a -good -projection for every , then by Lemma~\ref{lemma:goodProjection} we are done. 

  For every cut , partition  into , where  is the -projection of .
  Since , by the pigeonhole principle, at least for one ,  has more than  edges.
  Hence, for every cut , there exists a -good -projection.  
  By Lemma~\ref{lemma:goodProjection}, for any  and for any  that is power of  every -good -projection contains at least one sampled edge with probability at least .
  Therefore, every  contains at least one sampled edge w.h.p..
\end{proof}

\subsection{Sampling and Component Graph}
Let  be the set of sampled edges. 
We now prove the two properties of sampled edges  and the component graph  induced by . 

We say an edge  is \textit{charged} to vertex  if .  
  If  then the edge  is charged to either  or  arbitrarily. 
  Hence every edge is charged to exactly one vertex.
\begin{lemma}\label{lemma:ssize}
  Let  be an -vertex graph  and let  be the set of edges obtained by independently sampling each edge  with probability . 
  Then, with probability at least , 
  the number of sampled edges charged to a vertex is at most  and 
  the total number of sampled edges is .
\end{lemma}
\begin{proof}
  Consider a vertex .
  Let  be the set of edges charged to .
  Edges in  are sampled with probability . 
  If  then we are done, therefore assume . 
  Let  be the indicator random variable indicating if edge  is sampled. 
  Let  denote the total number of sampled edges charged to . 
  Then . 
  Since edges are sampled independently, by Chernoff's bound we have, 
   
  By applying a union bound over all vertices, for every vertex  the probability that the number of sampled edges charged to  exceeds  is at most . 
  Therefore, the total number of sampled edges is  w.h.p..
\end{proof}

\begin{lemma}\label{lemma:smallcut}
  Let  be an -vertex graph  and let  be the set of edges obtained by independently sampling each edge  with probability . 
  Let  be the component graph . 
  Then with probability at least ,  .
\end{lemma}
\begin{proof} 
  We first prove that the max-cut size of  is less than . 
  Assume for the sake of contradiction that a cut  in  where  has size more than . 
  This means that the cut  has size more than  in , since each edge in  is induced by of one or more edges from .
  By Theorem~\ref{thm:cut}, w.h.p.,  contains at least one edge from the cut  of .
  Let  such that  and . 
  Hence  has to be in one of  and let it be . 
  This implies in the component graph,  and  to be in the same component . Hence a contradiction. 
  This is true w.h.p. for any cut of size more than  in . 
  Therefore the max-cut size of  is less than  w.h.p.. 

  \noindent Consider the following randomized algorithm to find a cut in . 
  Each vertex in  is independently added to a set  with probability . 
  We now analyze the size of the cut .  
  The probability that an edge crosses this cut is . 
  Since there are  edges, the expected size of this cut is . 
  But we know that the max-cut size is at most . Therefore, . 
\end{proof}

\noindent We summarize this section with the following theorem.  
\begin{theorem}\label{thm:sample}
  Let  be an -vertex graph  and let  be the set of edges obtained by independently sampling each edge  with probability . 
  Let  be the component graph induced by . 
  Then with probability at least  we have, 
  \begin{enumerate}
    \item The number of sampled edges is , 
    \item The number of inter-component edges, that is, the number of edges in  is .
  \end{enumerate}
\end{theorem}

\section{Connectivity Verification via Random Edge-Sampling} \label{sec:conver}
In this section, we describe how to utilize the degree-based edge sampling from the previous section to solve the Connectivity Verification problem on a Congested Clique.
This randomized algorithm solves the Connectivity Verification problem in  rounds w.h.p. by combining the degree-based edge sampling with the Lotker et al. deterministic MST algorithm~\cite{lotker2005mstJournal}. 
We first describe the  Lotker et al. MST algorithm~\cite{lotker2005mstJournal}.

The Lotker et al. algorithm runs in phases, taking constant number of communication rounds per phase.
At the end of phase , the algorithm has computed a partition  of the nodes of  into clusters.
Furthermore, for each cluster , the algorithm has computed a minimum spanning tree . 
It is worth noting that every node in the network knows the partition  and the collection  of trees.
It is shown that at the end of phase  the size of the smallest cluster is at least  and hence . 
In the following we refer to the Lotker et al. algorithm as the \textsc{CC-MST} algorithm. 
Let \textsc{CC-MST} denote the execution of \textsc{CC-MST} on graph  for  phases. 
\begin{theorem}[Lotker et al.\cite{lotker2005mstJournal}]\label{thm:lotker}
  \textsc{CC-MST} computes an MST of an -node edge-weighted clique in  rounds. 
  At the end of phase , \textsc{CC-MST} has computed a partition  and  which has the following properties: 
  (i) , 
  (ii) Every node knows  and , and
  (iii) If the largest weight of an edge in a cluster  is , then there is no edge with weight  such that it has one end point in  and other in  for any . 
\end{theorem}

Our connectivity verification algorithm runs in three phases. 
Initially, our graph can be viewed as having  components - one for each vertex. 
In Phase~1 we reduce the number of components by running \textsc{CC-MST} for  phases. 
Phase~2 operates on the component graph induced by the edges selected in Phase~1  and samples edges from this component graph using degree-based probabilities as discussed in the earlier section. 
Phase~3 is executed on the component graph induced by edges selected in Phase 2. 
Each phase outputs a forest  and a component graph  induced by edges in , that is, 
at the end of each phase every node knows all the edges in  and knows which of the incident edges are the inter-component edges in .  
Given a subgraph of  that is a tree, we call this tree \textit{finished} if it is a spanning tree of a connected component in the graph .
A tree which is not finished is referred as \textit{unfinished} tree. 
Each phase construct trees, some of which might be unfinished. 
A finished tree need not play any further part in the algorithm.
We show that Phase~2 and Phase~3 run in  rounds each w.h.p. and 
at the end of Phase 3 all trees are finished. 

We make use of the following subroutine at the end of Phase 1 and Phase 2 to ``construct'' the component graph 
(refer to Subsection~\ref{sub:tech} for definitions and notations). 
The subroutine \textsc{BuildComponentGraph} takes a subset of edges of  as input and it is assumed that initially all nodes know all edges in  and components induced by .  
It returns the component graph . 
At the end of this subroutine each leader knows the inter-component edges incident on its component. 
This subroutine can be implemented in  rounds using \lra~as follows:
every node  in a component , for every incident edge  such that  adds a message destined for  in the sending queue to notify  of the presence of the inter-component edge , if it already has such a message in the queue (due to a different incident edge ) then  ignores this edge.
Hence the sending queue of each node contains at most  messages (since there can be at most  components). 
Each leader receives at most  messages since each node is sending only a single message to a leader.
Therefore, we can use \lra~to route these messages in  rounds. 
After this step, every leader  knows the incident inter-component edges. 

Algorithm \textsc{ReduceComponents} describes Phase~1. 
\begin{algorithm}[H]
  \caption{Phase 1: \textsc{ReduceComponents} \label{algo:phase1}}
  \begin{algorithmic}[1]
    \REQUIRE A graph . 
    \ENSURE   - a spanning forest of  with at most  unfinished trees and component graph induced by these edges  
    \STATE   Assign unit weights to edges in  to obtain a weighted graph ; make  a clique by adding edges not in  and assign weight  to these newly added edges.  
    \STATE    \textsc{CC-MST}
    \STATE   
    \STATE  \textsc{BuildComponentGraph}
    \RETURN 
  \end{algorithmic}
\end{algorithm}
\noindent Input to Algorithm \textsc{ReduceComponents} is a graph . 
At the end of this algorithm, every node knows the ID of the leader of the component it belongs to and every leader knows incident inter-component edges in the component graph induced by edges selected during the execution. 
In Step~1, to every edge in the input graph  we assign weight ; pairs of vertices not adjacent are assigned weight . 
Step~2 simply executes \textsc{CC-MST} on this weighted clique for  phases which returns clusters  and a forest  of trees, one spanning tree per cluster. 
There might be few edges selected by \textsc{CC-MST} with weights  and in Step~3 we discard these edges. 
By Theorem~\ref{thm:lotker}, every node knows  (so ) and hence we can execute \textsc{BuildComponentGraph} (Step~4) in  rounds. 
At the end of \textsc{ReduceComponents} we have the following properties:
\begin{lemma}
  \label{lemma:phase1Finished}
 If a tree in  has an edge with weight  then after removing this edge both of the obtained trees are either finished trees of  or contains further -weight edges. If we remove all the -weight edges then all the newly obtained trees are finished trees of . 
\end{lemma}
\begin{proof}
  Let  be an edge in   has weight , i.e., .  
  By Theorem~\ref{thm:lotker} (Property (iii)), all the incident edges on  have weights .
  In other words, there is no edge in  which has exactly one endpoint in . 
  If the trees obtained by removing  does not contain any further -weight edges then the both trees are finished trees. 
  If it contains -weight edges then we repeat the above argument on the both of the trees until we obtain trees with no -weight edges.
  By the earlier argument all these obtained trees are finished trees. 
\end{proof}
\begin{lemma}
  \label{lemma:phase1Unfinished}
  The number of unfinished trees in  are at most . 
\end{lemma}
\begin{proof}
  By Theorem~\ref{thm:lotker} (Property (i)), we have . 
  By Lemma~\ref{lemma:phase1Finished}, by removing -weight edges increases only the number of finished trees. 
  Therefore, the number of unfinished trees cannot be more than . 
\end{proof}
\noindent Also, it is easy to see that Phase~1 runs in  rounds, since Step~2 takes  rounds, but the rest take only  rounds each.   
\begin{comment}
\begin{lemma}
  \textsc{BuildComponentGraph} runs in  rounds in the Congested Clique.
\end{lemma}
\begin{proof}
  Please refer to the description of \textsc{BuildComponentGraph}. 
  By Lemma~\ref{lemma:f}, there are at most  different components and hence a node  has at most  neighbors  with distinct  values. 
  Hence the sending queue of each node has at most  messages to send. 
  Every leader has to receive at most  messages since each node sends at most one message to each leader. 
  Therefore by using Lenzen's routing algorithm we can route these messages in  rounds on the Congested Clique. 
\end{proof}
\end{comment}
 
Phase~2 runs on the component graph  returned by Phase~1 and computes a spanning forest  of  such that the component graph induced by  has at most  inter-component edges. 
Note that there might be some finished trees in . 
The components induced by finished trees do not have any incident edge in  and hence the corresponding vertices will be isolated in . 
Let  be the graph obtained by removing isolated vertices from . 
By Lemma~\ref{lemma:phase1Unfinished}, . 
Let  denote the vertex in  with minimum ID.
\begin{algorithm}[H]
  \caption{Phase~2: \textsc{RemoveLargeCuts} \label{algo:phase2}}
  \begin{algorithmic}[1]
    \REQUIRE  obtained by removing isolated vertices from  where  and   
    \ENSURE   - a spanning forest of  such that the number of edges in the component graph  induced by  is .
    \STATE  . \\ For each edge , add edge  to  with probability  where  is the rounded-degree of  with respect to .
    \STATE  Gather  at vertex  (the node in  with the lowest ID).
    \STATE   executes locally : \textsc{SpanningForest}. 
    \STATE   assigns each edge in  to a node in  such that each node is assigned a single edge and send edges to assigned nodes.  
    Each node in  then broadcast the edge it received from  so that all nodes now know .   
    \STATE   \textsc{BuildComponentGraph} 
    \RETURN 
  \end{algorithmic}
\end{algorithm}

Step~1 of Phase~2 can be implemented as follows. 
Each node in  broadcast its degree with respect to . 
An edge  is ``charged'' to node  if  or  and . 
Node  computes  for each edge  charged to it and then samples each  independently  with probability . 
Node  constructs a queue of messages intended for node  consisting of all edges it sampled. 
We show below that the contents of all these queues can be sent to  in  rounds. 
Step~3 is a local step executed at . 
Step~4 makes sure that each node knows all the components induced by sampled edges in Step~1. 
Therefore, Step~5 can be executed in  rounds. 
We now show that Step~2 can be implemented in  rounds by proving the following claim and then appealing to Lenzen's routing algorithm to route the messages in the queue of each node.  
\begin{lemma}
  \label{lemma:p2sample}
   with probability at least .
\end{lemma}
\begin{proof}
  By Lemma~\ref{lemma:ssize}, the number of sampled edges charged to a node is  w.h.p. and therefore, 
  if a graph has  vertices then the number of sampled edges is  w.h.p.. 
   The graph  is the component graph induced by unfinished trees in Phase~1 and we showed that . 
   Therefore,  w.h.p..
\end{proof}
\noindent Since each node's queue can contain at most  messages w.h.p. and since  w.h.p.,  has to receive at most  messages w.h.p., and hence we can route these messages in  rounds w.h.p. by using Lenzen's routing algorithm. 

\begin{lemma}
  \label{lemma:phase2}
  Phase~2 runs in  rounds w.h.p. and returns a spanning forest  such that the component graph  induced by  has  edges.
\end{lemma}
\begin{proof}
  The discussion just before Lemma~\ref{lemma:p2sample} proves that each step in Algorithm~\ref{algo:phase2} can be implemented in  rounds w.h.p.. 
  By Theorem~\ref{thm:sample}, the number of inter-component edges in  is  w.h.p..
\end{proof}

\noindent We execute the Phase~3 on the component graph  obtained in Phase~2.  
Let  denote the graph obtained by removing isolated vertices from . 
Phase~3 computes  -a spanning forest of . 
\begin{algorithm}[H]
  \caption{Phase 3: \textsc{HandleSmallCuts}}
  \begin{algorithmic}[1]
    \REQUIRE  obtained by removing isolated vertices from  where  and 
    \ENSURE   - a spanning forest of .
    \STATE   Gather  at vertex  (the node in  with the lowest ID).
    \STATE    locally executes:  \textsc{SpanningForest}.  
    \STATE    assigns each edge to a node in  such that each node is assigned a single edge and send edges to assigned nodes.  
	    Each node then broadcast the edge it received so that all nodes now know .
    \STATE    \textsc{BuildComponentGraph}
    \RETURN  . 
  \end{algorithmic}
\end{algorithm}
By Lemma~\ref{lemma:phase2}, the number of inter-component edges () in the component graph  is  and the degree of each node in  is at most . 
Therefore, Step~1 can be executed in  rounds using Lenzen's routing algorithm.
Algorithm \textsc{Conn} summarizes our algorithm. 
\begin{algorithm}[H]
  \caption{\textsc{Conn}\label{algo:conn}}
  \begin{algorithmic}[1]
    \REQUIRE 
    \ENSURE  a maximal spanning forest of 
    \STATE    \textsc{ReduceComponents}
    \STATE    \textsc{RemoveLargeCuts} 
    \STATE    \textsc{HandleSmallCuts}
    \RETURN  
  \end{algorithmic}
\end{algorithm}
\noindent We now prove that Algorithm \textsc{Conn} solves the Connectivity Verification problem. 
\begin{lemma}
   At the end of Algorithm \textsc{Conn} every node in  knows a spanning forest with exactly as many trees as the number of connected components in , that is, \textsc{Conn} returns a maximal spanning forest of .
\end{lemma}
\begin{proof}
  Let  denote the spanning forest returned by Algorithm \textsc{Conn}. 
  Let  be the number of connected components in . 
  Let  be the number of maximal trees in  (which are the number of vertices in ). 
  We want to show that . 

  Assume .
  Therefore, there exists at least one edge  such that  and  are in the same connected component of  but they are not in the same tree in . 
  Let  is in tree  and  is in tree , , that is  and  are the unfinished trees.
  It means  and  were in the separate components at the end of Phase~1 and Phase~2. 
  But then in Phase~3, the edge  is inspected and they will be in the same spanning tree computed by Phase~3. 
  Hence a contradiction.

  Now assume . 
  This is possible only if we add an edge  to  during the execution of \textsc{Conn}. 
  We only add additional edges in Phase~1 but we assign weight  to edges which are not in  and these edges are removed from .  
  Therefore the additional edge must have weight  and hence not in  and won't be present in . 
  
  \noindent By combining the above two arguments we have .
\end{proof}
\noindent This lemma establishes the correctness of our algorithm. 
The discussion in this section also shows that \textsc{Conn} runs in  rounds with high probability. 
We summarize the result of this section in the following theorem. 

\begin{theorem}
  Algorithm \textsc{Conn} solves the Connectivity Verification problem in  rounds with probability at least . 
\end{theorem}

\section{Exact MST via Random Edge-Sampling} \label{sec:mst}
In this section we show how to solve the MST problem on a Congested Clique using ideas from our Connectivity Verification algorithm.
Initially each node is a component and hence initially there are  components. 
We first reduce the number of components to  using the Lotker et al. MST algorithm similar to Phase~1 of our Connectivity Verification algorithm in  rounds. 
Then we reduce the MST problem on this graph to two subproblems using a sampling lemma by Karger et al.~\cite{KKT1995MST}.
Each subproblem has to compute a MST of a weighted graph whose average degree is at most . 
We first show that this reduction can be completed in  rounds. 
Finally we show how to compute MST on a graph with average degree  and number of components  in  rounds.

\subsection{Reducing Components and Edges}
We first reduce the number of components to at most  components by executing \textsc{CC-MST} for  phases similar to our Connectivity Verification algorithm. 
Let  be the spanning forest and  be the component graph obtained by executing the above step. 
By the property of \textsc{CC-MST},  is a subset of a MST of  (Theorem~\ref{thm:lotker}). 
Our goal now is to complete this MST by deciding which of the edges in  are in the MST. 

Karger et al.~\cite{KKT1995MST} designed a randomized linear-time algorithm to find a MST in a edge-weighted graph in a sequential setting (RAM model).
A key component of their algorithm is a random edge sampling step to discard edges that cannot be in the MST. 
For completeness we state their sampling result and the necessary terminology.
\begin{definition}[-light edge~\cite{KKT1995MST}] 
 Let  be a forest in a graph  and let  denote the path (if any) connecting  and  in . 
 Let  denote the maximum weight of an edge on  (if there is no path then ). 
 We call an edge  is \emph{-heavy} if , and \emph{-light} otherwise. 
\end{definition}
\noindent Karger et al.~\cite{KKT1995MST} proved the following lemma. 
\begin{lemma}[KKT Sampling Lemma~\cite{KKT1995MST}]
 \label{lemma:kkt}
Let  be a subgraph obtained from  by including each edge independently with probability ,
and let  be the minimum spanning forest of . 
The number of -light edges in  is at most  w.h.p.. 
\end{lemma}
\noindent The implication of the above lemma is that if we set  then the number of sampled edges in  and the number of -light edges in  both are  w.h.p.. 
Also, none of the -heavy edges can be in a MST of . 
Therefore if we compute a minimum spanning forest  of  then we can discard all the -heavy edges and 
it is sufficient to compute a MST of graph induced by -light edges in . 
We have reduced the problem in two problems: (i) compute minimum spanning forest  of  where the number of edges in  is  w.h.p. and (ii) compute minimum spanning tree of the graph induced by -light edges in . 
Note that these two problems cannot be solved in parallel since the later problem depends on the output of the first problem. 

Algorithm~\ref{algo:kkt} summarizes our approach. 
In the beginning of Algorithm \textsc{Exact-MST} every node knows weights of incident edges and at the end of the execution every node knows all the edges that are in a MST computed by the algorithm. 
Algorithm \textsc{SQ-MST} computes a MST of a graph with  vertices and  edges and at the end of the execution of this algorithm, all nodes knows the MST computed by it.
In the next subsection we describe this algorithm and show that it runs in  rounds w.h.p.. 
\begin{algorithm}[H]
 \caption{\textsc{Exact-MST}\label{algo:kkt}}
 \begin{algorithmic}[1]
  \REQUIRE An edge-weighted clique 
  \ENSURE  MST of 
  \STATE   \textsc{CC-MST}
  \STATE     a subgraph of  obtained by sampling each edge independently with probability  
  \STATE    \textsc{SQ-MST}
\STATE    
  \STATE    \textsc{SQ-MST}
  \RETURN  
 \end{algorithmic}
\end{algorithm}

\subsection{Computing MST of -size Graph}
In this subsection we show how to compute an MST of a subgraph  of  with  edges and  vertices  using our edge-sampling technique similar to the Connectivity Verification algorithm.

We have a graph  ( with at most  vertices and  edges  where  is the number of nodes in the Congested Clique network .
The bounds on number of vertices and number of edges are critical ensuring that our MST algorithm runs in  rounds. 
Algorithm \textsc{SQ-MST} (MST algorithm on a graph with average degree ) describes our MST algorithm on subgraph . 
The high level idea is to sort the edges based on their weights, that is, 
each node needs to know the \emph{rank}  of each incident edge which is the index of  in a global enumeration of the sorted edges.
This sorting problem can be solved in  rounds on the Congested Clique by using Lenzen's distributed sorting algorithm~\cite{lenzen2013routing}. 
Then each node partitions the incident edges based on their ranks. 
Thus we partition  into at most  sets  () each containing  edges ( might have less than  edges) 
such that  contains all the edges whose ranks are in the range  to ,  contains the edges with ranks between  and , and so on. 
That is, each node knows the partition index of each incident edge. 

In the next step we gather set  at a single \textit{guardian} node .
This can be done in  rounds as well because . 
The role of a guardian node  is to determine which of the edges in  are a part of the MST. 
Specifically,  wants to know for each edge  whether there is a path between its endpoints in the graph induced by edges with ranks less than . 
That is, for each edge  that a  has,  needs to find out whether there is a path between endpoints of  in the graph induced by edges  . 
Thus each  needs to know a spanning forest of the graph  induced by edges , and we show that it can be computed by executing the similar steps as Phase 2 and 3 of the Connectivity Verification algorithm on  in  rounds.
Steps~\ref{algo:sqmst:2s} to~\ref{algo:sqmst:2e} of Algorithm \textsc{SQ-MST} are similar to \textsc{RemoveLargeCuts} procedure of Algorithm \textsc{CONN}(Algorithm~\ref{algo:conn}) which samples the incident edges (with respect to ) with probability based on its degree (with respect to ). 
Step~\ref{algo:sqmst:3} is similar to \textsc{HandleSmallCuts} which simply gathers the inter-component edges at the guardian node and process it locally. 
There are  such guardians - one for each partition  and hence the challenge is executing  instances of these steps in parallel on the Congested Clique network. 
What helps in showing that these  instances can be executed in parallel is that  has at most  vertices and  edges. 
The procedure \textsc{RouteLabels} implements this parallel execution in  rounds w.h.p..
We describe this procedure along with how to run all these steps in parallel in the next subsection. 
\begin{algorithm}[t]
  \caption{\textsc{SQ-MST} \label{algo:sqmst}}
  \begin{algorithmic}[1]
    \REQUIRE a weighted subgraph  with  vertices and  edges
    \ENSURE  an MST of 
    \STATE    \textsc{DistributedSort} in non-decreasing order of edge-weights. 
    \STATE   Partition edges in  based on their ranks  into  partitions  (),
	     each partition having  edges ( might have less than  edges) such that 
	      contains edges with ranks ;  contains edges with ranks ; and so on.
    \STATE   Let  be the node in  with ID  and
	     assign  as the guardian of partition . \\
	     Gather partition  at .
    \FOR{ \TO  \textbf{in parallel}}
        \STATE Let .\label{algo:sqmst:2s} \\ 
	       .
	\STATE Each node  executes this: for each incident edge , 
	       adds edge  to  with probability  where
	        is the rounded-degree of node  with respect to . 
	\STATE Gather  at .
	\STATE  executes locally: 
	\STATE  informs each  about its component label  induced by . \label{algo:sqmst:2m}  
	\STATE Execute \textsc{RouteLablesAndInterComponentEdges}. It does the following: \\
	       (a). Identifies the inter-component edges ()  in . \\
	       (b). Gather  at .  \label{algo:sqmst:2e}
	\STATE  executes locally: \\ \label{algo:sqmst:3}
	       (a).  \\ 
	       (b).  processes edges in  in rank-based order. \\
		    For each edge  in  : \\
		    if there is path between  and  in  then \\
		    discard  else add  to .  
    \ENDFOR
    \RETURN  
  \end{algorithmic} 
\end{algorithm}

\subsection{Parallel Execution in Algorithm \textsc{SQ-MST}}
In this subsection we show that the for-loop on Line~\ref{algo:sqmst:2s}-\ref{algo:sqmst:3} of Algorithm~\ref{algo:sqmst} can be implemented in  rounds w.h.p..

Consider Lines~\ref{algo:sqmst:2s}-\ref{algo:sqmst:2m}. 
In these steps we sample incident edges as described in the algorithm.
We can gather  at  for each  in  rounds in parallel as follows: 
each node has  sampled edges (Lemma~\ref{lemma:ssize}) over all  execution. 
There are at most  vertices in  therefore,  for each . 
Hence each node needs to send  messages and each guardian is a receiver of  messages.
Therefore we can deliver these messages in  by appealing to \lra. 

In Line~7,  locally computes a spanning forest  induced by edges in . 
Let  denote the label of the component in ,  belong to. 
For each ,  sends  to  (Line~8) and this can be done for all  in parallel. 
Now each  posses a -size vector  consisting of labels obtained from each guardian.
Let  denote the inter-component edges in the component graph .
The goal of \textsc{RouteLabels} is to identify which of the incident edges on  are in  and gather  at  for each  in parallel in  rounds w.h.p..   
Recall that an edge  is an inter-component edge in  if and only if . 
This goal is similar to the goal of procedure \textsc{BuildComponentGraph} but here we need to do it for  different instances in parallel. 
Notice that this is a non-trivial task since each node has a -size label vector  and there can be as many as  neighbors to which this vector has to be delivered in order to identify edges in . 
We describe how to do a careful load-balancing to identify edges in  for all  in parallel with the help of \emph{supporter} nodes. 

Partition  into  where  and  is the degree of  with respect to  and  is constant such that . 
We call nodes in  as \emph{supporter} nodes of .
Such a partition exists because  for a suitable constant . 
Each  informs all nodes in  about its -size label vector . 
This can be done in  rounds by using \lra:
each node  has  labels to send to at most  supporter nodes, that is,  messages to send and each supporter node is a receiver of  messages. 
The next task is to distribute the incident edges on  to nodes in . 
Let  denote edges incident on  in the graph . 
Partition  into size-( parts. 
Hence there are at most  such parts and let these parts are . 
We can send part   to supporter node  in  rounds for all . 
Let  denote the ID of the supporter in  to which edge  is sent. 
Each node  sends a message to its neighbor  informing about  so that node  knows that  assigned edge  to . 
Then each node  notifies  about  for each incident edge . 
At this stage, each supporter  knows the supporter of the end-point of all edges in .  
Now to decide which of the edges in  are in , node  needs to know  for all  such that . 
Node  requests this information to the corresponding supporter node, that is, for each edge , node  requests  to send . 
Since ,  needs to receive  messages. 
On the other hand, it needs to send  messages in total. 
Hence this communication can be done in  rounds since  using \lra.
At this stage each  has the necessary information to decide which of the edges in  are in . 
For each edge in  if it belongs to  then  sends this edge to . 
There are  edges in  and there are at most  different values of , hence  has  messages to send. 
Each guardian  needs to receive  which is of size  by our Sampling Theorem. 
Hence this communication can be done in  rounds. 
We summarize the above description in the Algorithm \textsc{RouteLabels} below.
\begin{algorithm}[H]
  \caption{\textsc{RouteLabels}}
  \begin{algorithmic}[1]
    \REQUIRE Each  knows the -size label vector 
    \ENSURE  Each guardian  for  should know inter-component edges  
    \STATE   Each vertex  broadcast its degree . Let . 
    \STATE   Each vertex  deterministically (all vertices use the same scheme) partitions  ( nodes)  into  partitions:  where
	    . \\
	      is the set of \emph{supporter} nodes of . 
    \STATE   Each  sends the -size vector  to all nodes in . 
    \STATE   Let  be the set of incident edges on  in . \\
	     Each  partitions  into  partitions  and
	     sends partition  to  for . 
    \STATE   Let  denote the node to which  sent edge .\\
	     For each incident edge ,  sends a message to  notifying about . 
    \STATE   For each  and , each  executes the following steps in parallel: 
    \bindent
        \STATE  sends the -size vector  to all  such that .
	\STATE For each  and for each :\\
	\IF {} \STATE  sends  to  \ENDIF 
    \eindent
  \end{algorithmic}
\end{algorithm}
The above discussion shows that each step of Algorithm \textsc{RouteLabels} can be implemented in  rounds w.h.p.. 


\begin{theorem}
  Algorithm \textsc{Exact-MST} computes a MST of a weighted clique in  rounds with probability at least  on the Congested Clique. 
\end{theorem}

\bibliography{mymst}
\end{document}
