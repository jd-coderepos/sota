
\documentclass[3p]{elsarticle}
\clearpage{}
\usepackage{epsfig}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{ifthen}
\usepackage[vlined,ruled]{algorithm2e}
\usepackage{algorithmic}
\usepackage{latexsym}
\usepackage{appendix}
\usepackage{epsfig}
\usepackage{scalefnt}


\newtheorem{theorem}{Theorem}
\newtheorem{assertion}[theorem]{Assertion}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{figger}[theorem]{Figure}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{properties}[theorem]{Properties}
\newtheorem{proof}[theorem]{Proof}

\newcommand{\buchi}{B\"{u}chi}
\newcommand{\nb}{{nondeterministic} B\"{u}chi}
\newcommand{\infi}{\ensuremath{\mathit{inf}}}
\newcommand{\ib}{\ensuremath{i^{\bullet}}}
\newcommand{\ic}{\ensuremath{i^{\circ}}}
\newcommand{\protimes}{}
\newcommand{\kvaut}[1]{\ensuremath{\mathsf{KVF}(#1)}}
\newcommand{\kvsaut}[1]{\ensuremath{\mathsf{KVFS}(#1)}}
\newcommand{\cmpnd}[1]{\ensuremath{\widetilde{ #1 }}}
\newcommand{\mxmdef}[0]{\ensuremath{\lfloor \, \rfloor_{even}}}
\newcommand{\mxm}[1]{\ensuremath{\lfloor #1 \rfloor_{even}}}
\newcommand{\kvranking}[0]{\ensuremath{\mathsf{r^{KV}_{\aA,\alpha}}}}
\newcommand{\gkvranking}[0]{\ensuremath{\mathsf{r^{gKV}_{\aA,\alpha}}}}
\newcommand{\kvrankingfull}[0]{\ensuremath{\mathsf{r^{\bullet}_{\aA,\alpha}}}}
\newcommand{\fullranking}[0]{\ensuremath{\mathsf{r^{\star}_{\aA,\alpha}}}}
\newcommand{\fullrankingsimp}[0]{\ensuremath{\mathsf{r^{\star}}}}
\newcommand{\kvrankingextend}[0]{\ensuremath{\mathsf{r^{\circ}_{\aA,\alpha}}}}
\newcommand{\kvrankingsimp}[0]{\ensuremath{\mathsf{r^{KV}}}}
\newcommand{\gkvrankingsimp}[0]{\ensuremath{\mathsf{r^{gKV}}}}
\newcommand{\kvrankingweak}[0]{\ensuremath{\mathsf{r^{KV}_{weak}}}}
\newcommand{\threadranking}[0]{\ensuremath{\mathsf{r^\diamond_{\aA,\alpha}}}}
\newcommand{\twone}[0]{\ensuremath{{[2n-1]}^{even}}}
\newcommand{\twono}[0]{\ensuremath{{[2n-1]}^{odd}}}
\newcommand{\myleq}[0]{\ensuremath{\leq}}
\newcommand{\mylt}[0]{\ensuremath{<}}
\newcommand{\mygeq}[0]{\ensuremath{\geq}}
\newcommand{\mygt}[0]{\ensuremath{>}}
\newcommand{\minst}[1]{\ensuremath{\mathsf{MinSt}(#1)}}
\newcommand{\succleq}[1]{\ensuremath{\mathsf{succ}_\myleq(#1)}}
\newcommand{\predleq}[1]{\ensuremath{\mathsf{pred}_\myleq(#1)}}
\newcommand{\startlev}{\ensuremath{\mathsf{StartLevel}}}
\newcommand{\minstartlev}{\ensuremath{\mathsf{MinStartLevel}}}
\newcommand{\maxstartlev}{\ensuremath{\mathsf{MaxStartLevel}}}
\newcommand{\satlevel}{\ensuremath{\mathsf{SatLevel}}}
\newcommand{\slice}{\ensuremath{\mathsf{Slice}}}
\newcommand{\editline}[0]{\noindent----------------------------------------------------------------------}
\newcommand{\myrange}[0]{\ensuremath{{\langle 2n \rangle }}}
\newcommand{\eqrela}{\sim_{\mathcal{A}}}
\newcommand{\topdown}{\textsf{TopDown}}
\newcommand{\maxg}{\ensuremath{\mathsf{max_G}}}
\newcommand{\maxr}{\ensuremath{\mathsf{max_R}}}
\newcommand{\maxq}{\ensuremath{\mathsf{max_q}}}
\newcommand{\setL}[1]{{#1}^{\{\}}}
\newcommand{\dv}{\ensuremath{\dot{v}}}
\newcommand{\dV}{\ensuremath{\dot{V}}}
\newcommand{\du}{\ensuremath{\dot{u}}}
\newcommand{\dt}{\ensuremath{\dot{t}}}

\newcommand{\mychoose}[2]{\ensuremath{ \left ( 
   \begin{array}{c}
   #1 \\
   #2
   \end{array}
   \right )} }


\newcommand{\true}{\ensuremath{\mathsf{True}}}
\newcommand{\aA}{\ensuremath{\mathcal{A}}}
 \newcommand{\dD}{\ensuremath{\mathcal{D}}}
 \newcommand{\dr}{\ensuremath{\mathcal{D}_R}}
 \newcommand{\ds}{\ensuremath{\mathcal{D}_S}}
 \newcommand{\dP}{\ensuremath{\mathcal{D}_P}}
 \newcommand{\dm}{\ensuremath{\mathcal{D}_M}}
 \newcommand{\cC}{\ensuremath{\mathcal{A}_C}}
 \newcommand{\aS}{\ensuremath{\mathcal{A}_S}}
 \newcommand{\ar}{\ensuremath{\mathcal{A}_R}}
 \newcommand{\ap}{\ensuremath{\mathcal{A}_P}}
 \newcommand{\am}{\ensuremath{\mathcal{A}_M}}
 \newcommand{\CGS}{\ensuremath{\textsf{CGS }}}



\newcommand{\killit}[1]{}

\newcommand{\algo}[1]{\ensuremath{\textsf{{#1}}}}

\newcommand{\set}{\textit{Set}}

\newcommand{\algoblock}[4]{{{{
                                     \vspace{5mm}
                                     \hrule 
				     \vspace{2mm} 
                                     \noindent \textsf{\bfseries Algorithm : {#1}}
				     \vspace{2mm} 
                                     \hrule 
				     \vspace{2mm}
                                     \hrule 
				     \vspace{2mm}
                                     \noindent \textsf{ {\bfseries Input:} {#2}}\\
                                     \noindent \textsf{ {\bfseries Output:} {#3}}
				     \vspace{2mm}
				     \hrule
				     \vspace{2mm}
{#4} 
				     \vspace{2mm}
				     \hrule
				     \vspace{2mm}
                                     \noindent \textsf{\bfseries End Algorithm : {#1}}}
				     \vspace{2mm}
                                     \hrule 
				     \vspace{2mm}
                          }}
                         }

\newcommand{\plainalgoblock}[2]{{\fontfamily{cmdh}\selectfont
				     {
                                     \vspace{5mm}
                                     \hrule 
				     \vspace{2mm} 
                                     \noindent \textsf{\bfseries Algorithm : {#1}}
				     \vspace{2mm} 
                                     \hrule 
				     \vspace{2mm}
                                     \hrule 
				     \vspace{2mm}
{#2} 
				     \vspace{2mm}
				     \hrule
				     \vspace{2mm}
                                     \noindent \textsf{\bfseries End Algorithm : {#1}}}
				     \vspace{2mm}
                                     \hrule
				     \vspace{2mm}
                          }
                         }











\clearpage{}

\title{Determinization of -automata unified}
 \author[hk]{Hrishikesh Karmarkar}
 \ead{hrishik@cse.iitb.ac.in}
 \author[sc]{Supratik Chakraborty}
 \ead{supratik@cse.iitb.ac.in}
 \address[hk]{Department of Computer Science and Engineering, Indian Institute of Technology Bombay}
 \address[sc]{Department of Computer Science and Engineering, Indian Institute of Technology Bombay}


\begin{document}
 \thispagestyle{empty}
 \begin{abstract}
 We present a uniform construction for converting -automata
 with arbitrary acceptance conditions to equivalent deterministic
 parity automata (DPW).  Given a non-deterministic automaton with 
 states, our construction gives a DPW with at most 
 states and  parity indices.  The corresponding bounds when the
 original automaton is deterministic are  and ,
 respectively.  Our algorithm gives better asymptotic bounds on the
 number of states and parity indices vis-a-vis the best known technique
 when determinizing Rabin or Streett automata with 
 acceptance pairs, where .  We demonstrate this by describing a
 family of Streett (and Rabin) automata with  non-redundant
 acceptance pairs, for which the best known determinization technique
 gives a DPW with at least  states, while our
 construction constructs a DRW/DPW with  states.
 An easy corollary of our construction is that an
   -language with Rabin index  cannot be recognized by any
   -automaton (deterministic or non-deterministic) with fewer
   than  states.
 \end{abstract}
 \begin{keyword}
-automata, determinization, infinity sets
 \end{keyword}

\maketitle
\section{Introduction}

The literature contains several interesting constructions for obtaining
deterministic Rabin/parity automata from nondeterministic -automata with
different accepting conditions \cite{buchi73, eilenberg74, choueka74, rabin72,
tb73, sch75, thomas81, emerson-sistla, safra, safra06, muller-schupp,
schewe-det, piterman, kaewil, colcombet}. However, all known constructions are
tailor-made to work for nondeterministic automata with a specific kind of
accepting condition. For example, Safra's celebrated B\"{u}chi determinization
construction~\cite{safra, safrathesis} can be used to convert non-deterministic
B\"{u}chi automata over words (NBW) to deterministic Rabin automata over words
(DRW).  Piterman showed that Safra's construction can be augmented with
additional machinery to obtain deterministic parity automata (DPW) over words
from NBW~\cite{piterman, liu-wang}.  It requires the use of a completely
different technique (once again, originally due to
Safra~\cite{safra-stoc92,safra06} and subsequently improved by
Piterman~\cite{piterman}) to convert non-deterministic Streett automata over
words (NSW) to equivalent DRW or DPW.  We are unaware of any construction for
directly converting non-deterministic M\"{u}ller automata over words (NMW) to
DRW or DPW.  A two-step approach would involve first converting an NMW to NBW,
and then using Safra's/Piterman's determinization construction for NBW to obtain
a DRW/DPW.  In this backdrop, we propose a uniform determinization construction
for all -automata for which the acceptance condition is based on
\emph{infinity sets}, i.e., the set of states visited infinitely often in a run
of the automaton.  It is worth noting that the acceptance conditions for all
important classes of -automata studied in the literature are based on
infinity sets.

We begin by quickly reviewing different acceptance conditions of
-automata used in the literature.  Let  be a (possibly non-deterministic) -automaton,
where  is the alphabet,  is the set of states,
 is the set of initial states,  is the transition relation, and  is the
acceptance condition.
An acceptance condition  based on infinity sets specifies properties of
the set of states visited infinitely often in an accepting run of the automaton.
Hence,  can be thought of as defining a predicate  over .
Formally, for every , we say  iff , viewed
as the infinity set of a run of , satisfies the properties specified by
. This is a re-statement of the fact that any -automaton with
acceptance condition based on infinity sets can be converted to a Muller
automaton by preserving the transition structure of the automaton and by listing
all subsets of states that satisfy  in the Muller acceptance set.  We list
below acceptance conditions of some important classes of -automata and
indicate the interpretation of  in each case.  In all cases, we assume
that  is a subset of .

\begin{itemize} 
\item {\buchi} condition :  is given by , and
   iff .

\item Muller condition :  is given by a collection , where  for all , and  iff .

\item Rabin condition :  is given by a table of pairs
  , where
   for all , and
   iff there exists an 
  such that  and .

\item Streett condition:  is given by a table of pairs, similar
  to that used for Rabin condition.  However, in this case  iff for all ,  whenever .

\item Parity condition:  is given by a sequence of sets
  , where  for all .  Here,  iff for some even number ,  and for all , .

\item Emerson-Lei condition~\cite{emersonlai}:  is given by a
  fairness condition, expressed as a Boolean combination  of
  special linear-time temporal logic formulae over atomic propositions
  labeling states of the -automaton.  The sub-formulae of 
  are such that their truth can be determined simply by knowing the
  set of sets visited infinitely often along a path (or run) of the
  automaton, and from the labels of these states.  Therefore,
   iff every run of the automaton with infinity set
   satisfies the temporal logic formula .
\end{itemize}
It follows from the above discussion that to determine if an
-word  is accepted by , it suffices to determine
the set of infinity sets for all runs of  on , and to
check if  evaluates to  for any of these infinity sets.
This observation forms the basis of our construction for determinizing
-automata with arbitrary acceptance conditions based on
infinity sets.

The primary contribution of this paper is a uniform construction for
converting -automata with arbitrary acceptance conditions
based on infinity sets to deterministic parity automata.  Given a
non-deterministic automaton with  states, our construction gives a
DPW with at most  states and  parity
indices.  The corresponding bounds when the original automaton is
deterministic are  and , respectively.  Our algorithm
gives better asymptotic bounds on the number of states and parity
indices vis-a-vis the best known technique when determinizing Rabin
or Streett automata with  acceptance pairs, where .  We demonstrate this by describing a family of Streett (and Rabin)
automata with  non-redundant acceptance pairs, for which the
best known determinization technique gives a DPW with at least
 states and  parity indices.  An easy corollary
  of our construction is that an -language with Rabin index
   cannot be recognized by any -automaton (deterministic or
  non-deterministic) with fewer than  states.

The remainder of this paper is organized as follows.
We begin by revisiting Schwoon's version of Safra's NSW determinization construction and
Piterman's optimization of it. We then describe our uniform construction for
determinization of -automata along with intuition behind the
construction and an example that demonstrates steps of the construction. We then
prove the correctness of our construction and compute its complexity. Finally,
we demonstrate the existence of a family of NSW for which our construction
provides better upper bounds for determinization than any of the existing
methods.



\section{Determinizing NSW: A Recap of Safra's and Piterman's Constructions}
\label{safransw}
Since our construction is obtained by adapting Safra's determinization
construction for NSW~\cite{safra-stoc92,safra06} and borrows some key
optimization ideas from Piterman's construction~\cite{piterman}, we
provide an overview of Safra's and Piterman's constructions below.
Additional details of Safra's construction can be found
in~\cite{safra-stoc92,safra06,2001automata}, and those of Piterman's
construction can be found in~\cite{piterman}.

Safra's determinization construction for NSW is based on the idea of
\emph{witness sets} and hierarchically related \emph{decompositions}.
Since we will use a different notion of witness sets later in the
paper, we will henceforth call witness sets as defined by Safra as
\emph{Streett Safra witness sets}.  For a Streett automaton , the acceptance condition  is
given by a Streett pairs table .  Let  be the set of indices of
Streett pairs in .  A subset  of  is called a
\emph{Streett Safra witness set} for a run  of  iff for
every , some state in  is visited infinitely often in
, and for every , no state in  is visited
infinitely often in .  It is easy to see that every accepting
run of  has at least one Streett Safra witness set, and any run
of  with a Streett Safra witness set is an accepting run.  Note,
however, that an accepting run of  can have multiple Streett Safra
witness sets.  The \emph{decompositions} used in Safra's construction
can be viewed as hierarchically related processes, each of which
tracks a subset of runs of  on a given word, and checks if a
certain subset of  is a Streett Safra witness set for all the tracked runs.
While Safra's original exposition~\cite{safra-stoc92,safra06}
represents the hierarchy between decompositions using the notion of
sub-decompositions, Schwoon's exposition of Safra's
construction~\cite{2001automata} explicitly represents the
hierarchical relation between decompositions as a tree.  Each node in
this tree represents a decomposition as defined by Safra, and children
of a node represent sub-decompositions in Safra's terminology.  We
will use the tree representation of decompositions, called -trees by Schwoon~\cite{2001automata}, in the following discussion
for clarity of exposition.

Following the definition given by Schwoon~\cite{2001automata}, a -tree over  is a finitely branching rooted tree with the
following properties.
\begin{itemize}
\item Every leaf node is labeled with a non-empty subset of 
  (states of the Streett automaton ).
\item State labels of leaf nodes are pairwise disjoint.
\item Every node is assigned a name from the set .
\item No two nodes have the same name.
\item Every edge is annotated with an element of .
\item No edge annotation other than  occurs more than once on any path from
  the root to a leaf.
\item Every non-leaf node has at least one child connected by an edge
  with a non-zero annotation.
\item The children of every node are ordered from left to right.
\end{itemize}


Every node  in a -tree can be thought of as being
associated with a Streett Safra witness set, , defined as
follows.  If  is the root node, then .  Otherwise, if  is the parent of  and if the edge from 
to  is annotated with , then .
Let  denote the set of Streett states labeling the leaves
of the sub-tree rooted at .  Thus, if  is a leaf node,
 is the state label of .  However, if  has children , then  itself does not have a state label but
 is the disjoint union of .  A node  in a -tree represents a
process that tracks the runs represented by states in ,
and checks if  is a Streett Safra witness set for all these
runs.  This is done by waiting until all  for  are
visited in order along the runs, without visiting any  for .  If this happens, the process represented by  is said
to have ``succeeded''; it is then ``reset'' and the check starts all
over again.  Clearly, if the process represented by  is reset
infinitely often, then  is a Streett Safra witness set for the
runs tracked by this process have, and hence these are accepting runs
of .  On the other hand, if some state in  for  is seen in a run being tracked by the process represented by
, then that run is removed from this process, and a new process is
started for that run.  The hierarchical relation between processes is
explicitly represented by the parent-child relation between nodes in a
-tree.  Intuitively, if  is the parent of  and if the
edge from  to  is annotated with , the process represented
by  tracks a subset of the runs tracked by  after giving up
hope that it will see a state from  ever in the future.  While
the parent  keeps alive the hope that  is the Streett Safra
witness set for all runs tracked by , the child  refines and
corrects that hope by expecting  to be
the Safra Streett witness set for the subset of runs tracked by .

The DRW obtained by applying Safra's construction to a Streett
automaton  is given by , where  is the set of all
-trees over , and  is a singleton set containing
the -tree consisting of only a root node with name  and
labeled with  (set of initial states of ).  Since  is a
deterministic automaton,  can be thought of as a function
that takes a state (i.e., -tree)  and a letter  and returns the next state (i.e., -tree) .  The
computation of  from  and  is detailed in algorithm
\algo{SafraNext} given below (adapted from Schwoon's
exposition~\cite{2001automata} and Piterman's
correction~\cite{piterman} of an erroneous step
in~\cite{safra06,2001automata}).  Note that algorithm \algo{SafraNext}
calls a recursive procedure \algo{SafraNextRecursive} that is
parameterized by the root node of a -sub-tree and the
corresponding Streett Safra witness set.  If  and ,
the Rabin acceptance condition  is given by a table
, where  is the set of all -trees with no
node named , and  is the set of all -trees in
which a leaf node named  occurs.


\algoblock{SafraNext}
{ -tree over ,~~  letter in }
{ -tree over } 
{
  \begin{enumerate}
  \item {\bfseries [Initialization]} For every leaf node  of ,
    set the state label of  to .
    
  \item {\bfseries [Recursive transformation]} Let  be
    the root node of .  \\Invoke 
    \algo{SafraNextRecursive}.

  \item Return  as the -tree rooted at .
\end{enumerate}
}

\algoblock{SafraNextRecursive}
{ root of a -sub-tree,~~  subset of }
{ Transformed -sub-tree rooted at }
{
  \begin{enumerate}
  \item \label{safra1} If  is a leaf and ,
    return  as the -sub-tree rooted at .
    
  \item \label{safra2} If  is a leaf and , create a
    new child  of  with state label , remove  from
    the state label of  (since  is no longer a leaf) and annotate the
    edge from  to  with .  Assign an unused name 
    from  to .
    
  \item \label{safra3} If, after the execution of Steps (\ref{safra1})
    and (\ref{safra2}),  is not a leaf, then let 
    be the children of  ordered from left to right.  Let the edge
    from  to  be annotated with  for all .
    
    \begin{enumerate}
      
    \item \label{safra3a} For all  from  to , invoke
      \algo{SafraNextRecursive}
      
    \item \label{safra3b} For every child  of  and every , do the following
      \begin{enumerate}
        
      \item \label{safra3b1} If , remove  from the
        state labels of all leaves of the sub-tree rooted at , create a
        new rightmost child  of  with state label , and
        annotate the edge from  to  with .  Assign an
        unused name from 
        to .
        
      \item \label{safra3b2} If , create a new
        rightmost child  of  with state label  and annotate
        the edge from  to  with .  In other words, the edge is
        annotated with the largest integer less than  but in ,
        if it exists.  Otherwise, it is annotated with .  Assign an
        unused name from 
        to .
        
      \end{enumerate}
      
    \end{enumerate}
    
  \item \label{safra4} Let  be the children
    of  after the above steps.  Let  be
    the annotations of the corresponding edges from  to its children.
    For every , where 
    and , do the following.
    \begin{enumerate}
      
    \item If , remove  from the state labels of all leaves of
      the sub-tree rooted at .
      
    \item If  and  is to the left of , remove  
      from the state labels of all leaves of the sub-tree rooted at .
      
    \end{enumerate} 
    
  \item \label{safra5} For every descendant  of  such that
    , delete  and all its descendants.
    
  \item \label{safra6} If, after the previous steps, all edges from
     to its children are annotated with , then the process
    represented by  has ``succeeded'' and needs to be ``reset''.
    Let .  Make  a leaf node by deleting all its
    children and their descendants, and set the state label of  to .
    
  \item \label{safra7} Return  as the -sub-tree rooted at .
  \end{enumerate}
}

It was shown by Safra that given an NSW with  and ,
the above construction gives a deterministic Rabin automaton with
 states and  Rabin
acceptance pairs.  Although a proof of correctness of the construction
was provided in~\cite{safra-stoc92,safra06,2001automata}, Piterman
pointed out a minor error in the construction and rectified it
in~\cite{piterman}.  Fortunately, Piterman's correction affects only a
single step of Safra's construction and does not change the asymptotic
count of states or Rabin acceptance pairs.  The fact that this
erroneous step evaded the scrutiny of researchers for almost 
years is testimony to the intricate nature of arguments used in
Safra's construction.  Piterman also proposed an adaptation of Safra's
construction that uses only  names (instead of  names used by Safra) and gives a deterministic parity
automaton with  states and
 parity indices.  Currently, Piterman's construction
is the best known determinization construction for NSW.

Piterman's adaptation of Safra's construction involves two key ideas:
(i) a new strategy for naming nodes, and (ii) addition of two
integer-valued components,  and , to every state of the
constructed automaton that allows a parity acceptance condition to be
defined.  In the new naming strategy, whenever a new node is created
in steps (\ref{safra2}), (\ref{safra3b1}) or (\ref{safra3b2}) of
algorithm \algo{SafraNextRecursive}, it is assigned the smallest name
larger than all names used so far in the construction of  from
.  In addition, after algorithm \algo{SafraNext} has finished
computing , a name-compaction step is performed.  In this step,
for each node  with name  in , we determine the count,
, of nodes that were removed during the construction
of  from  and had names less than .  The name of  is then
reduced from  to .  This ensures that there
are no gaps in the set of names assigned to nodes in a -tree
after the name-compaction step.  Piterman's naming strategy also
ensures that the name of a node  is less than that of node  iff
 was created before .  Since the name of a node that stays back
in a run (sequence of -trees) can only reduce finitely many
times, it follows that all nodes that eventually stay back in a run
get fixed names that are smaller than the names of all other nodes
that keep getting created and removed.

The new state components  and  in Piterman's construction keep
track of the smallest name of a node removed and the smallest name of
a node that represents a successful process (see step (\ref{safra6})
of algorithm \algo{SafraNextRecursive}) respectively in the
construction of  from .  A state in the resulting automaton is
therefore a -tree coupled with a pair of integers , with the restriction that the root
node is always named  and all nodes are assigned names from .  Piterman calls these states \emph{compact
  Streett Safra trees} over , and obtains a deterministic parity
automaton by defining a parity acceptance condition as follows.  Let
 denote the set of all compact Streett Safra trees over .
Piterman's parity acceptance condition is given by , where 
and s are defined as follows.
\begin{itemize}
\item  
\item ,
  for all 
\item , for
  all 
\end{itemize}
A proof of correctness of the above construction is given
in~\cite{piterman}.  It is also shown there that the DPW obtained
using this construction has at most  states and 
parity indices.


\section{A uniform determinization construction for -automata}

We now describe a construction for converting -automata with
arbitrary acceptance conditions based on infinity sets to
deterministic parity automata.  Our construction can be viewed as an
adaptation of Safra's NSW determinization construction that works for
arbitrary acceptance conditions.  As part of our construction, we use
Piterman's naming strategy and his idea of using  components of
states to get a parity acceptance condition.  Interestingly, although
our construction is based on Safra's and Piterman's constructions, we
are able to sharpen the asymptotic upper bound for Streett and Rabin
determinization beyond those obtainable by Safra's and Piterman's
constructions.

Let  be an -automaton,
where  is an arbitrary acceptance condition based on infinity
sets.  Let  denote the predicate corresponding to .
Without loss of generality, we will assume that , where . For notational clarity, we will
henceforth refer to states of  as -states, and use  to
denote the set  for every natural number .
For every , we also define  to be the set .

Motivated by the role played by Streett Safra witness sets in Safra's
NSW determinization construction, we now define \emph{generalized
  witness sets} for -automata with arbitrary acceptance
conditions based on infinity sets.
\begin{definition}[Generalized Witness Set]
A set  is a generalized witness set for a run 
of  iff  and .
\end{definition}
Note that Streett Safra witness sets are distinct from generalized
witness sets even when  is a Streett automaton.  By definition, a
Streett Safra witness set is a subset of indices of Streett acceptance
pairs, while a generalized witness set is a subset of indices of
-states.  Thus, if  has  states and  pairs in its
acceptance table, and if  (examples of NSW with this property
are given in Section~\ref{sec:large-acc-sets}), there can be many more
Streett Safra witness sets than generalized witness sets. The
situation is reversed if .  It follows from the definition
above that a run  of  can have at most one generalized
witness set, although it may have multiple Streett Safra witness sets.
Furthermore, the generalized witness set of  uniquely determines
, while a Streett Safra witness set for  does not
necessarily determine  uniquely.  Finally, if  is a
Streett automaton and if a run  of  has a generalized
witness set, then it has at least one (and perhaps more) Streett Safra
witness sets.  Conversely, if  has at least one Streett Safra
witness sets, then it has exactly one generalized witness set.

The use of generalized witness sets allows us to adapt Safra's
construction to obtain a uniform determinization construction for
-automata with arbitrary acceptance conditions.  We detail
this construction in the following subsections.

\subsection{Intuition}
\label{sec:intuition}
The intuition behind our construction parallels that behind Safra's
NSW determinization construction, with some key differences stemming
from the use of generalized witness sets instead of Streett Safra
witness sets.  The overall idea is to construct a deterministic
automaton that simulates all runs of  on an -word
, and uses a Rabin acceptance condition to simultaneously
identify the set of state indices in the -set of a run and
check if this set is a generalized witness set. The construction of
the Rabin automaton can be adapted to give a deterministic parity
automaton using techniques employed by Piterman~\cite{piterman}.
Although there are an exponential number of potential generalized
witness sets, we use Safra's idea of building a process decomposition
(represented as a tree), in which each process tracks a subset of runs
and checks if a given subset of -state indices is a generalized
witness set for these runs.  Using the same reasoning as used by
Safra, we can show that only a polynomial number of generalized
witness sets need to be examined at any time in order to determine if
a run has a generalized witness set.

As in Safra's and Piterman's
constructions~\cite{safra-stoc92,safra06,2001automata,piterman}, each
state of the DPW obtained by our construction is a tree of
hierarchically related processes, with additional book-keeping
information. The process represented by a node in the tree tracks a
subset of runs of the automaton .  Each process is also
associated with a set of indices of -states, called the
\emph{hope set} for the process.  A process hopes that its hope set
gives the indices of states in the -set of all runs tracked by
it.  This is checked by waiting for all states with indices in the
hope set to be visited in turn by every run tracked by the process,
without visiting any state with index outside the hope set.  If this
happens, the process is said to have ``succeeded'' locally; it is then
``reset'' and the check starts all over again.  Clearly, if the
process represented by a node  is reset infinitely often, its hope
set gives the indices of states in the -set of all runs
tracked by it.  If, in addition, the set of states with indices in the
hope set causes  to evaluate to \true, the hope set must be a
generalized witness set of all runs tracked by the process.  In this
case, there exists at least one accepting run of  on the input
word.  On the other hand, if some state with an index outside the hope
set is seen in a run tracked by a process, the corresponding run is
removed from the process, and a new process is initiated for that run.
As in Safra's and Piterman's constructions, we use an acceptance
condition that checks for the existence of a node  that is
eventually never deleted in the sequence of trees (states) in an
infinite run of the constructed automaton, but is reset infinitely
often.  Unlike Safra's and Piterman's construction, we also require
that the hope set of the process corresponding to node  be such
that the corresponding set of -states renders  \true.  In
the remainder of the discussion, we will refer to a node and the
process represented by it interchangeably when there is no confusion.


\subsection{The determinization construction}
\label{sec:inf-set}

Piterman used compact Streett Safra trees to represent states of the
deterministic parity automaton in his NSW determinization
construction~\cite{piterman}.  We follow the same approach and use a
variant of compact Streett Safra trees, called compact generalized
Safra trees, or \CGS trees.  Formally, a \CGS tree  over  is a -tuple , where
\begin{itemize}

\item   is the set of nodes.

\item  is the naming function.

\item  is the root node.

\item  is the parenthood function defined for .  Thus,  is the parent of .


\item  is a state labeling function that
  associates a subset of  with each node.  The state label of every
  node is equal to the union of state labels of its
  children. Furthermore, the state labels of two siblings are
  disjoint.

\item  is an annotation of nodes with a
  subset of .  The root is always annotated with . The
  annotation of every node is contained in that of its parent and
  differs by atmost one element from the annotation of its parent. Every
  non-leaf node  has at least one child with an annotation that is
  a strict subset of .  For a node  with annotation  and
  child  with annotation , we will say
  that the edge from  to  is annotated with .  If ,
  we will say that the edge from  to  is annotated with .

\item  are two integers used to define the
  parity acceptance condition.
\end{itemize}
Note that \CGS trees differ from compact Streett Safra
trees~\cite{piterman} only in the annotation of nodes.  In a compact
Streett Safra tree, each node is annotated with a potential Streett
Safra witness set, while in a \CGS tree, the annotations are potential
generalized witness sets.  As discussed earlier, generalized witness
sets can differ significantly from Streett Safra witness sets even
when  is a Streett automaton.  Intuitively, each node  in a
compact generalized Safra tree represents a process that tracks the
runs of  currently represented by , and hopes that
 is the -set of these runs.  The set  may
therefore be viewed as the hope set for the process represented by
.

Given , we now construct a
deterministic parity automaton (DPW)  such that .  In the following, we
assume that  and .  The different components of
 are as defined below.
\begin{itemize}
\item  is the set of all \CGS trees over .
  
\item  is the \CGS tree with a single (root) node , with
  ,  and . For , we
  set .
  
\item The parity acceptance condition  is defined in the same manner as done by
  Piterman~\cite{piterman}.  Specifically,
  \begin{itemize}
    
  \item 
    
  \item  for 
    
  \item  for 
    
  \item 
    
  \end{itemize}
  \noindent For reasons to be seen later, no \CGS tree that arises
  in our construction can have ; hence \CGS trees with 
  are excluded from the  sets defined above.
  
\item  is a deterministic transition function that returns a
  unique next state (\CGS tree)  for every current state 
  and input symbol .  The computation of  from
   and  is accomplished by invoking algorithm
  \algo{GeneralizedNext}, as detailed below.
\end{itemize}



Recall that a \CGS tree has named, state-labeled and annotated nodes
hierarchically arranged as a rooted tree, along with two integer
valued components named  and .  Computing  from  and
 therefore involves transforming the hierarchical arrangement
of nodes and determining new values for  and , in general.
Component  of  is intended to record the smallest name of a
node that was deleted during the transformation of the hierarchical
arrangement.  Similarly, component  is meant to record the smallest
name of a node that was ``reset'' (in the sense described in
Section~\ref{sec:intuition}), had a hope set such that the
corresponding set of  states satisfies , and was not
deleted subsequently during the transformation of the hierarchical
arrangement.  Since a node can be deleted in a step after being reset,
algorithm \algo{GeneralizedNext} uses a set  to remember all nodes
that were reset and had hope sets such that the corresponding set of
 states satisfies , in some step during the
transformation.  Finally, component  is set to the smallest name of
a node in  that survives the transformation.  The task of
transforming the hierarchical arrangement of nodes is accomplished by
invoking algorithm \algo{GeneralizedNextRecursive}, as described
below.  As the transformation proceeds through recursive calls to
\algo{GeneralizedNextRecursive} and nodes are reset and/or deleted
from the \CGS tree, component  and the set  described above are
updated.  After the transformation of the hierarchical arrangement is
completed, a name-compaction step is performed on the nodes of the
resulting \CGS tree in the same way as is done in~\cite{piterman}.
Although intermediate steps of algorithm
\algo{GeneralizedNextRecursive} may use names of nodes outside the set
, the name-compaction step ensures that all names used in the
final \CGS tree  are within . The pseudocode of algorithms
\algo{GeneralizedNext} and \algo{GeneralizedNextRecursive} are
presented below.

\algoblock{GeneralizedNext}
{ \CGS tree over , ~~  letter in }
{ \CGS tree over }
{
  \begin{enumerate}

  \item \label{Nxt1} {\bfseries [Initialization]} Initialize  and
     to .  Initialize  to . For every node 
    in , set  to .
    
  \item \label{Nxt2} {\bfseries [Recursive transformation]} Let
     be the root node of .  \\Invoke 
    \algo{GeneralizedNextRecursive}.
    
  \item \label{Nxt3} {\bfseries [Name-compaction]} Let 
    be the \CGS tree rooted at  after Step
    (\ref{Nxt2}).  Let  be the set of \CGS tree nodes removed
    during the execution of Step (\ref{Nxt2}).  For every node  in
    , let  .  Update  to .


  \item \label{Nxt4} {\bfseries [Updation of component ]} Let
     be the \CGS tree rooted at  that
    results after Step (\ref{Nxt3}).  Let  be the set
    of nodes in .  Set  to the minimum of its
    current value and .
  
  \item Return  as the \CGS tree rooted at  with
     and  components as calculated above.
  \end{enumerate}
}

\algoblock{GeneralizedNextRecursive}
{ root of a \CGS sub-tree}
{ Transformed \CGS sub-tree rooted at , updated values of  and }
{
  \begin{enumerate}

  \item \label{GNR1} If  is a leaf and ,
    return  as the \CGS sub-tree rooted at .
    
  \item \label{GNR2} If  is a leaf and , create a
    new child  of .  Set ,  and  to the smallest name
    greater than all names already used.  Note that this may require
    using names not in .
    
  \item \label{GNR3} If, after the execution of Steps (\ref{GNR1}) and
    (\ref{GNR2}),  is not a leaf, then let  be the
    children of  ordered according to their names.  Let  be indices such that  \footnote{Note that if ,
      then .}.  As discussed earlier (in the definition of
    compact generalized Safra trees), we will say that the edge from
     to  is annotated with .
    
    \begin{enumerate}
      
    \item \label{GNR31} For all  in  through , invoke \algo{GeneralizedNextRecursive}
      


    \item \label{GNR32} For every child  of  and every , do
      the following. 
      
      \begin{enumerate}
        
      \item \label{GNR3a} If  then 
create a new child  of .\\  Set ,
        .  The edge from  to  is
        thus annotated with the largest integer smaller
        than  but in , if it exists.  Otherwise, the edge
        is annotated with .  Set  to the smallest
        name greater than all names already used.
        
      \item \label{GNR3b} If  and , remove  from
         and also from  for all descendants
         of .



      \end{enumerate}
      
      
    \end{enumerate}
    
    
  \item \label{GNR4} Let  be the children of
     after the above steps. Let  be the
    annotations of the corresponding edges from  to its children.
    In other words, let  for . Then for every , where  and , do the following.
    
    \begin{enumerate}
    \item If , remove  from  and from
       for all descendants  of .
      
    \item If  and , remove  from
       and from  for all descendants 
      of .
      
    \end{enumerate}
    
  \item \label{GNR5} For every descendant  of  such that
    , delete  and all its descendants.


  \item \label{GNR6} If, after the previous steps, all children of 
    have annotation , then the process represented by  is
    said to ``succeed'' locally and needs to be ``reset''.  Delete all
    descendants of , so that  becomes a leaf node.
    Additionally, if , then update  to .
    
  \item \label{GNR7} Update  to the minimum of its previous value and
    the smallest name among all descendants of  that were deleted.

  \item \label{GNR8} Return  as the \CGS sub-tree rooted at .
    


  \end{enumerate}
}

The similarity of algorithms \algo{GeneralizedNext} and
\algo{GeneralizedNextRecursive} to the corresponding algorithms in
Safra's and Piterman's NSW determinization constructions is striking.
Yet, there are important differences that enable our construction to
achieve something different, and even better Safra's and Piterman's
constructions when the number of Streett pairs is large compared to
the number of Streett states.

The computation of  starts by determining the
successors of all -states appearing in state labels of nodes in the
\CGS tree , under the input symbol .  Algorithm
\algo{GeneralizedNextRecursive} is then invoked on the resulting tree
rooted at .  This recursively ``extends'' the tree (in
Steps (\ref{GNR1}), (\ref{GNR2}) and the recursive call in Step
(\ref{GNR3}) of algorithm \algo{GeneralizedNextRecursive}) by adding
new leaf nodes with successively smaller hope sets until each leaf
node has an empty hope set.  As the recursive calls return, algorithm
\algo{GeneralizedNextRecursive}) determines in a bottom-up manner
which nodes in the extended \CGS tree must have their hope sets
invalidated and/or hierarchical relations modified.  We explain below
the reasoning behind this crucial step in the computation of .


Suppose the hope set of a node  is  and that of its child
 is .  Suppose further that the edge from  to  is
annotated with , i.e., .  This
represents a situation wherein the process represented by  is
waiting to see  in the subset of runs being tracked by its
child , but the process represented by  has given up hope of
seeing any further 's in the runs it is tracking.  Now,
suppose after reading an input symbol , the initialization
step of algorithm \algo{GeneralizedNext} places  in
 (and hence also in ).  This implies that
 has seen a state along a run it was tracking, such that the
corresponding state index is outside its own hope set but is in the
hope set of its parent.  Since every node expects to see all and only
states with indices in its hope set in all runs being tracked by it,
the above situation warrants two actions: (i)~invalidating the hope
set of  for the run represented by , and
(ii)~registering progress towards the realization of 's hope set as
the set of state indices in the -set of the run represented by
.  Accordingly,  is removed from  by
the sequence of steps~\ref{GNR3a} and \ref{GNR4} of algorithm
\algo{GeneralizedNextRecursive}.  In addition, step~\ref{GNR3a}
creates a new child  of  with , and
annotates the edge from  to  with the next index (after 
in decreasing order), say , in the hope set of .  This
represents the new situation wherein the process represented by 
has seen  and is waiting to see the next -state in its
hope set, i.e. , in the run (currently) represented by
.  The new child  however hopes to see no further
's in the run represented by ; hence its hope set is
set to .  A special situation arises if
 is the lowest indexed -state in .  In this
case, node  has seen all states with indices in its hope set in the
run represented by  since the last time  was ``reset''.
The edge from  to  is annotated with a special index, i.e. ,
to represent this situation.  The newly created child  retains the
same hope set as , i.e. , and is now delegated the task of
checking if  is the - set of the run currently
represented by .  Meanwhile, the parent node  continues to
check if all states with indices in its hope set, i.e. , are
seen in the \emph{remaining} runs (other than the one currently
represented by ) that it was tracking.

A different situation arises if the initialization step of
algorithm \algo{GeneralizedNext} places  in 
for a child  of , but  is neither the annotation of the
edge from  to , nor is in the hope set of .  This
represents a situation wherein the process represented by  was
waiting to see some -state other than  next in the runs
being tracked by , and the process represented by  was
expecting to never see  in any run being tracked by it.
Since  is in , the hope set of  must be
invalidated for the run currently represented by .  This is
done in step~\ref{GNR3b} of algorithm \algo{GeneralizedNextRecursive}
by removing  from the state label of  and all its descendants.
Note, however, that we cannot remove the run represented by 
from the state label of  yet.  Although  was not expecting 
to be the \emph{next} -state in the runs being tracked by ,
the hope set of  may still contain .  Therefore, the hope set
of  need not be invalidated yet for the run corresponding to
.  As the recursive calls to algorithm
\algo{GeneralizedNextRecursive} return, the hope set of  will be
examined in turn to determine if a run being tracked by  has
encountered a state with index outside 's hope set.  If so, the run
will then be removed from the set of runs being tracked by .
 
Since runs tracked by different nodes in a \CGS tree may merge, we may
encounter a situation wherein the same -state  appears in the
state labels of multiple nodes that are not related as ancestors or
descendants in the tree.  However, by definition, two nodes in a \CGS
tree can have overlapping state labels only if one is an ancestor (or
descendant) of the other.  Algorithm \algo{GeneralizedNextRecursive}
rectifies this situation by ensuring that whenever an -state 
appears in the state labels of multiple children of a node , at most one
child eventually gets to retain  in its state label.  The chosen child is
the one that represents the maximum progress (since  was last
reset) towards realisation of the hope set of  as the set of state
indices in the -set of the run represented by .  This choice
can be made by examining the annotations on the edges from  to the
subset of its children containing  in their state labels.  Specifically,
the child that represents the most progress is the one that has the
smallest annotation on the edge from .  This is because a child
with an edge from  annotated with  represents the situation
wherein all -states with indices greater than  and in the hope
set of  have been seen since  was last reset.  In the event that
an -state  appears in the state labels of two siblings with the same
annotation on the edges from their parent, we choose to retain  in
the state label of the node that was created earlier, i.e. has a smaller
name.  As the recursive calls to algorithm
\algo{GeneralizedNextRecursive} return, step~\ref{GNR4} examines the
nodes of the \CGS tree in a bottom-up manner and applies the above
criterion to ensure that two nodes not related as ancestor and
descendant do not share any -state in their state labels in the final
tree.

Step~\ref{GNR5} of algorithm \algo{GeneralizedNextRecursive} deletes
all nodes with empty state labels from the \CGS tree constructed thus far,
since the processes represented by these nodes no longer track any
runs.  In Step~\ref{GNR6}, we examine the annotations on the edges to
all children of the current node .  If these annotations are all
, we have a situation wherein all runs being tracked by  have
seen all states with indices in 's hope set since the last time 
was reset.  This constitutes a step of progress in establishing that
the hope set of  is indeed the set of state indices in the
\infi-set of all runs being tracked by it.  Node  is therefore said
to have ``succeeded'' locally, and is ``reset'' in step~\ref{GNR6} of
algorithm \algo{GeneralizedNextRecursive} by deleting all its
descendants. If, in addition,  then we have a
step of progress in establishing that  is the generalized
Safra witness set of all runs being tracked by .  Step~\ref{GNR6}
of algorithm \algo{GeneralizedNextRecursive} keeps track of this fact
by updating the set .  As explained earlier,  is eventually used
to obtain the value of component  of the \CGS tree .  Finally,
step~\ref{GNR7} of algorithm \algo{GeneralizedNextRecursive} updates
component  of  by recording the smallest name of a node deleted
in the recursive transformation of the \CGS tree.

\subsection{An Example}
\label{sec:inf-set-example}
We now illustrate the working of our determinization construction
using the non-determinisic M\"{u}ller automaton (NMW)  shown in
Figure (\ref{infset1}).  The M\"{u}ller acceptance condition of this
automaton is given by .
\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.6]{infset1.eps}
\end{center}
\caption{Example non-deterministic Muller automaton}
\label{infset1}
\end{figure}
Let  be the corresponding deterministic parity automaton obtained
by our construction.  To see how different states and transitions in
 are obtained, we will follow the construction of states
encountered in  on reading a short prefix of the word
 that is accepted by .  Since  has  states,
we have  and .  Thus, every node in the
\CGS tree representing a state of  has a name in , and a
hope set that is a subset of .  Every edge in the tree is
annotated with an element of .  Since the hope set
of the root node is always , and since the hope set of any other
node  can be obtained by eliminating from  the annotations of
edges on the path from the root to , we will simply annotate edges
with elements of  and not explicitly represent hope sets.
Similarly, since the state label of every node is the union of the
state labels of its children, we will simply label leaves of the \CGS
tree with subsets of -states.  To help illustrate the
intermediate steps of the construction, we will also indicate the
updated values of  and  (components of the \CGS tree) in the
following discussion.
\begin{figure}[ht]
\begin{minipage}[b]{0.48\linewidth}
\begin{center}
\includegraphics[scale=0.63]{infset2.eps}
\end{center}
\label{infset2}
\end{minipage}
\hspace{5mm}
\begin{minipage}[b]{0.48\linewidth}
\begin{center}
\includegraphics[scale=0.63]{infset3.eps}
\end{center}
\label{infset3}
\end{minipage}
\caption{Steps in determinization construction}
\label{infset23}
\end{figure}

\begin{figure}[ht]
\begin{minipage}[t]{0.6\linewidth}
\vspace{0pt}
\begin{center}
\includegraphics[scale=0.63]{infset4.eps}
\end{center}
\label{infset4}
\end{minipage}
\begin{minipage}[t]{0.4\linewidth}
\vspace{0pt}
\begin{center}
\includegraphics[scale=0.63]{infset6.eps}
\end{center}
\end{minipage}
\caption{Steps in determinization construction}
\label{infset45}
\end{figure}

We start in the initial state consisting of a \CGS tree having a
single node named  and labeled , as shown in Figure
(\ref{infset23}-).  The values of  and  are both  in this state.  On reading the letter , the state label of the
node named  (also a leaf in this case) is first changed to
, since  transitions to  on reading  in
automaton .  The \CGS tree consisting of only the root node is
then extended in Steps (\ref{GNR1}), (\ref{GNR2}) and through the
recursion in Step (\ref{GNR31}) of algorithm
\algo{GeneralizedNextRecursive} to give the tree shown in Figure
(\ref{infset23}-).  As the recursive calls return in sequence,
all nodes other than the ones named  and  are deleted.  When the
recursion returns to the topmost level with the root named  as the
current node , the condition in Step (\ref{GNR3a}) of algorithm
\algo{GeneralizedNextRecursive} is satisfied.  Consequently, a new
node named  is created as a child of the root, and assigned the
state label .  The edge from the root to this child is
annotated with , as shown in Figure (\ref{infset23}-).
Subsequently, Step (\ref{GNR4}) of algorithm
\algo{GeneralizedNextRecursive} removes  from the state label of
the leaf named  in Figure (\ref{infset23}-).  This is because
the annotation of the edge from the root to this node is larger than
that of the edge from the root to its sibling having the same
-state, , in its state label.  Removing  from its state
label causes the leaf named  in Figure (\ref{infset23}-) to
acquire an empty state label; hence this node is deleted in Step
(\ref{GNR5}) of algorithm \algo{GeneralizedNextRecursive}.  This gives
a tree with only two nodes -- a root named  and a leaf named 
with state label .  The condition in Step (\ref{GNR6}) is not
satisfied; hence no nodes are ``reset'' and  continues to be the
empty set.  In Step (\ref{GNR7}), the component  finally acquires
the value , since that is the smallest name of a node that is
deleted.  Once we return from algorithm
\algo{GeneralizedNextRecursive} to algorithm \algo{GeneralizedNext},
the name-compaction step assigns the name  to the leaf node that
was named  earlier.  Since no node is reset and the set  is
empty, the updated value of the component  remains at .  The
resulting \CGS tree obtained after reading the first  from the
input word is shown in Figure (\ref{infset23}-).

On reading the next , a sequence of transformations similar to that
described above results in a \CGS tree with a root named  and a
leaf named  with state label  and edge annotation .  Here
too, the component  acquires the value  and  remains empty,
causing  to have the value .  Figures (\ref{infset23}-) to
(\ref{infset23}-) illustrate the steps in the construction of
this \CGS tree.

When the third  in the input word is read, the tree in Figure
(\ref{infset23}-) is extended in Steps (\ref{GNR1}), (\ref{GNR2})
and through the recursion in Step (\ref{GNR31}) of algorithm
\algo{GeneralizedNextRecursive} to give the tree shown in Figure
(\ref{infset45}-) sans the nodes named  and .  As the
recursive calls to algorithm \algo{GeneralizedNextRecursive} return in
sequence, Step (\ref{GNR3a}) creates two new leaf nodes (albeit in
different recursive calls) named  and , with state labels
 and  respectively.  The edges from the respective
parents to the new leaves named  and  are annotated  and ,
respectively.  The resulting tree is as shown in Figure
(\ref{infset45}-), except that the node named  no longer has
 or  in its state label.  In fact, Step (\ref{GNR4}) of
algorithm \algo{GeneralizedNextRecursive} removes both  and 
(once again, in different recursive calls) from the state label of
this node, leaving it with an empty state label.  Subsequently, this
node is removed in Step (\ref{GNR5}), giving the intermediate \CGS
tree shown in Figure (\ref{infset45}-).  Observe that the node
named  in this tree has the edge to its sole child annotated .
Therefore, this node is ``reset'' in Step (\ref{GNR6}) of algorithm
\algo{GeneralizedNextRecursive} and the child named  is deleted.
Additionally, since the hope set for the node named  in Figure
(\ref{infset45}-) is , and since , we have
.  Therefore,  is added to the set  in
Step (\ref{GNR6}) of algorithm \algo{GeneralizedNextRecursive}.  Since
the smallest name of a node that is deleted is , component 
finally acquires the value  in Step (\ref{GNR7}).  Once we return
to algorithm \algo{GeneralizedNext}, the name-compaction step renames
the leaf node named  to , as shown in Figure
(\ref{infset45}-).  The value of  is updated to .  The final \CGS tree obtained after reading  is shown in
Figure (\ref{infset45}-).  Figures (\ref{infset45}-) and
(\ref{infset45}-) show the final \CGS trees (states) obtained after
reading  and  respectively.  For all subsequent 's
that are read from the input word, the \CGS tree in Figure
(\ref{infset45}-) is obtained.  Therefore, the automaton 
loops infinitely in the state represented by Figure
(\ref{infset45}-) after reading .  Note that nodes named 
and  are deleted only finitely often but appear as leaves
infinitely often in the sequence of \CGS trees (states) visited on
reading the word .  Interestingly, the hope sets of the
nodes named  and  in Figure (\ref{infset45}-) are precisely
the -sets of the runs of  on the word .  As
we will see subsequently, this is not a coincidence, but a consequence
of our construction.

Let  be the set of all \CGS tree over .  The parity acceptance
condition for automaton  is , where ,
 for ,
 for , and
.  If we let  denote the run
of  on the word , then clearly , while  for
.  Therefore,  is accepted by .



\section{Proof of Correctness}

Let  be an -automaton
with acceptance condition based on infinity sets, and let  be the
corresponding DPW obtained by our construction.  Let  be an -word, and let  be the unique run of  on .  Here,  is the state (tree)
of  reached after reading the prefix  of
.

We will first show that if  is a \CGS tree, as defined in Section
(\ref{sec:inf-set}), then every , for , in  is
also a \CGS tree.  From algorithms \algo{GeneralizedNext} and
\algo{GeneralizedNextRecursive}, it is easy to see that if  is a
rooted tree with nodes labeled by subsets of  and annotated with
subsets of , then so is , for all .  Since
 and  are initialized to  and
subsequently updated to the smaller of their respective current value
and the name of a node in , it follows that  and
 are always in .  Given these observations, it
suffices to show the following three additional properties of
 in order to establish that  is indeed a \CGS tree.
\begin{enumerate}
\item \emph{There are no more than  nodes in
  .}  Since the name-compaction step of algorithm
  \algo{GeneralizedNext} ensures the absence of gaps in the set of
  names eventually assigned to nodes of , proving the above
  property guarantees that the range of the naming function 
  is indeed .  We will defer the proof of this
  property to Section (\ref{sec:inf-set-size}).
\item \emph{The (hope-set) annotation of every node in  is
  contained in the annotation of its parent, and differs by atmost one
  element from that of its parent.  In addition, every non-leaf node
   in  has at least one child with an annotation that is a
  strict subset of }.  The first property is proved in Lemma
  (\ref{lemmaD}) below.  The second property is a consequence of Lemma
  (\ref{lemmaD}) and Step (\ref{GNR6}) of algorithm
  \algo{GeneralizedNextRecursive}.
\item \emph{The state label of every node in  is the union of
  state labels of its children in .  In addition, the state
  labels of sibling nodes in  are mutually disjoint.}  We will
  prove the first property in Lemma (\ref{lemmaC}) below.  The second
  property is a consequence of Step (\ref{GNR4}) of algorithm
  \algo{GeneralizedNextRecursive} and the fact that no step of
  algorithm \algo{GeneralizedNextRecursive} adds any element to an
  already existing state label of a node.
\end{enumerate}

\begin{lemma}
\label{lemmaD}
For every  and for every node  and its child  in
,  and .
\end{lemma}
\noindent {\bf Proof: } We will prove the lemma by induction on the
indices of .

\noindent \emph{Base Case:} For the tree  with only the root node
, the claim in the lemma holds vacuously since there are no nodes
with children in .

\noindent \emph{Hypothesis:} We assume that the claim in the lemma
holds for , where .

\noindent \emph{Induction:} Consider the tree  obtained by
applying algorithm \algo{GeneralizedNext} to .  From the
pseudocode of algorithms \algo{GeneralizedNext} and
\algo{GeneralizedNextRecursive}, we observe that the hope set of a
node in  can be updated only in Step (\ref{GNR2}) or Step
(\ref{GNR3a}) of algorithm \algo{GeneralizedNextRecursive}.  In both
these steps, the node whose hope set is updated is a newly created
node that is added as a child of the current node.

Now let  be an arbitrary node in .  We consider two
cases below.
\begin{itemize}
\item Suppose .  Thus,  was present in
   and was not deleted in the process of transforming  to
  .  Since deletion of a node (Step (\ref{GNR5} or Step
  (\ref{GNR6}) of algorithm \algo{GeneralizedNextRecursive}) entails
  deletion of all descendants of the node as well, the fact that 
  was not deleted implies that no ancestor of  was deleted either
  in the process of transforming  to .  Thus, both 
  and its parent, say , in  were present in , and
  neither of them was newly created in Step
  (\ref{GNR2}) or Step (\ref{GNR3a}) of algorithm
  \algo{GeneralizedNextRecursive} during the transformation of 
  to .  Hence,  and .  By the induction hypothesis, we already know that
   and .
  The inductive claim now follows immediately.
  
\item Suppose  was newly created in the process of transforming
   to .  Since new nodes can be created only in Step
  (\ref{GNR2}) or Step (\ref{GNR3a}) of the recursive algorithm
  \algo{GeneralizedNextRecursive},  must have been created in one
  of these steps.  From the pseudocode of algorithm
  \algo{GeneralizedNextRecursive}, it is easy to see that both these
  steps set  to , where  is
  the parent of  in  and .  It
    follows that  and .
\end{itemize}

Therefore, by the principle of mathematical induction, the claim in
the lemma holds for all , where . \qed

\begin{lemma}
\label{lemmaC}
For every  and for every non-leaf node  in ,
, where .
\end{lemma}
\noindent {\bf Proof: }
We will prove the lemma by induction on the indices of .

\noindent \emph{Base Case:} For the tree  with only the root node
, the claim in the lemma holds vacuously since there are no
non-leaf nodes in .

\noindent \emph{Hypothesis:} We assume that the claim in the lemma
holds for , where .

\noindent \emph{Induction:} Consider the tree  obtained by
applying algorithm \algo{GeneralizedNext} to .  Since the claim
in the lemma holds for  (by induction hypothesis), and since the
initialization step of algorithm \algo{GeneralizedNext} replaces the
state label of every node  with , it
follows that the state label of every non-leaf node continues to be
the union of state labels of its children even after the
initialization step.  Since no nodes are added or deleted, and the
state labels of no nodes are changed in Steps (\ref{Nxt3}) and
(\ref{Nxt4}) of algorithm \algo{GeneralizedNext} (i.e., during
name-compaction and updation of component ), the inductive claim
can be proved by establishing that Step (\ref{Nxt2}) of algorithm
\algo{GeneralizedNext} does not violate the claim.  This amounts to
showing that algorithm \algo{GeneralizedNextRecursive} preserves the
property that the state label of every node is the union of state
labels of its children.  We therefore focus on the steps of algorithm
\algo{GeneralizedNextRecursive} below.

Clearly, Step (\ref{GNR1}) of algorithm
\algo{GeneralizedNextRecursive} preserves the desired property.
Although Step (\ref{GNR2}) results in the creation of a new child 
of , the desired property is preserved, since the state label of
 is set to that of .  In Step (\ref{GNR3a}), new children may
be created for , but the union of state labels of children of 
remains unchanged.  This is because for every new child  that is
created, Step (\ref{GNR3a}) sets the state label of  to ,
where  is in the state label of an already existing child of .
Step (\ref{GNR3b}) presents a more interesting situation.  Let 
be a child of  such that the annotation on the edge from  to
 is .  From Lemma (\ref{lemmaD}) and from the definition of
edge annotations, we know that .  If a state  in the state label of  is such that  and , Step (\ref{GNR3b}) of
algorithm \algo{GeneralizedNextRecursive} removes  from the state
label of  and from the state labels of all its descendants.  This
can give rise to a situation wherein  is in the state label of 
(parent of ) but not in the state label of any child of ,
potentially violating the property that the state label of every node
is the union of state labels of its children. However, such a
violation is only temporary and is rectified by the time the recursion
of algorithm \algo{GeneralizedNextRecursive} terminates.  To see why
this is so, notice that since  and , we must have .  Hence, when the recursion of
algorithm \algo{GeneralizedNextRecursive} returns to the level where
the current node is the parent  of node  in , we have
two possibilities.
\begin{enumerate}
\item Suppose , where  is the annotation of the edge
  from  to  in .  In this case, Step (\ref{GNR3a}) of
  algorithm \algo{GeneralizedNextRecursive} creates a new child 
  of  with state label , and with an edge annotation that is
  smaller than .  This eventually causes  to be removed from the
  state label of  in Step (\ref{GNR3a}) of algorithm
  \algo{GeneralizedNextRecursive}.

\item Suppose , where  is the annotation of the edge
  from  to  in .  Since  as
  well, Step (\ref{GNR3b}) of algorithm
  \algo{GeneralizedNextRecursive} removes  from the state label of
  .
\end{enumerate}
Therefore, if  is removed from the state label of a child  of
 by Step (\ref{GNR3b}) of algorithm
\algo{GeneralizedNextRecursive}, then it is also eventually removed
from the state label of .  This ensures that the desired property
of the state label of a node being the union of state labels of its
children is eventually preserved.  Step (\ref{GNR4}) of algorithm
\algo{GeneralizedNextRecursive} can remove a state  from the state
label of a node, but only if  is also present in the state label of
a sibling node.  Hence, Step (\ref{GNR4}) cannot change the union of
state labels of children of a node.  Step (\ref{GNR5}) deletes nodes
with an already empty state label, while Steps (\ref{GNR6}) and (\ref{GNR7})
do not modify the state label of any node.  Step (\ref{GNR6}) can
cause a non-leaf node to turn into a leaf node, but this does not
affect the desired property, which relates only to non-leaf nodes.

Thus, if algorithm \algo{GeneralizedNextRecursive} is invoked on a
tree in which the state label of every node is the union of state
labels of its children, the algorithm preserves this property after it
has transformed the tree recursively.  This, coupled with the
inductive hypothesis, implies that  satisfies the
inductive claim.

Therefore, by the principle of mathematical induction, the claim in
the lemma holds for all , where .  \qed

\CGS trees encountered along a run of  have several interesting
properties that are useful in proving the correctness of our
construction.  We will prove these propeties below by considering an
arbitrary run  of  and by inductively
showing that the respective properties hold for every \CGS tree 
along .


\begin{proposition}\label{initialpath}
For every , for every  and for every , there is a run of the automaton  from some  to  on the prefix .
\end{proposition}
\noindent {\bf Proof:} We will prove this by induction on the indices
of .

\noindent \emph{Base Case:} For the tree  with only the root node
, the claim in the lemma holds trivially, since  by definition.

\noindent \emph{Hypothesis:} We assume that the claim in the lemma
holds for , where .

\noindent \emph{Induction:} Consider the tree  obtained by
applying algorithm \algo{GeneralizedNext} to .  We know from the
initialization step (Step (\ref{Nxt1}) of algorithm
\algo{GeneralizedNext} that the state label of  is initially
set to .  We also know from the
pseudocode of algorithm \algo{GeneralizedNextRecursive} that invoking
this algorithm on a \CGS tree rooted at a node  does not change the
state label of .  Since Step (\ref{Nxt2}) of algorithm
\algo{GeneralizedNext} invokes algorithm
\algo{GeneralizedNextRecursive} on the \CGS tree rooted at ,
the state label of  remains unchanged at
 after the call to
\algo{GeneralizedNextRecursive} returns.  Subsequently, neither Step
(\ref{Nxt3}) nor Step (\ref{Nxt4}) of algorithm \algo{GeneralizedNext}
changes the state label of any node in .  Therefore,
.  Now let
 be an arbitrary node in  and let .  By Lemma (\ref{lemmaC}), we know that .  By the
inductive hypothesis, for every , there is a
run of  from some  to  on the prefix .  Therefore, there is a run of  from some  to
 on the prefix .

By the principle of mathematical induction, the claim in the lemma
holds for all . \qed

\begin{lemma}\label{lemmaA}
For every  and for every  such that  is a
non-leaf node of , we have .
\end{lemma}
\noindent {\bf Proof:} From Lemma (\ref{lemmaD}) and Step (\ref{GNR6})
of algorithm \algo{GeneralizedNextRecursive}, it follows that if 
is a non-leaf node of , it must have a child  such that
 is a \emph{strict subset} of .  This immediately
implies that . \qed

\begin{lemma}
\label{lemmaB}
Let .  For every , if ,
there exists a leaf node  in  with name  such
that .
\end{lemma}
\noindent {\bf Proof: } 
We will prove the lemma by induction on the indices of .

\noindent \emph{Base Case:} For the \CGS tree  with only the root
node , the claim in the lemma holds vacuously since .

\noindent \emph{Hypothesis :} We assume that the claim in the lemma
holds for , where .

\noindent \emph{Induction :} Consider the \CGS tree  obtained
by applying algorithm \algo{GeneralizedNext} to .  The value of
 is set in Step (\ref{Nxt4}) of algorithm
\algo{GeneralizedNext} to the smaller of  and the smallest name
of a node added to the set  in Step (\ref{GNR6}) of algorithm
\algo{GeneralizedNextRecursive}.  Therefore, if , a
node  with  must have been added to the set
 in Step (\ref{GNR6}) of a recursive call of algorithm
\algo{GeneralizedNextRecursive}.  Furthermore,  must have been the
root node of the \CGS sub-tree transformed by this specific recursive
call.  The condition in Step (\ref{GNR6}) of algorithm
\algo{GeneralizedNextRecursive} requires that all children of  must
have their hope set equal to  (or alternatively, the
annotations on all edges from  to its children must be ).
Therefore,  must have been a non-leaf node prior to being ``reset''
in Step (\ref{GNR6}) of algorithm \algo{GeneralizedNextRecursive}.  We
now consider two cases below depending on whether the node  was
present in  or not, and show that  in
both cases.
\begin{itemize}
\item Suppose .  By the argument given in the
  proof of Lemma (\ref{lemmaD}), we know that .
  If  was a non-leaf node in , by Lemma (\ref{lemmaA}),
  .  Hence,  as
  well.  If  was a leaf node in , we could either have  or .  In the latter case, we
  easily get .  In the former
  case, we note that  cannot become a non-leaf node prior to Step
  (\ref{GNR6}) of algorithm \algo{GeneralizedNextRecursive} in the
  process of transforming  to .  This is because Step
  (\ref{GNR1}) of algorithm \algo{GeneralizedNextRecursive} prevents
  any children from being added to  if .
  Therefore,  must have been non-empty in , and the claim
  in the lemma follows.
\item If  is newly created in the process of transforming  to
  , then by the argument used in the proof of Lemma
  (\ref{lemmaD}),  must have been created either in Step
  (\ref{GNR2}) or in Step (\ref{GNR3a}) of algorithm
  \algo{GeneralizedNextRecursive}.  If  was created as a leaf node
  in Step (\ref{GNR3a}), it could not have become a non-leaf node
  prior to execution of Step (\ref{GNR6}). This is because algorithm
  \algo{GeneralizedNextRecursive} is not called recursively on any
  leaf node created in Step (\ref{GNR3a}).  If  was created as a
  leaf node in Step (\ref{GNR2}), the only way it could have become a
  non-leaf node prior to execution of Step (\ref{GNR6}) is by a
  recursive invokation of algorithm \algo{GeneralizedNextRecursive} on
  this node in Step (\ref{GNR3}).  However, Step (\ref{GNR1}) of
  algorithm \algo{GeneralizedNextRecursive} ensures that such a
  recursive invokation adds a child to  only if the hope set of 
  is non-empty.  Therefore, we must have .
\end{itemize}

Since node  is ``reset'' and all descendants of  are deleted in
Step (\ref{GNR6}) of algorithm \algo{GeneralizedNextRecursive}, 
becomes a leaf node at the end of Step (\ref{GNR6}).  Furthermore,
since  and  are trees, every node has a unique parent
in  and , and hence, algorithm
\algo{GeneralizedNextRecursive} is recursively invoked at most once on
a node in Step (\ref{GNR3}).  It follows that after node  is
``reset'' and turned into a leaf by a recursive call of algorithm
\algo{GeneralizedNextRecursive}, there are no subsequent recursive
calls to \algo{GeneralizedNext} with  as the root of a \CGS subtree
to be transformed.  From the pseudocode of algorithm
\algo{GeneralizedNext}, we note that this implies that no child gets
added to  after it is ``reset''.  Therefore,  either remains as
a leaf node in  or is subsequently deleted in the process of
transforming  to .  However, since  is set to
, we know from Step (\ref{Nxt4}) of algorithm
\algo{GeneralizedNext} that  is present in .  Therefore,
 is a leaf node in  with  and
.

By the principle of mathematical induction, the claim in the lemma
holds for all , where .  \qed

\begin{lemma}\label{claim1} Let  be an -word and 
let  be the unique run of  on .
Let  be indices and let  be a node such that: (i) ,
(ii) for all , node  is present in
 and , and (iii) node  is a leaf in
both  and , and is a non-leaf node in all , where .  Then the following claims hold.
 \begin{enumerate}
   \item \label{claim1a} Node  is ``reset'' in the process of
     transforming  to .
   \item \label{claim1b} For every , there is a
      such that there is a run  of  on
      with ,  and
      for all .
   \item \label{claim1c} For every run  of  on the word
     segment  such that 
     for all , all states in 
     are visited in .
 \end{enumerate}
\end{lemma}
\noindent {\bf Proof:} 
\begin{enumerate}
\item We will prove this claim by contradiction.  If possible, suppose
   becomes a leaf node in  without being ``reset'' in the
  process of transforming  to .  Consider the case when
  .  Since  is a leaf in  and , Step (\ref{GNR2}) of algorithm
  \algo{GeneralizedNextRecursive} creates at least one child of 
  with the same non-empty state label as that of  when
  \algo{GeneralizedNextRecursive} is invoked with  as the root of
  the \CGS subtree to be transformed.  If , then since  is
  a non-leaf node in , there is at least one child of 
  with a non-empty state label in .  By Lemma (\ref{lemmaC}),
  the state label of  in this case is also the union of state
  labels of its children in .  Thus, in either case, there is
  an intermediate step during the transformation of  to 
  when  has one or more children with non-empty state labels, and
  the union of state labels of its children equals the state label of
  .  All these children must eventually be deleted before 
  becomes a leaf node in .

  From the pseudocode of algorithm \algo{GeneralizedNextRecursive}, we
  note that the only steps that delete nodes from a \CGS tree are Step
  (\ref{GNR5}) and Step (\ref{GNR6}).  Since  exists in  and
  is assumed not to have been ``reset'' in the process of transforming
   to , its children could not have been deleted in Step
  (\ref{GNR6}).  Therefore, all its children must have been deleted in
  Step (\ref{GNR5}) of algorithm \algo{GeneralizedNextRecursive}.
  This requires all children of  to acquire the empty state label.
  We know from above that there exist one or more children of  with
  non-empty state labels in an intermediate step during the
  transformation of  to .  The state labels of all such
  children must therefore be emptied before they can be deleted in
  Step (\ref{GNR5}).  From the pseudocode of algorithm
  \algo{GeneralizedNextRecursive}, the only steps that remove states
  from the state labels of nodes are Step (\ref{GNR3b}) and Step
  (\ref{GNR4}).  Unfortunately, State (\ref{GNR4}) simply removes
  duplicates from the state labels of siblings, and cannot render the
  state labels of all children of  empty.  Therefore, Step
  (\ref{GNR3b}) must eventually be responsible for emptying the state
  labels of all children of .  However, we know from the proof of
  Lemma (\ref{lemmaC}) that if a state is removed from the state label
  of a child of  in Step (\ref{GNR3b}) of algorithm
  \algo{GeneralizedNextRecursive}, then that state is eventually
  removed from the state label of  as well.  Since the state label
  of  equals the union of state labels of all its children at an
  intermediate step in the transformation of  to , the
  above implies that all states in the state label of  must
  eventually be removed in the process of transforming  to
  .  This, in turn, implies that  is removed from  in
  Step (\ref{GNR5}) of algorithm \algo{GeneralizedNextRecursive} -- a
  contradiction!

\item Since node  is present in all , for , it follows from Step (\ref{Nxt1}) that 
  is always initialized to ,
  for .  Since no other step of algorithm
  \algo{GeneralizedNext} or algorithm \algo{GeneralizedNextRecursive}
  adds states to the state label of an already existing node, the
  claim now follows from an easy induction on .

\item From the pseudocodes of algorithms \algo{GeneralizedNext} and
  \algo{GeneralizedNextRecursive}, we note that since node  exists
  in  for all , the hope set of 
  must stay unchanged, i.e.,  for all .  Now let  be an arbitrary index such that .  Suppose node  has a child  in a (possibly
  intermediate) step of algorithm \algo{GeneralizedNextRecursive}
  during the transformation of  to .  Suppose further
  that the edge from  to  is annotated with  and the state
  label of  is  in this step.  We will first prove the
  following claim.

  \emph{{\bfseries Claim 1:} For every run  of  on
     such that  for all  and , all states in
     are visited
    in .}

    The proof is by induction on .

    \noindent \emph{Base Case}: We know that  is a leaf node in
     with .  Therefore, during the
    transformation of  to , Step (\ref{GNR2}) of
    algorithm \algo{GeneralizedNextRecursive} creates a child  of
     and adds all states in  to the
    state label of .  In addition, the edge from  to  is
    annotated with .  This implies that .  Hence,
    the claim follows vacuously.

    Suppose additional children of  are subsequently created in
    Step (\ref{GNR3a}) of algorithm \algo{GeneralizedNextRecursive}.
    Since  is a leaf in , it can be seen from the pseudocode
    of algorithm \algo{GeneralizedNextRecursive} that prior to
    execution of Step (\ref{GNR3a}),  could have had only a single
    child -- the one created in Step (\ref{GNR2}), with the edge from
     to this child annotated with .  In order for
    a new child of , say , to be created in Step
    (\ref{GNR3a}), we note from the pseudocode of algorithm
    \algo{GeneralizedNextRecursive} that the state label of  must
    be  and the annotation of the edge from  to 
    must be .
    Since , it follows that .  Since the state label of
     is also , the claim is easily seen to hold for
    .  Since no other step of algorithm
    \algo{GeneralizedNextRecursive} or algorithm
    \algo{GeneralizedNext} adds any state to the state label of ,
    this proves the base case of the induction.

    \noindent \emph{Hypothesis}: We assume that the claim is true
    for , where .

    \noindent \emph{Induction}: Consider the transformation of
     to .  Let  be a child of  in some step
    of algorithm \algo{GeneralizedNextRecursive} during this
    transformation.  Suppose further that the edge from  to  is
    annotated with  and the state label of  is  in
    this step.  We consider two cases below.
    \begin{itemize}
    \item If  is present in , then by the argument used
      in the proof of Lemma (\ref{lemmaD}),  must also have been
      present in , with  and
      .  Therefore, by the definition of
      edge annotations, the edge from  to  must have been
      annotated with  in  as well.  Step (\ref{Nxt1}) of
      algorithm \algo{GeneralizedNext} ensures that the state label of
       is initialized to 
      during the transformation of  to .  This,
      along with the inductive hypothesis, and the facts that
       and the edge annotations from  to
       are the same in  and in , imply that the
      claim holds for  after the initialization step during the
      transformation of  to .  Since no other step
      of algorithm \algo{GeneralizedNextRecursive} or algorithm
      \algo{GeneralizedNext} adds any state to the state label of
      , this proves the inductive claim for .

    \item If  is not present in , it must have been
      created as a child of  in Step (\ref{GNR2}) or in Step
      (\ref{GNR3a}) of algorithm \algo{GeneralizedNextRecursive}
      during the transformation of  to .  Since  (by the condition in our inductive hypothesis), we know
      that  is a non-leaf node in .  Therefore,  could
      not have been created in Step (\ref{GNR2}) of algorithm
      \algo{GeneralizedNextRecursive} (this step requires  to be a
      leaf node in ).  Hence,  must have been created
      in Step (\ref{GNR3a}).

      From the pseudocode of algorithm
      \algo{GeneralizedNextRecursive}, we note that when  is
      created as a child of  in Step (\ref{GNR3a}), the state label
      of  is set to , where  is the annotation
      of the edge from  to an already existing child , and
       is in the state label of  at the time of creation
      of .  In addition, the annotation of the new edge from 
      to  is set to .  Since  is a non-leaf node in ,
      the child  itself could not have been created in Step
      (\ref{GNR2}) of algorithm \algo{GeneralizedNextRecursive} during
      the transformation of  to .  It could not have
      been created in Step (\ref{GNR3a}) of algorithm
      \algo{GeneralizedNextRecursive} either, since Step (\ref{GNR32})
      of algorithm \algo{GeneralizedNextRecursive} iterates over the
      children of  existing prior to execution of Step
      (\ref{GNR3}).  Therefore, the child  of  must be present
      in .

      Since  and  are present in both  and in the
      intermediate \CGS tree at the time of creation of , the hope
      sets of  and , and the annotation of the edge from 
      to  must be the same in  and in the intermediate
      \CGS tree.  This implies that the edge from  to  is
      annotated with  in .  By virtue of Step
      (\ref{Nxt1}) of algorithm \algo{GeneralizedNext}, we also know
      that there is a state  such that
      .  This, along with the
      inductive hypothesis, and the facts that  and the annotation of the new edge from  to 
      is , imply that for every run  of  on
       such that  for  and , all states in
       are
      visited.

      From the pseudocode of algorithm
      \algo{GeneralizedNextRecursive}, no step other than Step
      (\ref{GNR3a}) adds any state to the state label of  after it
      is created in Step (\ref{GNR3a}).  Therefore,  has at most
      one state, , in its state label in any intermediate
      step of algorithm \algo{GeneralizedNextRecursive} during the
      transformation of  to .  We have already
      considered the case of  in the state label of 
      above.  Hence, this proves the inductive claim for  and
      also completes the proof of Claim 1.
    \end{itemize}

    To complete the proof of Lemma (\ref{claim1}-\ref{claim1c}), we
    note from Lemma (\ref{claim1}-ref{claim1a}) that  is ``reset''
    during the transformation of  to .  Therefore, from
    Step (\ref{GNR6}) of algorithm \algo{GeneralizedNextRecursive},
     must have had at least one child with non-empty state label
    prior to being ``reset''.  In addition, the annotations of all
    edges from  to its children with non-empty state labels must
    have been  prior to the resetting of .  It then follows from
    Claim 1 that for every run  of  such that  for all  and  is in
    the state label of some child of  prior to it being reset, all
    states in  are
    visited in .  

    This does not prove Lemma (\ref{claim1}-\ref{claim1c}) yet, since
    we must show the above result for .
    We have seen earlier, in the proof of Lemma (\ref{lemmaC}), that
    the state label of a node  may temporarily contain states that
    are not in the state labels of any of its children after
    intermediate steps of algorithm \algo{GeneralizedNextRecursive}.
    However, we also saw in the same proof that all such states are
    eventually removed from the state label of  after all recursive
    invokations of \algo{GeneralizedNextRecursive} have returned.
    Therefore, proving the claim of Lemma (\ref{claim1}-\ref{claim1c})
    for  in the state labels of children of  prior to
     being ``reset'' proves Lemma (\ref{claim1}-\ref{claim1c})
    itself. 
\end{enumerate}
\qed




\begin{lemma}\label{claim2} Let  be an -word and 
let  be the unique run of  on .
For every  and for every node  in , .
\end{lemma}

\noindent {\bf Proof:} We will prove this claim by contradiction.
Suppose there exists an  and a node  in  such that
 although .  Clearly, 
cannot be the root, , of , since  contains the indices of all states of .  Therefore, 
must have a parent, say , in .  Recalling that  has only
a single node (i.e., ) without any parent, we can immediately
infer that .  In other words, there exists a \CGS tree
 such that  is obtained by applying algorithm
\algo{GeneralizedNext} to .

From the pseudocode of algorithm \algo{GeneralizedNextRecursive}, we
observe that during the transformation of  to , the only
nodes in  on which the recursive algorithm \algo{GeneralizedNextRecursive} is
not recursively invoked are those that are generated in Step
(\ref{GNR3a}).  Furthermore, every node generated in Step
(\ref{GNR3a}) is either deleted or survives as a leaf in the
transformation of  to .  Since node  is a non-leaf
node in , algorithm \algo{GeneralizedNextRecursive} must have
been invoked with  as the root of the \CGS subtree to be
transformed, during the transformation of  to .

Let  be the annotation of the edge from  to  in .  There
are two possibilities that we consider separately below.
\begin{itemize}
\item Suppose  is created during the transformation of  to
  .  This can happen either in Step (\ref{GNR2}) or in Step
  (\ref{GNR3a}) of the recursive invokation of algorithm
  \algo{GeneralizedNextRecursive} with  as the root of the \CGS
  subtree to be transformed.  
  \begin{itemize}
    \item If  is created in Step (\ref{GNR3a}), it follows from the
      pseudocode of algorithm \algo{GeneralizedNextRecursive} that
      , where  is the annotation of
      an edge from  to an already existing child, say , of
      .  In addition,  is set to .  By the definition of edge annotations,  and hence .  It then
      follows that  as well.
      Therefore, .  Since no other
      step of algorithm \algo{GeneralizedNextRecursive} adds any state
      to  subsequently, we have .  This gives us a contradiction!
    \item If  is created in Step (\ref{GNR2}), then Step
      (\ref{GNR3a}) must subsequently be executed in the same
      recursive invokation of \algo{GeneralizedNextRecursive} with 
      as the root of the \CGS subtree to be transformed.  This is
      similar to the case considered below wherein  exists in
      , and Step (\ref{GNR3a}) is executed in the recursive
      invokation of \algo{GeneralizedNextRecursive} with  as the
      root of the \CGS subtree to be transformed.
  \end{itemize}
  \item Suppose  exists in .  It follows that the parent,
    , of  must also exist in .  Consider Step
    (\ref{GNR3a}) in the recursive invokation of algorithm
    \algo{GeneralizedNextRecursive} with  as the root of the \CGS
    subtree, during the transformation of  to .  We
    have two sub-cases to consider.
    \begin{itemize}
    \item If , a new child, say , of  is been created in
      Step (\ref{GNR3a}), the state label of  is set to 
      and the edge from  to  is annotated with an index .
      This implies that in Step (\ref{GNR4}) of algorithm
      \algo{GeneralizedNextRecursive},  is removed from the state
      label of .  Since no other step of algorithm
      \algo{GeneralizedNextRecursive} adds states to 
      subsequently, it follows that .
      This gives a contradiction!
    \item Suppose .  Since  is also not in , it
      follows that in Step (\ref{GNR3b}) of the recursive invokation
      of \algo{GeneralizedNextRecursive} with  as the root of the
      \CGS subtree to be transformed,  is removed from
      .  By the same argument used above,  cannot
      be subsequently added to .  Hence,  -- a contradiction again!
    \end{itemize}
\end{itemize}

We have therefore shown that there is no  and no node  in
 such that  and .
\qed


Armed with the above properties of \CGS trees encountered along a run
of , we will now show that the languages accepted by  and
 are the same.  As before, let  be an -word in
 and let  be the unique run of  on
.  By definition of the acceptance condition for , there
exists an even index , where , such that \CGS
trees from the parity acceptance set  are seen infinitely
often along , while \CGS trees from all parity acceptance sets
, where , are seen only finitely often along
.  Let  be the smallest index  such that all \CGS
trees  for  are outside .
The following lemma describes important properties of the suffix  of , where .

\begin{lemma}\label{greentogreen}
Let  and  be indices such that (i) , (ii)
both  and  are in , and (iii)  for all .  Then there exists a
node  such that the following hold.
\begin{enumerate}
\item  is present in  for all .
  In addition,  and  for
  all .
  
\item  is a non-leaf node in , for all .

\item For every state , there is some state  such that there is a run of  from  to 
  on  that visits all and only states in
  .
\end{enumerate}
\end{lemma}

\noindent {\bf Proof:}
\begin{enumerate}
\item Since both  and  are in , it follows from
  the definition of even-indexed parity acceptance sets that .  Also, since , we have .  Therefore, by Lemma (\ref{lemmaB}), both  and 
  contain a leaf node with name  and with a non-empty hope set.

  Since , it follows from the definition of  that
  for all , the \CGS tree  is not in
  .  Recalling the definitions of
   for odd and even indices , we see that this implies  for all .  Hence no node with
  name  is removed in the process of transforming  to
  ,  to , and so on until  is
  obtained.  Therefore, the node  with name  in 
  continues to be a part of all , where .  Since
  , the name-compaction step of algorithm
  \algo{GeneralizedNext} keeps the name of node , i.e, ,
  unchanged in all of .  Hence, node  is present in  and
  , for all .
  Furthermore, since  and since  is not
  deleted in the sequence of transformations from  to ,
  it follows that , for .

\item Consider an index  such that .  If  was a
  non-leaf node in , then it starts off as a non-leaf node
  with at least one child having a non-empty state label when
  algorithm \algo{GeneralizedNextRecursive} is invoked on  to
  transform it to .  If  was a leaf node in  (as is
  the case when , for example), then since  (by Lemma (\ref{greentogreen}-) above), Step
  (\ref{GNR2}) of algorithm \algo{GeneralizedNextRecursive}) ensures
  that  becomes a non-leaf node with at least one child having a
  non-empty state label in an intermediate step during the
  transformation of  to .  Thus, in either case, 
  becomes a non-leaf node with at least one child having a non-empty
  state label in some intermediate step of algorithm
  \algo{GeneralizedNextRecursive}.

  In order for  to subsequently become a leaf node in , all
  its children must be deleted.  Deletion of nodes can only happen in
  Step (\ref{GNR5}) or Step (\ref{GNR6}) of algorithm
  \algo{GeneralizedNextRecursive}.  We show that none of these steps
  can delete all children of  in .
  \begin {itemize}
    \item Since  stays back in  (by Lemma
      (\ref{greentogreen}-) above), if the leaves of  are
      deleted in Step (\ref{GNR6}) of algorithm
      \algo{GeneralizedNextRecursive},  must be ``reset'' and
       must be added to  (since ) in Step (\ref{GNR6}).  Therefore,
       must be set to a value no larger than  in Step
      (\ref{Nxt4}) of algorithm \algo{GeneralizedNext}.  Since  (as shown in the proof of Lemma (\ref{greentogreen})-),
      this would imply that , where .
      Recalling the definition of , this contradicts the fact
      that .
    \item If all leaves of  are deleted in Step (\ref{GNR5}) of
      algorithm \algo{GeneralizedNextRecursive}, then the union of
      state labels of the children of  must be empty at some
      intermediate step of algorithm \algo{GeneralizedNextRecursive}.
      We have seen above in the proof of Lemma (\ref{lemmaC}) that the
      state label of a node is eventually no larger than the union of
      state labels of its children at any intermediate step of
      algorithm \algo{GeneralizedNextRecursive}.  Therefore, if all
      leaves of  are deleted in Step (\ref{GNR5}) of algorithm
      \algo{GeneralizedNextRecursive}, the state label of  must
      eventually become empty in .  However,  must then be
      deleted from  by Step (\ref{GNR5}) of algorithm
      \algo{GeneralizedNextRecursive}.  This contradicts Lemma
      (\ref{greentogreen}-) proved above.
  \end{itemize}
  Therefore,  must be a non-leaf node in .

\item Lemma (\ref{greentogreen}-) is an immediate consequence of
  Lemmas (\ref{greentogreen}-), (\ref{greentogreen}-),
  (\ref{claim1}-\ref{claim1b}), (\ref{claim1}-\ref{claim1c}) and
  (\ref{claim2}).





\end{enumerate}
\qed





\begin{lemma}\label{lemma1}
.
\end{lemma}

\noindent {\bf Proof:} We will prove this lemma by constructing a
finitely branching infinite tree  along the lines of Safra's proof
of correctness of his NSW determinization construction, and by showing
the existence of an infinite accepting path of  in this tree.

The vertices of  are elements of , where  is a special vertex representing the
root of .  For every , we draw an edge from
 to .  As defined earlier, let  be the
minimum index after which no \CGS tree from , for ,
is visited in the sequence .  Let  be the
smallest index greater than  such that , and let
 be the node in  identified in Lemma
(\ref{greentogreen}-).  From Lemma (\ref{greentogreen}-), we
know that  and 
for all .  For every state  in  we
add a vertex  to the tree .  For every such state ,
Proposition (\ref{initialpath}) tells us that there is a state  such that there is a run of  from  to  on
.  We add an edge from  to  in
tree  for every such  and .
Subsequently, we extend the tree  inductively as follows. Given a
tree with a leaf , where  and
 is such that , we find the smallest
 such that .  Since \CGS trees in
 are encountered infinitely often in  (by
the acceptance condition of ), such an  always exists.
For every state , we now add a vertex
 to the tree .  By Lemma (\ref{greentogreen}-),
there is a state  in  such that there is a run of
 from  to  on  that visits all and
only states in .  For every such  and , we add an edge
from  to  to extend the tree .  It is
easy to see that  is an infinite tree with the branching of each
node  restricted by the cardinality of
, i.e. .  Therefore, it follows from
K\"onig's lemma that there is an infinite path in . 

From Proposition (\ref{initialpath}), every edge  corresponds to a run of  on  that
starts at  and ends at . From Lemma (\ref{greentogreen}-),
every edge  for  corresponds to a
run of  on  that starts at  and ends
at  and visits all and only states in .
Therefore, the infinite path in  identified above corresponds to a
run  of  that starts from some  and eventually
visits all and only states in .  In other words,
.  Furthermore, since 
and , we must have .  In other words, , and hence 
is an accepting run of . This implies .  \qed



\begin{lemma}\label{lemma2}
.
\end{lemma}



\noindent {\bf Proof: } Consider an -word .
Let  be an accepting run of
 on , and let  be the unique
run of  on , where  is the \CGS tree .  Consider the transformation of 
to  by algorithm \algo{GeneralizedNext}.  Step (\ref{Nxt1})
of algorithm \algo{GeneralizedNext} updates the state label of 
to .  Subsequently, no step of
algorithm \algo{GeneralizedNext} or algorithm
\algo{GeneralizedNextRecursive} deletes any state from the state label
of , deletes , or adds  as the child of any other node.
It therefore follows from an easy inductive argument that the root
 of  eventually survives as the root  of ,
for all .  Since  and , and
since every node in  that is not deleted in transforming  to
 retains its name and hope set in , we have
 and  for
all .  Also, by definition, .  Therefore,
 for all .

Let  be the set of indices of all states in , i.e., .  Let  be the smallest index
such that for all , we have .  We
wish to identify those nodes  in  that have , for all .  In other words, we wish to
identify nodes in the sequence of \CGS trees  that track the run  of  from position  onwards.  

We have already seen above that  survives as the root node in
all \CGS trees in .  We also know that ,
by definition.  Since Step (\ref{Nxt1}) of algorithm
\algo{GeneralizedNext} updates  to
 for all , and since no
subsequent step during the transformation of  to 
deletes any state from the state label of the root , it
follows from an easy inductive argument that , for all .

Now suppose the root node becomes a leaf infinitely often in
.  Let  and  be arbitrary indices such
that , and the root node is a leaf in  and
, but not in any , for .  Since we also know
that  for all , it follows
from Lemma (\ref{claim1}-\ref{claim1c}) and Lemma (\ref{claim2}) that
the set of states visited in  is exactly .  By repeating the same argument for all successive pairs of
indices  such that , and the root node is a
leaf in  and , but not in any  in between, we get
, for every .  Since  is an
accepting run of , we also know that .  This implies that  for all those
indices  where  becomes a leaf node in .  By Lemma (\ref{claim1}-\ref{claim1a}), we know that 
is ``reset'' in these steps as well.  Hence  is added to the set
 in Step (\ref{GNR6}) of algorithm \algo{GeneralizedNextRecursive}
during the transformation of  to  for each such .
Since the root has the smallest name (), the component
 of the \CGS tree  is set to  infinitely often, while
. Hence the set  is visited infinitely often and .



If the root node becomes a leaf finitely often, there is an index  such that the root node is a non-leaf node in all  for .  By Lemma (\ref{lemmaC}), we know that for all ,
every state in  is also in  for some
child  of .  Since  for all , it follows that for all , there is a child  of 
such that .  Now consider the transformation
of  to  for , and let  be the node in
 such that .  Step (\ref{Nxt1}) of
algorithm \algo{GeneralizeNext} initializes the state label of 
with , thereby placing 
in the state label of .  Subsequently, if  is moved
out of the state label of , either Step (\ref{GNR3b}) or Step
(\ref{GNR4}) of algorithm \algo{GeneralizedNextRecursive} must be
responsible for this.  However, if  is removed from the
state label of  in Step (\ref{GNR3b}), from the argument used in
the proof of Lemma (\ref{lemmaC}), we know that  must
eventually be removed from the state label of the parent of  in
, i.e. from the state label of .  This is a
contradiction, since  for all .
Therefore, if  is removed from the state label of ,
Step (\ref{GNR4}) of algorithm \algo{GeneralizedNextRecursive} must be
responsible for the removal.  From the pseudocode of
\algo{GeneralizedNextRecursive}, we now observe that if  is
the new node containing  in its state label in ,
then either  or the
annotation of the edge from  to  in  is
lesser than the annotation of the edge from  to  in
.  Since both  and  existed in ,
the annotation of the edge from  to  in  must
be the same as the annotation of the edge from  to  in
.  Therefore, if the child of the root that tracks  changes
from  to , then either the name of the node reduces or
the annotation of the edge from the root to this node reduces during
the transformation from  to .  Since neither the name
nor the annotation can decrease infinitely, there must be an index
 such that for all , the child of the root that
contains  in its state label has the same name and the same
annotation of the edge from the root to this child.  In other words,
if  and  are children of the root in  and 
respectively such that  and , then  and
.

If possible, let  and  be distinct nodes.  As seen
above, Step (\ref{GNR4}) of algorithm \algo{GeneralizedNextRecursive}
is responsible for moving  from the state label of  to
that of  during the transformation of  to .
From the pseudocode of algorithm \algo{GeneralizedNextRecursive}, we
note that either the annotation of the edge from the root to 
must be less than the annotation of the edge from the root to ,
or the name of  must be less than the name of  at the
time of execution of Step (\ref{GNR4}).  Since the name of 
can only reduce further during the name-compaction step and since the
annotation of the edge from the root to  cannot change
subsequently in any step of algorithm \algo{GeneralizedNextRecursive}
or algorithm \algo{GeneralizedNext}, we cannot have both the names and
the annotations of the edges from the root identical for  in
 and for  in .  Since , this gives us
a contradiction!  Therefore,  is the same node as  for
all .  Since  also stays unchanged for all , no node with name  is deleted during the
transformation of  to , for .  This implies
that  for all .

We now claim that  for all .  To see
why this is so, suppose  for some  and
let  be the annotation of the edge from  to  in .
Consider Step (\ref{GNR32}) of the recursive invokation of algorithm
\algo{GeneralizedNextRecursive} with the parent of , i.e. ,
as the root of the \CGS subtree to be transformed.  Let  be a
state in the state label of  when Step (\ref{GNR32}) is executed.
If , then Step (\ref{GNR3a}) creates a new sibling  of
, sets the state label of  to  and sets the
annotation of the edge from  to  to an index .  Since no
further step removes the state label of the newly created leaf ,
state  gets removed from the state label of  in Step
(\ref{GNR4}) of algorithm \algo{GeneralizedNextRecursive}.  If, on the
other hand, , then since  is assumed to be
, Step (\ref{GNR3b}) removes  from the state label of
.  Thus, in either case, no state eventually remains in the state
label of  in  if .  This implies that 
is deleted from  in Step (\ref{GNR5}) -- a contradiction!
Therefore, we must have  for all . 

We now consider the case where the node  becomes a leaf
infinitely often in .  By using the same argument
as used above when the root becomes a leaf infinitely often, we find
that for every  such that  is a leaf in , the node
 is added to the set  in Step (\ref{GNR6}) of algorithm
\algo{GeneralizedNextRecursive} during the transformation of 
to .  Therefore,  for all .  We have
also seen above that  for all .  This implies
that a parity acceptance set  with an even index  is visited
infinitely often by the run  of .  Hence .

If  becomes a leaf only finitely often in ,
we can repeat the same argument as used above and show that there is
an index  and a child  of  such that (i)  is
present in , (ii) , (iii) , and (iv) , for all
.  Since all \CGS trees  have height  (as argued
in Section (\ref{sec:inf-set-size})), by continuing the above
argument, we find that there must exist an even index  such that
 is visited infinitely often by .  In other words, .
\qed











\begin{theorem}

\end{theorem}



\noindent {\bf Proof:} Follows from Lemmas (\ref{lemma1}) and
(\ref{lemma2}). \qed













 

\section{Complexity}
\label{sec:inf-set-size}






\begin{theorem}\label{count-thm}
Given an automaton  with  states, the deterministic parity
automaton  constructed above has at most  states
and  parity acceptance sets.
\end{theorem}

\noindent {\bf Proof:}
The computation for the number of states of the automaton  is
similar to that done by Piterman for his NSW to DPW construction
\cite{piterman}.  Since every state of  is a \CGS tree over
, we will count the total number of \CGS trees over  below,
assuming  and .



The salient steps in counting the number of \CGS trees over 
are as follows.
\begin{itemize}
\item Since the state labels of leaves in a \CGS tree are pair-wise
  disjoint, and since every leaf has a nonempty state label, there can
  be at most  leaves.

\item If we collapse the vertices at the head and tail of every
  -annotated edge in a \CGS tree, we will get a tree with no
  -annotated edges.  Since the hope set of the root is always 
  and since the hope set of a child in the collapsed tree misses
  exactly one index from the hope set of its parent, the height of the
  collapsed tree can be at most .  This, along with the fact that
  there are at most  leaves, implies that there are at most  nodes in the collapsed tree.

\item To count the nodes that were removed due to the collapsing
  operation described above, we note that each node in the original
  \CGS tree must have a path (possibly of zero length) to a leaf such
  that each edge along this path has a non- annotation.  Hence, if
   and  are nodes such that the edge from the parent of  to
   and that from the parent of  to  are both annotated with
  , the path of non- annotated edges from  to a leaf cannot
  overlap with the corresponding path from  to a leaf.  Therefore,
  there can be atmost  nodes in a \CGS tree such that the edges
  from the respective parents to these nodes are annotated with .
  This implies that the total number of nodes in a \CGS tree can be
  atmost .

\item By construction, the parent of a node always has a smaller name
  than the node. Thus the parenthood relation can be represented by a
  sequence of at most  names where the  name is a value
  in .  For a tree with  nodes, the there are at
  most  such sequences of length . Considering all
  trees with number of nodes in , there are at most
  , i.e.  such sequences.  Hence,
  there are at most as many named trees where children have larger
  names than their respective parents.

\item The state label of a node is given by the union of state labels
  of leaves in the sub-tree rooted at that node.  In addition, the
  labels of leaves are pairwise disjoint. Therefore, the state labels
  of all nodes in a tree can be obtained by associating each
  -state with the leaf that contains it in its state label.
  Since leaves in a tree may not be named with the first few
  contiguous names, we sort the leaves by names and then use a mapping
  from -states to positions of leaves in this name-sorted order.
  If an -state doesn't appear in any leaf, we associate the
  position  with it.  Thus, the number of state labelings of a
  named tree is at most the number of mappings , i.e.  .




\item The (hope set) annotation of a node is represented using edge
  annotations as follows. Suppose the hope set of a node  is 
  and that of its child  is .  Then the edge from  to
   is annotated with , if , and with  if .  By properties of \CGS trees,
   and .
  Therefore, the edge annotation is a unique element in .  Similarly, the hope set for every node is uniquely
  determined if the annotations of all edges are given.  Specifically,
  the hope set of a node is simply  sans the annotations on edges
  along the path from the root to this node.  Therefore, it is
  sufficient to count the number of edge annotation functions to
  obtain the count of hope set annotations of nodes.  Each edge can be
  identified by the name of the node it points to.  The total number
  of edge annotation functions is then easily seen to be the number of
  functions .  This is bounded above by
  .

\item For the acceptance condition, we need to know the value of 
  when , and the value of  when . Thus we need to
  keep track of at most  values.
\end{itemize}

Combining the above counts, the total number of \CGS trees over 
is at most
.  
The number of parity acceptance sets is . \qed


\section{An improved upper bound for -automata}
\label{sec:large-acc-sets}

The determinization construction proposed above gives a DPW starting
from a variety of different non-deterministic automata, all of which
have an acceptance condition based on infinity sets.  By Theorem
(\ref{count-thm}), the number of states of the DPW is at most
 or , while the number of sets in the
parity acceptance condition is at most , where  is the
number of states of the original automaton .  This bound also
holds when the input automaton is a pairs automaton viz. a Streett or
a Rabin automaton. This is significant since the size of the output
DPW, both in terms of number of states and acceptance pairs, is
independent of the number of pairs of the input pairs automaton. This
is different from the case of Safra's determinization construction for
NSW\cite{safra06}\cite{2001automata}\cite{piterman}, where the output
DRW/DPW has at most  states and  pairs,
where  and  are the count of states and pairs, respectively, of
the input NSW.


This naturally leads us to ask if  is a better bound
than  for determinization of NSW/NRW. The answer to
this question is not immediately obvious and requires us to show that
there are indeed examples of NSW/NRW with  states and  pairs
for which Safra's and Piterman's NSW determinization construction will
end up constructing automata with state count worse than . In the following, we present a class of such automata. In the
case when , where , this immediately implies an
improved worst case complexity bound on NSW/NRW determinization.




\begin{theorem}
\label{familyimprovedbound}

There exists a family  of NSW where each NSW  has  states and  accepting pairs for which the
Safra-Schwoon (Piterman) construction constructs a DRW (DPW) with
 states, while our construction (algorithm
\algo{GeneralizedNext}) constructs a DRW/DPW with  states.


\end{theorem}

The proof of Theorem (\ref{familyimprovedbound}) is given in Subsection
(\ref{familyconstruction}) by demonstrating the construction of an automaton
from the family .
 
To begin with, a strategy to generate more than  states for
the DRW/DPW using Safra's/Piterman's construction is established. The input NSW
for such a strategy has  states and  pairs.  One way to generate a
sufficiently large number of -trees (as used in Schwoon's exposition of
Safra's construction) is to obtain different permutations of the edge labels on
a path from a leaf to the root, and then repeat this for all paths in the tree.
We shall follow the construction of Schwoon\cite{2001automata} described in
algorithms \algo{SafraNext} and \algo{SafraNextRecursive} (see Subsection
(\ref{safransw})) for NSW determinization.

\begin{figure}[ht]
\begin{minipage}[b]{0.48\linewidth}
\begin{center}
\includegraphics[scale=0.53]{counter1.eps}
\end{center}
\label{counterex1}
\end{minipage}
\hspace{5mm}
\begin{minipage}[b]{0.48\linewidth}
\begin{center}
\includegraphics[scale=0.53]{counter2.eps}
\end{center}
\label{counterex2}
\end{minipage}
\caption{Steps in construction of counter-example}
\label{counterex12}
\end{figure}

Figure (\ref{counterex12}) shows three possible -trees,  and
 that can be generated using the Safra-Schwoon construction in algorithm
\algo{SafraNextRecursive} starting from the initial tree , where  is
the \CGS tree with a single (root) node , with , ,  and for  we have .

The first tree  is not hard to generate, since Steps (\ref{safra1}) and
(\ref{safra2}) recursively extend a -tree at its leaves. If the Streett
state label of the leaf node in the first tree  is  and  for all , then in Step (\ref{safra3b1}) a
new node is created for each such  with the edge from the root node
to the newly created node annotated , giving the second tree .  An
application of Steps (\ref{safra1}) and (\ref{safra2}) will result in the
extension of the second tree  at its leaves giving the third tree .
For each Streett state ,  that appears in the label of a leaf
node in the third tree , the path from the leaf to the node is disjoint
from every other path in the tree. Each such disjoint path has exactly the same
edge annotations.  Note that since the number of leaves in a -tree can
never be more than the total number of Streett states, we cannot expect to get
more than  disjoint paths from a leaf to the root.  The challenge now is to
permute the edge annotations giving a large number of -trees.







Since, the maximum length of a disjoint path in a -tree depends on the
number of pairs of the NSW, one would like to start with an NSW with as many
pairs as possible. Suppose, we start out with  pairs in the NSW. A
permutation of  edge annotations would give us  possible trees with
just one branch and  trees with all  disjoint branches. With
only  states in the NSW and  pairs, it is clear that one or more Streett
states will be replicated across pairs.  This replication of Streett states is a
potential problem as the example in Figure (\ref{counterex3}) shows.  

\begin{figure}
\begin{center}
\includegraphics[scale=0.53]{counter3.eps}
\end{center}
\caption{Example transformation of -trees}
\label{counterex3}
\end{figure}

Figure (\ref{counterex3}) shows different edge annotations for a path of length
 (with no  edges) in a -tree. The different edge annotations are
obtained as the Streett state label at the leaf changes. We assume that .
It is not hard to obtain the edge annotations along  from the edge
annotations along . In this transformation only the edge annotation of
the first edge in  changes from  to . 
This is possible if there is a state  in the leaf label that is also in the
pair  of the pair . This causes the entire path to
be replaced by a pair of nodes - the root node with exactly one child.  The edge
between the root and its child node is annotated . This path is again
extended by Steps (\ref{safra1}) and (\ref{safra2}) of algorithm
\algo{SafraNextRecursive}. We see that repeated application of this change
allows us to change the edge annotations of  to those shown along
, where the edge annotation on the edge from the root to the first child
node is . Note that this requires that the NSW has a path from  back
to itself on some letter or word segment. Once the first edge annotation is
fixed we can apply a similar set of transformations using some other state 
to fix the second edge annotation to .  But, this immediately implies
that the state  cannot be in  or  since that would
either change the annotation of the first edge to  or reset the path
back to the third path  shown in the figure. Hence, every time we fix the edge
annotation for an edge it constrains the possible pairs that a Streett state can
belong to. With only  states and  pairs, we are soon forced to repeat
Streett states across pairs in our example NSW.  This in turn forces already
fixed edge annotations to change, defeating our purpose.  Thus, generating
arbitrary permutations of  pair indices along paths in a -tree is
extremely hard with an NSW with just  states. 

We then ask if  is too many pairs and try to see if  or  or some
number of pairs polynomial in  allows us to achieve our objective of
obtaining arbitrary permutations of edge annotations.  But, with  pairs in
the NSW, for some constant , even if obtaining arbitrary permutations of edge
annotations is possible, we can obtain at most  permutations along a
path and hence  -trees using all the paths. But,
 is , which matches the bound given by our
construction and does not serve our purpose. 

We now show a solution to the above dilemma. We start out with  pairs in
the NSW, but we partition the  pairs into 
\emph{blocks} of  pairs each.  Hence  is the
first block,  
is the second block and so on. If , then the
last or  block is 
 .  Instead of trying to generate arbitrary
permutations of  pair indices we try to generate permutations of only 
pair indices, but with the following properties for a permutation , where  for all .  

\begin{itemize}

\item We pick  blocks starting with the last
block  and picking successively lower numbered blocks .

\item From each block we pick exactly one pair index. For example if we pick the
 pair in block  then pair is
. We call this pair index
. 

\item If pair index  is already picked from block , then
we do not pick  for , for every pair of blocks
 and  that are picked. 

\end{itemize}

This system of picking elements of the permutation not only allows us to permute
only  elements along every path from a leaf to the root, but also allows us
to choose from  Streett pairs and at the same time have only  states
for the example NSW. We shall see later that this method ends up generating more
than  -trees. We shall call a permutation that
satisfies the conditions described above as a \emph{block permutation} of size
. An example of a NSW with  states and  pairs for which the
corresponding DPW constructed using the Safra/Piterman construction has more
than  states is given below. 


\subsection{An example showing improved worst case bounds}
\label{familyconstruction}

Consider the the NSW  defined
as follows. The NSW  is an automaton in the family 
described in Theorem (\ref{familyimprovedbound}).

\begin{itemize}

\item  is the state set containing  states  \{   \} .
States of the form  are called -states,
-states and -states respectively.

\item  is the initial state.

\item  is the alphabet .

\item The transitions for the automaton are defined as follows

\begin{enumerate}

\item \label{ex1} 

\item \label{ex2}  for all 

\item\label{ex3}  for all 



\item \label{ex5} for all 

\item \label{ex6} for all 


\item \label{ex7} for all 

\item \label{ex8} for all 

\item \label{ex9} for all 

\item \label{ex10} for all 


\end{enumerate}

\item There are  Streett pairs , where , for all
 satisfying the following constraints

\begin{enumerate}

\item  and 
 for all .

\item  for all  and for
all .
 
\item  for all  and for
all .

\item  

\item  for all  and 
 for all  and .

\item  for all 
and for all .


\end{enumerate}



\end{itemize}

\begin{figure}
\begin{center}
\includegraphics[scale=0.56]{counter4.eps}
\end{center}
\caption{Example transformation of -trees}
\label{counterex4}
\end{figure}





\begin{figure}[ht]
\begin{minipage}[b]{0.48\linewidth}
\begin{center}
\includegraphics[scale=0.53]{counter5.eps}
\end{center}
\label{counterex5}
\end{minipage}
\hspace{5mm}
\begin{minipage}[b]{0.48\linewidth}
\begin{center}
\includegraphics[scale=0.53]{counter6.eps}
\end{center}
\label{counterex6}
\end{minipage}
\caption{Example transformation of path }
\label{counterex56}
\end{figure}

As discussed earlier our goal is to permute  pair indices chosen carefully
from different blocks. For example let  be a block permutation of size . Our goal is to
start with an arbitrary assignment of edge annotations along a path in a -tree and obtain the permutation  along that path. We do not insist that
the elements of  appear along successive edges along the path, but we
insist that they appear along the path in the same order as they appear in
.

Figures (\ref{counterex4}), (\ref{counterex56}) and (\ref{counterex78})
demonstrate the main steps in the process of generating the required
permutations of pair indices for the example automaton. In Figure
(\ref{counterex4}), starting from the initial -tree consisting of just
the root node, we obtain the tree extended at the root and with Streett state
label  using the
transition from  on letter  and Steps (\ref{safra1}) and
(\ref{safra2}) of the Safra-Schwoon construction. This single path changes to
the branched tree in which the root has  children with the edge to each child
annotated  and the  child has Streett state label .
Using a sequence of transitions on the letters  and  we
obtain the final tree that has  leaves and  disjoint paths, one from each
leaf to the root node. 

Note that the letter  causes only state  to change to
the next state , while Streett state labels for all other leaves
remain unchanged. This results in the edge annotation between the root and the
leftmost child to change to . On reading the letter , state
 changes to  giving us the tree  in the figure. Note
that  is only an intermediate tree and will evolve through different steps
of the Safra-Schwoon algorithm.  We observe that by changing the Streett label
of just one path at a time we can systematically generate permutations of edge
annotations one path at a time.  This will be our general strategy henceforth
and we shall see how a path  in tree  evolves with succeeding steps. 

The -states can be thought of as the \emph{source} states of every
path transformation. We change a -state to an -state only along the
path whose edge annotations we need to modify.  

Figure (\ref{counterex56}) shows the transformations of path  in order to
obtain the block permutation  in order along the edges in . It is
straightforward to obtain the first element  along the first edge.
All it requires is successive applications of letter  to
 follows by .  We now try and change the other edge
annotations keeping the first edge annotation fixed. On reading the letter
 we change the second edge annotation to . Here,
we need to be careful, since an application of  at this point will
change  to  but it will also change  to ,
because of the way the Streett pairs are organised. Hence, we defer the
application of  and instead apply letter  again, which
changes  to . Now an application of  will change 
to , since  already appears on the edge above. Using this general
strategy of deferring the application of a letter if it changes an edge
annotation that is already on an edge above and part of , we can obtain the
required block permutation  along path . Note that it is possible
that all elements , for all , where  is
the number of blocks may appear between the first element  and the
second element  of  in order. 

Once all elements of  appears along , we ``seal'' path , by
applying the letter , which affects only  at the leaf of
 and does not affect the -states on the other paths. After this the
state  and hence the edge annotations for  do not ever
change. We now apply  to change  to  at the
leaf of the second path. We then use our usual strategy discussed above to
obtain another block permutation along that path. Continuing this way we can
obtain arbitrary block permutations of size  along every path in 
trees. 

\begin{figure}[ht]
\begin{minipage}[b]{0.48\linewidth}
\begin{center}
\includegraphics[scale=0.53]{counter7.eps}
\end{center}
\label{counterex7}
\end{minipage}
\hspace{5mm}
\begin{minipage}[b]{0.48\linewidth}
\begin{center}
\includegraphics[scale=0.53]{counter8.eps}
\end{center}
\label{counterex8}
\end{minipage}
\caption{Example transformation of path }
\label{counterex78}
\end{figure}

Although, we consider only special types of -trees, where the paths of
the trees are disjoint from one another, we shall show that this is sufficient
to generate enough trees to go beyond the  upper bound given
by our construction. 

There are  blocks of Streett pairs, with 
elements in each block. Note that if  i.e  is not
a power of , then some pairs may not appear in any block, but this does not
affect our construction. Also, the pair  is not considered at
all and serves only as a placeholder for the -states.  Consider a block
permutation , where .
Each element , for all  can be chosen
from one of  blocks. There are  ways of ordering the blocks themselves.
Hence there are  ways of choosing a block permutation in each
branch. Since, we consider -trees that always have  disjoint
branches/paths there are  ways of choosing block
permutations in all branches. But, . Since  and Stirling's approximation gives us
, this is equal to
 or
, which is . Hence, the
Safra-Schwoon construction generates  -trees, which are
states of the DRW, while our construction gives a bound of  on
the number of states of the constructed DPW/DRW. Since, the bounds for the
Safra-Schwoon construction are obtained by counting (Q,H)-trees without names,
the same bounds work when constructing a DPW from an NSW using compact
(Q,H)-trees as described by Piterman\cite{piterman}.


Hence, its has been effectively demonstrated that our construction for
determinization of -automata using generalized witness sets, results in
an improved worst case complexity bound for NSW determinization when the number
of pairs of the NSW is . Since, our construction constructs deterministic
parity automata and complementing parity automata is trivial, the same arguments
can be used to show an improved upper bound for NRW determinization. 

In the following we show another interesting consequence of our construction. We
show a new lower bound on the number of states of any -automaton
accepting a given -regular language. Interestingly, this lower bound on
the number of states is a function of the Rabin index of the -regular
language.






\section{A new lower bound for -automata}



demonstrate a new lower bound on the number of states of any
-automaton that uses an acceptance condition based on infinity
sets to accept a given -regular language . Interestingly,
this lower bound is a function of the Rabin index of the
-regular language. The Rabin index of an -regular
language is defined as follows.

\begin{definition}[Rabin Index]
\label{ri}
Let  be the set of all -regular languages that are
accepted by DRW with  or less number of pairs. For any -regular
language  the smallest  such that  is called the
Rabin index of .  

\end{definition}

Wagner \cite{wagner} and Kaminski\cite{kaminski} showed that the Rabin
index is a property of an -regular language and not of the
deterministic pairs automaton accepting the given language.  They also
provided a characterization of the Rabin index in terms of structural
properties of deterministic automata accepting a given
-regular language.  We provide below a lower bound on the
number of states of any -automaton that uses an acceptance
condition based on infinity sets and accepts an -regular language
with a given Rabin index.

\begin{theorem}
Given an -regular language  with Rabin index , any
-automaton (deterministic or non-deterministic) that uses an
acceptance condition based on infinity sets and accepts  must have
at least  states.
\end{theorem}
\begin{proof}
\noindent {\bf Proof :} Let  be an -automaton with 
states that uses an acceptance condition based on infinity sets and
accepts .  Using the construction of Section (\ref{sec:inf-set}),
we can obtain an equivalent DPW with at most  states and
 parity acceptance sets.  This DPW can be
interpreted as an equivalent DRW with the same number of states and at
most  Rabin acceptance pairs.  By definition of Rabin
index we must have .  It follows that . \qed
\end{proof}



\section{Conclusion}

In this paper, we presented a new construction for determinization
of -automata whose acceptance condition is based on the notion
of infinity sets. We extended the Safra/Piterman construction for NSW
determinization using the concept of generalized witness sets to
construct an equivalent DPW.  We demonstrated, by way of an example,
that there are families of NSW with  states and  pairs for
which our construction gives a DPW with better worst case complexity
bounds than the Safra/Piterman construction.  Effectively, we have
improved the worst case complexity for NSW/NRW determinization.  Also,
there is no known direct determinization procedure for NMW; every
known procedure uses an indirect method by first translating the NMW
to either an NSW or an NBW and then using determinization on it. Our
method provides a direct determinization construction for NMW. As an
easy corollary of our construction, we demonstrate a new lower bound
on the number of states of an -automaton accepting a given
-regular language, as a function of the Rabin index of the
language.















\bibliographystyle{plain}
\bibliography{tcs-infset}








\end{document}
