

\typeout{IJCAI-19 Instructions for Authors}



\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
\usepackage{ijcai19}

\usepackage{times}
\usepackage{xcolor}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb} 
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{bm}
\urlstyle{same}
\usepackage{multirow}
\long\def\zhcomment#1{{\color{blue}{\bf ZH: }{\small [#1]}}}

\title{3D Graph Convolutional Networks with Temporal Graphs: A Spatial Information Free Framework For Traffic Forecasting}

 \author{
Bing Yu \thanks{Equal contributions.}, 
 Mengzhang Li, 
 Jiyong Zhang, 
 Zhanxing Zhu \thanks{Corresponding author.}
 \\
 \affiliations
 School of Mathematical Sciences, Peking University, Beijing, China\\
 Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, China\\
 Center for Data Science, Peking University, Beijing, China\\
 Beijing Institute of Big Data Research (BIBDR), Beijing, China\\
 School of Automation, Hangzhou Dianzi University, Hangzhou, China\\
 \emails
 \{byu,mcmong,zhanxing.zhu\}@pku.edu.cn 
 }

\begin{document}
\maketitle
\begin{abstract}
Spatio-temporal prediction plays an important role in many application areas especially in traffic domain. However, due to complicated spatio-temporal dependency and high non-linear dynamics in road networks, traffic prediction task is still  challenging. Existing works either exhibit heavy training cost or fail to accurately capture the spatio-temporal patterns, also ignore the correlation between distant roads that share the similar patterns. In this paper, we propose a novel deep learning framework to overcome these issues: 3D Temporal Graph Convolutional Networks (3D-TGCN). Two novel components of our model are introduced. (1) Instead of constructing the road graph based on spatial information, we learn it by comparing the similarity between time series for each road, thus providing a spatial information free framework. (2) We propose an original 3D graph convolution model to model the spatio-temporal data more accurately. Empirical results show that 3D-TGCN could outperform state-of-the-art baselines. 
\end{abstract}

\section{Introduction}
Traffic speed prediction is a crucial task for many key purposes in intelligent traffic systems and urban planning. For example, it is useful for not only explicit tasks such as calculating how many lanes a road should have, monitoring whether some places have a traffic jam, but it can also reflect road conditions for downstream traffic problems, e.g., employing it as an important feature for estimating time of arrival, route planning and traffic light control.

In traffic forecasting problems, we typically choose density \cite{kriegel2008statistical}, speed \cite{ma2015long} and volume \cite{okutani1984dynamic} as indicators to characterize current traffic conditions. The traffic forecasting problem can be categorized into three types, namely, based on the length of prediction, i.e., short-term (less than 30 min) \cite{vlahogianni2005optimized} and long term(30  60 min) \cite{ostring2001influence}, based on the data source, i.e., fixed sensors on several roads \cite{li2018diffusion} and moving GPS trajectories treated with map-matching algorithm \cite{castro2012urban}, and based on the road type, i.e., urban road \cite{stathopoulos2003multivariate} and highway \cite{fitzpatrick2000speed}. These prediction types are  challenging due to the complexity of spatio-temporal dependencies and particularly the uncertainty of long-term forecasting. 

Before data-driven approaches spring up, researchers usually apply mathematical tools such as differential equations and traditional traffic knowledge to simulate traffic behaviour by numerical simulation~\cite{vlahogianni2015computtionl}. This makes strong assumptions, such as drivers' identical behaviour and no sudden accidents. In the past several decades, many statistical and machine learning methods such as Auto-Regressive Integrated Moving Average (ARIMA) models \cite{yu2004switching,williams2003modeling}, support vector regression (SVR) \cite{hong2011traffic}  
were proposed. However, these methods rely on the stationary assumption of time series that are hard to model highly non-linear traffic flow and they ignore the correlation between different roads. Meanwhile, some works consider spatial structure of input data, namely, applying convolutional neural network (CNN) to capture the adjacent correlation and recurrent neural network (RNN) or long short-term memory (LSTM) network on time axis  \cite{ma2017learning,wu2016short,zhao2017lstm}. However, normal convolutional operation applies on grid structures such as images and videos, not suitable for traffic networks; and training of RNN, LSTM networks is time consuming and difficult.

To model temporal pattern and spatial dependencies effectively, recent works introduce graph convolutional network (GCN) to learn the traffic networks~\cite{li2018diffusion,defferrard2016convolutional}. DCRNN~\cite{li2018diffusion} utilizes the bi-directional random walks on the traffic graph to model spatial information; and captures temporal dynamics by gated recurrent units (GRU). This sequence-to-sequence model performs well at the cost of very expensive computation during training. STGCN \cite{yuspatio} relies on graph convolution on spatial domain and 1-D convolution along time axis. Though STGCN could significantly save training time due to its pure convolution operations, it processes graph information and time series separately, unfortunately, which might ignore accurately modeling the interaction between spatial and temporal dynamics. 
 
 On the other hand, existing graph-based prediction approaches consider the relationship between roads by  relying on   the graph constructed based on the spatial distance (e.g. GPS distance), or road connectivity. However, in some practical scenarios, the spatial adjacency matrix is difficult to generate, since for some free editable maps such as OpenStreetMap \cite{haklay2008openstreetmap}, acquiring up-to-date and  accurate spatial topology information is hard. Meanwhile, the service of commercial map is expensive and its API will constrain query times for distance calculation\footnote{For example, Baidu Map, one of the biggest commercial map app around the world, provides individual developers with at most 30, 000 query times per day and its full basic service costs 10 thousand dollars per month. See \url{http://lbsyun.baidu.com/apiconsole/auth/privilege}.}.
  More importantly, we argue that this way of graph construction unfortunately ignores the \emph{correlation between distant roads that share the similar temporal pattern}.  For instance, at rush hours, most roads near office buildings that have similar traffic patterns will encounter traffic jams in the same period. Both of these influence could be extracted from the time series themselves.

To overcome the drawbacks above, we propose a novel methodology for improving traffic prediction from aspects of both model design and graph construction. To  extract  better spatio-temporal dependencies, we propose a 3D graph convolution network  where 3D convolution is applied to simultaneously learn the spatial and temporal patterns together. Furthermore, we offer a spatial information free approach for constructing the graph for traffic network, purely relying on the similarity of time series for each road. This new proposal could capture more effective patterns between different roads than the spatial graph, facilitating superior prediction performance.   
The contributions of this work can be summarized as follows.  
\begin{enumerate}
\item We create a 3D GCN model to jointly learn the static road graph and temporal dynamics together. This new network structure strikes a better balance between training efficiency and effectiveness of feature learning.
\item Instead of using spatial information, we construct the adjacency matrix between nodes only according to the time series similarity  by dynamic time warping (DTW) algorithm. The difference between the two types of graph construction is presented in Figure~\ref{fig:stg}. It solves the difficulty of acquirement of geographic information. We empirically show that the performance of this temporal graph performs much better than spatial graph. 
 To the best of our knowledge, it is the first time to put aside spatial adjacency matrix and construct spatio-temporal graph by a data-driven method which extracts effective features from road networks' time series themselves.
\item We conduct extensive experiments on two open large-scale real-world datasets. Results show both of 3D GCN model and our spatial information free graph obtains significant improvement over state-of-the-art baseline methods.
\end{enumerate}

\begin{figure}
	\begin{minipage}[t]{0.5\linewidth}
		\centering
		\includegraphics[width=1.7in]{./spatial.png}
	\end{minipage}\begin{minipage}[t]{0.5\linewidth}
		\centering
		\includegraphics[width=1.7in]{./temporal.png}
	\end{minipage}
	\caption{\label{fig:stg} Comparison between the constructed graphs based on spatial distance and similarity of time series, respectively.}
\end{figure}
\section{Preliminary}
\subsection{Traffic Forecasting Problem}
We can represent the road network as a graph , where  is a finite set of nodes , corresponding to observation of  sensors or roads;  is a set of edges and  is a weighted adjacency matrix representing the nodes proximity (e.g. spatial distance or temporal similarity). Denote the observed graph signal , the element of which means observed traffic flow of each sensor. Let  represents the graph signal on time step . The aim of traffic forecasting is learning a function  from previous  speed observations to predict next -th traffic speed from  correlated sensors on the road network. 

\subsection{Convolution on graphs}
Different from normal convolutional operation which processes regular grids on images or videos, graph convolution operation mainly has two types. One is based on the spectrum of the graph Laplacian, namely, extending convolutions to graphs in spectral domain by finding the corresponding Fourier basis~\cite{bruna2013spectral}. The other is generalizing spatial neighbours by rearranging the neighbours of vertices in a graph to apply regular convolutional operation~\cite{niepert2016learning}. 

Graph convolutional operation based on the spectrum is able to extract local features with different reception fields from non-Euclidean structures\cite{hammond2011wavelets}. It is defined over a graph , where  is the set of all vertices in this graph and  is the adjacency matrix whose entries represent certain distance between vertices. Let its normalized graph Laplacian matrix be , where  is an identity matrix,  is the degree matrix with .  is the Fourier basis which is composed of eigenvectors of Laplacian matrix . The graph signal  is filtered by a diagonal matrix kernel  with multiplication between  and :

where the kernel  is a group of parameters to be trained,  and  denotes the output of this GCN layer.

To reduce the number of parameters and generate a kernel which has better spatial localization, the kernel  can be redesigned as the Chebshev polynomial , It has a truncated order  and utilizes the largest eigenvalue of  to rescale :  \cite{defferrard2016convolutional}. 

Then we could reformulate Equation \ref{gcn_1st} into:


where  is the scaled Laplacian and  are parameters which could be trained by Back Propagation.



\subsection{Similarity of Temporal Sequences}
 Generally speaking, the methods for measuring the similarity between time series can be divided into three categories: (1) timestep-based, such as Euclidean distance reflecting point-wise temporal similarity; (2) shape-based, such as Dynamic Time Warping~\cite{berndt1994using} according to the trend appearance; (3) change-based, such as Gaussian Mixture Model(GMM)\cite{povinelli2004time} which reflects similarity of data generation process. 

In this work, we utilize Dynamic Time Warping to measure similarity  i.e., the spatial shape of time series, between different roads to predict future time series. Given two time series  and  whose length are  and . We first introduce a series distance matrix  whose entry is Euclidean distance of two series points . Then we can define the cost matrix (accumulated distance matrix) {}:
\begin{small}

\end{small}

After several iterations of  and  (i.e., each of them increases from 1 to  and ),  is the final distance between  and  with the best alignment which can represent the similarity between two time series.

From Equation \ref{mc} we can tell that Dynamic Time Warping is an algorithm based on dynamic programming and its core is solving the warping curve, i.e., matchup of series points  and . In other words the "warping path"

is generated through iterations of Equation \ref{mc}. Its element  means matchup of  and . The warping path  starts from  and ends with  thus every series points of  and  must appear in . Moreover,  and  in  must increase monotonically to avoid crossover of each matchup. For instance, given  and  then  and .

\section{Proposed Model: 3D-TGCN}
In this section, we explicitly formalize the spatio-temporal traffic prediction problem and describe our \textit{3D Temporal Graph Convolutional Networks}.

\subsection{Graph Generation}
Different from those proposed models that requires spatial adjacency matrix, 3D-TGCN could learn those roads' interior temporal pattern by calculating their corresponding time series' distance. This way of graph construction is completely data-driven, helping to capture more effective information than the priori given spatial information. For instance, if traffic data are aggregated every 5 minutes then each road has 288 time steps in one day. Given time series  for one road and time series  of another, then we could utilize Dynamic Time Warping algorithm to find optimal match and calculate distance of their time series.

As shown in Figure \ref{fig:dtw}, given two roads' time series whose length is 288 then we could achieve their warping path. The distance of those two time series could be calculated by Equation \ref{mc} (i.e.,  in this case). From the figure we could tell the warping path elongates along the diagonal since the trend of two time series are similar, consequently the difference between match  and  of the element  of warping path  are close.
 \begin{figure}
\centering
\includegraphics[height=2in]{./dtw.png}
 \caption{\label{fig:dtw}Two time series of different roads in one day and their warping path calculated by Dynamic Time Warping algorithm.}
 \end{figure}

Then we generate topology network . For each road , we pick up its top  most similar roads  and let  while others . Moreover, it is possible that  while , then we reassign  if . After this treatment, the constructed  could be applied in our 3D-TGCN model, described in the following.

\subsection{3D Graph Convolution Networks}

\begin{figure*}[ht!]
\centering
\includegraphics[width=7in]{./tgcn.png}
\caption{\label{fig:tgcn}  Network architecture of 3D-TGCN}
\end{figure*}

\textbf{3D Graph Convolutional Layer}

Many existing approaches deal with  spatial and temporal dependencies separately since they utilize graph convolution on spatial dependencies and leverage 1-D CNN~\cite{yuspatio} or RNN-based models~\cite{li2018diffusion} to extract temporal dependency along time axis. For instance, if 1-D CNN was deployed in the temporal direction, the output of each 1-D convolution could be rewritten as,


where  is the size of convolutional kernel on time-axis at time step .

We now propose a 3D graph convolutional operation on all dimensions, including graph topology and temporal direction. 



For the input  () with  channels, it can be extended to multi-dimensional arrays . The 3D graph convolutional layer integrates all dimensions together: 


where  and  are the size of input and output of this 3D  graph convolutional layer,  respectively and  is the parameter to be trained in each output channel of this layer. From Equation \ref{g2}, the graph convolution operator of each layer could be denoted as "" with . 

The 3D graph convolutional layer scans  neighbours on time-axis without padding and -order neighbourhood of temporal graph  at the same time. This method shortens the length of sequences by  each time. It follows by a gated linear units (GLU) whose input is:  where  is split in half with the size of  channels. As a result, the final output of 3D graph convolutional layer is  where  denotes the Hadamard product and  denotes the sigmoid function.

This integrated design of 3D graph convolution allows us 
to jointly learn graph structure and temporal dynamics as a whole. It is also easy for building such multi-layer 3D graph convolutional structures. 



\subsection{The Entire Architecture of 3D-TGCN Network}
Figure~\ref{fig:tgcn} sketches the overall architecture of our proposed  3D-TGCN model. It consists of four 3D graph convolutional blocks (3D-Conv blocks), one output block. Each 3D-Conv block contains two 3D graph convolutional layers and a layer normalization layer to prevent overfitting. The output block consists of several 3D graph convolutional layers or 1D temporal convolutional layers and a weight sharing fully-connected output layer to obtain the prediction . 

The  loss and  loss will be used together to train our model and the loss function of 3D-TGCN model could be formulated as below:


In summary, our 3D-TGCN model has several advantages:
\begin{itemize}
\item 3D-TGCN does not require  spatial adjacency matrix, instead, it constructs temporal adjacency matrix to learn temporal patterns of different roads in a pure data-driven way. 
\item The 3D graph convolution integrates all dimensions (i.e., time-axis on each road and correlation between different roads) into one graph convolutional networks. This design presents a better balance between training efficiency and effectiveness of feature learning on complex spatio-temporal graph, compared with STGCN and DCRNN. 
\item 3D-TGCN could be applied into many other tasks that have spatio-temporal features. Its universal framework can learn spatio-temporal dependencies between each participant. By calculating similarity between time series, 3D-TGCN could extract  important temporal pattern of different participants which might appear uncorrelated and make accurate prediction.
\end{itemize}


\section{Experiments}
\begin{table*}[h]
	\centering
	\resizebox{\textwidth}{!}{
		\begin{tabular}{c||c|c|c||c|c|c}
			\hline \hline
			\multirow{2}{*}{Model} & \multicolumn{3}{|c||}{PeMSD7(M) (15/ 30/ 60 min)} & \multicolumn{3}{c}{PeMSD7(L) (15/ 30/ 60min)}\\ \cline{2-7}
			& MAE & MAPE (\%) & RMSE & MAE & MAPE (\%) & RMSE \\ \hline \hline
			HA & 4.01 & 10.61 & 7.20 & 4.60 & 12.50 & 8.05 \\ \hline
			LSVR & 2.49/ 3.46/ 4.94 & 5.91/ 8.42/ 12.41 & 4.55/ 6.44/ 9.08 & 2.69/ 3.85/ 4.79 & 6.27/ 9.48/ 12.42 & 4.88/ 7.10/ 8.72 \\ \hline
			FNN & 2.53/ 3.73/ 5.28 & 6.05/ 9.48/ 13.73 & 4.46/ 6.46/ 8.75 & 2.61/ 3.71/ 5.36 & 6.11/ 9.20/ 14.68 & 4.74/ 6.76/ 9.09 \\ \hline
			FC-LSTM & 3.57/ 3.92/ 4.16 & 8.60/ 9.55/ 10.10 & 6.20/ 7.03/ 7.51 & 4.36/ 4.51/ 4.66 & 11.10/ 11.41/ 11.69 & 7.68/ 7.94/ 8.20\\ \hline
			STGCN & 2.24/ 3.02/ 4.01 & 5.20/ 7.27/ 9.77 & 4.07/ 5.70/ 7.55 & 2.37/ 3.27/ 4.35 & 5.56/ 7.98/ 11.17 & 4.32/ 6.21/ 8.27\\ \hline
			DCRNN & 2.25/ 2.98/ 3.83 & 5.30/ 7.39/ 9.85 & 4.04/ 5.58/ 7.19 & 2.36/ 3.24/ 4.34 & 5.51/ 8.18/ 11.91 & 4.45/ 6.31/ 8.33\\ \hline
			3D-TGCN &\textbf{2.23}/ \textbf{2.97}/ \textbf{3.65}& \textbf{5.13}/ \textbf{7.08}/ \textbf{8.79}& \textbf{3.93}/ \textbf{5.31}/ \textbf{6.66} & \textbf{2.27}/ \textbf{3.16}/ \textbf{3.79} & \textbf{5.31}/ \textbf{7.85}/ \textbf{9.76} & \textbf{4.18}/ \textbf{5.71}/ \textbf{7.13} \\ \hline


			 \hline
	\end{tabular}}
	\caption{Performance comparison of different models on PeMSD7 dataset.}
	\label{tab:pemsd7}
\end{table*}

\subsection{Datasets}
Our model is verified on two real-world traffic datasets which are used by two related state-of-the-art models: STGCN \cite{yuspatio} and DCRNN \cite{li2018diffusion}. 

\paragraph{PeMSD7} has a medium and a large scale \textbf{PeMSD7 (M)} and \textbf{PeMSD7 (L)} containing 228 and 1, 026 sensors separately among the District 7 of California. The data ranges from May and June of 2012 which are all at weekdays. 

\paragraph{PEMS-BAY} has 325 sensors in Bay Area and its collecting time is 6 months, ranging from Jan 2017 to June 2017.

These datasets are collected from California Transportation Agencies (Caltrans) Performance Measurement System (PeMS) in real-time by over 39, 000 sensor stations, which are deployed in the major metropolitan areas of California highway system\cite{chen2001freeway}. It is aggregated into 5-minute interval (228 time steps per day).
To compared strictly with those state-of-the-art models, we  follow all data preprocessing methods in each paper such as (1) the proportion and content of training, validation and test set, (2) utilizing the Gaussian kernel\cite{shuman2012emerging} to construct the spatial adjacency matrix.

\subsection{Experimental Settings and Baselines}
All experiments are compiled and tested on a Linux cluster(CPU: Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.20GHz, GPU: Tesla P40). All model parameters are fine-tuned by gird search based on performance on validation set. Each prediction task uses past 60 minutes (i.e., 12 time steps are in time window ) to forecast traffic conditions in the next 15, 30 and 60 minutes ().

\paragraph{Evaluation Metric}
Several criteria are introduced to evaluate 3D-TGCN, including the Mean Absolute Percentage Errors (MAPE), the Mean Absolute Errors (MAE) and the Root Mean Squared Errors (RMSE). All of them are used widely in traffic prediction tasks.

\textbf{3D-TGCN model}
The channels of each 3D graph convolutional layer in 3D-Conv block is 64. Receptive field of temporal graph  is set to 3 and  is set to 2. We use GLU as activation function in 3d-Conv block and sigmoid in output block. The learning rate  is set to  with a decay rate of  after  epochs. We train our models by minimizing the mean square error and mean absolute error using Adam for  epochs with batch size as . 

\paragraph{Baselines}
We compare our model with several baselines as follows:
\begin{itemize}
\item \textbf{HA}  Historical Average (HA), which treats the traffic speed value as a seasonal process and use weighted average of past several seasons as prediction value.
\item \textbf{SVR} Support Vector Regression (SVR), which uses linear support vector machine for regression tasks.
\item \textbf{FNN} Feed-Forward Neural Network (FNN), which is a classical neural network architecture with two hidden layers and loss function is RMSE.
\item \textbf{FC-LSTM} Full-Connected LSTM~\cite{sutskever2014sequence}, which is a Recurrent Neural Network with fully connected LSTM hidden units.
\item \textbf{DCRNN} Diffusion Convolutional Rrcurrent Neural Network(DCRNN)~\cite{li2018diffusion}, which models spatiotemporal dependencies with graph convolution into gated recurrent unit.
\item \textbf{STGCN} Spatio-Temporal Graph Convolutional Networks(STGCN)~\cite{yuspatio}, which models spatiotemporal dependencies with graph convolution into convolution structures.
\end{itemize}
All neural network based models are implemented in  Tensorflow~\cite{abadi2016tensorflow}.

\subsection{Experiment Results}
In this section, we compare our model with those baselines on the two datasets, shown in Table~\ref{tab:pemsd7} and \ref{tab:pems-bay}. It is obvious to observe that,  although all methods could perform well in short-term prediction, their performance varies greatly in long-term prediction. Deep learning models generally can achieve better performance than traditional machine learning models. Especially, STGCN and DCRNN, both of them have achieved significant improvement over other deep learning approaches since they extract additional information from spatial topology graph.  3D-TGCN could achieve the state-of-art performance especially when it only combines with temporal graph, demonstrating the importance of our proposed graph construction.

\paragraph{Accumulated Error of Sequence-to-Sequence Prediction}
RNN-based model and CNN model are different especially on the format of their output: while RNN-based ones conduct the next few time steps recursively, GCNs could predict few time steps recursively or directly predict the target time step.  Generally, RNN-based model performs better in time series tasks since the strategies such as  scheduled sampling~\cite{bengio2015scheduled} which can reduce accumulated error could be adopted on the sequence-to-sequence architecture. To compare these two types of outputs, we check the performance of 3D-TGCN: (1) predicting directly next -th time step, (2) predicting the value of next  time steps recursively. As we can see from Table \ref{tab:accumulated_error}, 3D-TGCN is more suitable for single step prediction task, it performs worse when predicting recursively due to accumulated error since its performance is close to DCRNN. However, 3D-TGCN could achieve better training efficiency since convolution-type models have less parameters than RNN-based models and STGCN.

\begin{table}
	\centering
	\resizebox{0.48\textwidth}{!}{
		\begin{tabular}{c||c|c|c}
			\hline \hline
			\multirow{2}{*}{Model} & \multicolumn{3}{|c}{PeMSD7(M) (15/ 30/ 60 min)} \\ \cline{2-4}
			& MAE & MAPE (\%) & RMSE \\ \hline \hline
			DCRNN& 2.25/ 2.98/ 3.83 & 5.30/ 7.39/ 9.85 & 4.04/ 5.58/ 7.19 \\ \hline
			STGCN & 2.24/ 3.02/ 4.01 & 5.20/ 7.27/ 9.77 & 4.07/ 5.70/ 7.55\\ \hline
			3D-TGCN (iteration)& 2.25/ 2.97/ 3.77 & 5.17/ 7.10 9.05 & 4.06/ 5.59/ 7.19 \\ \hline
			3D-TGCN (straightly) & 2.23/ 2.97/ 3.65 & 5.13/ 7.08/ 8.79& 3.93/ 5.31/ 6.66 \\ \hline
	\end{tabular}}
	\caption{Performance comparison of iteration / no iteration.}
	\label{tab:accumulated_error}
\end{table}

\begin{table}
	\centering
	\resizebox{0.48\textwidth}{!}{
		\begin{tabular}{c||c|c|c}
			\hline \hline
			\multirow{2}{*}{Model} & \multicolumn{3}{|c}{PeMSD7(M) (15/ 30/ 60 min)} \\ \cline{2-4}
			& MAE & MAPE (\%) & RMSE \\ \hline \hline
			STGCN (spatial) & 2.24/ 3.02/ 4.01 & 5.20/ 7.27/ 9.77 & 4.07/ 5.70/ 7.55\\ \hline
			STGCN (temporal) & 2.24/ 3.02/ 3.92 & 5.19/ 7.13/ 9.29 & 4.06/ 5.61/ 7.15 \\ \hline
			DCRNN (spatial) & 2.25/ 2.98/ 3.83 & 5.30/ 7.39/ 9.85 & 4.04/ 5.58/ 7.19 \\ \hline
			DCRNN (temporal) & 2.26/ 2.98/ 3.66 & 5.33/ 7.33/ 9.27 & 4.04/ 5.50/ 6.73 \\ \hline
			TGCN (spatial) &  2.24/ 3.00/ 3.76 & 5.21/ 7.12/ 8.96 &  3.96/ 5.37/ \textbf{6.64}\\ \hline
			TGCN (temporal) & \textbf{2.23}/ \textbf{2.97}/ \textbf{3.65} & \textbf{5.13}/ \textbf{7.08}/ \textbf{8.79}& \textbf{3.93}/ \textbf{5.31}/ 6.66 \\ \hline
	\end{tabular}}
	\caption{Performance comparison of spatial and temporal matrices.}
	\label{tab:t_and_s}
\end{table}

\begin{table}
	\centering
	\resizebox{0.48\textwidth}{!}{
		\begin{tabular}{c||c|c|c}
			\hline \hline
			\multirow{2}{*}{Model} & \multicolumn{3}{|c}{PEMS-BAY (15/ 30/ 60 min)} \\ \cline{2-4}
			& MAE & MAPE (\%) & RMSE \\ \hline \hline
			HA & 2.88 & 6.80 & 5.59 \\ \hline
			SVR & 1.85/ 2.48/ 3.28 & 3.80/ 5.50/ 8.00 & 3.59/ 5.18/ 7.08\\ \hline
			FNN & 1.49/ 2.04/ 2.88 & 3.09/ 4.59/ 7.11 & 3.25/ 4.45/ 5.99 \\ \hline
			FC-LSTM & 2.20/ 2.34/ 2.55 & 4.85/ 5.30/ 5.84 & 4.28/ 4.74/ 5.31 \\ \hline
			STGCN & 1.41/ 1.84/ 2.37 & 3.02/ 4.19/ 5.39 & 3.02/ 4.19/ 5.27 \\ \hline
			DCRNN & 1.38/ 1.74/ 2.07 & 2.9/ 3.9/ 4.9 & 2.95/ 3.97/ 4.74\\ \hline
			3D-TGCN & \textbf{1.34}/ \textbf{1.69}/ \textbf{2.07} & \textbf{2.78}/ \textbf{3.76}/ \textbf{4.76} & \textbf{2.79}/ \textbf{3.71}/ \textbf{4.56}\\ \hline
			\hline
	\end{tabular}}
	\caption{Performance comparison of different models on PEMS-BAY dataset.}
	\label{tab:pems-bay}
\end{table}


\paragraph{Temporal v.s. Spatial Pattern} 
Previous works  focus on incorporating spatial topology information of roads into time series prediction. Differently, our model switches to their dependencies of temporal patterns and has achieved the best performance on both short and long-term forecasting. The results of two types of graph construction are shown in Table~\ref{tab:t_and_s}. The performance of 3D-TGCN on dataset PeMSD7 is extremely well because road network of PeMSD7 is more complicated and systematic.

3D-TGCN does not require priori knowledge of spatial topology. On the contrary, it builds graphs on temporal dependency. As illustrated in Figure~\ref{fig:stg}, the left panel is spatial graph and right is temporal graph, the sparsity of them are both 5\%. The reason why temporal graph tends to be better than the spatial one is intuitive: (1) realistic data is full of noise, similar temporal dependency of different roads (maybe at distance) is much more important than spatial causality of neighbors; (2) traffic prediction is a time-series prediction task thus learning temporal pattern is more directly meaningful. 

An involuntary doubt about dynamic time warping is its computational complexity. Although  is somewhat costly, in traffic prediction problem it is acceptable since the length of time series is 288 when time step is 5 min. Dataset PeMSD7(L) is one of biggest dataset in academic traffic speed field which has 1026 roads, in which the scalable version of DTW algorithm is still acceptable.


\section{Conclusion and Future works}
In this paper, we propose an original and effective deep learning framework 3D-TGCN for traffic prediction. It learns the relations between roads by comparing temporal similarity from the roads' times series and merges spatial and temporal information into 3D convolution simultaneously in the 3D graph convolutional layers. Numerical experiments show our model outperforms existing state-of-the-art models on two real-world datasets. Especially, our model does not require spatial topology. 3D-TGCN also achieves faster training  and better convergence. Our discovery of the new way of graph generation paves a  promising way for future graph-based learning approaches, due to the no need for spatial information based adjacency matrix, which in many cases are difficult to generate or achieve.  

\appendix

\bibliographystyle{named}
\bibliography{gcn3d}

\end{document}
