

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2019}
\usepackage{times}
\usepackage{latexsym}
\usepackage{bm}
\usepackage{multirow}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{xspace}
\usepackage{url}

\aclfinalcopy 



\newcommand\BibTeX{B\textsc{ib}\TeX}

\newcommand\BERTBASE{BERT\xspace}
\newcommand\BERTLARGE{BERT\xspace}
\newcommand\OCNBASE{OCN\xspace}
\newcommand\OCNLARGE{OCN\xspace}

\title{Option Comparison Network for Multiple-choice Reading Comprehension}

\author{Qiu Ran\thanks{\ \ indicates equal contribution}, Peng Li\footnotemark[1], Weiwei Hu, Jie Zhou \\
  Pattern Recognition Center, WeChat AI, Tencent Inc, China \\
  \texttt{\{soulcaptran,patrickpli,weiweihu,withtomzhou\}@tencent.com}}

\date{}

\begin{document}
\maketitle
\begin{abstract}
Multiple-choice reading comprehension (MCRC) is the task of selecting the correct answer from multiple options given a question and an article. Existing MCRC models typically either read each option independently or compute a fixed-length representation for each option before comparing them. However, humans typically compare the options at multiple-granularity level before reading the article in detail to make reasoning more efficient. Mimicking humans, we propose an option comparison network (OCN) for MCRC which compares options at word-level to better identify their correlations to help reasoning. Specially, each option is encoded into a vector sequence using a skimmer to retain fine-grained information as much as possible. An attention mechanism is leveraged to compare these sequences vector-by-vector to identify more subtle correlations between options, which is potentially valuable for reasoning. Experimental results on the human English exam MCRC dataset RACE show that our model outperforms existing methods significantly. Moreover, it is also the first model that surpasses Amazon Mechanical Turker performance on the whole dataset.
\end{abstract}

\begin{table}
    \small
    \centering
    \begin{tabular}{|p{0.95\columnwidth}|}
    \hline
    {\bf Article:} \\
    Are you a crazy chocolate fan? Have you heard about Hershey's Kisses? Do you love the movie Charlie and the Chocolate Factory? If your answer was, "yes", to any of the questions, then my experience will make you jealous. I just went to the famous Hershey Chocolate Factory! ...... When we arrived at the factory, we realized that this was much more than just a factory. The whole town is a chocolate-themed amusement park ......
Jason, our tour guide, began telling us about this quiet little town ......
Jason went on, ``The factory first started on a small farm. It developed very fast. So they built this town for factory workers to live in. Then they built hotels, hospitals, stadiums, theaters and even museums with the theme of chocolate. Isn't that cool?''
    ``Yes, a hundred times yes!'' I yelled ( ) with delight.\\
    {\bf Question:}\\
    What can we know from the writer's answer to the guide?\\
    {\bf Options:}\\
    A. The writer had never heard about Hershey Chocolate. \\
    B. The writer didn't want to visit the factory any more. \\
    C. The writer had visited the factory before. \\
    D. The writer couldn't wait to visit the factory. \\
    {\bf Answer:} D\\
    \hline
    \end{tabular}
    \caption{An MCRC example from the RACE dataset.}
    \label{tab:example}
\end{table}

\section{Introduction}
\label{sec:intro}

Multiple-choice reading comprehension (MCRC) aims to selecting the correct answer from a set of options given a question and an article. As MCRC requires both understanding of natural language and world knowledge to distinguish correct answers from distracting options, it is challenging for machine and a good testbed for artificial intelligence. With the rapid development of deep learning, various neural models have been proposed for MCRC and achieve promising results in recent years~\cite{StanfordAR,yin2016HCQA,trischler2016,GAReader,MRU,ElimiNet,HAF,co-matching,DFN,Reading-Strategies-Model,shuailiang2019DCMN}.

Comparing options before reading the article in detail is a commonly used strategy for humans when solving MCRC problems. By comparing the options, the correlations between the options can be identified and people only need to pay attention to the information related to the correlations when reading the article. As a result, questions can be answered more efficiently and effectively. Taking Table~\ref{tab:example} as an example, by comparing option B and D, people may identify that the key difference is whether the writer would like to visit the factory, which can be decided easily by skimming the article.

However, the strategy is not adopted by most existing MCRC methods.
The Stanford AR~\cite{StanfordAR} and GA Reader~\cite{GAReader} variants used in~\cite{RACE} encode question and article independent of options, ignoring their correlations.
In contrast, \newcite{co-matching} and \newcite{shuailiang2019DCMN} leverage sophisticated matching mechanisms to gather the correlation information, while \newcite{Reading-Strategies-Model} relies on a pre-trained language model~\cite{OpenAIGPT} to extract such information. 
Nevertheless, none of them consider the correlations between options explicitly.
To the best of our knowledge, \cite{HAF} is the only work that considers option correlations explicitly. Whereas, the options are compressed into fixed-length vectors before being compared, which may make it hard for a model to identify subtle differences or similarities between options.

To gather option correlation information more effectively, we propose option comparison network (OCN), a novel method for MCRC which explicitly compares options at word-level to mimic the aforementioned human strategy. Specially, we first use a skimmer network to encode options into vector sequences independently as their features. Then for each option, it is compared with other options {\em one-by-one} at {\em word-level} using an attention-based mechanism in vector space to identify their correlations. Finally, the article is reread with the gathered correlation information to do reasoning and select the correct answer.
As options are compared one-by-one, the correlations between each pair of options can be explicitly identified. By comparing options at word-level, we allow the model to detect subtle correlations more easily.

With a BERT~\cite{BERT} based skimmer, our method outperforms the state-of-the-art baselines with large margins on RACE, a human exam MCRC dataset created by experts for assessing the reading comprehension skills of students, indicating the effectiveness of our model. More importantly, it is the first time that a model surpasses the Amazon Mechanical Turker performance on this dataset.


\section{Option Comparison Network}


Suppose we have a question  with  tokens , an article  with  tokens , and a candidate answer set  with  options . Each option  consists of  tokens .
Formally, MCRC is to select the correct answer  from the candidate answer set  given question  and article .

Our model selects the correct answer from the candidate answer set in four stages. First, we concatenate each (article, question, option) triple into a sequence and use a skimmer to encode them into vector sequences (Sec.~\ref{sec:encoding}). Then an attention-based mechanism is leveraged to compare the options (Sec.~\ref{sec:comparison}). Next the article is reread with the correlation information gathered in last stage as extra input (Sec.~\ref{sec:rereading}). And finally the probabilities for each option to be the correct answer are computed (Sec.~\ref{sec:prediction}). The details will be introduced in the following sections.

\subsection{Option Feature Extraction}
\label{sec:encoding}
A skimmer network is used to skim the options independently together with the question and article to extract option features.
As BERT~\cite{BERT} has been shown to be a powerful feature extractor for various tasks, it is used as the skimmer. Specially, for option , it is concatenated with the question  and article , denoted as ~\footnote{Delimiter [SEP] are added between ,  and . We omit [SEP] from the notation for brevity.}. Then the sequence is fed to BERT to compute their vector space encoding, which is denoted as 

where , , , and  denotes the network defined in~\cite{BERT} \footnote{We refer the readers to~\cite{BERT} for details of .}. 

As question and options are closely related, we use

as features of , where  and  denotes row-wise concatenation.


\subsection{Option Correlation Features Extraction}
\label{sec:comparison}
This module is used to compare options at word level to extract option correlation information to support reasoning. For each option, an attention-based mechanism is used to compare it with all the other options to gather the correlation information.

Given input matrices  and , the attention weight function  specified by the parameter  is defined as

where  denotes column-wise concatenation,  denotes the element-wise multiplication operation, and  is the attention weight matrix.

The option correlation features are extracted in three steps as follows:

First, an option is compared with all other options one-by-one to collect the pairwise correlation information. Specially, for option , the information  gathered from option  is computed as


Then the pairwise correlation information gathered for each option is fused to get the option-wise correlation information, which is defined as

where  and . Note that option  is not compared with itself. 

Finally, an element-wise gating mechanism is leveraged to fuse the option features with the option-wise correlation information to produce the option correlation features . Specially, the gates  are defined as

where  denotes the -th column of , and  is the attentive-pooling of  defined as

The option correlation features  are computed as

Note that  is not compressed into a fixed-length vector, because we believe this will enable our model to utilize the correlation information in a more flexible way.

\subsection{Article Rereading}
\label{sec:rereading}
Mimicking humans, the article will be reread with the option correlation features as extra input to gain deeper understanding. Specially, the co-attention~\cite{DCN} and self-attention~\cite{r-net} mechanisms are adopted for rereading.
First, for each option , co-attention is performed as

Then  is fused with option correlation features  as

where , , and .
Finally, the full-info option representation  for option  is computed with self-attention as

where  and .

\subsection{Answer Prediction}
\label{sec:prediction}
The score  of option  to be the correct answer is computed as

where  performs row-wise max pooling and .

The probability  of option  to be the correct answer is computed as

And the loss function is defined as

where  denotes all trainable parameters,  is the training example number, and  is the ground truth for the -th example.


\begin{table*}
    \vspace{-1em}
	\centering
	\small
	\begin{tabular}{lcccc}
		\toprule
		Model & Pre-training & RACE-M & RACE-H & RACE \\
		\midrule \multicolumn{5}{c}{Single Model} \\
\midrule
		Stanford AR~\cite{StanfordAR} & / & 44.2 & 43.0 & 43.3 \\
		GA Reader~\cite{GAReader} & / & 43.7 & 44.2 & 44.1 \\
		ElimiNet~\cite{ElimiNet} & / & 44.4 & 44.5 & 44.5 \\ HAF~\cite{HAF} & / & 45.0 & 46.4 & 46.0 \\ Hier-Co-Matching~\cite{co-matching} & / & 55.8 & 48.2 & 50.4 \\ DFN~\cite{DFN} & / & 51.5 & 45.7 & 47.4 \\  MRU~\cite{MRU} & / & 57.7 & 47.4 & 50.4 \\ OpenAI GPT~\cite{OpenAIGPT} & GPT & 62.9 & 57.4 & 59.0 \\ Reading Strategies Model~\cite{Reading-Strategies-Model} & GPT & 69.2 & 61.5 & 63.8 \\ DCMN~\cite{shuailiang2019DCMN} & BERT & {\bf 76.7} & 68.5 & 70.9 \\\BERTBASE & BERT & 70.5 & 63.0 & 65.2 \\
		\BERTLARGE & BERT & 76.4 & 68.8 & 71.0 \\
		\OCNBASE & BERT & 71.6 & 64.8 & 66.8 \\
		\OCNLARGE & BERT & {\bf 76.7} & {\bf \underline{69.6}} & {\bf 71.7} \\
		\midrule \multicolumn{5}{c}{Ensemble} \\
\midrule
		GA Reader~\cite{GAReader} & / & / & / & 45.9 \\
		ElimiNet~\cite{ElimiNet} & / & 47.7 & 46.1 & 46.5 \\ DFN~\cite{DFN} & / & 55.6 & 49.4 & 51.2 \\ MRU~\cite{MRU} & / & 60.2 & 50.3 & 53.3 \\ Reading Strategies Model~\cite{Reading-Strategies-Model} & BERT & 72.0 & 64.5 & 66.7 \\ DCMN~\cite{shuailiang2019DCMN} & BERT & 77.9 & \underline{69.8} & 72.1 \\\OCNBASE & BERT & 74.4 & 67.0 & 69.2 \\
		\OCNLARGE & BERT & {\bf 78.4} & {\bf \underline{71.5}} & {\bf \underline{73.5}} \\
		\midrule Amazon Mechanical Turker & / & 85.1 & 69.4 & 73.3 \\
		Human Ceiling Performance & / & 95.4 & 94.2 & 94.5 \\
		\bottomrule
	\end{tabular}
	\caption{Experimental results. The best results in each group are in bold, and those better than Amazon Mechanical Turker are underlined.}
	\label{tab:results}
	\vspace{-1em}
\end{table*}

\section{Experiments}
\subsection{Dataset}



We evaluate our model on RACE~\cite{RACE}, an MCRC dataset collected from the English exams for middle and high school students in China. The dataset is further devided into RACE-M and RACE-H, containing only data from middle school and high school examinations respectively. As the articles, questions and options are generated by English instructors for assessing the reading comprehension skills of humans, the dataset is inherently more difficult than other widely used reading comprehension datasets such as SQuAD~\cite{squad}. Analysis conducted in~\cite{RACE} shows that  of the questions in RACE require reasoning, which is significantly higher than that of SQuAD (). And the most frequent reasoning skills required are detail reasoning, whole-picture understanding, passage summarization, attitude analysis and world knowledge. Therefore, RACE is extremely challenging for MCRC models.

\subsection{Training Details}

Adam optimizer~\cite{adam} is used to train our model. 
The model is trained for 3 epochs with batch size 12 and learning rate  when \BERTBASE is used as the skimmer, and trained for 5 epochs with batch size 24 and learning rate  when \BERTLARGE is used.
For both cases, the learning rate linearly increases from 0.0 to the aforementioned value in the first  training steps and then linearly decays until training is completed. The L2 weight decay  is set to 0.01. Articles, questions and options are trimmed to 400, 30 and 16 tokens respectively for memory and speed consideration.

\subsection{Experimental Results}
We compare our model with various state-of-the-art methods and the results are shown in Table~\ref{tab:results}, where \OCNBASE and \OCNLARGE denote our model with \BERTBASE and \BERTLARGE as the skimmer (Sec.~\ref{sec:encoding}) respectively.
From the results we can observe that:
(1) Our model outperforms the baselines significantly, indicating the effectiveness of our model.
(2) Our ensemble model with \BERTLARGE as the skimmer surpasses Amazon Mechanical Turker on the whole dataset and the margin on the RACE-H subset is significantly large. Moreover, \OCNLARGE also outperforms Amazon Mechanical Turker without ensembling. All these results indicate that our model has learned certain reasoning skills. 
(3) There is still a large gap between human ceiling performance and our model's performance. We believe this is because our model still struggles in complex reasoning as expected.
(4) All the models using pre-trained contextualized representations (GPT~\cite{OpenAIGPT} and BERT) outperform the other models with significantly large margins, indicating pre-training is a promising research direction for learning semantics from unsupervised data.


\begin{table}
	\centering
	\small
	\begin{tabular}{lccc}
		\toprule
		Model & RACE-M & RACE-H & RACE \\
		\midrule
		Ours (\BERTBASE) & 71.6 & 64.8 & 66.8 \\
		w/o Opt. Comp. & 71.5 & 63.9 &  66.1\\
		w/ ELMo & 50.9 & 45.7 & 47.2 \\
		\bottomrule
	\end{tabular}
	\caption{Ablation study. ``Opt. Comp.'' denotes option comparison.}
	\label{tab:ablation}
	\vspace{-1.1em}
\end{table}

The ablation study results are shown in Table~\ref{tab:ablation}. Removing the option comparison component (Sec.~\ref{sec:comparison}) causes significant performance drop, especially on RACE-H, indicating the effectiveness of considering the correlations between options. The performance of our model drops seriously when BERT is replaced with ELMo~\cite{elmo}, suggesting that BERT is a powerful feature extractor that can capture rich semantics.

\section{Conclusion and Future Work}
To leverage option correlations to improve reasoning ability, we propose option comparison network (OCN) for multiple-choice reading comprehension in this work. By representing options as vector sequences and comparing them vector-by-vector, we allow our model to identify the correlations between options more effectively.
Experimental results show that our model outperforms the state-of-the-art baselines significantly and surpasses Amazon Mechanical Turker on the whole RACE dataset for the first time, indicating that our model is effective and has learned certain reasoning skills.


As shown in the ablation study, our model relies on the pre-trained BERT model heavily. However, BERT model is large and slow. How to reduce the model size and improve its speed with acceptable performance drop is an interesting future work.

\bibliography{race-bert}
\bibliographystyle{acl_natbib}

\appendix
\end{document}