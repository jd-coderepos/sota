\documentclass{LMCS}

\usepackage{amssymb,algorithm,algorithmic,graphicx,hyperref,enumerate}

\def\doi{4 (4:15) 2008}
\lmcsheading {\doi}
{1--44}
{}
{}
{Nov.~\phantom{0}2, 2006}
{Dec.~23, 2008}
{}   

\begin{document}

\title{The Wadge Hierarchy of Deterministic Tree Languages\rsuper*}

\author[F.~Murlak]{Filip Murlak}

\address{Institute of Informatics, University of Warsaw, ul.~Banacha
  2, 02--097 Warszawa, Poland}

\email{fmurlak@mimuw.edu.pl}

\thanks{Supported by KBN Grant~4~T11C~042~25.}

\keywords{Wadge hierarchy, deterministic automata, infinite trees, decidability}

\subjclass{F.4.3, F.4.1, F.1.1, F.1.3}

\titlecomment{{\lsuper*}An extended abstract of this paper was
  presented at ICALP'06 in Venice, Italy.}



\begin{abstract} 
We provide a~complete description of the Wadge hierarchy for
deterministically recognisable sets of infinite trees. In particular
we give an elementary procedure to decide if one deterministic tree
language is continuously reducible to another. This extends Wagner's
results on the hierarchy of -regular languages of words to the
case of trees. 
\end{abstract}

\maketitle


\section{Introduction}

Two measures of complexity of recognisable languages of infinite words
or trees have been considered in literature: the index hierarchy,
which reflects the combinatorial complexity of the recognising
automaton and is closely related to -calculus, and the Wadge
hierarchy, which is the refinement of the Borel/projective hierarchy
that gives the deepest insight into the topological complexity of
languages. Klaus Wagner was the first to discover remarkable relations
between the two hierarchies for finite-state recognisable
(-regular) sets of infinite
words~\cite{wagner0}. Subsequently, decision procedures determining an
-regular language's position in both hierarchies were given
\cite{kupferman,kwiatek,wagner}.

For tree automata the index problem is only solved when the input is
a~deterministic automaton \cite{hie,urban}. As for topological
complexity of recognisable tree languages, it goes much higher than
that of -regular languages, which are all
. Indeed, co-B\"uchi automata over trees may recognise
-complete languages \cite{gap}, and Skurczy\'nski
\cite{skurcz} proved that there are even weakly recognisable tree
languages in every finite level of the Borel hierarchy. This may
suggest that in the tree case the topological and combinatorial
complexities diverge. On the other hand, the investigations of the
Borel/projective hierarchy of deterministic languages \cite{split,gap}
reveal some interesting connections with the index hierarchy.

Wagner's results \cite{wagner0,wagner}, giving rise to what is now
called the Wagner hierarchy (see~\cite{perrin}), inspire the search
for a~complete picture of the two hierarchies and the relations
between them for recognisable tree languages. In this paper we
concentrate on the Wadge hierarchy of deterministic tree languages: we give a
full description of the Wadge-equivalence classes forming the
hierarchy, together with a procedure calculating the equivalence class
of a given deterministic language. In particular, we show that the hierarchy has the height , which should be compared with  for regular -languages \cite{wagner},  for deterministic context-free -languages \cite{contextfree},  for -languages recognised by deterministic Turing machines \cite{selivanov}, or an unknown ordinal  for -languages recognised by nondeterministic Turing machines, and the same ordinal  for nondeterministic context-free languages \cite{finkel}.


The key notion of our argument is an adaptation of the Wadge game to
tree languages, redefined entirely in terms of automata. Using this
tool we construct a~collection of canonical automata representing the
Wadge degrees of all deterministic tree languages. Then we provide a~procedure calculating the canonical form of a~given deterministic automaton, which runs within the time of finding the productive states of the automaton (the exact complexity of this problem is unknown, but not worse than exponential).


\section{Automata}\label{sect:automata}

We use the symbol  to denote the set of natural numbers . For an alphabet ,   is the set of finite words over  and  is the set of infinite words over . The {\em concatenation}  of words  and  will be denoted by , and the empty word by . The concatenation is naturally generalised for infinite sequences of finite words . The concatenation of sets ,  is .


A {\em tree}  is any subset of  closed under the prefix relation. An element of a~tree is usually called a~{\em node}.  A {\em leaf}  is any node of a~tree which is not a~(strict) prefix of some other node. A~{\em -labelled tree}  (or a~tree over ) is a~function  such that  is a~tree. For  we define   as a~subtree of  rooted in , i.~e., , .

A {\em full -ary -labeled}  tree is a~function . The symbol  will denote the set of full binary trees over . From now on, if not stated otherwise, a~``tree'' will mean a~full binary tree over some alphabet. 


Out of a~variety of acceptance conditions for automata on infinite
structures, we choose the parity condition. A~{\em nondeterministic
  parity automaton on words}  can be presented as a~tuple , where  is
a~finite input alphabet,  is a finite set of states,  is the transition relation, and  is the initial state. The meaning of the function  will be explained later. Instead of  one usually writes . A {\em run} of an automaton  on a~word  is a~word  such that  and if , , and , then . A~run  is {\em accepting} if the highest rank repeating infinitely often in  is even; otherwise  is {\em rejecting}. A~word is {\em accepted} by  if there exists an accepting run on it. The language recognised by , denoted  is the set of words accepted by . An automaton is {\em deterministic} if its relation of transition is a~{\em total} function . Note that a deterministic automaton has a~unique run (accepting or not) on every word. We call a~language deterministic if it is recognised by a~deterministic automaton.

A {\em nondeterministic automaton on trees}  is a~tuple , the only difference being that . Like before,  means . We write   if there exists a~state  such that . Similarly for  . A~{\em run} of  on a~tree  is a~tree  such that  and if , ,  and , then . A~path  of the run  is {\em accepting} if the highest rank repeating infinitely often in  is even; otherwise  is {\em rejecting}. A~run is called accepting if all its paths are accepting. If at least one of them is rejecting, so is the whole run. An automaton is called deterministic if its transition relation is a~total function .


By  we denote the automaton  with the initial state set to . A~state  is {\em all-accepting}  if  accepts all trees, and {\em all-rejecting} if  rejects all trees. A~state (a transition) is called {\em productive} if it is used in some accepting run. Observe that being productive is more than just not being all-rejecting. A~state  is productive if and only if it is not all-rejecting and there is a~path  such that , , and  is  not all-rejecting for .

Without loss of generality we may assume that all states in  are productive save for one all-rejecting state  and that all transitions are either productive or are of the form . The reader should keep in mind that this assumption has influence on the complexity of our algorithms. Transforming a~given automaton into such a~form of course needs calculating the productive states, which is equivalent to deciding a~language's emptiness. The latter problem is known to be in  and has no polynomial time solutions yet. Therefore, we can only claim that our algorithms are polynomial for the automata that underwent the above preprocessing. We will try to mention it whenever it is particularly important. \label{explicitproductive}

The {\em Mostowski--Rabin index of an automaton}  is a~pair  An automaton with index  is often called a~-automaton. Scaling down the  function if necessary, one may assume that  is either 0 or 1. Thus, the indices are elements of . For an index  we shall denote by  {\em the dual index}, i.~e., , .
Let us define an ordering of indices with the following formula

In other words, one index is smaller than another if and only if it uses less ranks. This means that dual indices are not comparable. 
 {\em The Mostowski--Rabin index hierarchy} for a~certain class of automata consists of ascending sets (levels) of languages recognised by -automata (see Fig.~\ref{fig:indexhierarchy}). 

\begin{figure}
\centering
{\setlength\arraycolsep{1pt}
}
\caption{The Mostowski--Rabin index hierarchy.}
\label{fig:indexhierarchy}
\end{figure}

The fundamental question about the hierarchy is the strictness, i.~e., the existence of languages recognised by a~-automaton, but not by a -automaton. The strictness of the hierarchy for deterministic automata follows easily from the strictness of the hierarchy for deterministic word automata \cite{wagner}: if a~word language  needs at least the index , so does the language of trees that have a word from  on the leftmost branch. The index hierarchy for nondeterministic automata is also strict \cite{klony}. In fact, the languages showing the strictness may be chosen deterministic: one example is the family of the languages of trees over the alphabet  satisfying the parity condition on each path.

The second important question one may ask about the index hierarchy is how to determine the exact position of a~given language. This is known as the {\em index problem}.

Given a~deterministic language, one may ask about its {\em deterministic index}, i.~e., the exact position in the index hierarchy of deterministic automata (deterministic index hierarchy). This question can be answered effectively. Here we follow the method introduced by Niwi{\'n}ski and Walu\-kiewicz \cite{kwiatek}. 

A path in an automaton is a~sequence of states and transitions: 
A {\em loop}  is a~path starting and ending in the same state, . A~loop  is called {\em accepting}  if  is even. Otherwise it is {\em rejecting}. A~-loop is a~loop with the highest rank on it equal to . A~sequence of loops  in an automaton is called {\em an alternating chain} if the highest rank appearing on  has the same parity as  and it is higher then the highest rank on  for . A~{\em -flower} \index{flower} is an alternating chain  such that all loops have a~common state  (see Fig. \ref{fig:02flower}). \footnote{This is a slight modification of the original definition from \cite{kwiatek}.} 
\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{02flower}
\caption{A~-flower.}
\label{fig:02flower}
\end{figure}

Niwi{\'n}ski and Walukiewicz use flowers in their solution of the index problem for deterministic word automata. 

\begin{thm}[Niwi{\'n}ski, Walukiewicz \cite{kwiatek}] \label{omegaindch}
A deterministic automaton on words is equivalent to a~deterministic -automaton iff it does not contain a~-flower. \qed
\end{thm}

\noindent For a~tree language  over , let  denote the language of generalised paths of , 
A deterministic tree automaton , can be treated as a~deterministic
word automaton recognising . Simply for , take , where . Conversely, given a~deterministic word automaton recognising , one may interpret it as a~tree automaton, obtaining thus a~deterministic automaton recognising . Hence, applying Theorem \ref{omegaindch} one gets the following result.

\begin{prop} \label{indch}
For a~deterministic tree automaton  the language  is recognised by a deterministic -automaton iff  does not contain a -flower. \qed
\end{prop}

In \cite{split} it is shown how to compute the {\em weak deterministic index} of a~given deterministic language. An automaton is called {\em weak} if the ranks may only decrease during the run, i.~e.,  if , then . The weak deterministic index problem is to compute a~weak deterministic automaton with minimal index recognising a given language. The procedure in \cite{split} is again based on the method of difficult patterns used in Theorem \ref{omegaindch} and Proposition \ref{indch}. We need the simplest pattern exceeding the capability of weak deterministic -automata. Just like in the case of the deterministic index, it seems natural to look for a~generic pattern capturing all the power of  . Intuitively, we need to enforce the alternation of ranks provided by . Let a~{\em weak -flower} \label{weakflowers} be a~sequence of loops  such that  is reachable from , and  is accepting iff  is even (see Fig. \ref{fig:weak02flower}). 

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{weak02flower}
\caption{A weak -flower.}
\label{fig:weak02flower}
\end{figure}

\begin{prop}[\cite{split}] \label{windch}
A deterministic automaton  is equivalent to a~weak deterministic -automaton iff it does not contain a~weak -flower. \qed
\end{prop}

For a~deterministic language one may also want to calculate its {\em nondeterministic index},  i.~e., the position in the hierarchy of nondeterministic automata. This may be lower than the deterministic index, due to greater expressive power of nondeterministic automata. Consider for example the language  consisting of trees whose leftmost paths are in a~regular word language . It can be recognised by a~nondeterministic -automaton, but its deterministic index is equal to the deterministic index of , which can be arbitrarily high.

The problem transpired to be rather difficult and has only just been solved in \cite{hie}. Decidability of the general index problem for nondeterministic automata is one of the most important open questions in the field.


\section{Topology}\label{sect:topology}

We start with a~short recollection of elementary notions of descriptive set theory. For further information see \cite{kechris}.

Let  be the set of infinite binary sequences with a~metric given by the formula 
 and~ be the set of infinite binary trees over  with a metric

Both  and , with the topologies induced by the above metrics, are Polish spaces  (complete  metric spaces with countable dense subsets). In fact, both of them are homeomorphic to the Cantor discontinuum. 

The class of Borel sets of a~topological space  is the closure of the class of open sets of  by complementation and countable sums. Within this class one builds so called {\em Borel hierarchy}. The initial (finite) levels of the Borel hierarchy are defined as follows:
\begin{enumerate}[]
  \item  --  open subsets of ,
  \item  --  complements of sets from , 
  \item  --  countable unions of sets from .
\end{enumerate}
For example,  are closed sets,  are  sets, and  are  sets. By convention,  and .

Even more general classes of sets from the {\em projective hierarchy}. \index{projective hierarchy} We will not go beyond its lowest level:
\begin{enumerate}[]
  \item  --  {\em analytical} subsets of , i.~e., projections of Borel subsets of  with product topology,
  \item  --  complements of sets from .
\end{enumerate}

Whenever the space  is determined by the context, we omit it in the notation above and write simply , , and so on. 

Let  be a~continuous map of topological spaces. One
says that  is a~{\em reduction} of  to , if . Note that if  is in a~certain class of the above
hierarchies, so is . For any class  a~set  is
-{\em hard}, if for any set  there
exists a~reduction of  to . The topological hierarchy is strict
for Polish spaces, so if a~set is -hard, it cannot be in
any lower class. If a~-hard set  is also an element
of , then it is -{\em complete}.

In 2002 Niwi\'nski and Walukiewicz discovered a~surprising dichotomy
in the topological complexity of deterministic tree languages:
a~deterministic tree language has either a~very low Borel rank or it
is not Borel at all (see Fig.~\ref{fig:borelhierarchy}). We say that
an automaton  admits a~{\em split} if there are two loops  and  such that the highest ranks
occurring on them are of different parity and the higher one is odd.

\begin{thm}[Niwi{\'n}ski, Walukiewicz \cite{gap}] \label{topgap} \index{Gap Theorem}
For a~deterministic automaton ,  is on the level  of the Borel hierarchy iff  does not admit split; otherwise  is -complete (hence non-Borel). \qed
\end{thm}

\begin{figure}
\centering
{\setlength\arraycolsep{1pt}
}
\caption{The Borel hierarchy for deterministic tree languages.}
\label{fig:borelhierarchy}
\index{Borel hierarchy!of deterministic languages}
\end{figure}

An important tool used in the proof of the Gap Theorem is the
technique of difficult patterns. In the topological setting the
general recipe goes like this: for a~given class identify a~pattern
that can be ``unravelled'' to a language complete for this class; if
an automaton does not contain the pattern, then  should be in
the dual class. In the proof of the Gap Theorem, the split pattern is
``unravelled'' into the language of trees having only finitely many
1's on each path. This language is -complete (via a~reduction
of the set of well-founded trees).

In \cite{split} a~similar characterisation was obtained for the
remaining classes from the above hierarchy. Before we formulate these
result, let us introduce one of the most important technical notions
of this study. A~state  is {\em replicated} \label{replicated}
\index{state!replicated} \index{replication} by a~loop  if there exist a~path  such that . We will say
      that a~flower is replicated by a~loop  if it contains
      a~state replicated by . The phenomenon of replication
      is the main difference between trees and words. We will use it
      constantly to construct hard languages that have no counterparts
      among word languages. Some of them occur in the proposition
      below.

\begin{thm}[Murlak \cite{split}] \label{borelch}
Let  be a~deterministic automaton.
\begin{enumerate}[\em(1)]
\item  iff  does not contain a~weak -flower.
\item  iff  does not contain a~weak -flower.
\item  iff  does not contain a~-flower nor a weak -flower replicated by an accepting loop.
\item  iff  does not contain a~-flower.
\item  iff  does not contain a~-flower replicated by an accepting loop. \qed
\end{enumerate}
\end{thm}


\section{The Main Result}

The notion of continuous reduction defined in
Sect. \ref{sect:topology} yields a preordering on sets. Let  and
 be topological spaces, and let , .
We write  (to be read `` is {\em Wadge reducible} to
''), if there exists a~continuous reduction of  to , i.~e.,
a~continuous function  such that
. We say that  is {\em Wadge equivalent} to ,
in symbols , if  and . Similarly
we write  if  and . The {\em
  Wadge ordering} is the ordering induced by  on the
-classes of subsets of Polish spaces. The Wadge ordering
restricted to Borel sets is called the {\em Wadge hierarchy}.

In this study we only work with the spaces  and
. Since we only consider finite , these spaces
are homeomorphic with the Cantor discontinuum  as long
as . In particular, all the languages we consider are
Wadge equivalent to subsets of . Note however that the
homeomorphism need not preserve recognisability. In fact, no
homeomorphism from  to  does: the Borel
hierarchy for regular tree languages is infinite, but for words it
collapses on . In other words, there are regular tree
languages (even weak, or deterministic), which are not Wadge
equivalent to regular word languages. Conversely, each regular word
language  is Wadge equivalent to a~deterministic tree language 
consisting of trees which have a~word from  on the leftmost branch.
As a~consequence, the height of the Wadge ordering of regular word
languages gives us a~lower bound for the case of deterministic tree languages, and this is essentially everything we can conclude from the word case. 

The starting point of this study is the  Wadge reducibility problem. 

\begin{center}
\fbox{
\begin{tabular}{rl}
{\sc Problem}: & Wadge reducibility \\
{\sc Input}: & Deterministic tree automata  and \\
{\sc Question}: & ?
\end{tabular}
}
\end{center}

\noindent An analogous problem for word automata can be solved fairly
easy by constructing a tree automaton
recognising Duplicator's winning strategies (to be defined in the next
section). This method however
does not carry over to trees. One might still try
to solve the Wadge reducibility problem directly by comparing carefully the
structure of two given automata, but we have chosen a~different
approach. We will provide a family of {\em canonical} deterministic
tree automata  such that 
\begin{enumerate}[(1)]
\item given , it is decidable if ,
\item for each deterministic tree automaton there exists exactly
  one  such that , and this  can be
  computed effectively for a given .
\end{enumerate}
\noindent The decidability of the Wadge reducibility problem follows
easily from the existence of such a family: given two
deterministic automata  and , we compute  and  such that
 and , and check if
. 

More precisely, we prove the following theorem. 
\begin{thm} \label{main}
There exists a family of deterministic tree automata  with ,

such that  
\begin{enumerate}[\em(1)]
\item for , whenever
  the respective automata are defined, we have 

where  means , and  and
 are incomparable,

\item for each deterministic tree automaton  there exists exactly
  one automaton  such that 
  and it is computable, i.e., there exists an algorithm
  computing for a given  a pair   such that . 
\end{enumerate}
\end{thm}
\noindent The family  satisfies the conditions
postulated for the family of canonical automata : for ordinals presented as
arithmetical expressions over  in
Cantor normal form the ordinal order is decidable, so we can take   as the indexing set of . 

Observe that the pair  computed for a given  can be seen
as a name of the -class of . Hence, the set 
 together with the order defined in the
statement of theorem provides a complete effective description of the Wadge hierarchy
restricted to deterministic tree languages. One thing that follows is that the height of the hierarchy is . 


The remaining part of the paper is in fact a single long proof.
We start by reformulating the classical criterion of reducibility via
Wadge games in terms of automata (Sect. \ref{gamesandautomata}). This
will be the main tool of the whole argument. Then we define four ways
of composing automata: sequential composition , replication
, parallel composition , and alternative 
(Sect. \ref{operations}). Using the first three operations we
construct the canonical automata, all but top three ones  
(Sect. \ref{canonicalautomata}). Next, to rehearse our proof method,
we reformulate and prove
Wagner's results in terms of canonical automata (Sect.
\ref{withoutbranching}). Finally, after some preparatory remarks
(Sect. \ref{theuseofreplication}), we prove the first part of Theorem
\ref{main}, modulo three missing canonical automata.

Next, we need to show that our family our family contains all deterministic
tree automata up to Wadge equivalence of the recognised languages. Once again we turn to the
methodology of patterns used in Sect. \ref{sect:automata} and
Sect. \ref{sect:topology}. We introduce a fundamental notion of
admittance, which formalises what it means to contain an automaton as
a~pattern (Sect. \ref{patternsinautomata}). Then we generalise 
to -replication
 in order to define the remaining
three canonical automata, and
rephrase the results on the Borel hierarchy and the Wagner hierarchy
in terms of admittance of canonical automata
(Sect. \ref{wagnerhierarchyandbeyond}). Basing on these results, we
show that the family of canonical automata is closed by the
composition operations (Sect. \ref{closureproperties}), and prove the
Completeness Theorem asserting that (up to Wadge equivalence) each
deterministic automaton may be obtained as an iterated composition of  and  (Sect. \ref{sect:completeness}). As
a~consequence, each deterministic automaton is equivalent to
a~canonical one. From the proof of the Completeness Theorem
we extract an algorithm calculating the equivalent canonical automata, which concludes the proof of Theorem~\ref{main}.


\section{Games and Automata} \label{gamesandautomata}

A classical criterion for reducibility is based on the notion of {\em Wadge games}. Let us introduce a~tree version of Wadge games (see \cite{perrin} for word version). By  {\em the th level} of a tree we understand the set of nodes . The 1st level consists of the root, the 2nd level consists of all the children of the root, etc. For any pair of tree languages  the game  is played by Spoiler and Duplicator. Each player builds a tree,  and  respectively. In every round, first Spoiler adds some levels to  and then Duplicator can either add some levels to  or skip a~round (not forever). The result of the play is a pair of full binary trees. Duplicator wins the play if . We say that Spoiler {\em is in charge of } , and Duplicator {\em is in charge of} . 

Just like for the classical Wadge games, a~winning strategy for Duplicator can be easily transformed into a~continuous reduction, and vice versa. 

\begin{lem} \label{wadgegame}
Duplicator has a~winning strategy in  iff . 
\end{lem}

\proof A~strategy for Duplicator defines a~reduction in an obvious
way. Conversely, suppose there exist a~reduction . It follows that there exist a~sequence  (without
loss of generality, strictly increasing) such that the level  of
 depends only on the levels  of
. Then the strategy for Duplicator is the following: if the number
of the round is , play the th level of  according to
; otherwise skip. \qed

\vspace{5pt}

We would like to point out that Wadge games are much less interactive
than classical games. The move made by one player has no influence on
the possible moves of the other. Of course, if one wants to win, one
has to react to the opponent's actions, but the responses need not be
immediate. As long as the player keeps putting some new letters, he
may postpone the real reaction until he knows more about the
opponent's plans. Because of that, we will often speak about
strategies for some language without considering the opponent and even
without saying if the player in charge of the language is Spoiler or
Duplicator.

Since we only want to work with deterministically recognisable
languages, let us redefine the games in terms of automata. Let ,
 be deterministic tree automata. The {\em automata game} 
starts with one token put in the initial state of each automaton. In
every round players perform a~finite number of the actions described
below.
\begin{enumerate}[\hbox to6 pt{\hfill}]
\item\noindent{\hskip-11 pt\bf Fire a~transition:}\ for a~token placed
  in a~state  choose a transition , take the old token away
  from  and put new tokens in  and .
\item\noindent{\hskip-11 pt\bf Remove:}\ remove a~token placed in
  a~state different from .
\end{enumerate}\smallskip
Spoiler plays on  and must perform one of these actions at least
for all the tokens produced in the previous round. Duplicator plays on
 and is allowed to postpone performing an action for a~token, but
not forever. Let us first consider plays in which the players never
remove tokens. The paths visited by the tokens of each player define
a~run of the respective automaton. We say that Duplicator wins a~play
if both runs are accepting or both are rejecting. Now, removing
a~token from a~state  is interpreted as plugging in an accepting
subrun in the corresponding node of the constructed run. So,
Duplicator wins if the runs obtained by plugging in an accepting
subrun for every removed token are both accepting or both rejecting.

Observe that removing tokens in fact does not give any extra power to
the players: instead of actually removing a~token, a~player may easily
pick an accepting subrun, and in future keep realising it level by
level in the constructed run. The only reason for adding this feature
in the game is that it simplifies the strategies. In a~typical
strategy, while some tokens have a significant role to play, most are
just moved along a~trivially accepting path. It is convenient to
remove them right off and keep concentrated on the real actors of the
play.

We will write  if Duplicator has a~winning strategy in . Like for languages, define  iff  and  . Finally, let  iff  and .


\begin{lem} \label{automatagame} 
For all deterministic tree automata  and , 
\end{lem}

\proof First consider a modified Wadge game , where players are allowed to build their trees in an arbitrary way provided that the nodes played always form one connected tree, and in every round Spoiler must provide both children for all the nodes that were leaves in the previous round. It is very easy to see that Duplicator has a winning strategy in  iff he has a winning strategy in .

Suppose that Duplicator has a~winning strategy in . We will show that Duplicator has a~winning strategy in , and hence . What Duplicator should do is to simulate a~play of  in which an imaginary Spoiler keeps constructing the run of  on the tree  constructed by the real Spoiler in , and Duplicator replies according to his winning strategy that exists by hypothesis. In  Duplicator should simply construct a~tree such that 's run on it is exactly Duplicator's tree from . 

Let us move to the converse implication. Now, Duplicator should simulate a~play in the game  in which Spoiler keeps constructing a~tree such that 's run on it is exactly the tree constructed by the real Spoiler in , and Duplicator replies according to his winning strategy. In  Duplicator should keep constructing the run of  on  constructed in the simulated play.  \qed

\vspace{5pt}

As a~corollary we have that all automata recognising a~given language have the same ``game power''. 

\begin{cor} 
For deterministic tree automata  and , if , then . \qed
\end{cor}

Classically, in automata theory we are interested in the language recognised by an automaton. One language may be recognised by many automata and we usually pick the automaton that fits best our purposes. Here, the approach is entirely different. We are not interested in the language itself, but in its Wadge equivalence class. This, as it turns out, is reflected in the general structure of the automaton. Hence, our main point of interest will be that structure. 

We will frequently modify an automaton in a~way that does change the
recognised language, but not its -class. One typical thing we need to do with an automaton, is to treat it as an automaton over an extended alphabet in such a~way, that the new recognised language is Wadge equivalent to the original one. This has to be done with some care, since the automaton is required to have transitions by each letter from every state.  Suppose we want to extend the input alphabet \label{extalphabet} by a~fresh letter . Let us construct an automaton . First, if  has the all-rejecting state , add a~transition . Then add an all-accepting state  with transitions  for each  (if  already has the state , just add a~transition ). Then for each , add a~transition . 

\begin{lem} \label{extended}
For every deterministic tree automaton  over  and a~letter , .
\end{lem}

\proof It is obvious that : since  contains all transitions of , a~trivial winning strategy for Duplicator in  is to copy Spoiler's actions. Let us see that new transitions do not give any real power. Consider . While Spoiler uses old transitions, Duplicator may again copy his actions. The only difficulty lies in responding to a~move that uses a~new transition. Suppose Spoiler does use a~new transition. If Spoiler fires a~transition  for a~token  in a~state , Duplicator simply removes the corresponding token in , and ignores the further behaviour of  and all his descendants. The only other possibility is that Spoiler fires .  Then for the corresponding token Duplicator should fire  for some . The described strategy is clearly winning for Duplicator. \qed


\vspace{5pt}

An automaton for us is not as much a~recognising device, as a~device to carry out strategies. Therefore even two automata with substantially different structure may be equivalent, as long as they enable us to use the same set of strategies. A~typical thing we will be doing, is to replace a~part of an automaton with a~different part that gives the same strategical possibilities. Recall that by  we denote the automaton  with the initial state changed to . For  let  denote the automaton obtained from a copy of  and a~copy of  by replacing each 's transition of the form  with . Note that  is equivalent to . 

\begin{lem}[Substitution Lemma] \label{substitution} 
Let , ,  be deterministic automata with pairwise disjoint sets of states, and let  be a~state of . If , then . 
\end{lem}

\proof Consider the game  and the following strategy for Duplicator. In  Duplicator copies Spoiler's actions. If some Spoiler's token  enters the automaton , Duplicator should put its counterpart  in the initial state of , and then  and its descendants should use Duplicator's winning strategy from  against  and its descendants. 

Let us see that this strategy is winning. Suppose first that Spoiler's run is rejecting. Then there is a~rejecting path, say . If on  the computation stays in , in Duplicator's run  is also rejecting. Suppose  enters . Let  be the first node of  in which the computation is in . The subrun of Spoiler's run rooted in  is a~rejecting run of . Since Duplicator was applying a~winning strategy form , the subrun of Duplicator's run rooted in  is also rejecting. In either case, Duplicator's run is rejecting. 

Now assume that Spoiler's run is accepting, and let us see that so is Duplicator's. All paths staying in  are accepting, because they are identical to the paths in Spoiler's run. For every  in which the computation enters , the subrun rooted in  is accepting thanks to the winning strategy form  used to construct it. \qed

\section{Operations} \label{operations}

It this section we introduce four operations that will be used to
construct canonical automata representing Wadge degrees of
deterministic tree languages.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{ops}
\caption{The alternative , the parallel composition , and the replication  (transitions to  and  are omitted).}
\label{fig:alternative}
\end{figure}

The first operation yields an automaton that lets a~player choose between  and . For two deterministic tree automata  and  over , the {\em alternative}   (see Fig. \ref{fig:alternative}) is an automaton with the input alphabet  consisting of disjoint copies of  and  over the extended alphabet ,  and , and a~fresh initial state  with transitions  (only if  put ). By Lemma \ref{substitution},  is a~congruence with respect to . Furthermore,  is associative and commutative up to .  Multiple alternatives are performed from left to right:  

The {\em parallel composition}   is defined analogously, only now we extend the alphabet only by  and add transitions  (only if  or , put ).  Note that, while in  the computation must choose between  and , here it continues in both. Again,  is a~congruence with respect to . The language  is Wadge equivalent to  and  is associative and commutative up to . Multiple parallel compositions are performed from left to right, and for  the symbol  denotes .\label{automatapower}

To obtain the {\em  replication} , extend the alphabet again by
, set , and add and transitions 
 Like for two previous operations,  is a congruence with respect to .

The last operation we define produces out of  and  an automaton that behaves as , but in at most one point (on the leftmost path) may switch to . A state  is {\em leftmost}  if no path connecting the initial state with  uses a~right transition. In other words, leftmost states are those which can only occur in the leftmost path of a run. Note that an automaton may have no leftmost states. Furthermore, a leftmost state cannot be reachable from a non-leftmost state. In particular, if an automaton has any leftmost states at all, the initial state has to be leftmost. For deterministic tree automata  and  over , the {\em sequential composition}  (see Fig. \ref{fig:sequential})  
\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{sequential}
\caption{The sequential composition .}
\label{fig:sequential}
\end{figure}
is an automaton with the input alphabet , where  is a~fresh letter. It is constructed by taking copies of  and  over the extended alphabet   and replacing the transition  with  for each leftmost state  and .  Like for  and , we perform the multiple sequential compositions from left to right. For  we often use an abbreviation .  Observe that if  has a leftmost state, then a state in  is leftmost iff it is a leftmost state of  or a leftmost state of . It follows that the -class of a~multiple sequential composition does not depend on the way we put parentheses. An analog of  for word automata defines an operation on -classes, but for tree automata this is no longer true. We will also see later that  is not commutative even up to .

The priority of the operations is . For instance . Nevertheless, we usually use parentheses to make the expressions easier to read. 

Finally, let us define the basic building blocks, to which we will
apply the operations defined above. The {\em canonical -flower}  (see Fig. \ref{fig:flower2})
\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{flower2}
\caption{The canonical -flower .}
\label{fig:flower2}
\end{figure}
is an automaton with the input alphabet ,  the states  where the initial state is  and , and transitions  
for  and . A~flower  is {\em nontrivial} if  .


In the definitions above we often use an all-accepting state . This is in fact a~way of saying that a~transition is of no importance when it comes to possible strategies: a~token moved to  has no use later in the play. Therefore, we may assume that players remove their tokens instead of putting them to . In particular, when a~transition is of the form , it is convenient to treat it as a ``left only'' transition in which no new token is created, only the old token is moved from  to . Consequently, when analysing games on automata, we will ignore the transitions to .


\section{Canonical Automata} \label{canonicalautomata}

For convenience, in this section we put together the definitions of all
canonical automata (save for three which will be defined much
later) together with some very simple properties. More explanations and
intuitions come along with the proofs in the next three 
sections. 

 For each  we define the {\em canonical automaton} . The automata  and  will only be defined for  and  with , ,  . All the defined automata have at least one leftmost state, so the operation  is always non-trivial. 

Let , , and . For  define 


For  we only define . Let  and  for . For every  from the considered range we have a~unique presentation , with ,  and . For  define

and for  set


Now consider . For  let ,  and .  For every  from the considered range we have a~unique presentation  with  and . Let , with  and .  For  and  let 

for   and  let

for  let 

and for  let 


Finally consider . Let , and for  let . We have a~unique presentation  with  and . Let , with  and . For  let 

for  and  let 

for  and  let

and in the remaining case ( or ) let



Let  denote the family of the canonical automata, i.~e.,
 
In the next three sections we will investigate the order induced on  by the Wadge ordering of the recognised languages. 

Now, let us discuss briefly the anatomy and taxonomy of the canonical automata. {\em Simple}  automata are those canonical automata that cannot be decomposed with respect to~,  i.~e., the automata on the levels , , and  for . {\em Complex}  automata are those obtained from simple ones by means of . If for some automata  we have  , we call  {\em components} of . If  are simple, they are called {\em simple components} of ,  is the {\em head component}, and  is the {\em tail component}.  {\em Non-branching} canonical automata are those constructed from flowers without the use of , i.~e.,  for  and . The remaining automata are called {\em branching}. The term {\em head loop} refers to any minimal-length loop around the initial state. If the head component of a canonical automaton is branching, then the automaton has only one head loop. Similarly, if the head component is  or .


According to the definition of the automata game, in a~branching
transition a token is split in two. However in branching canonical
automata, the role to be played by two new tokens is very
different. Therefore, we prefer to see the process of splitting
a~token as producing a~new token that moves along the right branch of
the transition, while the original one moves left. Thus each token
moves along the leftmost path from the node it was born in, bubbling
out new tokens to the right. Let us prove the following simple yet 
useful property of those paths. 

\begin{prop}\label{rejectingpath}
If a~run constructed by a~player in charge of a canonical automaton is
rejecting, one of the tokens has visited a~rejecting path.  
\end{prop}

\proof  Observe that in a~canonical automaton the only loop using
right transitions is the loop around . In other words, each path
of the constructed computation that does not reach  goes right
only a~bounded number of times (depending on the automaton). Now,
consider a~rejecting run constructed during a~play. It must
contain a~rejecting path . The token created during the last
right transition on  visits a~suffix of , which of course is
a~rejecting path.\qed 

\vspace{5pt}

Recall that we have defined the operation  in such a~way, that
the second automaton can only be reached via a~leftmost path. This
means that the only token that can actually move from one simple
automaton to another is the initial token. Since passing between the
simple automata forming a~canonical automaton is usually the key
strategic decision, we call the initial token {\em critical}, and the
path it moves along, the {\em critical path}.

Since we can remove the tokens from  with no impact on the
outcome of the game, we can assume that in transitions of the form  or 
  no new tokens are
produced, only the old token moves from  to . The following fact
relies on this convention. 

\begin{prop}\label{finitelymanytokens} 
If a~player in charge of a canonical automaton produces infinitely may
tokens, the resulting run is rejecting.  
\end{prop}

\proof We will proceed by structural induction. The claim holds
trivially for non-branching automata. Suppose now that . If the constructed run is to be accepting, the player can only
loop a finite number of times in the head loop of
, thus producing only a~finite number of new tokens. 
By the induction hypothesis for , those tokens can only have
finitely many descendants. Hence, in the whole play there can be only
finitely many tokens. 


Now, take . Suppose there were infinitely many tokens
in some play on . Observe that all the tokens in  are
descendants of 's critical token. Hence, if there were infinitely
many tokens in , by the induction hypothesis for  the whole
run is rejecting. Suppose there were infinitely many tokens in
. Consider a~play in which the critical token instead of moving to
 stays in the last accepting loop of  (it exists by the
definition of canonical automata). In such a~play a~run of  is
build. Since there are infinitely many tokens used, the run is
rejecting by the induction hypothesis for . Consequently, the run
of  constructed in the original play must have been rejecting as
well. \qed

\section{Without Branching} \label{withoutbranching}

In this section we briefly reformulate Wagner's results on regular word languages \cite{wagner} in terms of canonical automata. For the sake of completeness, we reprove them in our present framework. 

The scenario is just like for tree languages: define a~collection of canonical automata, prove that they form a~strict hierarchy with respect to the Wadge reducibility, check some closure properties, and provide an algorithm calculating the equivalent canonical automaton for a~given deterministic automaton, thus proving that the hierarchy is complete for regular languages.

Since the non-branching canonical automata have only left transitions, they only check a~regular word property on the leftmost path. It is easy to see that for each word language , the language of trees whose leftmost branch is in  is Wadge equivalent to . Based on this observation, we will treat the non-branching canonical automata as automata on words. 

Let  denote the language of infinite words over  that satisfy the parity condition, i.~e., the highest number occurring infinitely often is even.

\begin{lem} \label{eliotakappa}
For every index  and every deterministic tree automaton  of index at most , 
\begin{enumerate}[\em(1)]
\item ,
\item , 
\item  iff .
\end{enumerate}
\end{lem}

\proof A reduction showing (1) is given by , where
 is the run of  on the word .

For (2) the remaining reduction is obtained by assigning to a~sequence
 the tree with the word
 on the leftmost
branch, and a  elsewhere.

Since  can be recognised by a~
automaton, one implication in (3) follows from (1). To prove the
remaining one, it is enough to show that . Let us fix  and proceed by
induction on . For  the claim holds trivially:
 and  are not reducible to
each other. Take  and let . Consider the game . As long as
Duplicator does not play , Spoiler can follow the strategy
from . If Duplicator never plays
, he loses. When Duplicator plays , Spoiler should
play , and then again follow the strategy from ,
and so on. Each time, Duplicator has to play  finally,
otherwise he loses. But then he must play  infinitely many
times, and he loses to, since  and  have different
parity. \qed

\vspace{5pt}

For the sake of convenience let us renumber the non-branching automata. For  let 
Let  .\label{hat}

\begin{prop} \label{omegaorder}
For  we have

where  means . Furthermore,  and .
\end{prop}

\proof First, observe that : a~winning strategy for Duplicator in  is to move the initial token to , and then simply copy Spoiler's actions. Analogously, .

Let us now suppose that  for some . Then . 
By definition,  , has index at most  . Hence, by Lemma \ref{eliotakappa}, . If we increase the ranks in each  in  by 2, we obtain an automaton with index at most  recognising the same language. Hence, we also have .
 
Now, consider the general case.  We have a~unique pair of presentations  and  with . Let  be the largest number satisfying . Since , . Thus we have , , where , , .  Consider the game . The strategy for Duplicator is as follows. First move the token to the last  in . Then follow the strategy given by the inequality , as long as Spoiler stays in . If he stays there forever, Duplicator wins. If Spoiler moves to , Duplicator should do the same and keep copying Spoiler's move from that moment on. This also guarantees winning. The proof for  is entirely analogous.   


In order to prove that the inequalities are strict it is enough to show that  and . We only prove that ; the proof for  is entirely analogous. Let us proceed by induction. The assertion holds for : the whole space is not reducible to the empty set. Let us take . By the definition, , , where .  Consider the game . We have to find a~winning strategy for Spoiler. If Duplicator never leaves  Spoiler can stay in  and win using the strategy given by the Lemma \ref{eliotakappa} (3). Otherwise, after Duplicator enters , he must make choice between  and . Spoiler should loop in any loop of  waiting for Duplicator's choice. When Duplicator chooses one of  , , Spoiler should choose the other one and use the strategy given by the induction hypothesis. \qed


\vspace{5pt}

The third step is proving closure by natural operations. For word automata only the operations  and  make sense. The operation  is defined just like for trees. To define , simply assume that all states are leftmost. It is easy to see that  is a congruence with respect to  and . Both operations are associative up to .

\begin{prop} \label{omegaclosure}
For each , one can find in polynomial time automata  such that  and .  
\end{prop}

\proof Closure by  is easy. For  it holds that . Indeed,  , as  contains a copy of . For the converse inequality consider . In the first move, Spoiler moves his initial token either to  or to . If Spoiler chooses , Duplicator may simply mimic Spoiler's actions in his copy of . If Spoiler chooses , Duplicator wins by applying the strategy from , guaranteed by the inequality . 

In the remaining case  and  are incomparable. But then ,   for some   (or symmetrically). It is very easy to see that . 

Let us now consider .  Since  is associative up to  and only depends on the -classes of the input automata, it is enough to prove the claim for simple ; in order to obtain a~canonical automaton for , take . Let us first consider .  Observe that if , . It is enough to give a strategy for Duplicator in , since the other inequality is obvious. To win, Duplicator should first copy Spoiler's actions, as long as Spoiler stays in . When Spoiler moves to , Duplicator should simply switch to the strategy from .

Using the property above, we easily reduce the general situation to one of the following cases: , , or .  In the third case, the automaton is already canonical. Let us calculate the result in the first two cases. 

In the first case we have . Consider the game . Let  be the head component of . It holds that . In order to win the game, while Spoiler stays inside , Duplicator should stay in  and use the strategy from . When  Spoiler enters , Duplicator may simply copy his actions. The converse inequality is trivial.

In the second case  there are two possibilities. If the head component of  is  with , proceeding as before one proves . But if , we have . Consider the game . While Spoiler stays in , Duplicator should copy his actions. When Spoiler leaves , he has to choose between  and the next copy of . If he chooses , Duplicator also moves to his copy of , and mimics Spoiler actions. Suppose Spoiler chooses . Then Duplicator stays in his head component, and mimics  Spoiler's actions, as long as he stays in . When Spoiler leaves , he enters the initial state of , where . Duplicator should exit , go past ,  and enter his copy of . From now on, he can copy Spoiler's actions. 

For , simply dualise the claims and the proofs. For  , note that , and the equivalent canonical automaton can be obtained by previous cases. \qed

\vspace{5pt} 

Let us now see that the hierarchy is complete for word languages.

\begin{thm} \label{wagner}
For each word automaton  one can find in polynomial time a~canonical non-branching automaton  such that .
\end{thm}

\proof We will proceed by induction on the height of the DAG of
strongly connected components of . Without loss of generality we
may assume that all states of  are reachable from the initial
state. In such case, the DAG of SCCs is connected and has exactly one {\em root}
component, the one containing the initial state of the automaton. 

 Suppose that the automaton is just one strongly connected component. Let  be the highest index for which  contains  a~-flower. It is well defined, because if  contains a~-flower and a~-flower, it must also contain a~-flower. By Theorem \ref{indch},  is equivalent to a~-automaton and so, by Lemma \ref{eliotakappa}, . On the other hand it is easy to see, that in , Duplicator may easily use the -flower in  to mimic Spoiler's actions in . Hence, . 


Now, suppose that the DAG of SCCs of  has at least two nodes. Let
 be the root SCC. Like before, let  be the maximal index such that  contains a~-flower. Let  be all the states reached by the transitions exiting  (the ``initial'' states of the SCCs that are children of ). Recall that  is the automaton  with the initial state set to . Let  be the canonical non-branching automaton equivalent to . It is easy to see that . \qed



\begin{figure}
\centering
{\footnotesize {\setlength\arraycolsep{1pt}
}}

\caption{An initial segment of the Wagner hierarchy}
\label{fig:wagnerhierarchy}
\index{Wagner hierarchy}
\end{figure}


\section{The Use of Replication} \label{theuseofreplication}

Branching automata are defined by iterating . The significance of  lies in the fact that closing the family of non-branching automata by this operation gives, up to Wadge equivalence, almost all deterministic tree languages (only , , and  will be defined by means of a~stronger replication). In particular, we will show that the operation  is not needed. In other words,  is everything that deterministic tree automata have, which word automata have not. Let us see then what the use of the operation  is.

There are two kinds of simple branching automata. The first one is obtained by iterating  on , and generalises . Intuitively,  lets a~player in an automata game change his mind  times in the following sense. First, the player moves his (only) token along the head loop. The head loop is accepting, so if he keeps looping there forever, the resulting run will be accepting. But after some time he may decide that producing an accepting run is not a~good idea. In such a~case he can move to the rejecting loop in the first copy of . Later he may want to change his mind again, and again, until he reaches the last copy of . Now, when the player is in charge of  he can choose a~number , and looping in the head loop of  produce  tokens in the head loop of his copy of . We will see that with those tokens it is possible to simulate any strategy designed for . In other words,  offers the choice between  for arbitrarily high . The automaton  lets you choose the number of times you will be allowed to choose some , and so on. 

The second kind of simple branching automata, obtained by iterating  on , does the same with  instead of . For instance,  lets the player choose any  (see page \pageref{hat}), and in consequence  is hard for the class of regular languages of words.

Let us now see the proofs. The first lemma justifies the name replication. 

\begin{lem} \label{replication} For all automata  and all , 
\begin{enumerate}[\em(1)]
\item ,
\item .
\end{enumerate} 
\end{lem} 

\proof To see that  holds,  consider . Spoiler's initial moves produce a~token  in the head loop of , and
tokens , each in a~different copy of . Duplicator should
\begin{figure}
\centering
\includegraphics[width=\textwidth]{replication}
\caption{An initial part of the play in .}
\label{fig:replication}
\end{figure}
loop his starting token  around the head loop of  exactly  times producing for each  a~{\em doppelg\"anger}  and move them all to the initial state of  (see Fig.~\ref{fig:replication}). From now on  mimics , and  mimics  for . 

For the proof of  it is enough to check that .  Clearly . By Lemma \ref{substitution}, , and the claim follows. \qed

\vspace{5pt}

Next we need to calculate the value of  and . Apart from canonical -flowers , we consider the following automata containing weak -flowers (see page \pageref{weakflowers}):   We will refer to these automata as weak -flowers too. In fact, , , but we find the notation convenient.\label{canonicalweakflowers} 

A pair  is called {\em even} if both  and  are even. Otherwise  is {\em odd}. Let  denote the set  with the natural order. Consider the set  with the product order:  if  and . For  and  define an {\em alternating chain of type },  or -chain, as a~sequence , such that  is even iff  is even. Suppose we have a~-chain of maximal length in . The parity of  is equal to the parity of , as defined above, for otherwise we could extend the alternating chain with  and get a~-chain. Consequently, the following operation is well-defined: 

\begin{lem} \label{flowers}
For all indices  and  it holds that 

In particular,  and . Equivalently,   and  .
\end{lem}

\proof By Lemma \ref{eliotakappa}, , so  , where . We will show that , where .

Consider the following automaton . The state space is the set  and the initial state is the function constantly equal . The transition relation  is defined as  iff for all  and ,  , where  is defined as 

with  denoting any letter.

Let us now define the rank function. For  and  , let  and . Observe that , so . Set the rank of the states that never take the value  to . For the remaining states set the rank to , where   are the arguments for which the value  is taken.

Let us check that the automaton recognises . Take a~word . Let  and . In the run of  on , the states  satisfying  will occur infinitely often. Furthermore, from some moment on there only appear states  satisfying . Since , the highest rank used infinitely often in the run on  is . Finally,  is even iff  and  are even, so the run on  is accepting iff .

Since  has the index , the automaton itself provides a reduction of  to . 

By definition of , there exists a~sequence of pairs  such that for all  it holds that , , and  and  are even iff  is even. The reduction is given by the function  

The proof for weak flowers is entirely analogous. \qed

\begin{lem}\label{replicators} 
For all  and all 

In particular,  and .
\end{lem}

\proof Consider . Observe that Duplicator's critical token will move along a copy of  formed by the leftmost states of consecutive copies of  (see Fig. \ref{fig:replicators}). 
\begin{figure}
\centering
\includegraphics[width=\textwidth]{replicators}
\caption{The weak flower  formed by the leftmost states of .}
\label{fig:replicators}
\end{figure}
Spoiler's initial token splits in the first move in two tokens which continue moving along  and . For the purpose of this proof, call them both critical. 

The strategy for Duplicator is based on the fact that  (Lemma \ref{flowers}). Duplicator can loop his critical token inside an accepting loop as long as both Spoiler's critical tokens loop inside accepting loops. When Spoiler changes his mind and moves one of them to a rejecting loop, Duplicator should move to a~rejecting loop too, and keep looping there until both Spoiler's tokens are again in accepting loops. This can only repeat  times, so Duplicator is able to realise this strategy. 

This way, whenever Spoiler produces a~new token  using one of the critical tokens, Duplicator can produce its {\em doppelg\"anger }. The role of the {\em doppelg\"anger} is to mimic the original. \index{doppelg\"anger} The mimicking is in fact passed from generation to generation: if the original token bubbles a~new token ,  should bubble a~new {\em doppelg\"anger}  which is to mimic , and so on. 

In order to see that the strategy is winning it is enough to observe two facts: Duplicator's critical token stays in a~rejecting loop forever iff one of Spoiler's critical tokens does, and the sequence of ranks seen by any of Spoiler's non-critical tokens is equal to the one seen by its {\em doppelg\"anger}. Hence, . 

The converse inequality is proved in a~similar way and for the second equivalence the same proof works.\qed

\vspace{5pt}

\begin{cor} \label{hardautomata} For all   and all 
\begin{enumerate}[\em(1)] 
\item ,  , 
\item , . \end{enumerate}
\end{cor}

\proof Since ,  by Lemma \ref{replication} and  Lemma \ref{flowers} we get   and by the strictness of the hierarchy for word languages . Similarly, using Lemma \ref{replication} and Lemma \ref{replicators} we get . The remaining two inequalities are analogous. \qed



\section{Automata in Order} \label{automatainorder}


Let us start examining the order on canonical automata with the following simple observation.

\begin{lem} \label{CD1} 
For all  
\end{lem}

\proof We give a~proof for the first inequality; the second one is proved analogously. Consider the following strategy for Duplicator in . In every move, if any of Spoiler's tokens is inside a rejecting loop, Duplicator should move his critical token around a~-loop, otherwise he should loop around the -loop. Let us see that the strategy is winning. 

By Proposition \ref{finitelymanytokens} if Spoiler's run is to be accepting, he must produce only finitely many tokens. All of those tokens must finally get to some -loop, and stay there forever. This means that after some number of moves, all Spoiler's tokens are in -loops which they will never leave later. But from this moment on Duplicator's critical token will keep looping around the -loop, so Duplicator's run will also be accepting. 

By Proposition \ref{rejectingpath}, if Spoiler's run is to be rejecting, there must be a~token that from some moment on stays forever in a~-loop. Then Duplicator's token will also get trapped in the rejecting loop in , and Duplicator's run will be rejecting too. \qed

\vspace{5pt}

Let us now see that we can restrict the way the players use non-critical tokens. For a~simple automaton  and a~canonical automaton  with  simple, we say that  {\em dominates}\index{domination}\label{domination}  if one of the following conditions holds
\begin{enumerate}[]
\item  is non-branching
\item ,  , and ,
\item  and  or  for .
\end{enumerate}

\begin{lem} \label{resetrule}
Let  be simple and let  be a~canonical automaton dominating all . For every deterministic automaton , if Spoiler has a winning strategy in , then he also has a strategy in which he removes all non-critical tokens before entering . Similarly for Duplicator in . 
\end{lem} 

\proof Let  with  simple. Suppose that at some moment the strategy tells Spoiler to enter  (if this never happens, the claim is obvious). If there are no non-critical tokens left in , then we are done. However if there are, we have to take extra care of them. Suppose Spoiler has produced non-critical tokens , and  is in . Since  is not on a~critical path of , by the definitions of canonical automata, it will stay within a~copy of  over the alphabet extended to the alphabet of . 

Suppose . Since  dominates ,  for all . Spoiler should replace the token  with  and let  take over the duties of . To produce , Spoiler should loop once in the head loop of . If , or , Spoiler may simply move  to  a~copy of  and let it perform exactly the actions  would take. If , , Spoiler should move  to the copy of  contained in , and let it apply the strategy guaranteed by Lemma \ref{CD1}. To see that the strategy is applicable, it is enough to note that it does not require any waiting, and that  contains a~copy of .

Suppose now that  is non-branching. Then,  for all . In this case Spoiler cannot produce a~token to take over 's duties. Instead, he has to modify the actions of the critical token. He should move the critical token according to his original strategy moving from flower to flower, only when one of his non-critical tokens would be in a~rejecting loop, he should choose a~-loop in his current flower (instead of the loop suggested by the old strategy). Just like in the proof of Lemma \ref{CD1}, if in a~play according to the original strategy one of the non-critical tokens stays forever in a~rejecting loop, then in the game according to the new strategy the critical token finally also gets trapped in a~-loop. Otherwise, there are only finitely many non-critical tokens, and all of them finally stabilise in an accepting loop. From that moment on, the critical token will see exactly the same ranks as it would see if Spoiler was playing with the original strategy. Hence, the modified strategy is also winning. 

If the original strategy brings Spoiler to a~branching automaton, he should produce counterparts of his non-critical tokens just like above. \qed


\begin{cor} \label{resetrule2}
For every canonical automaton of the form   and every deterministic tree automaton , if a~Spoiler has a~winning strategy in , than he has also a~winning strategy which removes all non-critical tokens before entering . Similarly for Duplicator in .
\end{cor}

\proof Let  with  simple. From the structure of canonical automata it follows that if  is canonical,  dominates  for . \qed

\vspace{5pt}

Now we are ready to get back to the order on . 

\begin{lem} \label{order}
If  then 
 and whenever  and  are defined,
. If , then 
.
\end{lem}

\proof As an auxiliary claim let us see that if  is canonical and , . Indeed, the following is a~winning strategy for Duplicator in . While Spoiler keeps inside , apply the strategy from . If Spoiler enters , by Corollary~\ref{resetrule2} we may assume he removes all non-critical tokens. Hence, Duplicator may remove non-critical tokens, move the critical token to  and copy Spoiler's actions. 

Let us now see that  for ; the other inequalities may be proved in an analogous way. We will proceed by induction on  with lexicographic order. If , the result follows by the word languages case. Suppose that . Let  and , .  First, assume that . Obviously , simply because  contains a~copy of . If  the claim follows directly from Corollary~\ref{hardautomata}. For , using the induction hypothesis and Corollary~\ref{hardautomata}, we get . Now, assume that . Then ,  for some ordinals . By definition , , and by induction hypothesis, . Hence, by the auxiliary claim above, .

Now, suppose that . Let ,  for  . If  , then by induction hypothesis , and   follows by the auxiliary claim above.  Assume that . By Lemma \ref{CD1}, . Replacing  with  in the above strategy, we get . By Proposition \ref{omegaorder},  and  since  is contained in , we get . Observe that the argument works also for  or  equal to .

The case  is analogous to . \qed

\vspace{5pt}

For a~complete description of the ordering on the canonical automata (see Fig.~\ref{fig:wadgecanonical}) we need the strictness of the inequalities from the previous lemma.

\begin{thm} \label{strictorder}
Let . Whenever the respective automata are defined, it holds that  , , , and  for ,  , .
\end{thm}

\proof By Lemma \ref{order} it is enough to prove , , , , . We will only give a~proof of the first inequality; the others can be argued similarly.  We will proceed by induction on . If , the claim follows by the word languages case.

Suppose . Then   with , . Let  (the remaining case is similar). We shall describe a~winning strategy for Spoiler in . Spoiler should first follow the winning strategy for , which exists by the induction hypothesis. Suppose that Duplicator enters the head loop of . We may assume that he removes all his non-critical tokens (Corollary \ref{resetrule2}). Spoiler should remove all his non-critical tokens, move his critical token to any accepting loop in . Let us check that such a loop is always reachable for the critical token. 

Let  with  simple. If , Spoiler can move his critical token to . If  is not of this form, then by definition of canonical automata,  or . Recall that  and  (see page \pageref{canonicalweakflowers}). It follows that in any play on  or , if one has a winning strategy, one also has a winning strategy never entering the rejecting loop of the tail component. Hence, the accepting loop in the tail component is always reachable (or has been reached already).  

 Thus, Spoiler can move his critical token to an accepting loop in the tail component of  and loop there until Duplicator leaves the head loop. If Duplicator stays forever in the head loop of , he loses. Suppose that Duplicator leaves the head loop of  after producing  tokens. The rest of the game is equivalent to  for , where  is the part of  accessible for the Duplicator's th token. If , then  for each . Hence  and by Corollary \ref{hardautomata} Spoiler has a winning strategy in . Let us suppose . Then  for  and so, by Lemma \ref{substitution},  . Hence, by Lemma~\ref{replicators}, . Since , we may use the induction hypothesis to get a~winning strategy for Spoiler in . In either case Spoiler has a~winning strategy in  as well.

 Now, assume . Let  with  , . Again, we describe a~strategy for Spoiler in  only for , leaving the remaining case to the reader. First follow the winning strategy from . If Duplicator does not leave the  component, he will lose. After leaving , Duplicator has to choose  or . Suppose he chooses . Again, by Corollary \ref{resetrule2} we may assume that he removes all non-critical tokens. Now, Spoiler has to remove all non-critical tokens and move the critical token to the initial state of  and use the winning strategy from . 

For  argue like for .\qed 



\begin{figure}
\centering
{\scriptsize {\setlength\arraycolsep{1pt}
}}
\caption{The Wadge ordering of the canonical automata.}
\label{fig:wadgecanonical}
\end{figure}


\section{Patterns in Automata} \label{patternsinautomata}

Compare the notion of -flower defined
in Sect. \ref{sect:automata} and the canonical flower . It is fairly clear that if  contains
a~-flower, Duplicator can win in  by copying Spoiler's actions. In that case it seems plausible to
look at  as if it ``contained'' a copy of . In this section we provide a~notion which captures this intuition.

Two paths  and   in a~deterministic automaton  are {\em branching} iff there exists  such that for all  it holds that ,  , and . Note that the condition implies that  for . 

An automaton  can be {\em embedded} into an automaton , if there exists a~function  and a~function , where  is the set of paths in , satisfying the following conditions:
\begin{enumerate}[(1)]
\item if  and  then , ,
\item for all  the paths  and  are branching,
\item for every loop  in , the corresponding loop in  (obtained by concatenating the paths assigned to the edges of ) is accepting iff  is accepting. 
\end{enumerate}

For each tree automaton , let  be the automaton obtained from  by unravelling the DAG of strongly connected components into a~tree (for the purpose of this definition, we allow multiple copies of ). An automaton  {\em admits} an automaton , in symbols , if the automaton  can be embedded into . Note that if  can be embedded into , then .

\begin{lem} \label{admittance}
For all deterministic tree automata  and  
\end{lem} 

\proof Since , without loss of generality we may assume that . We have to provide a~winning strategy for Duplicator in . Without loss of generality, we may assume that Spoiler never removes his tokens. Let   and  be the embedding functions.  We will show that Duplicator can keep a~collection of {\em doppelg\"angers}, one for each Spoiler's token, such that if some Spoiler's token  is in the state , its {\em doppelg\"anger}  is in the state . 

Let us first assume that . Then the invariant above holds when the play starts. As long as Spoiler does not enter , the invariant can be maintained by means of the function  as follows. Suppose that Spoiler fires a~transition   for some token  obtaining new tokens  and . Let  

with . 
 
Let  be such that , , and  for , , , where .

Recall that we assume that for every transition, either both target states are  or none.  Since  and  then, by the condition (3) of the definition of admittance,  and  and consequently all the states , ,  , , ,  are not equal to . Hence, Duplicator can proceed as follows. Starting with the token  (the {\em doppelg\"anger} of ), fire the transitions forming the common prefix of both paths, each time removing the token sent to . Thus he reaches the state  with a~descendant of the token . Then he should fire the next transition producing two tokens  and , and  for each of them fire the remaining sequence of transitions (again removing the tokens in the states  and ). Thus he ends up with two tokens in the states  and . Hence, the token in  may be the {\em doppelg\"anger} of , and the token in  may be the {\em doppelg\"anger} of .

Let us see that if Spoiler never enters , Duplicator wins. Observe that the function  induces a~function  from the set of infinite paths in  to the set of infinite paths in . Owing to the condition (3),  is accepting iff  is accepting. The strategy used by Duplicator guarantees that for each path  in Spoiler's run, Duplicator's run contains the path . The paths in Duplicator's run that are not images of paths from Spoiler's run were all declared accepting by removing the corresponding tokens. Hence, Duplicator's run is accepting iff Spoiler's run is accepting. 

Now, if Spoiler enters , Duplicator proceeds as before, only if some , , or  is equal to , instead of removing the token from there (he is not allowed to do that), he lets the token and all its descendants loop there forever.  In the end, again each path in Spoiler's run has a~counterpart in Duplicator's run. The images of the rejecting paths (which exist in Spoiler's run), will be rejecting too. Hence, Duplicator also wins in this case. 

Finally we have to consider the situation when . In this case, Duplicator should first move his initial token to the state ,  removing the other tokens produced on the way whenever possible, and then proceed as before.  \qed

\vspace{5pt}

Another property that makes admittance similar to containment is transitivity. 

\begin{lem} \label{transitivity}
For all deterministic tree automata , , and ,
 
\end{lem}

\proof Again, we may assume that . Furthermore, since the states from one SCC have to be mapped to states from one SCC, then  can be embedded directly into . Hence, we may also assume that . Let ,  be functions embedding the automaton  into  . The embedding of  into  is simply a~composition of two given embeddings: , , where  is the function induced by  in the natural way. It is easy to see that  and  satisfy the conditions from the definition of admittance. \qed

\vspace{5pt}

Embedding for automata on words is defined analogously, only the function  is defined on  instead of , and the condition (2) is dropped. Admittance is defined identically. The two lemmas above carry over with analogous proofs. 

\section{Hard Automata} \label{wagnerhierarchyandbeyond}

In previous sections we have described an extended hierarchy of
canonical automata. As we have already mentioned there are still three
canonical automata left to define. In their definition we will make
the first use of a stronger variant of the operation .

In the operation ,
instead of one (rejecting) loop replicating an automaton, we have a whole flower whose each
loop replicates a different automaton. Recall that  
is an automaton whose input alphabet is , the states are , , the initial state is ,  and transitions  
for  and . Let  be deterministic tree automata over . The {\em -replication}     (see Fig. \ref{fig:flower}) 
\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{flower}
\caption{The -replication .}
\label{fig:flower}
\end{figure}
is obtained as follows. Take a~copy of  over the
extended alphabet , where  is a~fresh letter. Add single disjoint
copies of   and  over the extended
alphabet . Finally, in  over the extended alphabet,
replace the transition 
(where ) with , and  with    for . 

Using Lemma \ref{substitution} it is easy to see that the
-class of the defined automaton depends only on  and the -classes of . Hence,  is a congruence with respect to
 for every
.  

Note also that  and  
are equal up to the names of letters and states. In particular  
.

Let us now define the three missing automata. Let  and  . The last automaton,  consists of the states , ,  with  and transitions   
Using canonical automata we can formulate results from Sect. \ref{sect:topology} in a~uniform way. In the proof we will need the following technical lemma. 

\begin{lem} \label{embeddingtop}
Let  be a~deterministic tree automaton. For every productive state  in  there exists a~state , a~path  from  to ,  and pair of branching paths ,  from  to  forming accepting loops.
\end{lem}

\proof Take an accepting run starting in . For  each node  of
the run let  be the set of states of the automaton that appear
below . Note, that if  is a descendant of , . Since all 's
are non-empty, there exists a node  such that for all descendants  of
, . Pick a state . There exists a node  under , labeled with . Both
 and  are labeled with , so there exist a nodes 
under  and  under  that are also labeled with . To
conclude, let  be the path in  induced by the path from
 to , and let  be the path induced by the path
between  and  for . \footnotemark[1] \footnotetext[1]{This elegant proof was suggested by one
  of the referees in place of a clumsier inductive argument.} \qed

\begin{thm} \label{borelautomata} 
Let  be a~deterministic automaton.
\begin{enumerate}[\em(1)]
\item  is -complete;   iff  does not admit .
\item  is  -complete;  iff  does not admit .
\item  and   are -complete; \\  iff  does not admit  nor . 
\item  is -complete;  iff  does not admit .
\item  is -complete;  iff  does not admit . 
\item   iff  does not admit .
\item   is -complete;  is -complete iff  admits .
\end{enumerate}
\end{thm}

\proof It is enough to check that for an automaton it is the same to contain the patterns from Theorem \ref{borelch} (page \pageref{borelch}) and to admit the respective automata. It is straightforward to check that it indeed is so. The only difficulty is embedding the transitions to all-accepting states, but this is solved by Lemma \ref{embeddingtop}. Let us just see the case of . If  admits , then the image of the two loops in   that contain the initial state is a~split. 

Suppose that  contains a~split consisting of an -loop  and a~-loop , such that  is even,  is odd, and . Without loss of generality we may assume that . Let , and let , ,  be the states guaranteed by Lemma \ref{embeddingtop} for , , and  respectively. 

Let  be the automaton obtained from  by unravelling the DAG of SCCs. The only way it differs from  is that instead of one state  it contains 5 all-accepting states , one for each transition from the root SCC: 
  
Define , , , , . The function  is defined as follows:

where  denotes any letter and by  we mean the concatenation of two paths. Checking that this is an embedding is straightforward. \qed

\vspace{5pt}

For the proof of the next theorem, settling the position of the last canonical automaton,  , we will need the following property of replication. 

\begin{lem}[Replication Lemma] \label{replicationlemma} 
A state occurs in infinitely many incomparable nodes of an accepting run iff it is productive and is replicated by an accepting loop. 
\end{lem}

\proof If a~state  is replicated by an accepting loop, then by productivity one may easily construct an accepting run with infinitely many incomparable  occurrences of . Let us concentrate on the converse implication. 

Let  occur in an infinite number of incomparable nodes  of an accepting run . Let  be a~path of  going through the node . Since  is compact, we may assume, passing to a~subsequence, that the sequence  converges to a~path . Since  are incomparable,  is not on . Let the word  be the sequence of states labelling the path from the last common node of  and  to . Cutting the loops off if needed, we may assume that  for all . Consequently, there exist a~word  repeating infinitely often in the sequence . Moreover, the path  is accepting, so the starting state of  must lay on an accepting productive loop. This loop replicates .\qed


\begin{thm} \label{hardcore}
 is Wadge complete for deterministic  tree languages. In particular,  for each .
\end{thm}

\proof Since  admits neither  nor ,  is a~deterministic  language (Theorem \ref{borelautomata}). Let us see that it is hard in that class. 

Take a~deterministic automaton  recognising a~-language.  By Theorem \ref{borelautomata} (5),   does not admit .  Let us divide the states of  into two categories: a~state is {\em blue} if it is replicated (see page \pageref{replicated}) by an accepting loop, otherwise it is {\em red}. Note that every state reachable from a~blue state is blue.

Let  be the automaton  with the ranks of red states set to , and let  be  with the ranks of the blue states set to . Let us see that  . The strategy for Duplicator in  is to copy Spoiler's actions in , both in  and . To show that this strategy is winning it is enough to show that for each  a run of  on  is accepting iff  the runs of  and  on  are accepting. Take a path  of the run of . Let  and  be the corresponding paths of the computations of  and . If  only visits red states, then the ranks on  and  are identical, and  contains only 's. Otherwise,  enters a blue state at some point, and then stays in blue states forever. In such case, the blue suffixes of  and  have the same ranks, and the blue suffix of  contains only 's. Thus,  is accepting iff  and  are accepting and the claim follows. 

Since  does not admit , it follows that all -flowers in  are red. Consequently,  does not admit , and so  is . Since   is -hard (Theorem \ref{borelautomata} (3)), .

Now consider . Once you enter a blue state, you can never move to a red state. Consequently, since in  all blue states have rank , we may actually replace them all with one all-accepting state  without changing the recognised language. Recall that, by convention, instead of putting tokens into  we simply remove them. Hence, when for some token in  a~transition of the form  or  is fired, we imagine that the token is moved to  without producing any new tokens. By the Replication Lemma (Lemma \ref{replicationlemma}) the occurrences of red states in an accepting run may be covered by a~finite number of infinite paths. Hence, by our convention, only finitely many tokens may be produced in a~play if the constructed run is to be accepting.
 
Let us now show that Duplicator has a~winning strategy in  , where  is the index of .  Whenever Spoiler produces a~new token (including the starting token), Duplicator should loop once around the head -loop producing a~{\em doppelg\"anger}  in , and keep looping around the head -loop. The new token is to visit states with exactly the same ranks as the token produced by Spoiler. Let us see that this strategy works. Suppose Spoiler's run was accepting. Then, there were only finitely many red tokens produced, and hence the head -loop was visited only finitely often. Furthermore, each Spoiler's token visited an accepting path. But then, so did its {\em doppelg\"anger}, and Duplicator's run was also accepting. Now suppose Spoiler's run was rejecting. If infinitely many red tokens were produced, the head -loop was visited infinitely often, and Duplicator's run was also rejecting. If there were finitely many tokens produced, then one of the tokens must have gone along a~rejecting path, but so did its {\em doppelg\"anger} and Duplicator's run was also rejecting. Hence . 

By Lemma \ref{substitution}, , so it is enough to check that  . Consider the following strategy for Duplicator in the game . First, loop once around the -loop and produce a~new token in  and use it to mimic Spoiler's actions in . Then, for each new token  Spoiler produces in his -loop and sends to , Duplicator should produce tokens  in . By Lemma \ref{flowers}, , so Duplicator has a winning strategy in . Adapting this strategy, Duplicator can simulate the actions of Spoiler's token  in  with the tokens  in . If Spoiler loops the -loop without producing a~new token, or loops around the -loop, Duplicator should copy his actions. Clearly, this strategy is winning for Duplicator.  

Finally, let us see that  for each . Take . Observe that in  no state is replicated by an accepting loop. Hence,  may not admit  nor . By Theorem \ref{borelautomata},   is in . By Lemma \ref{order}, for each  there exists  such that . Hence, for all , , and . \qed

\vspace{5pt}

From Theorems \ref{borelautomata} and \ref{hardcore} we obtain the
following picture of the top of the hierarchy:  Let . Note that it already follows
that the height of the Wadge hierarchy of deterministic tree languages
is at least
. In the remaining of the paper we will
show that each deterministic automaton is Wadge equivalent to one of
the canonical automata from , thus providing a matching
upper bound.

\section{Closure Properties} \label{closureproperties}

Our aim is to show that each deterministic tree language is Wadge equivalent to the language recognised by one of the canonical automata. If this is to be true, the family of canonical automata should be closed (up to Wadge equivalence) by the operations introduced in Sect. \ref{operations}. In this section we will see that it is so indeed. The closure properties carry substantial part of the technical difficulty of the main theorem, whose proof is thus made rather concise. \index{closure properties}

\begin{prop}\label{lor_closure}
For  one can find in polynomial time an automaton in  equivalent to .
\end{prop}

\proof Proceed just like for nonbranching automata (Proposition~\ref{omegaclosure}, page \pageref{omegaclosure}). Take . If , then  and if  , then . If  and  are incomparable, by Lemma \ref{order} we get that they must be equal to  and . It follows easily from the definitions of the canonical automata that . \qed

\begin{prop}\label{oplus_closure}
For  one can find in polynomial time an automaton in  equivalent to .
\end{prop}

\proof Recall that simple automata are those that cannot be written as  for some canonical automata . Let us first assume that  is a~simple branching automaton.  First let us prove that for , . Let us consider the game . The following is a~winning strategy for Duplicator.  While Spoiler keeps inside the head loop of , mimic his actions. When he exits the head loop, let all the non-critical tokens produced so far copy the actions of their counterparts belonging to Spoiler, and for the critical token (and all new tokens to be produced) proceed as follows. If  is a~canonical automaton, then,  by the shape of the hierarchy,  and Duplicator may use the winning strategy from . If  is not canonical, then  for some . It is very easy to see that , and again Duplicator can use the winning strategy from .

Let us assume now that  where  are simple and . Suppose  for some . Then . Indeed, consider the game . While Spoiler keeps inside , Duplicator should keep in  and apply the strategy from . Suppose Duplicator enters . Since , it holds that  dominates  and we may assume that Spoiler has removed his non-critical tokens before entering . From now on Duplicator may simply mimic Spoiler's behaviour. 

An analogous argument shows that for , we get . For ,  is a canonical automaton (up to a~permutation of the input alphabet). 

Now, consider ,  simple and . By the definition of canonical automata, , and since , . Let  be the least number for which . Let  and . In order to reduce this case to the previous one it is enough to check that  (the converse inequality is obvious). Consider . While Spoiler's critical token stays inside , Duplicator follows the strategy from . If Spoiler does not leave , he loses. Suppose that Spoiler finally enters . Note that  dominates  and . Hence, by Lemma \ref{resetrule}, we may assume that Spoiler removes all his non-critical tokens on entering . Duplicator should simply move his critical token to the initial state of  and mimic Spoiler's actions. 

Suppose now that   or . Let  with  simple. For  proceeding like in Proposition \ref{omegaclosure} (page \pageref{omegaclosure}) one proves that 
\begin{enumerate}[(1)]
\item ,
\item , 
\item ,

\item ,
\item .
\end{enumerate}
In the remaining case,  , argue like for branching .

For , the implications (2), (3), and (4) also hold, and give a canonical form if  is non-branching.  If  is branching,  for , and  for .

Finally let , where  are simple. Using the fact that  is associative up to , and Lemma \ref{substitution} (page \pageref{substitution}), we get  where  is a~canonical automaton equivalent to . Repeating this  times more we obtain a~canonical automaton equivalent to .\qed

\vspace{5pt}

In the following proofs we will need the following property. For simple branching automata , let . \index{}

\begin{lem} \label{auxiliary_oplus} 
For every  and every simple branching   one can find in polynomial time a~canonical automaton equivalent to .
\end{lem}

\proof  is simple branching, so  where  or .  Let , where  and   is a~simple automaton. Suppose first that  is a~branching automaton. Then  and  with  or . Let us check that . Consider the following strategy for Duplicator in . While Spoiler's critical token  can reach the head loop of  or  , Duplicator may keep his critical token  looping in the head loop of his automaton . For every new token produced by Spoiler in the head loop of  or , Duplicator produces a~{\em doppelg\"anger} in  the head loop of . When Spoiler moves his critical token  to , Duplicator does the same with  and lets it copy 's actions. As the converse inequality is obvious,  gives the canonical form for .

Now, let  be non-branching. Suppose first that  is one of the automata , ,  for . If ,  by the proof of the closure by . The converse inequality is obvious. Similarly, if , . The converse inequality is obvious again.

The remaining possible values for  are ,  and . If , , and the canonical automaton is obtained via closure by . For , observe that  . By the proof of the closure by  we get . Hence . The converse inequality is obvious. Finally, if , we get . By the structure of canonical automata,  must start with  or . In both cases we can use one of the previous cases to get an equivalent canonical automaton.

If  the whole argument is analogous, only in the last case, for ,  we have . \qed

\begin{prop}\label{land_closure}
For  one can find in polynomial time an automaton in  equivalent to .
\end{prop}

\proof We will proceed by induction on  with the product order induced by . Let ,  with ,  simple. Let  for  and  for .

First, assume that , and either  for some , or  for . Let . Let us see that  . In the first move Spoiler produces token  in  and  in . While  stays in  and  stays in the head loop of ,  Duplicator should keep his critical token in the head loop of  and for each , a~child of  or , produce a~token  whose task is to play against . The token  after being produced is put in the head loop of  or, if , in the head loop of . The token  is put in the head loop of . Since ,  can adapt the strategy from  if  is in , or simply copy 's actions if  is in . Now, two things may happen. If  enters  while  stays in the head loop of , Duplicator should move his critical token to  and split it into  sent to  and  sent to . Then  should mimic , and  should mimic . If  exits the head loop of , Duplicator should move to , produce two tokens, and mimic Spoiler's actions. The converse inequality is even simpler. In a~similar way we prove  for ,  for , and  for . In all four cases using the induction hypothesis, the closure by , , and the Substitution Lemma (Lemma \ref{substitution}, page \pageref{substitution}) we obtain an automaton of the form , where  is canonical. Lemma \ref{auxiliary_oplus} gives an equivalent canonical automaton. 

Next, suppose that , . Assume . Using Lemma \ref{flowers} one proves easily that .  Similarly, for , , we have  and the canonical form follows from the induction hypothesis. For ,  proceed symmetrically. For , . Again, using the induction hypothesis, the closure by , , and the Substitution Lemma, we get an equivalent canonical automaton. 

The general case may be reduced to one of the special cases above, because  . \qed

\vspace{5pt}

Since -replication requires a~rather involved analysis, let us first consider . 

\begin{prop}\label{to_closure}
For  one can find in polynomial time an automaton in  equivalent to .
\end{prop}

\proof First, let us deal with two special cases for which the general method does not work. For  simple calculations give the following equivalences:  for , , . By the Substitution Lemma, the equivalent canonical forms follow from the closure by , , and .

The second special case is when  contains non-trivial flowers but . First, let us see that  . The inequality  follows easily from Lemma \ref{replication}. For the converse it remains to observe that the following strategy is winning for Duplicator in : in  mimic Spoiler and  in  apply the strategy from  given by Theorem \ref{borelautomata} (3 and 4). An analogous argument shows that . For the remaining possible values of  we will show  .  Again,   is easy. For the converse, observe that  only uses ranks . Consider the following strategy for Duplicator in . In the component  simply mimic the behaviour of Spoiler's critical token. In  use the strategy from , where  denotes  with ranks  and  replaced by  and rank  replaced by . In  use the strategy from , where  denotes  with all 's replaced by 's. The combination of these three strategies is winning for Duplicator.

For the remaining automata, we will show that what really matters is the maximal simple branching automaton contained in . There are two main cases: either  ( for ),  or  ( for ).  In the first case , in the second case . Since the proofs are entirely analogous, we will only consider the first case. We only need to argue that , since the converse inequality is obvious.

Let us start with . Denote the head loop of  by . It is enough to show a~winning strategy in . Since no path from the head loop of  to  goes through an accepting loop, Duplicator may keep his critical token in the head loop of  as long as at least one of Spoiler's tokens can reach . Hence, for every token produced by Spoiler in , Duplicator can produce a~{\em doppelg\"anger}. When none of Spoiler's tokens can reach  any more, Duplicator moves his critical token to  and mimics Spoiler.

Let us now suppose that ,  (for  the proof is very similar). The strategy for Duplicator in  is as follows. Let  be such that . For every token  produced by Spoiler using the head loop of , Duplicator produces  tokens  using the head loop of . Then the tokens  play against  simulating Duplicator's winning strategy from . When Spoiler moves his critical token to , Duplicator does the same and keeps mimicking Spoiler in .

Thus we managed to simplify  to  where  or . An equivalent canonical automaton is provided by Lemma~\ref{auxiliary_oplus}.  \qed

\vspace{5pt}

Now we are ready to deal with -replication. Since , the class  is not closed by . However, adding the three top canonical automata is enough to get the closure property.

\begin{prop}\label{longrightarrow_closure} 
For , , one can find in polynomial time  an automaton in  equivalent to . 
\end{prop}

\proof Let . If  admits any of the automata , , , then it is equivalent to the maximal one it admits (see Theorems \ref{borelautomata} and \ref{hardcore}). Let us assume  admits none of the three automata above. Let us also assume that .

\paragraph{{\em  1. If some  contains a~-flower  and some  contains a -flower, then .}} It is easy to show that  (c.~f. Lemma \ref{replication}). We shall concentrate on the converse inequality. From the hypothesis that  does not admit , it follows easily that  must be odd and  must be  automata. Furthermore, since  does not admit ,  uses only ranks . The strategy for Duplicator in  is analogous to the one used in the proof of the previous proposition. In the component  simply mimic the behaviour of Spoiler's critical token. In , loop around the -loop whenever Spoiler loops around the -loop of a -flower in  (again, if the run is to be accepting, this may happen only finitely many times), otherwise loop around -loop. For the strategy in , treat all the ranks appearing in Spoiler's  or  as 's, and the 's in  as 's. Seen this way,  is a~-automaton, and by Theorem \ref{borelautomata} Spoiler's actions can be simulated in .

\paragraph{{\em 2. If  contain only -flowers, then  .}} This is proved just like the first case.

\paragraph{{\em 3. If  contain only -flowers, then   (use case 4 or 5 to get a~canonical form).}} Like in the first case,   must be odd,  must be -automata. Consequently, it must be  that contains a -flower. Since  contain no  (by the hypothesis no  does), .  Again  is easy. The strategy for Duplicator in  is to copy Spoiler's actions in  and in  keep record of all 's appearing in  (if the run is to be accepting, there may be only finitely many altogether).

\paragraph{{\em 4. If  contain no non-trivial flowers, , and  contains a~, then .}} The inequality  is proved just like in the first case. Let us see that the converse holds. Consider the game  and the following strategy for Duplicator. Copy Spoiler's actions in , but whenever Spoiler enters the -loop in , loop once around -loop, move the extra token to the head loop of , and keep looping around until Spoiler leaves his -loop. Then remove your extra token, and so on. It is easy to see that the strategy is winning for Duplicator. 

\paragraph{{\em 5. If  contain no non-trivial flowers and either  or  contains no , then .}} To prove it, we have to describe the strategy for Duplicator in . During the whole play keep numbering the new tokens produced by Spoiler according to their birth time. (As usual, the left token is considered a~parent, the right token is born, transitions of the form  or  do not produce new tokens.) The strategy is as follows. While there are no new tokens in rejecting loops in , keep copying Spoiler's moves in his . When the first new token, say , enters a -loop, start looping around the -loop of your  (the loop exists since ), and keep doing it until  leaves the -loop. If it does not happen, Spoiler will lose. When it does happen, stop looping around -loop. Investigate all the ranks used by Spoiler in -flower while you were simulating , choose the highest one, say , and loop once a~-loop. Afterwords, if there are no tokens in rejecting loops in , copy Spoiler's moves. Otherwise, choose the token with the smallest number, say , start looping around the loop with the highest rank  in your -flower, and so on.

Let us see that if Spoiler does not enter , he loses the game. If the run constructed by Spoiler is to be rejecting, either the highest rank used infinitely often in  is odd, or some token stays forever in a~rejecting loop in one of . In any case Duplicator's strategy guarantees a~rejecting run for him as well. Let us suppose that Spoiler's run is accepting. If only finitely many new tokens entered rejecting loops in , then there was a round such that from this round on Duplicator was simply mimicking Spoiler's actions in  and so Duplicator's run is also accepting. Suppose that infinitely many new tokens visited rejecting loops in . We have assumed that either  or  contains no . In either case the ranks greater then  must have been used infinitely many times in . Consequently, the highest rank used in  is greater then , and Duplicator's run is accepting despite infinitely many 's used in .

Suppose now that Spoiler leaves . Following the argument used in the proof of the closure by , we may suppose that the simple automaton containing the head loop of  is at least a~. When Spoiler enters , he may produce no more tokens in .  From now on Duplicator should mimic Spoiler's behaviour in his copy of , handling rejecting loops in  in the usual way.

\vspace{10pt}

What is left is the case . If  is odd, . If  is even,  must be a~-automaton. In the cases 2 and 4 proceed just like before. In the case 5, the automaton  cannot contain . If , then   . If , then  . \qed
 

\vspace{5pt}

 The following corollary sums up the closure results. 

\begin{cor} \label{closure}
The class of canonical automata  is closed by , , , , and the equivalent automaton can be found in polynomial time. 
\end{cor} 

\proof The claim is an almost immediate consequence of the preceding propositions. Only the automata , ,  need special care: if the result of the operation in question admits any of these automata, it is equivalent to the hardest one it admits (Theorems \ref{borelautomata} and \ref{hardcore}). \qed


\section{Completeness} \label{sect:completeness}

In this section we show that the canonical automata represent the -classes of all deterministically recognisable tree languages. We will implicitly use Corollary \ref{closure} and the Substitution Lemma (Lemma \ref{substitution}, page \pageref{substitution}) on several occasions. 

We will say that a~transition is {\em positive} \index{positive transition} if one of its branches lies on an accepting loop, and {\em negative} \index{negative transition} if one of its branches lies on a~rejecting loop. Note that a~transition may be positive and negative at the same time. Recall the notion of replication (see page \pageref{replicated}). We say that a~state is -replicated if it is replicated by a~-loop. An automaton is -replicated if its initial state is -replicated.

Finally, let us recall the {\em lifting operation} \index{lifting operation} invented by Niwi\'nski and Walu\-kiewicz and used to prove the decidability of the deterministic index hierarchy (Theorem \ref{omegaindch}, page \pageref{omegaindch}). 

\begin{lem}[Niwi\'nski and Walukiewicz \cite{kwiatek}] \label{lifting} 
For each deterministic automaton  one can compute (in polynomial time if the productive states are given) an automaton  such that  and if a~state  has the rank  than  lies on a~-loop of a~-flower. \qed
\end{lem}


\begin{thm} \label{completeness}
For every deterministic tree automaton there exists an equivalent canonical automaton.
\end{thm}

\proof Let  be a~deterministic tree automaton. From Theorem \ref{borelautomata} (7) it follows that if  admits , . If  does not admit , then by Theorem \ref{borelautomata} (5 and 6) if  admits , . Otherwise  and if  admits , then  (Theorem \ref{hardcore}). In the remaining of the proof we will assume that  admits none of these three automata. We will proceed by induction on the height of the DAG of SCCs of . Let  denote the root SCC of . We will say that  contains a~transition , if  contains all three states,  , , and . We consider four separate cases.

\paragraph{{\em 1.   contains a~positive transition.}} Observe that each state of  is replicated by an accepting loop. Therefore, if  admits , it must also admit , which is excluded by our initial assumption. Consequently,  is a~-automaton (Theorem \ref{indch}). Without loss of generality we may assume that  uses only ranks  and .

By Theorem \ref{borelautomata} (3 and 4),  is -complete and , which implies that . If  admits , then it also admits , and so . From Theorem \ref{borelautomata} (3) it follows that . Consequently, .

Suppose that  does not admit , but  contains a rejecting loop . Let  be a state on that loop. Since  contains a positive transition, it must contain an accepting loop and, in particular, a state with rank 2, say . Since  is strongly connected, we may find a loop  going from  to  via . Since  only uses ranks  and , and ,  is accepting. Hence,  and  form a -flower. In consequence, .  Hence, . 

Finally, suppose that  contains no rejecting loops and  does not admit . By Theorem \ref{borelautomata} (2),  and since  is -complete, . If  admits  it also admits , and so . If  does not admit  it means that it contains no rejecting loop. Hence,  accepts every tree and .

\paragraph{{\em 2.  contains an accepting loop and a~negative transition, but no positive transitions. }} Let  be an accepting loop in  and  be a~loop visiting all 's nodes and containing a~branch of the (negative) transition contained in . Since  does not contain positive transitions,  is rejecting. The loops   and  form a~-flower. Hence,  admits .  Furthermore, should  contain a~-flower, it would obviously be replicated by  and  would admit , which contradicts our general hypothesis. Hence,  does not admit , which means  is a -automaton (Theorem \ref{indch}, page \pageref{indch}). Without loss of generality we may assume that it uses only ranks . 

By Theorem \ref{borelautomata} (3 and 4), if  admits neither  nor  , then . Suppose that  admits one of these two automata. Consider the game . Let  and  be Spoiler's tokens in  and , respectively. Since  contains a~(negative) transition, Duplicator can split his critical token into  and  within , and move  to the -flower in , and  to the -flower, or to the accepting loop replicating a~weak -flower (if  admits ). Then  should mimic , and  should mimic  --- either directly, or adapting the strategy from . Hence, Duplicator has a~strategy to win the game. It follows that . 

For the converse inequality, let us call the states with rank 3 contained in a~-flower {\em red}, and the remaining {\em blue}. Since  does not admit , no red state is replicated by an accepting loop. Consider the game . For a strategy in   Duplicator should treat all the red states as if they had rank 1; the automaton   modified this way does not admit , so Duplicator may use the strategy given by Theorem \ref{borelautomata} (3 and 4). In  Duplicator should loop a~-loop whenever some Spoiler's token is in a~red state. Otherwise, Duplicator should loop a~-loop. Let us see that this strategy is winning. 

Suppose that Spoiler's run is accepting. After changing the ranks of red states from  to  it is still accepting, so Duplicator's token in  visited an accepting path. By the Replication Lemma (Lemma \ref{replication}, page \pageref{replication}), the occurrences of red states in Spoiler's run may be covered by a~finite number of paths. Furthermore, each of these paths is accepting, so it may only contain a~finite number of red states. Hence, there may be only finitely many red states in Spoiler's run and the path visited by Duplicator's token in  is also accepting. 

Suppose now, that Spoiler's run is rejecting. If red states occurred only finitely often, Spoiler's run is still rejecting after changing their ranks to , so Duplicator's token in  visited a~rejecting path. If there were infinitely many red states in Spoiler's run, Duplicator's token in  visited a~rejecting path. 

Hence,  and by Lemma \ref{flowers}, .

\paragraph{{\em 3.  contains some transitions but no accepting loops.}} Let ,  be all the transitions such that  and . Let   be all the remaining transitions such that   and . We will call the automata ,  and  the {\em child automata of }. By the induction hypothesis we may assume that they are in canonical forms. Let . It is not difficult to see that  is equivalent to . 

\paragraph{{\em 4.   contains no transitions. }} Recall that this means exactly  that at most one branch of every transition stays in . First replace subtrees rooted in the target states of transitions whose all branches leave  with one canonical automaton  just like above. Let  denote the highest index of a~flower contained in . It is well defined, because a~strongly connected component admitting   and  must also admit . We may assume that  uses only ranks , and that each -loop is indeed a~-loop in a -flower (Lemma \ref{lifting}).  For each , let  be the alternative of all the child automata replicated by a~-loop in . By induction hypothesis, we may assume that  and  are canonical automata. Let . We will show that .

If , the assertion is clear. Suppose that . Obviously, . Let us see that  . Let  denote the result of the following simplifications performed on .
\begin{enumerate}[]
\item If some  contains a~-flower and some  contains a -flower, replace  with a~-flower.
\item If some  contains a~-flower and no  contains a -flower, replace  with a~-flower.
\item If some  contains a~-flower and no  contains a -flower, replace  with a~-flower.
\item If  admit no  with , remove .
\item If  and  admits , replace  with . Otherwise, remove .
\item Remove all .
\end{enumerate}
  Examination of the five cases considered in the proof of Proposition
  \ref{longrightarrow_closure} reveals that  and  have
  identical canonical forms. Consequently, , and it is
  enough to show that . Consider all -flowers in . Choose any one whose -loop
  replicates , if there is one, or take any -flower otherwise. Then, extend the -loop to a~loop
  using all the transitions in . Denote this flower, together with
  the subtrees replicated by -loop or -loop, by
  . One can prove easily that , and obviously
  . \qed


\begin{algorithm}
\caption{The canonical form of deterministic tree automata}
\begin{algorithmic}[1]
\IF { admits } \STATE return 
\ELSIF { admits } \STATE return 
\ELSIF { admits } \STATE return 

\ELSE


\STATE  the root SCC of  
\IF { contains a~positive transition}
\IF { admits  or  admits }
\STATE return 
\ELSIF { admits }
\STATE return 
\ELSE 
\STATE return 
\ENDIF
\ELSIF { contains a~negative transition}
\IF { admits }
\IF { admits  or   admits }
\STATE return 
\ELSE
\STATE return  
\ENDIF
\ELSE
\STATE  the alternative of the canonical forms of 's children
\STATE return 
\ENDIF
\ELSE[ contains no transitions]
\STATE  the alternative of  the canonical forms of 's non-replicated children 
\STATE lift ranks in 
\STATE  the index of the maximal flower
\FOR { to } 
\STATE  the alternative of the canonical forms of 's -replicated children
\ENDFOR
\STATE return 
\ENDIF
\ENDIF
\end{algorithmic}
\end{algorithm}

From the proof of the Completeness Theorem one easily extracts an algorithm to calculate the canonical form of a~given deterministic automaton (Algorithm 1). 

\begin{cor} \label{canonical}
For a~deterministic tree automaton, a~Wadge equivalent canonical automaton can be calculated within the time of finding the productive states of the automaton.
\end{cor}

\proof It is easy to see that the size of the canonical forms returned by the recursive calls of each depth is bounded by the size of  (up to a~uniform constant factor). To prove the time complexity of the algorithm assume that the productive states of  are given. Checking if  admits any of the automata mentioned in the algorithm can be easily done in polynomial time. The operations on the automata returned by the recursive calls of the procedure (lines 25, 26, 29, 33, and 35) are polynomial in the size of those automata, and by the initial remark also in the size of the automaton. By Lemma \ref{lifting} the lifting operation is also polynomial. Therefore, when implemented dynamically, this procedure takes polynomial time for each SCC. Processing the entire automaton increases this polynomial by a~linear factor. \qed

\vspace{5pt}

Instead of a~canonical automaton, the algorithm above can return its
``name'', i.~e., a~letter , , or , and an ordinal
 presented as a~polynomial in
, with the coefficients presented as polynomials in
. Since for such presentation it is decidable in linear time
if , as an immediate consequence of Corollary
\ref{canonical} and Theorem \ref{strictorder} we get an algorithm for Wadge reducibility.

\begin{cor} 
For deterministic tree automata ,  it is decidable if  (within the time of finding the productive states of the automata). \qed
\end{cor}


\section*{Acknowledgements}

The author thanks Damian Niwi\'nski for drawing his attention to the Wadge hierarchy problems, and for reading carefully a preliminary version of this paper. The author is also grateful to the anonymous referees for their sharp yet extraordinarily useful comments that had a great impact on the present version of the paper. 

\begin{thebibliography}{99}

\bibitem{contextfree} J. Duparc. 
  A~hierarchy of deterministic context-free -languages.
   Theoret. Comput. Sci. {\bfseries 290} (2003) 1253--1300.

\bibitem{finkel} O. Finkel. 
  Borel ranks and Wadge degrees of omega context free languages. 
  Mathematical Structures in Computer Science {\bfseries 16} (2006) 813--840.

\bibitem{kechris} A. S. Kechris.
  \textit{Classical Descriptive Set Theory.}
  Graduate Texts in Mathematics Vol. 156, 1995.

\bibitem{kupferman} O. Kupferman, S. Safra, M. Vardi.
  Relating Word and Tree Automata. 
  \textit{11th IEEE Symp. on Logic in Comput. Sci.} (1996) 322--332.

\bibitem{split} F. Murlak.
  On deciding topological classes of deterministic tree languages.
  \textit{Proc. CSL'05}, LNCS 3634 (2005) 428--441. 

\bibitem {klony} D. Niwi\'nski.
  On fixed point clones.
  \textit{Proc. ICALP'86}, LNCS 226 (1986) 464--473.

\bibitem {kwiatek} D. Niwi\'nski, I. Walukiewicz.
  Relating hierarchies of word and tree automata.
  \textit{Proc. STACS'98}, LNCS 1373 (1998) 320--331.

\bibitem{gap} D. Niwi\'nski, I. Walukiewicz.
  A~gap property of deterministic tree languages.
  Theoret. Comput. Sci. {\bfseries 303} (2003) 215--231.

\bibitem{hie} D. Niwi\'nski, I. Walukiewicz.
  Deciding nondeterministic hierarchy  of deterministic tree automata.
  \textit{Proc. WoLLiC'04}, Electronic Notes in Theoret. Comp. Sci. 195--208, 2005.

\bibitem{perrin} D.~Perrin, J.-E.~Pin.
  \textit{Infinite Words. Automata, Semigroups, Logic and Games.}
  Pure and Applied Mathematics Vol. 141, Elsevier, 2004.

\bibitem{selivanov} V. Selivanov. 
  Wadge Degrees of -languages of deterministic Turing machines.
  Theoret. Informatics Appl. {\bfseries 37} (2003) 67-83.

\bibitem{skurcz} J. Skurczy\'nski.
  The Borel hierarchy is infinite in the class of regular sets of trees.
  Theoret. Comput. Sci. {\bfseries 112} (1993) 413--418.

\bibitem{urban} T. F. Urba\'nski.
  On deciding if deterministic Rabin language is in B\"uchi class.
  \textit{Proc. ICALP'00}, LNCS 1853 (2000) 663--674.

\bibitem {wagner0} K. Wagner.
  Eine topologische Charakterisierung einiger Klassen regul\"arer Folgenmengen.
  J. Inf. Process. Cybern. EIK {\bfseries 13} (1977) 473--487.

\bibitem{wagner} K. Wagner. 
  On -regular sets. 
  Inform. and Control {\bfseries 43} (1979), 123--177.

\end{thebibliography}

\end{document}
