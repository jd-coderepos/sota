The main result of this section is a data structure of near-linear size that can 
answer approximate simplicial depth queries in polylogarithmic time.
Later, it will be used to get an almost-optimal algorithm for approximating the
simplicial depth in 3D.
The problem can be stated as a triangle counting problem:
given a set of  points  in the plane, build a data structure 
capable of approximating
the number of triangles formed by points of  that contain a query point .

Let  be a -sample from .
Consider the simple and easy case when  is empty. Then, we have
 by linearity of expectation and the observation
that any triangle made by points of  containing 
survives with probability . By Lemma~\ref{lem:RS}, we can conclude that
a recursively computed approximation for  is with high probability
very close to .
If  is not empty, then it can only contain polylogarithmically many points
(as each point contributes a significant amount to the simplicial depth) and thus
we need to keep track of a ``few'' points.
The biggest challenge, however, is finding the subset .
This is done with the following lemma.
    Unfortunately its proof does not seem to be easy and in fact it requires overcoming
    many technical steps and combining shallow cuttings with various observations
    regarding the geometry of planar points. We ultimately reduce the problem
    to instances of orthogonal range reporting problem in eight(!) dimensional space, which fortunately can
    be solved with  space and  query time.
    The proof is given in Section~\ref{sec:findlarge}.

\begin{restatable}{lemma}{rlemfindlarge}
    \label{lem:findlarge}
	Let   be set of  points and let 
     in which
     is a -sample from .
    There exists a data structure of size , such that the following holds with high probability.
    Given  and a query point , define , where
     is a constant and  is a fixed parameter.
    If , then
    the data structure can find the set  that contains all
    the points  with  in  time.
	The data structure can be built in  expected time. 

    Also, the data structure defines  canonical halfplanes, such that 
     lies inside a halfplane  that contains  and  points of .
     only depends on  and not .
\end{restatable}


We also need the following lemma.
For the proof, see Section~\ref{sec:calc}.
\begin{restatable}{lemma}{lemcalc}\label{lem:calc}
    Given a parameter , 
    we can store a set  of  points in a data structure of size  
    that can answer the following queries. 
	Given a query point , a halfplane  
	with  on its boundary containing
     points of , and a subset of , we
    approximate the total number of triangles that contain  and include at least one point 
    from  in  time and with additive error of 
	at most .
\end{restatable}

In the rest of this section, we outline our solution to approximate the simplicial depth of a query point.
Consider a series of random samples 
 in which  is a -sample from 
and .
We store each sample  in the data structure from Lemma~\ref{lem:calc}.
Furthermore, we store the sampling sequence
sampling sequence  in the data structure from Lemma~\ref{lem:findlarge}.

We use a recursive approach where Lemmata~\ref{lem:RS},~\ref{lem:findlarge},
and \ref{lem:calc} are our bread and butter: during step  of the query
algorithm, 
we are given a set  containing  points, such that
.
The goal is to compute  where .
Initially,  and .

Our strategy will be to recursively compute the simplicial depth.
We will assume our recursion returns a relative -approximation of
. 
By using Lemmata~\ref{lem:RS},~\ref{lem:findlarge}, and \ref{lem:calc} with parameter , 
we can return a value that is a relative -approximation of 
. 
We set  such that at the top of the recursion we end up
with a relative -approximation. Now we present the details.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{figs/venn}
    \caption{ is a -sample of . 
     is obtained through Lemma~\ref{lem:findlarge} and it is shown in red.
    , , , and
     the greyed areas represent .}
    \label{fig:venn}
\end{figure}
\paragraph*{Approximating .}
Let .
First, observe that if , then we can directly approximate 
 using Lemma~\ref{lem:calc} by setting  in
Lemma~\ref{lem:calc}.
In the rest of this proof, we assume that .

See Figure~\ref{fig:venn} for a Venn diagram  of the various subsets involved
here.  We set  and using
Lemma~\ref{lem:findlarge}, we find the set . Let
, , and
.  Clearly,
, and  so
we can recurse. Assume we obtain a value  that is a relative  approximation
of .  Note that  is a -sample of .
From the definition of  and by Lemma~\ref{lem:RS}, we can
conclude that with high probability

By Lemma~\ref{lem:calc}, we can approximate the number of triangles, , that
contain at least one point from  with additive error
. This combined with  gives an approximate
value of  with additive error
.  Combined with (\ref{eq:high}),
this gives an estimate for  with additive
error .  Let , , be the number of triangles containing  that have  points from the set
 and  points from .  Clearly,  and .  Using Lemma~\ref{lem:calc}, we approximate  with
additive error . 
However,  and  are negligible compared to our error margins:
by Lemma~\ref{lem:SH}, 
but  can be at most  and  can be at most .
Since , it follows that
we can ignore  and  in our calculations and that Lemma~\ref{lem:calc} 
reveals an approximation of .
With these observations, we can 
obtain an approximation   with additive error
.  Combining this with an
approximation of  yields an approximation of  with additive
error .
Observe that the error factor in our additive term has worsened from  
(regarding  and ) to 
(regarding ).
However, we have  and there are at most  recursion steps.
Thus at the top of the recursion (that is for ), we obtain a
 approximation factor, as claimed.

\begin{theorem}\label{thm:2d}
	It is possible to preprocess a point set  of
	 points in  expected time
	using  space such that, given a query point ,
	a relative -approximation for the simplicial depth of  
	can be found in 
	 expected time for any arbitrary fixed constant 
	with high probability.
\end{theorem}


\section{Proof of Lemma~\ref{lem:findlarge}}~\label{sec:findlarge}

\begin{restatable}{lemma}{lemob}\label{lem:ob1}
    Let  be a set of  points,  an 
    arbitrary point and 
    a halfplane containing at most  points
    with  at its boundary.
    Consider the line  for a point  and assume
    it partitions  into two sets of sizes  and .
    If  then 
	 is a relative (1+-approximation of .
\end{restatable}
\begin{proof}
    The number of triangles containing  and involving  is at least
     and at most  where  
	is the number of points in .
    The lemma follows by a simple calculation and observing that  is minimized
    when  or  is .
\end{proof}

We also use shallow cuttings which we state in two dimensions.
For a set of lines  in the plane, the \emph{level} of a point  is the number
of points that pass below . 
Given an integer , the -level of  is the closure of all the points that have
level exactly .
The -level is defined as the closure of all the points with level at most .
\begin{theorem}\label{thm:shallow}
	Let  be a set of  lines in the plane and  be a given parameter .
	We can find a convex polygonal chain  of size  such that it lies above
	the -level of , the level of every vertex of  is .
	The cutting can be constructed in  time. 
\end{theorem}
\begin{proof}
	Matou\v sek~\cite{Matousek.reporting.points} proved that one can cover the -level
	with  triangles such that there are at most  lines passing below
	each triangle. 
	Chan~\cite{Chan.Range.Reporting.SJC00} observed that we can consider the convex hull of the triangles; 
	the number of lines passing below the convex hull is only increasing by .

	Ramos~\cite{Ramos.SOCG99} offered a randomized  construction in 1999
	and recently Chan and Tsakalidis have shown the same running time can be
	achieved with a deterministic algorithm~\cite{chanshallow}.
\end{proof}


We will also be working with point-line duality in the plane.
This transformation, maps a line  passing below (reps.\ above) a point 
to point  that lies below (resp.\ above) the line .



\rlemfindlarge*
\begin{proof}
    We will describe the data structures incrementally.
    Consider the set  of  lines dual to .
    Let , . 
	First, by \Mat's shallow cutting theorem (Theorem~\ref{thm:shallow}), for each , we build a shallow
    cutting  for the -level of , that is a convex
    polygonal chain of size  that lies between -level and -level of
    . 
    Each vertex  of the polygonal chain  defines a canonical halfplane in primal space 
    (the region below ).
    For each , the subset of  that lies inside a canonical halfplane is called a \emph{canonical set}.
    We also do the same for the -level (to obtain cuttings ).
	By Theorem~\ref{thm:shallow}, each chain  has  vertices and thus creates  canonical sets.
	Furthermore, each canonical set contains  points.
    Thus, the total size of canonical sets on  is  which is also an upper bound for the total
	size of the canonical sets on each . 
	This means, the total size of canonical sets,
    over all indices  is .
    Furthermore, a standard application of the Chernoff bound yields that  is below
	-level and above -level of , with high probability (similarly for ); let's
	call this the \emph{level property}.
    In the rest of this proof, we will build a separate data structure for each .
    There are  different indices  and thus this would only blow up the space by a  factor.
    Let  be the subset we are currently working with. 
    Given a query point , the goal is to report a subset  that contains all
    the points  with .



    \begin{figure}[h]
        \centering
        \includegraphics[scale=1.0]{figs/larged}
        \caption{(a) In dual space,  passes below a vertex  of a shallow cutting. 
		The set of lines below  are considered a \emph{canonical set}.
		(b) In primal space, the region below  is a canonical halfplane. We
		can draw a line  parallel to  from .
		(c) Any point that is above  cannot create  triangles that contain  since it is forced
		to pick a point from below  and there are only few such points.
		(d)  lies below . The line  is defined by connecting  and . 
	There are  points below the line  and  points above it.
		(e) If a line intersects the convex chain , then it creates an interval on its boundary.
		We can tell if two lines intersects between chains  and  by examining the
	corresponding intervals that they define. }
        \label{fig:larged}
    \end{figure}

    The given query  point , corresponds to a query line  in the dual space.
    If  is the smallest index such that  intersects  or , then
     is an approximation of  up to  factor, by the level property.
    W.l.o.g, assume  intersects  and thus passes below a vertex 
    (the other case when  intersects  can be found in an analogous way and by
    building analogous data structures).
	Let  be the point on  the lies directly below  (Figure~\ref{fig:larged}(a)).
    In the primal space,  corresponds to a line that goes through  and has 
    points below it, with high probability (by definition of , there are at least
	 points below  as well).
    Furthermore,  is parallel to a canonical halfplane that is the dual of  
    (see Figure~\ref{fig:larged}(a,b)).
     defines .

    We now claim,  has to be a subset of points of  that are below .
    See Figure~\ref{fig:larged}(c).
    Consider a point  that is not below ; any triangle that contains  and includes ,
    must include a point below .
    Remember that  has only  points below it. 
    This means, .
     By Lemma~\ref{lem:SH}, we have .
    Note that we need to answer queries for when ,
	namely, when ,
    so we have .
    This means .

    Now that we have established  has to be a subset of  below , we turn our attention to 
    building the proper data structures to find it.

    Consider a canonical set that contains the subset of  below the line ; denote this
	canonical set by  and let .
    We can build  canonical \emph{subgroups}, where each subgroup is a subset of 
    such that the points below any line  parallel to  can be
    expressed as the union of at most  canonical subgroups:
    this is done by projecting the points of  onto a line perpendicular to ,
    and then building a balanced binary tree on the resulting one-dimensional point set; each
    node of the balanced binary tree defines a canonical subgroup.
    The total size of the canonical subgroups created on  is .

    Remember that our goal was to find all the points  below  with .
    We can now use the canonical subgroups, since there  subgroups that cover all the
	points below ;
    we can query each such subgroup independently to find the subset of  that lies in that subgroup;
    this would only blow up the query time by a  factor.
    Furthermore, remember that the total size of all canonical sets was  and thus the total size
    of all canonical subgroups is .
    Thus, we can afford to build  a separate data structure for each canonical subgroup.

    Consider a canonical subgroup  that contains  points.
    Our new goal is to find all  points   such that .
    We claim to approximate  it suffices to draw the 
    line  and then multiply the number of points of  that lie at either side of 
    .
    See Figure~\ref{fig:larged}(d). 
    Let  and  where  and 
    corresponds to the halfplane above and below .
    W.l.o.g, assume .
    Consider a point  with .
    We have
	
	and thus we must have
	
    and thus
    
    Let  be the number of points below .
    On the other hand, we have 
    
    Since , it follows that 
    
    and thus  is  a constant factor approximation of .
    This in turn implies  is also a constant factor approximation of .
    This is the motivation for defining the following concept:
    For a point  below , we call the minimum number of points of  
    at either side of line  its {\em dissection value with respect
    to  and \/} (or its dissection value for short).
    In Figure~\ref{fig:larged}(d),  is the dissection value of , if .

    Thus, our goal can be further reduced to the following, that we call \emph{dissection reporting}: 
    For a canonical subgroup  that contains  points,
    build a data structure that can answer the following:
    given a query point , a threshold , and a line  parallel to  such that 
     lies below , find all points in  with dissection value larger than .
    To find the part of  in , we simply set  for an appropriate constant
    hiding in the  notation; as we observed, the dissection value times  is a
    constant approximation of  so this way, we can find a subset that contains
    all the point in . 
    However, we will report a few extra points as well; nonetheless, we can observe that the number
    of extra points reported is only a constant factor larger since every point that gets reported
    contributes a lot to the simplicial depth of  and there cannot be too many such points.

    To solve the dissection reporting problem, let  be the set of lines dual to . 
    We build a shallow cutting  for the -level of
     (resp.  for the -level of ), for  for a large enough constant .
     is a convex polygonal chain and  if
     is set large enough, then  lies between the -level and the -level of .
    This means that the polygonal chains  will be non-intersecting and  is contained
    inside .
    Consider a line  in dual space (see Figure~\ref{fig:larged}(e)).
    If  intersects , then it creates an interval on , marked by the two intersection
    points of  with . 
    Let's call this ; note that the end points of this interval come from a
    one dimensional domain which can be parameterized in various different ways, such as using
    polar angles from a point inside each polygonal chain.
    Consider  for every point  as well as the
    interval  defined by the
    line dual to the query point. 
    We say two intervals  and  intersect if they have a point in common and none of the intervals
    fully contains the other.
    Consider an index  such that  intersects the interval   
    but  does not intersect the interval .
    This means that the intersection point of the lines  and  is between
     and  (see Figure~\ref{fig:larged}(e)).
	Imagine for the upper chains, the intersection point of the lines  and  
	is between  and  where .
    This implies that the dissection value of line  is .

    Motivated by the observation in the above paragraph, we do the following.
    For each pair of indices , we create a data structure that is capable of finding all the
	lines  that the intersection point of  and 
	lies between  and  and also between  and .
	If we do this, then we can perform dissection reporting by issuing  such queries:
	we first query , then query  and  and so on.
	Specifically, to find points with dissection value  we query
	 as well as .

	It thus remains to show how a query pair  is answered.
    For every point , we create a tuple of four input intervals corresponding to the
	intersection of  with , and .
    The query also defines a tuple of four intervals in a similar fashion.
	The goal is to store the input tuples of intervals in a data structure
    such that given a query tuple of intervals
    we can find all the input interval tuples such that they
	guarantee  and  intersect between  and  and also between  and .
	Let  an input tuple of four intervals.
	We create an eight-dimensional  point .

	We now claim the problem can be solved using dominance reporting in eight dimensional space.
	In dominance reporting, a point  is said to \emph{dominate} a point  if
	any coordinates of  is greater than that of . 
	In dominance reporting, we are to store a set of points in a data structure such that given a point ,
	we can report all the points dominated by .
	Observe that in our subproblem, we can also map the tuple of intervals corresponding to the query
	to the eight dimensional space. 
	Here, we can express the constraints that 
	 and  intersect between  and  and also between  and 
	as inequalities between respective coordinates of the eight dimensional points, meaning,
	the problem can be solved by building a constant number of eight dimensional dominance reporting
	data structures and issuing a constant number of dominance reporting queries.
	
    Dominance reporting queries can be answered in polylogarithmic time,  using  data structure that 
	needs near-linear space and preprocessing time~\cite{AAL3,Chan.Kasper.Mihai.orth,Bentley.80,Chazelle.filtering.search,Chazelle.Guibas.fractional.II}
	polylogarithmic time, we can find the subset of  in  using polylogarithmic space overhead and polylogarithmic
    query time.

    Thus, in overall, our data structure will use  space and preprocessing time and can 
	answer queries in  time.
\end{proof}


\section{Proof of Lemma~\ref{lem:calc}}\label{sec:calc}
\lemcalc*
\begin{proof}
    We recall the definition of the dissection value from the proof of Lemma~\ref{lem:findlarge}:
    For a point , we call the minimum number of points of  
    at either side of line  its {\em dissection value with respect
    to  and } (or its dissection value for short).
	Let  be the number of points in .

	We build data structure for approximate range counting~\cite{Afshani.Chan.SOCG07}, 
	and halfplane range reporting~\cite{cgl85} on .
	Using these, for every point 
	 we can obtain a constant factor approximation of its dissection value.

	Consider a point .
	Draw the line  and 
    let  and  where  and 
    corresponds to the halfplane above and below 
	(very similar to the situation in Lemma~\ref{lem:findlarge}; see also Figure~\ref{fig:larged}(d)).
	Assume .
	Let  be the set of triangles that contain  and have  as one of their vertices.


	As first case, assume .
	At most  triangles from  can have two points from .
	However,  contains at least 
	 
	triangles.
	Observe that if  then 
	 
	Thus, the number of triangles in  with two points from  is negligible.
	So, we focus on the triangles that have exactly one point from . 
	This is at most  and at least .
	Again, an easy calculation yield that  and thus
	 is a relative -approximation of the number of triangles
	in .

	Thus, it suffices to handle points with dissection value less than .
	In the rest of this proof, we assume all the points in  have dissection value
	less than this.

\begin{figure}[b]
    \centering
    \includegraphics[scale=0.5]{figs/small}
    \caption{(a) The input configuration for Lemma~\ref{lem:calc}. (b) For each
    point , a line through  and  is created. This subdivides the
    plane into ``wedges'' that are ifinite triangles with  as their only vertex. By knowing
    the exact number of points inside each wedge, we can compute the simplicial depth in  time.}
    \label{fig:small}
\end{figure}

	As a second case,	assume  which also implies ,
	and that the dissection value of the points in  is at most .
	Let  be all the points in .
	We create the lines  by connecting  to .
	Using halfplane range reporting, we can exactly compute the number of points at one side of 
	each line  in  time. 
	Over all the points in  this will take  time. 
	Given these values, we can compute the number of points that lie inside each ``wedge'' created
	by the lines  (see Figure~\ref{fig:small}(b)) in
	 time. 
	Given these values, the total number of triangles that contain  and have one or two 
	points from the set  can be counted in  time
    (see~\cite{GilStWi1992,KhullerJo1990}).

	Finally, we assume .
	This case can be handled using similar ideas as the previous two.
	Here,  we claim among triangles in , the number of those that
	include two points from  is negligible: the number of such triangles is at most
	 where at the simplicial depth of  is at least 
	by Lemma~\ref{lem:SH}.
	We have
	
	so we can safely ignore triangles that contain two points from .
	This limits us to triangles that have exactly one point from .
	Let  be the points in .
	Again, we create the lines  by connecting  to .
	Using halfplane range reporting, we can exactly compute the number of points at each side
	of the line  in  time. 
	Over all the points in  this will take  time. 
	As before, these values enable us to compute the number of triangles containing one point from .


	Combining all these cases, we obtain a relative -approximation.
	By scaling  by a constant, we can obtain a relative -approximation.
	The total query time is .
\end{proof}
