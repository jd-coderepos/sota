\documentclass{LMCS}

\def\dOi{10(1:19)2014}
\lmcsheading {\dOi}
{1--33}
{}
{}
{Oct.~29, 2010}
{Mar.~31, 2014}
{}

\subjclass{F.2 Analysis of Algorithms and Problem Complexity,
F.4 Mathematical Logic and Formal Languages}

\ACMCCS{[{\bf Theory of computation}]: Design and analysis of
  algorithms; Computational complexity and cryptography---Complexity
  theory and logic; Logic; Formal languages and automata theory}



\usepackage[english]{babel}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{color}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{float}
\usepackage{subfig}
\usepackage{tikz}
\usepackage{xspace}
\usepackage{ulem}
\normalem
\usepackage{hyperref}

\usetikzlibrary{positioning,fit}

\theoremstyle{plain}\newtheorem{mainthm}[thm]{Main Theorem}

\DeclareSymbolFont{letters}{OML}{cmbboard}{m}{it} 

\newcommand{\ncp}{\textnormal{\texttt{ncp}}}
\newcommand{\HZ}[1]{{\color{red}#1}}
\newcommand{\HZdropped}[1]{{\color{red}\sout{#1}}}
\newcommand{\MK}[1]{{\color{blue}#1}}
\newcommand{\MKdropped}[1]{{\color{blue}\sout{#1}}}

\newcommand{\NE}{\hspace{-0.4em}&\hspace{-0.4em}}\newcommand{\NR}{\\}\newcommand{\minfty}{-\infty}

\newcommand\zero{\mathop{\mathsf{zero}}}
\newcommand\BITS{\text{}\xspace}
\newcommand\arity[1]{\ensuremath{\mathsf{arity}(#1)}}
\renewcommand\math[1]{\text{}}
\newcommand\Nat{\ensuremath{\mathbb{N}}}
\newcommand\NAT{\Nat}
\newcommand\Arctic{\ensuremath{\mathbb{A}}}
\newcommand\ALG[1]{\ensuremath{\mathcal{#1}}}
\newcommand\SIG[1]{\ensuremath{\mathcal{#1}}}
\newcommand\VAR[1]{\ensuremath{\mathcal{#1}}}
\newcommand\TERMS[2]{\mathcal{T}(#1,#2)}
\newcommand\GTERMS[1]{\mathcal{T}(#1)}
\newcommand\CGTERMS[1]{\mathcal{T}_\mathsf{Con}(#1)}
\newcommand\FVTERMS{\TERMS{\SIG{F}}{\VAR{V}}}
\newcommand\FTERMS{\GTERMS{\SIG{F}}}
\newcommand\TRS[1]{\ensuremath{\mathcal{#1}}}
\newcommand\TA[1]{\ensuremath{\mathcal{#1}}}
\newcommand\TPDB[1]{\texttt{#1}}
\newcommand\STR[1]{\texttt{#1}}
\newcommand\REL[2]{{\text{\ensuremath{#1 \kern0em/\kern0em #2}}}}
\newcommand\DPP[2]{(\TRS{#1},\TRS{#2})}
\newcommand\WDP{\mathsf{WDP}}
\newcommand\UR{\mathsf{UR}}

\newcommand\linear{\ensuremath{\OO(n)}\xspace}
\newcommand\quadratic{\ensuremath{\OO(n^2)}\xspace}
\newcommand\cubic{\ensuremath{\OO(n^3)}\xspace}
\newcommand\poly{\ensuremath{\OO(n^k)}\xspace}
\newcommand\avg{time\xspace}
\newcommand\timeout{timeout\xspace}
\newcommand\direct{\ensuremath{\mathsf{direct}}\xspace}
\newcommand\modular{\ensuremath{\mathsf{modular}}\xspace}
\newcommand\var[1]{\text{\it #1}}

\newcommand\MATCH{\mathsf{match}}
\newcommand\MATCHRT{\text{-}}
\newcommand\RAISE{\mathsf{raise}}
\newcommand\BASE{\mathsf{base}}
\newcommand\LIFT{\mathsf{lift}}
\newcommand\HEIGHT{\mathsf{height}}
\newcommand\MULEXT{\mathsf{mul}}
\newcommand\MUL{\mathcal{M}\mathsf{ul}}
\newcommand\DROP{\mathsf{drop}}
\newcommand\MFUN{{\mathcal{H}}}
\newcommand\Lg[1]{\mathcal{L}(#1)}
\newcommand\Succ[3][\to]{{#1_{#2}^*}(#3)}
\newcommand\Mul[1]{\MUL(#1)}
\newcommand\MFun[1]{\MFUN(#1)}
\newcommand\Raise[1]{\RAISE(#1)}
\newcommand\match[1]{\MATCH(#1)}
\newcommand\matchRT[3]{\MATCHRT^{#3}(\REL{#1}{#2})}
\newcommand\base[1]{\BASE(#1)}
\newcommand\lift[2]{\LIFT_{#2}(#1)}
\newcommand\height[1]{\HEIGHT(#1)}
\newcommand\lhs[1]{\mathsf{lhs}(#1)}
\newcommand\mge{\succeq_\MULEXT}
\newcommand\mgt{\succ_\MULEXT}
\newcommand\relgt{\succ}
\newcommand\relge{\succeq}
\newcommand\drop[2]{\DROP_{#2}(#1)}

\newcommand\TRSALLNUM{2132\xspace}
\newcommand\TRSDCNUM{1172\xspace}
\newcommand\TRSRCNUM{1339\xspace}
\newcommand\TRSRCNDNUM{910\xspace}
\newcommand\Var{\mathsf{Var}}
\newcommand\Pos{\mathsf{Pos}}
\newcommand\FPos{{\Pos_\mathcal{F}}}
\newcommand\Fun{\mathsf{Fun}}
\newcommand\DFun{\mathsf{Def}}
\newcommand\CFun{\mathsf{Con}}

\renewcommand\max{\mathsf{max}}
\renewcommand\min{\mathsf{min}}
\renewcommand\sup{\mathsf{sup}}
\newcommand\BM{\begin{pmatrix}}
\newcommand\EM{\end{pmatrix}}
\newcommand\OO{\mathcal{O}}
\newcommand\m[1]{\mathsf{#1}}
\newcommand\app{\mathbin{\circ}}
\newcommand\dl[2]{{\mathsf{dh}(#1,#2)}}
\renewcommand\dh[2]{\dl{#1}{#2}}
\newcommand\cp[3]{\mathsf{cp}_{#3}(#1,{#2})}
\newcommand\dc[2]{{\mathsf{dc}(#1,#2)}}
\newcommand\rc[2]{\mathsf{rc}(#1,#2)}
\newcommand\comment[1]{\begin{center} \texttt{#1} \end{center}}
\newcommand\SAT{SAT\xspace}
\newcommand\MINISAT{\ensuremath{\mathsf{\mbox{}Sat}}\xspace}
\newcommand\MINISMT{\ensuremath{\mathsf{\mbox{}Smt}}\xspace}
\newcommand\YICES{\ensuremath{\mathsf{Yices}}\xspace}
\newcommand\category[1]{\emph{#1}}
\newcommand\tpdb[1]{\ensuremath{\mathsf{#1}}\xspace}

\newcommand\rto{\xrightarrow{\smash{
 \raisebox{-0.15em}{}}}}

\newcommand\CETA{\textsf{CeTA}}
\newcommand\TTT{\ensuremath{\mathsf{T\kern-0.2em\raisebox{-0.3em}{}\kern-0.2emT}}\xspace }
\newcommand\TTTT{\ensuremath{\mathsf{T\kern-0.2em\raisebox{-0.3em}{}\kern-0.2emT\kern-0.2em\raisebox{-0.3em}2}}\xspace }
\newcommand\CAT{\ensuremath{\mathsf {C\kern-0.25em\raisebox{0.14em}{}\kern-0.2emT}}\xspace }
\newcommand\TCT{\ensuremath{\mathsf {T\kern-0.2em\raisebox{-0.3em}{}\kern-0.2emT}}\xspace }
\newcommand\MATCHBOX{\ensuremath{\mathsf{Matchbox}}\xspace}

\newlength{\mylength}
\newcommand\setl[1]{\settowidth\mylength{#1}}
\newcommand\fixl[1]{\ \makebox[\mylength][l]{}\ }
\newcommand\fixc[1]{\ \makebox[\mylength][c]{}\ }
\renewcommand\theequation{\arabic{equation}}

\begin{document}

\title[Modular Complexity Analysis]{Modular Complexity Analysis for
  Term Rewriting\rsuper*}

\author[H.~Zankl]{Harald Zankl\rsuper a}
\address{{\lsuper{a,b}}Institute of Computer Science\\University of
  Innsbruck\\Austria} 
\email{\{harald.zankl,martin.korp\}@uibk.ac.at}
\thanks{{\lsuper a}This research is supported by FWF (Austrian Science Fund)
  project P18763.}

\author[M.~Korp]{Martin Korp\rsuper b}
\address{\vspace{-18 pt}}


\keywords{term rewriting, complexity analysis, relative complexity,
derivation height}

\titlecomment{{\lsuper*}A preliminary version of this article appeared
  in RTA 2010.}


\begin{abstract}
\noindent
All current investigations to analyze the derivational complexity of term
rewrite systems are based on a single termination method, possibly
preceded by transformations. However, the exclusive use of direct
criteria is problematic due to their restricted power. To overcome this
limitation the article introduces a modular framework which allows to 
infer (polynomial) upper bounds on the complexity of term rewrite systems
by combining different criteria. Since the fundamental idea is based on 
relative rewriting, we study how matrix interpretations and match-bounds
can be used and extended to measure complexity for relative rewriting, 
respectively.
The modular framework is proved strictly more powerful than the conventional
setting. Furthermore, the results have been implemented and experiments
show significant gains in power.
\end{abstract}

\maketitle

\section{Introduction}

Term rewriting is a Turing complete model of computation. As an immediate
consequence all interesting properties are undecidable. Nevertheless many
powerful techniques have been developed to establish \emph{termination}.
The majority of these techniques have been automated successfully.
This development has been stimulated by the international competition of
termination tools.\footnote{\ \label{FOO:comp}\url{http://termcomp.uibk.ac.at}}
Most automated analyzers gain their power from a modular treatment
of rewrite systems (typically via the dependency pair
framework~\cite{AG00,HM05,T07}).

For terminating rewrite systems Hofbauer and Lautemann~\cite{HL89}
consider the length of derivations as a measurement for the complexity
of rewrite systems. The resulting notion of \emph{derivational complexity}
relates the length of a rewrite sequence to the size of its starting
term. Thereby it is, e.g., a suitable metric for the complexity of deciding
the word problem for a given confluent and terminating rewrite system
(since the decision procedure rewrites terms to normal form).
If one regards a rewrite system as a program and wants to estimate the
maximal number of computation steps needed to evaluate an expression to
a result, then the special shape of the starting terms---a function applied
to data which is in normal form---can be taken into account. Hirokawa and
Moser~\cite{HM08} identified this special form of complexity and named it
\emph{runtime complexity}.

To show (feasible) upper complexity bounds currently few techniques are
known. Typically termination criteria are restricted such that complexity
bounds can be inferred.
The early work by Hofbauer and Lautemann~\cite{HL89} considers polynomial
interpretations, suitably restricted, to admit quadratic derivational
complexity. Match-bounds~\cite{GHWZ07} and arctic matrix
interpretations~\cite{KW09} induce linear upper bounds on the
derivational complexity and triangular matrix interpretations~\cite{MSW08}
admit at most polynomially long derivations (the dimension of the matrices
yields the degree of the polynomial) in the size of the starting term.
All these methods share the property that until now they have been used
directly only, meaning that a single termination technique has to orient
all rules in one go. However, using direct criteria exclusively is
problematic due to their restricted power.

In~\cite{HM08,HM08b} Hirokawa and Moser lifted many aspects of the
dependency
pair framework from termination analysis into the complexity setting,
resulting in the notion of weak dependency pairs. So for the special
case of runtime complexity for the first time a modular approach
has been introduced. There the modular aspect amounts to using
different interpretation based criteria for (parts of the) weak dependency
graph and the
usable rules. However, still all rewrite rules considered must be oriented
strictly in one go and only restrictive criteria may be applied for the
usable rules. A further drawback of weak dependency pairs is that they
may only be used for bounding runtime complexity while there seems to be no
hope to generalize the method to derivational complexity.

In this article we present a different approach which admits a fully
modular treatment. The approach is general enough that it applies to
derivational complexity (and hence also to runtime complexity) and
basic enough that it allows to combine completely different complexity
criteria such as match-bounds and (triangular) matrix interpretations.
By the modular combination of different base methods also gains in power
are achieved. These gains come in two flavors. On the one hand our approach
allows to obtain lower complexity bounds for several rewrite systems where
bounds have already been established before and on the other hand we
found bounds for systems that could not be dealt with so far automatically.
More specifically, there are systems where the modular combination of
different criteria allows to establish an upper bound while any of the
involved methods cannot succeed on its own.

The remainder of the article is organized as follows. In
Section~\ref{PRE:main} preliminaries about term rewriting and complexity
analysis are fixed.
Afterwards, Section~\ref{REL:main} familiarizes the reader with the
concept of a suitable complexity measurement for relative rewriting.
Furthermore, it
formulates a modular framework for complexity analysis
based on relative complexity.
Criteria for measuring relative complexity via interpretations and
match-bounds are presented in Sections~\ref{MAT:main}
and~\ref{BOUNDS:main}, respectively.
In Section~\ref{ASS:main}
we show that the modular setting is strictly more powerful than the
conventional approach. Our results have been implemented in the complexity
prover \CAT. The technical details can be inferred from
Section~\ref{IMP:main}. Section~\ref{EXP:main} is devoted to demonstrate
the power of the modular treatment by means of an empirical evaluation.
Section~\ref{CON:main} concludes.

This article is a restructured and extended version of~\cite{ZK10}. It also
incorporates the results from the two notes~\cite{ZK10a,ZK10b} presented at
informal workshops. Furthermore results and presentation have been generalized
to address both derivational and runtime complexity.

\section{Preliminaries}
\label{PRE:main}

We assume familiarity with (relative) term rewriting~\cite{BN98,G90,TERESE}.
Let~\SIG{F} be a signature and~\VAR{V} a disjoint set of variables.
The set of terms over~\SIG{F} and~\VAR{V} is denoted by~ and
the set of ground terms over~\SIG{F} by~.
We write  for the set of function symbols occurring in a term~.
The size of a term~ is denoted~ and  computes the
number of occurrences of function symbols in~.
A term~ is called \emph{linear} if any variable~ occurs at most
once in~. 
Positions are used to address symbol occurrences in terms. Given a term 
we use  to denote the set of positions induced by the term  and
we write  with  for the symbol at position~ in the term
. The subset of positions  such that 
is denoted by .

A \emph{rewrite rule} is a pair of terms , written  such
that  is not a variable and all variables in~ are contained in~.
A rewrite rule  is \emph{size-preserving} (\emph{size-decreasing})
if  ().
A \emph{term rewrite system} (TRS for short) is a set of rewrite rules.
For complexity analysis we assume TRSs to be finite and terminating.
A TRS  is said to be \emph{duplicating} if there exist a rewrite
rule  and a variable~ that occurs more often in 
than in . 
A TRS~\TRS{R} is called \emph{linear} (\emph{left-linear}, \emph{right-linear})
if for all rewrite rules  the terms  and  (, )
are linear.
We call a TRS  \emph{collapsing} if it
contains a rewrite rule  such that  is a variable. The
\emph{defined symbols} of a TRS  are all function symbols
 for which there is a rewrite rule  in  such that
. In the following we denote this set of function symbols
by . Those function symbols of  which are not
defined are called \emph{constructor symbols}. So the set of all constructor
symbols is defined as .

A \emph{rewrite relation} is a binary relation on terms that is
closed under contexts and substitutions. For a TRS~\TRS{R} we define
 to be the smallest rewrite relation that contains~\TRS{R}.
As usual~ denotes the reflexive and transitive closure of~
and  the -th iterate of~.
A \emph{relative} TRS~ is a pair of TRSs~\TRS{R}
and~\TRS{S} with the induced rewrite relation
. In the
sequel we will sometimes identify a TRS~\TRS{R} with the relative
TRS~ and vice versa.
Furthermore properties defined for TRSs (as the ones above) naturally
extend to relative TRSs.

The \emph{derivation height} of a term  with respect to a relation 
is defined as follows: .
The \emph{complexity} of a relation  with respect to a (possibly infinite)
set of terms (or language)~, denoted by , computes the
maximal derivation height of all terms in~ up to size~ and is defined as
t \in L|t| \leqslant n.
Sometimes we say that a TRS  (relative TRS )
has linear, quadratic, etc.\ or polynomial complexity with respect to~ if
 () can be
bounded by a linear, quadratic, etc.\ function or polynomial in~.
Let  be a TRS over some signature . The
\emph{derivational complexity} of , abbreviated by
 and defined as
,
computes the complexity of  with respect to all
terms. In contrast, the \emph{runtime complexity} of 
considers the maximal derivation height of constructor-based terms only,
i.e., .
Here, the set of \emph{constructor-based terms} 
is defined as the set of all terms  such that
 and 
for all .

For functions  we write  if there
are constants  such that  for
all . Furthermore,  if  and  if
 and .

\section{Modular Complexity via Relative Complexity}
\label{REL:main}

In this section we present the basic idea that allows a modular treatment of
complexity proofs. To this end we introduce complexity analysis for relative
rewriting, i.e., given a relative TRS  only the
\TRS{R}-steps contribute to the complexity. To estimate the derivational
complexity of a relative TRS , a pair of orderings
 will be used such that  and
. The necessary properties of these orderings
are given in the next definition.

\begin{defi}
A \emph{complexity pair}  consists of two finitely
branching rewrite relations~ and~ that are
\emph{compatible}, i.e.,  and
.
We call a relative TRS  \emph{compatible} with a
complexity pair  if 
and .
\end{defi}

The next lemma states that given a relative TRS 
and a compatible complexity pair , the 
ordering is crucial for estimating the derivational complexity of
. Intuitively the result states that every
-step gives rise to at least one -step.

\begin{lem}
\label{LEM:bound}
Let  be a relative TRS
compatible with a complexity pair .
Then for any term~ we have
.
\end{lem}
\begin{proof}
By assumption  is compatible with .
Since  and  are rewrite relations
 and 
holds. From the compatibility of  and  we obtain
.
Hence for any sequence
\setl{}

also

holds. The result follows immediately from this.
\end{proof}

Obviously  must be at least well-founded if \emph{finite} complexities
should be estimated. Because we are especially interested in feasible upper
bounds the following corollary is specialized to polynomials.

\begin{cor}
\label{COR:bound}
Let  be a relative TRS compatible with a
complexity pair . If the complexity of~
with respect to some language~ is linear, quadratic, etc.\
or polynomial then the complexity of~ with
respect to~ is linear, quadratic, etc. or polynomial.
\end{cor}
\begin{proof}
By Lemma~\ref{LEM:bound}.
\end{proof}

This corollary allows to investigate the complexity of (compatible)
complexity pairs instead of the complexity of the underlying relative
TRS. Sections~\ref{MAT:main} and~\ref{BOUNDS:main} are dedicated to
formulate powerful complexity pairs.
A severe drawback of complexity pairs is that given a relative
TRS~\REL{\TRS{R}}{\TRS{S}} all rules in \TRS{R} must be oriented
strictly. In the following we present a modular approach which allows
to combine different techniques for estimating the complexity of a relative
TRS~\REL{\TRS{R}}{\TRS{S}} with respect to a language~. The fundamental
idea is based on the following simple procedure. Instead of computing the
complexity of \REL{\TRS{R}}{\TRS{S}} at once we try to bound the
complexity of \REL{\TRS{R}}{\TRS{S}} by splitting \TRS{R} into smaller
components  and . Here
. The aim is to over-estimate
 by
.
For each relative TRS 
with  we can proceed in two directions: we can either
split up  into smaller components or over-estimate
 by applying
some suitable method. (Section~\ref{IMP:main} shows that this choice is
performed automatically.) Finally the complexity of the original system is
determined by summing up all intermediate results. The next
lemma states the main observation in this direction.

\begin{lem}
\label{LEM:mod}
Let~ be a relative TRS and
let~ be a terminating term. Then
 .
\end{lem}
\begin{proof}
We abbreviate  by~\TRS{R}
and  by  for .
Assume that .
Then there exists a rewrite sequence

of length~. Next we investigate this sequence for every relative
TRS  ()
where  overestimates how often rules from  have been
applied in the original sequence.
Fix~. If the sequence~\eqref{SEQ:old} does not contain an 
step then 
and . In the other case there exists a maximal
(with respect to ) sequence

where . Together with the
fact that every rewrite rule in  is contained in 
or  we have . If  we obviously
have  and
if  with  we know
that  by the
choice of sequence~\eqref{SEQ:new}. (Note that in both cases it can
happen that  because
sequence~\eqref{SEQ:old} need not be maximal with respect to
.) Putting things together yields

which concludes the proof.
\end{proof}

As already indicated in the proof, the statement of the above lemma
does not hold for equality. This is illustrated by the following example.

\begin{exa}
\label{EXPL:mod}
Consider the relative TRS  with
 and
.
We have  or
. Hence
.
However, the sum of the derivation heights
 and

is~.
\end{exa}

Although for Lemma~\ref{LEM:mod} equality cannot be established the
next result states that for complexity analysis this does not matter.

\begin{thm}
\label{THM:modeq}
Let~ be a relative TRS
and  be a set of terminating terms. Then
.
\end{thm}
\begin{proof}
We have to show that there are constants  and 
such that for any term  the following two properties hold
(for  and  choose 0, i.e., a term  being a normal form):
\begin{itemize}
\item

\item

\end{itemize}
The result then follows from this. Lemma~\ref{LEM:mod} shows the first
property with . For the second property we reason as
follows. Let  and .
Since  implies

we obtain
.
The claim is shown by choosing .
\end{proof}

Theorem~\ref{THM:modeq} allows to split a relative
TRS~
into \emph{smaller} components
 and

and evaluate the complexities of these
components (e.g., by different complexity pairs) independently. Note that
this approach is not restricted to relative rewriting. To estimate the
complexity of a (non-relative) TRS~\TRS{R} just consider the
relative TRS~. The next example shows how
proofs in the modular framework look like. Section~\ref{IMP:main} gives
more details on proof trees.

\begin{exa}
\label{EX:reverse}
Proofs in the modular setting can be viewed as trees. We sketch such a proof
in Figure~\ref{FIG:sketch} using the TRS~ consisting of the following
five rules:

\begin{figure}
\begin{tikzpicture}[node distance=13mm and 15mm,on grid]
\node (1)                         {};
\node (2)   [below=of 1]          {};
\node (21)  [below left=of 2]     {};
\node (211) [below=of 21]         {};
\node (22)  [below right=of 2]    {};
\node (221) [below=of 22]         {};
\node (222) [below=of 221]        {};
\draw[->] (1)   to node[right]      {{\scriptsize}}   (2);
\draw[->] (2)   to node[base left]  {{\scriptsize}}   (21);
\draw[->] (2)   to node[base right] {{\scriptsize}}   (22);
\draw[->] (21)  to node[left]       {{\scriptsize}} (211);
\draw[->] (22)  to node[right]      {{\scriptsize}} (221);
\draw[->] (221) to node[right]      {{\scriptsize}}   (222);
\end{tikzpicture}
\caption{Sketch of a modular complexity proof}
\label{FIG:sketch}
\end{figure}The root node of the tree is the TRS of interest and the other nodes are
relative rewrite systems representing intermediate
complexity problems. The edges indicate the (derivational) complexity of
the proof steps.  It is possible to apply Theorem~\ref{THM:modeq}
explicitly to split a problem into two (or more) problems as demonstrated
in the second node.  Such situations do not affect the complexity of the
given problem which justifies the labels~.  The remaining proof
steps measure the complexity of the rewrite rules that are moved from the
first into the second component (relative to the remaining rules).
These steps rely on an implicit application of Theorem~\ref{THM:modeq}.
For instance in the proof tree shown in Figure~\ref{FIG:sketch} there is an
edge from  to  labeled
, stating that the (derivational) complexity of
 is at most cubic. This step is sound because
from Theorem~\ref{THM:modeq} we know that computing an upper bound on
 and  suffice to get
a valid upper bound on .  In
Sections~\ref{MAT:main} and~\ref{BOUNDS:main} we study criteria that
allow to perform such proof steps.  Since the leaves in the tree give
rise to constant complexity, the complexity of the original problem can
be overestimated by summing up the complexities annotated to the edges;
yielding a cubic upper bound in this exemplary case. Later
(Example~\ref{EX:opt}) we will see that this bound is not tight.
\end{exa}

In the next two sections we study how matrix interpretations and the
match-bounds technique can be suited for relative complexity analysis.

\section{Matrix Interpretations}
\label{MAT:main}

This section is aimed at formulating complexity pairs based on matrix
interpretations~\cite{EWZ08}. Since our interest is in polynomial upper
bounds, triangular matrix interpretations~\cite{MSW08} and arctic matrix
interpretations~\cite{KW08} are considered. The last part of this section
generalizes the weight gap principle from~\cite{HM08} to 
(a restriction of) triangular matrix interpretations and relative rewriting.

\subsection{Preliminaries}

An \emph{\SIG{F}-algebra}~\ALG{A} consists of a non-empty carrier~
and a set of interpretations~ for every~. By
 we denote the usual evaluation function
of~\ALG{A} according to an assignment~.
An~\SIG{F}-algebra~\ALG{A} together with two relations~
and~ on~ is called a \emph{monotone algebra} if
every  is monotone with respect to~ and~,
 is a well-founded order, and  and  are compatible.
Any monotone algebra~ induces a well-founded
order on terms, i.e.,  if for any assignment 
the condition  holds. The
order  is defined similarly.
A relative TRS~ is \emph{compatible} with a
monotone algebra~ if \REL{\TRS{R}}{\TRS{S}}
is compatible with .

\subsection{Triangular Matrix Interpretations}

\emph{Matrix interpretations}~
(often just denoted~\ALG{M}) are a special form of monotone algebras.
Here the carrier is  for some fixed
dimension~. The order
 is the point-wise extension of  to
vectors and
 if  and
. If every  of arity~
is interpreted as
 where  for all
 and  then
monotonicity of~ is achieved by demanding
 for any 
 and 
.
Such interpretations have been introduced in~\cite{EWZ08}.

A matrix interpretation where for every  all 
( where~ is the arity of~)
are upper triangular is called
\emph{triangular matrix interpretation} (abbreviated by TMI).
A square matrix~ of dimension~ is of \emph{upper triangular}
shape if  and  if  for all
.
For historic reasons a TMI based on matrices of dimension one is also
called \emph{strongly linear interpretation} (SLI for short).
In~\cite{MSW08} it is shown that the derivational complexity of
a TRS~\TRS{R} is bounded by a polynomial of degree~ if there
exists a TMI~\ALG{M} of dimension
such that~.
For our setting the following formulation is more useful.

\begin{thm}
\label{THM:tmi}
Let  be a TMI of dimension~ over a
signature . Then 
is a complexity pair. Furthermore
.
\end{thm}
\begin{proof}
Straightforward from \cite[Theorem~6]{MSW08}.
\end{proof}

The following example familiarizes the reader with
TMIs.

\begin{exa}
\label{EX:tmi}
Consider the relative TRS~ over the signature
 defined as
 and
. Then the TMI~ of dimension two
with
\begin{xalignat*}{2}
\m{f}_\ALG{M}(\vec x) &= \BM
1\NE 0\NR
0\NE 1\NR
\EM \vec x +
\BM
1\NR
1\NR
\EM
&
\m{g}_\ALG{M}(\vec x) &= \BM
1\NE 0\NR
0\NE 0\NR
\EM \vec x
\end{xalignat*}
induces the complexity pair
.
Furthermore  is compatible
with .
Theorem~\ref{THM:tmi} gives a quadratic upper bound on
.
Hence
the derivational complexity of~ is at most quadratic
by Corollary~\ref{COR:bound}.
It is easy to see (cf.\ Example~\ref{EX:ami}) that this bound is not
tight. We remark that there cannot exist an SLI that establishes a linear
upper bound because no SLI can orient the rule  strictly.
\end{exa}

\subsection{Arctic Matrix Interpretations}

We define .
For matrices  and
 the operation
 yields an  matrix and is defined as follows:

where  and  are extended naturally to deal with~
(see~\cite{KW08}). Furthermore  if and only if 
or , and  if and only if
 or .\footnote{\ Note that  and hence  is 
not well-founded. Hence such comparisons are disallowed at certain matrix
positions.}

An \emph{arctic matrix interpretation}~
(abbreviated by AMI and often just denoted~\ALG{A}) is a special
form of a monotone algebra. 
Here the carrier is  for some
fixed dimension~. The orders
 and  are the
point-wise extensions of  and 
to vectors, respectively.
Every unary function symbol~ is interpreted
as  where
 and every constant~ as
 where .
Monotonicity of~ is achieved by the restriction to at
most unary function symbols and by demanding that
 and  are different from~ for unary
function symbols~ and constants~, respectively.
In~\cite{KW08} it is shown that the derivational complexity of a
TRS~\TRS{R}, which contains unary and constant function symbols only, is
at most linear if there exists an AMI~\ALG{A} (of some dimension~)
such that~.

\begin{thm}
\label{THM:ami}
Let  be an AMI of dimension~ over a signature 
that contains constants and unary function symbols only.
Then 
is a complexity pair. Furthermore
.
\end{thm}
\begin{proof}
Straightforward from \cite[Lemma~17]{KW08}.
\end{proof}

\begin{exa}
\label{EX:ami}
Consider the TRSs from Example~\ref{EX:tmi}.
Then the AMI~ satisfying
\begin{xalignat*}{2}
\m{f}_\ALG{A}(\vec x) &= \BM
1\NE 3\NR
0\NE 3\NR
\EM \vec x
&
\m{g}_\ALG{A}(\vec x) &= \BM
0\NE 1\NR
\minfty\NE \minfty\NR
\EM \vec x
\end{xalignat*}
induces the complexity pair
. Furthermore
 is compatible with
.\break  Theorem~\ref{THM:ami} gives a
linear upper bound on . Hence the
derivational complexity of~ is at most linear
by Corollary~\ref{COR:bound}.  It is easy to see that this bound is
tight.
\end{exa}

\subsection{Complexity Gap Principle}

An obvious question is whether it suffices to estimate polynomial
complexity of  by establishing
polynomial upper bounds on the complexities of
 and 
(in contrast to 
as in Theorem~\ref{THM:modeq}). The following example by
Hofbauer~\cite{HW06t} shows that in general the complexity of
 might be much larger
than the sum of the components above; even for systems where both
parts have linear complexity. Here .

\begin{exa}
\label{EX:counterexample}
Consider the TRS~ consisting of the single rule
\begin{xalignat*}{3}
&& \m{c}(\m{L}(x)) &\to \m{R}(x) &&
\intertext{
and the TRS~ consisting of the rewrite rules
}
\m{R}(\m{a}(x)) &\to \m{b}(\m{b}(\m{R}(x))) &
\m{R}(x) &\to \m{L}(x) &
\m{b}(\m{L}(x)) &\to \m{L}(\m{a}(x))
\end{xalignat*}
The derivational complexity of the relative
TRS  is
linear, due to the SLI that just counts the 's. The derivational
complexity of  is linear as well since the system can be proved
terminating by the match-bound technique~\cite{GHWZ07}. However, the
TRS  admits exponentially long
derivations in the size of the starting term:
1ex]
&
\m{c}^{n-1}(\m{b}(\m{L}(\m{a}(x)))) &
\m{c}^{n-1}(\m{L}(\m{a}(\m{a}(x)))) &\to^* &
\m{L}(\m{a}^{2^n}(x))
\end{array}

\m{a}^n(\m{b}(x)) \to^2
\m{a}^{n-1}(\m{b}(\m{b}(\m{a}(x)))) \to^4
\m{a}^{n-2}(\m{b}(\m{b}(\m{b}(\m{b}(\m{a}(x)))))) \to^8
\cdots \to^{2^n}
\m{b}^{2^{n}}(\m{a}(x))

\sigma(x) =
\begin{cases}
{\uparrow} \{s_i \mid \text{ with }\} &
\text{if } \\
x & \text{otherwise}
\end{cases}

t
\to_\TRS{R} t_1
\to_\TRS{R} \cdots
\to_\TRS{R} t_{m-1}
\to_\TRS{R} t_m

t'
\rto_{\match{\TRS{R}}} t_1'
\rto_{\match{\TRS{R}}} \cdots
\rto_{\match{\TRS{R}}} t_{m-1}'
\rto_{\match{\TRS{R}}} t_m'

d =
\begin{cases}
\min\,\{c,\height{l'(\epsilon)}\}
& \text{if  and }\
For a relative TRS  we define
 as
.
Let~. The restriction of  to the signature
 is denoted by . Likewise
the relative TRS 
is defined as .
In case  then 
is abbreviated by 
and .
\end{defi}

The idea behind the requirement  in the above 
definition is that such rules cannot yield an increase with respect to
the multiset measure of heights.
Let us illustrate the above definition on an example.

\begin{exa}
\label{EXPL:RT enrichment}
Consider the relative TRS  with
 consisting of the rewrite rule
\begin{xalignat*}{1}
1\colon \m{rev}(x) &\to \m{rev}'(x,\m{nil})
\end{xalignat*}
and  consisting of the rewrite rules
\begin{xalignat*}{2}
2\colon \m{rev}'(\m{nil},y) &\to y&
3\colon \m{rev}'(\m{cons}(x,y),z) &\to \m{rev}'(y,\m{cons}(x,z))
\intertext{Then the rewrite rules}
\m{rev}_0(x) &\to \m{rev}'_1(x,\m{nil}_1) &
\m{rev}_1(x) &\to \m{rev}'_2(x,\m{nil}_2) \\
\m{rev}_2(x) &\to \m{rev}'_3(x,\m{nil}_3) &
&\cdots
\intertext{belong to  and
 contains the rules}
\m{rev}'_0(\m{nil}_0,y) &\to y &
\m{rev}'_0(\m{cons}_0(x,y),z) &\to \m{rev}'_0(y,\m{cons}_0(x,z)) \\
\m{rev}'_0(\m{nil}_1,y) &\to y &
\m{rev}'_0(\m{cons}_1(x,y),z) &\to \m{rev}'_1(y,\m{cons}_1(x,z)) \\
&\cdots &
\m{rev}'_2(\m{cons}_1(x,y),z) &\to \m{rev}'_1(y,\m{cons}_1(x,z))
\end{xalignat*}
Both TRSs together constitute .
\end{exa}

The new enrichment  allows to prove the
complexity of the rewrite rules in~\TRS{R} relative to the rules in~\TRS{S}.

\begin{defi}
\label{DEF:match-RT-boundedness}
Let  be a relative TRS. We call
 \emph{match-RT-bounded} for a language~ if there
exists a  such that the height of function symbols occurring in
terms in 
is at most~.
\end{defi}

An immediate consequence of the next lemma is that every
derivation in  can be lifted to a
-sequence of the same length.
This result is used later on to infer termination
and complexity results for relative rewriting.

\begin{lem}
\label{LEM:simulation via match-RT enrichment}
Let  be a left-linear relative TRS
and . If  ()
then for all terms  with 
there exists a term  such that  and
 ().
\end{lem}
\begin{proof}
Straightforward.
\end{proof}

To be able to prove that a relative TRS~\REL{\TRS{R}}{\TRS{S}}
admits a linear upper complexity bound whenever it is match-RT-bounded
for a language~ we slightly modify the orderings  and .
Let  be multisets. The function  removes
all occurrences of the number  from~. So for all 
we have  if  and 
otherwise. The orderings  and  are defined as 
if  and  if
. Let  be some signature. We extend
 and  to terms over the signature  as follows:
we have  if  and  if
 for terms .
The basic idea behind the new orderings  and  is that rewrite
rules in  which originate from~\TRS{R} are
compatible with  and the rules originating from~\TRS{S} are compatible
with . However there is one problem. If \TRS{R} contains a collapsing
rule  then the rule  appears in
 which cannot be oriented via the ordering
 although . The problem is that
collapsing rewrite rules do not increase the heights of function symbols
in a contracted redex because the right-hand sides consist just of single
variables. To avoid this problem we assume in the following that 
is non-collapsing. For collapsing~\TRS{R} one could follow the approach
in~\cite{ZK10} which can handle collapsing rewrite rules because it does not
not use an upper bound~ to limit the heights that can be introduced by the
enriched system. However, a disadvantages of this approach is that the heights
of a contracted redex are increased more often. So, apart from the collapsing
case the approach presented here is more powerful than the one introduced
in~\cite{ZK10} and completely subsumes the approach in~\cite{W07}.

\begin{lem}
\label{LEM:compatibility RT enrichment}
Let  and  be two non-duplicating
TRSs and . If  is non-collapsing then
 and
.
\end{lem}
\begin{proof}
From the proof of~\cite[Lemma~17]{GHWZ07} we know that for a non-duplicating
TRS  and terms~ and~ such that 
we have . So there are multisets~ and~ such that
, , and
for all  there is a  such that .
Because  is non-collapsing we know from the definition of
 that there is a  such that
 and  for all .
From this it follows that ,
, and for all  there is a
 such that . As an immediate consequence we
have  and hence .

Now let~ and~ be terms and  be a rewrite rule in
 such that . According to
Definition~\ref{DEF:RT enrichment} we have to consider two cases. The first 
case amounts to  where all function symbols in 
and  have the same heights. But then non-duplication of~\TRS{S}
implies  and thus . In the other
case if  is non-collapsing and  then we
obtain  as before and hence also . 
If  then 
 since

and if  is collapsing then  
since .
Hence in both situations .
\end{proof}

Since the length of every  chain is bounded by a function linear in
the size of the starting term---if the size-increase of the terms in the
chain can be bounded by a constant---we can prove that the complexity induced
by the relative TRS  on some language~ is at most
linear if  is match-RT-bounded for~.

\begin{thm}
\label{THM:match-RT-bounds => linear complexity}
Let  be a linear relative TRS and~\TRS{R} be
non-collapsing. If  is match-RT-bounded for
a language~ then  is terminating on~
and .
\end{thm}
\begin{proof}
First we show that  is terminating on~. Assume
to the contrary that there is an infinite rewrite sequence of the form

with . Because  is left-linear and
 is match-RT-bounded for~ by a ,
according to Lemma~\ref{LEM:simulation via match-RT enrichment},
the above derivation can be lifted to an infinite

rewrite sequence

starting from  such that 
for all  and the height of every function symbol occurring
in a term in the lifted sequence is at most~. Hence the employed
rewrite rules in the derivation emanating from  must come from
. With help of
Lemma~\ref{LEM:compatibility RT enrichment}, transitivity of ,
and compatibility of the orderings  and  we deduce that
 for all . However, this is excluded
because~ is well-founded on  and hence  is
well-founded on .

To prove the second part of the theorem, consider an arbitrary
(terminating) rewrite sequence

with . Similar as before this rewrite sequence can be lifted
to a -sequence of the same length

such that  and 
for all . Here  and  such
that the relative TRS  is match-RT-bounded for~
by~. Similar as in the proof of
Theorem~\ref{THM:match(-raise)-bounds => linear complexity} we
can conclude that the length of the -rewrite
sequence starting at the term~ is bounded by
 where~ is the maximal number of function
symbols occurring in some right-hand side in ;
just replace  by .
\end{proof}

We conclude this subsection with an example.

\begin{exa}
The relative TRS 
of Example~\ref{EXPL:RT enrichment}
is match-RT-bounded for  by~.
Here . Due to
Theorem~\ref{THM:match-RT-bounds => linear complexity} we can
conclude that  admits at most linear
derivational complexity. In Section~\ref{BOUNDS:auto} it is
explained how match-RT-boundedness can be checked automatically.
\end{exa}

\subsection{Raise-RT-Bounds for Non-Left-Linear Relative TRSs}
\label{BOUNDS:raise}

In order to generalize Theorem~\ref{THM:match-RT-bounds => linear complexity}
to non-duplicating relative TRSs we consider the relation
 instead of
 which uses raise-rules
to deal with non-left-linearity. Thereby the rewrite relation
 is defined as

where  is
defined similar to  (but based on
 instead of ).
This is essential to lift rewrite sequences in the relative TRS
 to sequences in .

\begin{defi}
Let  be a relative TRS.
We call  \emph{match-raise-RT-bounded}
for a language~ if there exists a number  such that
the height of function symbols occurring in terms belonging to

is at most~.
\end{defi}

Note that for left-linear relative TRSs, match-raise-RT-boundedness
coincides with match-RT-boundedness. By using the relation
 every derivation
induced by the relative TRS  can be
simulated via the rewrite rules in .

\begin{lem}
\label{LEM:simulation via match-raise-RT enrichment}
Let  be a relative TRS and . 
If  ( then for all terms
 with 
there exists a term  such that  and
 ().
\end{lem}
\begin{proof}
Straightforward.
\end{proof}

Before we can prove that match-raise-RT-boundedness of \REL{\TRS{R}}{\TRS{S}}
induces a linear upper bound on the complexity we have to ensure that the
raise-rules implicitly used by the relation

can be oriented via .

\begin{lem}
\label{LEM:compatibility raise}
For any signature  and  it holds that
.
\end{lem}
\begin{proof}
Assume that there are terms~ and~ such that
. According to the definition of
 we have
 for some
height . Thus  and hence 
according to the definition of .
\end{proof}

Using Lemma~\ref{LEM:compatibility raise} it is easy to extend
Theorem~\ref{THM:match-RT-bounds => linear complexity} to
TRSs that are non-linear but non-duplicating.

\begin{thm}
\label{THM:match-raise-RT-bounds => linear complexity}
Let  be a non-duplicating relative
TRS and \TRS{R} be non-collapsing. If 
is match-raise-RT-bounded for a language~ then
 is terminating on~. Furthermore,
.
\end{thm}
\begin{proof}
First we show that  is terminating on~.
Assume to the contrary that there is an infinite rewrite sequence
of the form

with . Let  be
match-raise-RT-bounded for~ by a .
Lemma~\ref{LEM:simulation via match-raise-RT enrichment} yields
an infinite  rewrite sequence

starting from  such that 
for all . Because  is
match-raise-RT-bounded for~ by~, the height of every function symbol
occurring in a term in the lifted sequence is at most~. Hence the
employed rewrite rules in the derivation emanating from  must come
from . With help of
Lemmata~\ref{LEM:compatibility RT enrichment}
and~\ref{LEM:compatibility raise}, transitivity of ,
and compatibility of  and  we deduce that
 for all . (Note that
Lemma~\ref{LEM:compatibility RT enrichment} requires that
 is non-duplicating.) However, this
is excluded because~ is well-founded on 
and hence  is well-founded on
.

To prove the second part of the theorem, consider an arbitrary
(terminating) rewrite sequence

with . Similar as before this rewrite sequence can be lifted
to a -sequence of the same length

such that  and  for all
. Here  and  such that
the relative TRS  is match-raise-RT-bounded
for~ by~. Similar as in the proof of
Theorem~\ref{THM:match(-raise)-bounds => linear complexity} we can
conclude that the length of the -rewrite
sequence starting at the term~ is bounded by
 where~ is the maximal number of function
symbols occurring in some right-hand side in ;
just replace  by .
\end{proof}

\subsection{Automation}
\label{BOUNDS:auto}

To automatically prove that a given relative TRS is match(-raise)-RT-bounded
for some language~ we use (quasi-deterministic, raise-consistent, and)
compatible tree automata. Here a tree automaton  is said to be
\emph{compatible} with a relative TRS
 and a language~ if  is compatible
with  and~.

\begin{lem}
Let  be a left-linear relative TRS,  a language,
and . Let  be a tree automaton. If  is compatible
with the relative TRS  and 
such that the height of each function symbol occurring in transitions in
 is at most~ then  is match-RT-bounded
for~.
\end{lem}
\begin{proof}
Easy consequence of Definition~\ref{DEF:match-RT-boundedness}
and the fact that compatible tree automata are closed under
left-linear rewriting.
\end{proof}

In case of non-left-linear TRSs we obtain the following result.

\begin{lem}
Let  be a relative TRS,  a language, and
. Let  be a quasi-deterministic and raise-consistent
tree automaton. If  is compatible with 
and  such that the height of each function symbol occurring in
transitions in  is at most~ then  is
match-raise-RT-bounded for~.
\end{lem}
\begin{proof}
Straightforward by using the fact that quasi-deterministic, raise-consistent
and compatible tree automata are closed under rewriting.
\end{proof}

To prove that a relative TRS  is
match(-raise)-RT-bounded for a set of terms~ we construct a
(quasi-deterministic and raise-consistent) tree automaton
 that is compatible with the rewrite rules
of  and . Since the set
 need not be
regular, even for left-linear  and  and regular~
(see~\cite{GHWZ07}) we cannot hope to give an exact automaton construction.
The general idea~\cite{G98,GHWZ07} is to look for violations of the
compatibility requirement: 
() and 
for some rewrite rule , state substitution
 (),
and state  (). Then we add new states and transitions
to the current automaton to ensure . After
 has been established, we repeat this process until
a (quasi-deterministic, raise-consistent, and) compatible automaton is
obtained. Note that this may never happen if new states are repeatedly added.
To guess an appropriate~ we start with . As soon as a new transition
 with  is added to the constructed tree
automaton, we set  and proceed with the construction.

\begin{exa}
We show that the relative TRS 
of Example~\ref{EXPL:RT enrichment} over the signature

is match-RT-bounded for~ by constructing a compatible
tree automaton. As starting point we consider the initial tree automaton
\begin{xalignat*}{4}
\m{nil}_0 &\to 1 &
\m{cons}_0(1,1) &\to 1 &
\m{rev}_0(1) &\to 1 &
\m{rev}'_0(1,1) &\to 1
\end{xalignat*}
which accepts all ground terms over the enriched signature .
The first compatibility violation we consider is caused by the rewrite rule
. We have
 but not . To solve
this violation we add the transitions  and
. The compatibility violation caused by the rewrite
rule  and
the derivation  is solved by adding the
transition . Note that we are currently using 
because the maximal height of a function symbol occurring in the underlying
tree automaton is~. Next we consider the compatibility violation
 but
 induced by the rule
. In order to ensure
 we reuse the transition
 and add the new transition
. Finally,
 and

give rise to the transition . After
this step, the obtained tree automaton is compatible with
. Hence 
is match-RT-bounded for~ by~. Due to
Theorem~\ref{THM:match-RT-bounds => linear complexity} we
can conclude that  admits at most
linear complexity. We remark that the ordinary match-bound technique
(Theorem~\ref{THM:match(-raise)-bounds => linear complexity})
fails on  because  induces
quadratic complexity:
\begin{xalignat*}{1}
\m{rev}^n(x)\sigma^m &\to
\m{rev}^{n-1}(\m{rev}'(x,\m{nil}))\sigma^m \to^m
\m{rev}^{n-1}(\m{rev}'(\m{nil},x))\sigma^m \\
&\to \m{rev}^{n-1}(x)\sigma^m \to^{(n-1)(m+2)}
x\sigma^m
\end{xalignat*}
with ) for all .
\end{exa}

\section{Assessment}
\label{ASS:main}

In this section we compare the complexity proving power
of the direct and the modular setting on a theoretical level.
Gains in power in practice are reported in Section~\ref{EXP:main}.
In the first part of this section we show that for TMIs of dimension one,
i.e.\ SLIs, in theory both approaches are equivalent but
in the general case the modular setting allows TMIs of smaller
dimensions to succeed. Since the dimension of the TMI corresponds to the
degree of the polynomial bound the modular setting allows to establish tighter
bounds. The second part of this section shows that the
modular setting is strictly more powerful than the direct one, i.e.,
there are systems where the modular setting admits a complexity proof but
all involved methods cannot succeed on its own in the direct setting.
To make the presentation easier we assume the original problems to be 
standard (in contrast to relative) TRSs. This has no effect on the results.
The next lemma states that for SLIs in theory there is no difference in power
between the two settings.

\begin{lem}
\label{LEM:pow1}
Let~ be a TRS. There exists
an~SLI~\ALG{M} compatible with~ if and only if there
exist SLIs~ and~ such that
 is compatible with  and
 is compatible with .
\end{lem}
\begin{proof}
The implication from left to right obviously holds since \ALG{M} is a
suitable candidate for  and . For the reverse
direction we construct an SLI~\ALG{M} compatible with~\TRS{R} based
on the SLIs  and . 
Let  and
.
It is straightforward to check that 

for any  yields an SLI~ compatible with~\TRS{R}.
\end{proof}

Due to Theorem~\ref{THM:modeq} the complexity is not affected when using
the modular setting. Hence when using SLIs in theory both approaches can
prove the same bounds. But experiments in Section~\ref{EXP:main} show that
in practice proofs are easier to find in the modular setting since, e.g.,
the coefficients of the interpretations can be chosen smaller (cf.\ the
proof of Lemma~\ref{LEM:pow1}).
If TMIs of larger dimensions are applied then just the only-if direction
of Lemma~\ref{LEM:pow1} holds. This is shown with the help of the next
example.

\begin{exa}
\label{EX:power_tmi}
Consider the TRS~\TRS{R} (\tpdb{Strategy\_removed\_AG01/\#4.21})
consisting of the rules:
\begin{xalignat*}{4}
1\colon\m{f}(\m{1})    &\to \m{f}(\m{g}(\m{1}))&
2\colon\m{f}(\m{f}(x)) &\to \m{f}(x)&
3\colon\m{g}(\m{0})    &\to \m{g}(\m{f}(\m{0}))&
4\colon\m{g}(\m{g}(x)) &\to \m{g}(x)
\end{xalignat*}
The TMIs~
\begin{xalignat*}{4}
\m{f}_{\ALG{M}_1}(\vec x) &= \BM
1\NE 1\NR
0\NE 0\NR
\EM \vec x +
\BM
0\NR
1\NR
\EM
&
\m{g}_{\ALG{M}_1}(\vec x) &= \BM
1\NE 0\NR
0\NE 0\NR
\EM \vec x
&
\m{0}_{\ALG{M}_1} &= \BM
0\NR
0\NR
\EM
&
\m{1}_{\ALG{M}_1} &= \BM
0\NR
1\NR
\EM
\intertext{and~}
\m{g}_{\ALG{M}_2}(\vec x) &= \BM
1\NE 1\NR
0\NE 0\NR
\EM \vec x +
\BM
0\NR
1\NR
\EM
&
\m{f}_{\ALG{M}_2}(\vec x) &= \BM
1\NE 0\NR
0\NE 0\NR
\EM \vec x
&
\m{1}_{\ALG{M}_2} &= \BM
0\NR
0\NR
\EM
&
\m{0}_{\ALG{M}_2} &= \BM
0\NR
1\NR
\EM
\end{xalignat*}
show quadratic upper bounds on the derivational complexity of the systems
 and ,
respectively. Theorem~\ref{THM:modeq} establishes a quadratic upper bound
for \TRS{R}.
\end{exa}

Although for the TRS in Example~\ref{EX:power_tmi} TMIs of dimension two
could establish a quadratic upper bound on the derivational complexity
in the modular setting, they cannot do so in the direct setting because
of the next lemma. (We remark that there exist TMIs of
dimension three that are compatible with this TRS).

\begin{lem}
\label{LEM:4.21}
The TRS~\tpdb{Strategy\_removed\_AG01/\#4.21} does not admit a TMI of
dimension two compatible with it.
\end{lem}
\begin{proof}
To address all possible interpretations we extracted the
set of constraints that represent a TMI of
dimension two compatible with the TRS~\tpdb{Strategy\_removed\_AG01/\#4.21}.
\MINISMT~\cite{ZM10} can detect unsatisfiability of these constraints.
Details of this proof can be found at the web site in Footnote~\ref{FOO:web}
on page~\pageref{FOO:web}.
\end{proof}

The next result shows that any direct proof transfers into the modular
setting without increasing the bounds on the complexity.

\begin{lem}
\label{LEM:pow}
Let~ be a finitely branching rewrite relation
and let~ be a TRS
compatible with~.
Then there exist complexity pairs  and
 which are
compatible with the relative TRSs
 and
, respectively.
Furthermore for any language~ we have
.
\end{lem}
\begin{proof}
Fix~. Let  be .
It is easy to see that  is a complexity pair because  and
 are compatible rewrite relations. It remains to show that
for any term  we have
.
To this end we observe that
 for all terms~.
Basic properties of the -notation yield the desired result.
\end{proof}

Due to Example~\ref{EX:power_tmi} and Lemmata~\ref{LEM:4.21} and~\ref{LEM:pow}
we obtain that the modular setting allows to use TMIs of smaller dimensions
than the direct one, which allows to establish tighter bounds. The next
example (together with Lemma~\ref{LEM:pow}) shows that in theory the modular
complexity setting is strictly more powerful than the direct one since it
allows to combine different criteria to establish an upper complexity bound
while any method on its own cannot succeed.

\begin{exa}
\label{EX:trafo}
Consider the TRS~\TRS{R} (\tpdb{Transformed\_CSR\_04/Ex16\_Luc06\_GM})
consisting of the rules:
\begin{xalignat*}{4}
1\colon\m{c} &\to \m{a} &
3\colon\m{mark}(\m{a}) &\to \m{a} &
5\colon\m{g}(x,y) &\to \m{f}(x,y)
\\
2\colon\m{c} &\to \m{b} &
4\colon\m{mark}(\m{b}) &\to \m{c} &
6\colon\m{g}(x,x) &\to \m{g}(\m{a},\m{b}) &
7\colon\m{mark}(\m{f}(x,y)) &\to \m{g}(\m{mark}(x),y)
\end{xalignat*}
The following SLI~
\begin{xalignat*}{6}
\m{a}_\ALG{M} &= 0&
\m{b}_\ALG{M} &= 0&
\m{c}_\ALG{M} &= 1&
\m{f}_\ALG{M}(x,y) &= x+y&
\m{g}_\ALG{M}(x,y) &= x+y+1&
\m{mark}_\ALG{M}(x) &= x+2
\end{xalignat*}
allows Corollary~\ref{COR:sli} to transform the TRS~\TRS{R}
into the relative TRS .
This problem can be split according to
Theorem~\ref{THM:modeq} into the two relative TRSs
 and
.
Match-bounds (Theorem~\ref{THM:match-raise-RT-bounds => linear complexity})
can show a linear upper bound on the first problem. The following
TMI~
\begin{xalignat*}{3}
\m{a}_\ALG{M}  &= \BM
0\NR
0\NR
\EM
&
\m{f}_\ALG{M}(\vec x,\vec y) &=
\vec x +
\BM
1\NE 0\NR
0\NE 0\NR
\EM
\vec y +
\BM
0\NR
1\NR
\EM
&
\m{mark}_\ALG{M}(\vec x) &= \BM
1 \NE 1\NR
0 \NE 1\NR
\EM
\vec x
\end{xalignat*}
where  and

gives a quadratic upper bound on the second relative TRS,
establishing a quadratic upper bound on the derivational complexity
of \TRS{R}. The quadratic bound is tight as  admits derivations

of length  where
,
, and
.
Last but not least we remark that none of the involved techniques
can establish an upper bound on its own. In case of match-bounds this
follows from the fact that~\TRS{R} admits quadratic derivational
complexity. The same reason also holds for Corollary~\ref{COR:sli}
because SLIs induce linear complexity bounds. Finally,
TMIs fail because they cannot orient the rewrite rule
.
\end{exa}

Hence we obtain the following corollary.

\begin{cor}
\label{COR:subsume}
The modular complexity setting is strictly more powerful than the direct~one.
\end{cor}
\begin{proof}
By Lemma~\ref{LEM:pow} and Example~\ref{EX:trafo}.
\end{proof}

Next we consider the TRS \tpdb{Zantema\_04/z086}. The question about the
derivational complexity of it has been stated as problem \#105 on the RTA
LooP.\footnote{\ \url{http://rtaloop.mancoosi.univ-paris-diderot.fr}}

\begin{exa}
Consider the TRS~\TRS{R} (\tpdb{Zantema\_04/z086}) consisting of the
rules:
\begin{xalignat*}{3}
1\colon\m{a}(\m{a}(x)) &\to \m{c}(\m{b}(x))&
2\colon\m{b}(\m{b}(x)) &\to \m{c}(\m{a}(x))&
3\colon\m{c}(\m{c}(x)) &\to \m{b}(\m{a}(x))
\end{xalignat*}
Adian~\cite{A09} showed that  admits at most quadratic
derivational complexity. Since the proof is based on a low-level
reasoning on the structure of~\TRS{R}, it is specific to this TRS
and challenging for automation. With our approach we cannot prove
the quadratic bound on the derivational complexity of .
However, Corollary~\ref{COR:sli} permits to establish some progress.
Using an SLI counting 's and 's, it suffices to
determine the derivational complexity of .
This means that  relative to
the other rules dominates the derivational complexity of~\TRS{R}.
The benefit is that now, e.g., a TMI must only orient one rule
strictly and the other two rules weakly (compared to all three
rules strictly).
It has to be clarified if
the relative formulation of the problem can be used to simplify the proof
in~\cite{A09}.
\end{exa}

The next example shows that although the modular approach often allows to
establish lower bounds compared to the direct one, further criteria for
splitting TRSs should be investigated.

\begin{exa}
\label{EX:4.30}
Consider the TRS~\TRS{R} (\tpdb{SK90/4.30})
consisting of the following rules:
\begin{xalignat*}{3}
1\colon\,\m{f}(\m{nil}) &\to \m{nil} &
3\colon\,\m{f}(\m{nil} \app y) &\to \m{nil} \app \m{f}(y) &
5\colon\,\m{f}((x \app y) \app z) &\to \m{f}(x \app (y \app z))\\
2\colon\m{g}(\m{nil}) &\to \m{nil} &
4\colon\m{g}(x \app \m{nil}) &\to \m{g}(x) \app \m{nil} &
6\colon\m{g}(x \app (y \app z)) &\to \m{g}((x \app y) \app z)
\end{xalignat*}
In~\cite{MSW08} a TMI compatible with~\TRS{R} of
dimension four is given showing that the derivational complexity is
bounded by a polynomial of degree four. Using Theorem~\ref{THM:modeq}
with TMIs of dimension three yields a cubic upper bound, i.e.,
the TMI~
\begin{xalignat*}{2}
\m{\circ}_{\ALG{M}_1}(\vec x,\vec y) &= \BM
1\NE 0\NE 0\NR
0\NE 0\NE 1\NR
0\NE 0\NE 1
\EM \vec x +
\vec y +
\BM
0\NR
0\NR
1\NR
\EM
&
\m{f}_{\ALG{M}_1}(\vec x) &= \BM
1\NE 1\NE 0\NR
0\NE 0\NE 1\NR
0\NE 0\NE 1
\EM \vec x +
\BM
0\NR
1\NR
0\NR
\EM
\\
\m{g}_{\ALG{M}_1}(\vec x) &= \BM
1\NE 0\NE 0\NR
0\NE 0\NE 1\NR
0\NE 0\NE 1
\EM \vec x
&
\m{nil}_{\ALG{M}_1} &= \BM
1\NR
1\NR
1\NR
\EM
\end{xalignat*}
yields a cubic upper bound on .
So does the TMI~ with
\begin{xalignat*}{4}
\m{f}_{\ALG{M}_2}(\vec x) &= \m{g}_{\ALG{M}_1}(\vec x)&
\m{g}_{\ALG{M}_2}(\vec x) &= \m{f}_{\ALG{M}_1}(\vec x)&
\m{\circ}_{\ALG{M}_2}(\vec x,\vec y) &= \m{\circ}_{\ALG{M}_1}(\vec y,\vec x)&
\m{nil}_{\ALG{M}_2} &= \m{nil}_{\ALG{M}_1}
\end{xalignat*}
for . Our approach enables showing a lower
complexity than~\cite{MSW08} but the derivational complexity
of~\TRS{R} is quadratic (see~\cite{MSW08}).
The quadratic lower bound is justified as~\TRS{R} admits derivations

of length  where
 and
.
We stress that the recent approach in~\cite{W10} allows to establish a
quadratic upper bound. For a comment on the integration of this method
into our setting we refer to Section~\ref{CON:main}.
\end{exa}

\section{Implementation}
\label{IMP:main}

In Section~\ref{IMP:est} we first show how the various theorems from the
previous sections can be implemented to obtain \emph{some} complexity proof.
Afterwards Section~\ref{IMP:imp} is concerned
with lowering the bounds starting from an existing complexity proof.

\subsection{Establishing Bounds}
\label{IMP:est}

To estimate the complexity of a TRS  with respect to a
language~, we first transform  into the relative TRS
. Obviously
.
If the input already is a relative TRS this step is omitted.
Afterwards for a relative TRS~\REL{\TRS{R}}{\TRS{S}} we try to
establish a bound on the complexity of
 with respect to~
for some ,  with

and continue with the relative TRS
.
This step is executed repeatedly until the remaining problem equals
. Then the complexity of
 with respect to~ is obtained by summing up
all intermediate bounds. In order to establish a maximal number of
complexity proofs we run all techniques from Sections~\ref{MAT:main}
and~\ref{BOUNDS:main} in parallel and the first technique that can
shift some rules is used to achieve progress.

Note that the procedure sketched above contains an implicit application of
Theorem~\ref{THM:modeq}, i.e., some method immediately proves a bound
for  and leaves
 as open proof obligation.
In contrast to an explicit application of Theorem~\ref{THM:modeq},
here the method that establishes the bound on
 can select the decomposition
of~\TRS{R} into  and  which is beneficial for
performance. As an immediate consequence, proof trees degenerate to
lists (cf.\ Example~\ref{EX:linear}). In the following we describe
the presented approach more formal and refer to it as the
\emph{complexity framework}.

\begin{defi}
A \emph{complexity problem} (CP problem for short) is a pair
 consisting of a relative TRS
 and a language~.
\end{defi}

To operate on CP problems so called \emph{complexity processors} are
used. Similar as in the dependency pair framework we distinguish between
sound and complete processors. Here sound complexity processors
are used to prove an upper bound on the complexity of a given CP problem
whereas complete complexity processors are applied to derive
lower bounds on the complexity.

\begin{defi}
\label{DEF:CP processor}
A \emph{complexity processor} (CP processor for short) is a function
that takes a CP problem  as input and returns
a set of pairs

as output.\footnote{\
For reasons of readability we write pairs

as triples
.
}
Here  is a complexity problem
and  for each .
A complexity processor is \emph{sound} if

and it is called \emph{complete} if

holds.
\end{defi}

In the sequel  denotes the constant zero function,
i.e.,  with .
Next we list some CP processors that can be derived from the previous
sections. The first one is based on complexity pairs and can, e.g., be
implemented by Theorems~\ref{THM:tmi} and~\ref{THM:ami}.

\begin{thm}
\label{THM:cp processor}
The CP processor
-0.5ex]
& \text{with a complexity pair }\\
\{(\REL{\TRS{R}}{\TRS{S}},L,\zero)\} & \text{otherwise}
\end{cases}

(\REL{\TRS{R}}{\TRS{S}},L) \mapsto
\begin{cases}
\{(\REL{\TRS{R}_1}{(\TRS{R}_2 \cup \TRS{S})},L,f)\}
& \text{if~\ALG{M} is a matrix interpretation with constant}\
where , and  is sound.
\end{thm}
\begin{proof}
Follows from Theorem~\ref{THM:modeq} and Theorem~\ref{THM:cgp_tmi}.
\end{proof}

The next CP processor is based on match-bounds.

\begin{thm}
\label{THM:match(-raise)-RT-bounds processor}
The CP processor
-0.5ex]
& \text{linear and match-RT-bounded for~L or}\
where ,
 is non-collapsing, and  is sound.
\end{thm}
\begin{proof}
Follows from Theorems~\ref{THM:modeq},~\ref{THM:match-RT-bounds => linear complexity}, and~\ref{THM:match-raise-RT-bounds => linear complexity}.
\end{proof}

The above processor is implemented by considering for any
rule  the decompositions
 and 
in parallel.
The next CP processor we present is not implemented for finding
a bound (cf.\ the discussion at the beginning of the section) but
very suitable to tighten existing bounds (see Section~\ref{IMP:imp}).

\begin{thm}
\label{THM:modeq processor}
The CP processor

where  is sound and complete.
\end{thm}
\begin{proof}
By Theorem~\ref{THM:modeq}.
\end{proof}

Finally, the main theorem states that the CP framework may be applied to
complexity analysis. We say that  is a complexity proof for a relative
TRS  and a language~ if all leaves in
 are of the shape .

\begin{thm}
\label{THM:imp}
Let  be a relative TRS and~ be a language.
Let  be a complexity proof for  and~
and  be the complexities occurring in this proof.
If all CP processors in  are sound then
.
Similarly, if all CP processors in  are complete then
.
\end{thm}
\begin{proof}
By Definition~\ref{DEF:CP processor} as well as basic
properties of -notation.
\end{proof}

We conclude the section with an (abstract) example which illustrates the
behavior of the complexity framework.

\begin{exa}
\label{EX:linear}
Consider the TRS  of Example~\ref{EX:reverse} on
page~\pageref{EX:reverse} with the complexity proof depicted in
Figure~\ref{FIG:linear}. After transforming  into the
relative TRS  the CP processor of
Theorem~\ref{THM:cp processor} is applied twice. First the
(derivational) complexity of the relative TRS 
is estimated by a polynomial of degree five. As a consequence, the
rules 1, 3, and 5 are moved into the relative component yielding a
CP problem consisting of the relative TRS .
After that the (derivational) complexity of
 is estimated by a quadratic bound.
Since the remaining CP problem is of the shape
 according to Theorem~\ref{THM:imp}
the (derivational) complexity of  is at most quintic.
\begin{figure}
\begin{tikzpicture}[node distance=12mm and 14mm,on grid]
\node (1)                  {};
\node (2)   [below=of 1]   {};
\node (22)  [below=of 2]   {};
\node (222) [below=of 22]  {};
\draw[->] (1)  to node[right] {{\scriptsize}}   (2);
\draw[->] (2)  to node[right] {{\scriptsize}} (22);
\draw[->] (22) to node[right] {{\scriptsize}} (222);
\end{tikzpicture}
\caption{Linear complexity proof}
\label{FIG:linear}
\end{figure}
\end{exa}

\subsection{Tightening Bounds}
\label{IMP:imp}

In contrast to termination, which is a plain YES/NO question, complexity
corresponds to an optimization problem. Hence automated tools should try to
establish as tight bounds as possible. In the direct setting all complexity
methods can be executed in parallel and after a fixed amount of time the
tightest bound is reported. The next example shows such a case.

\begin{exa}
\label{EX:direct}
Consider the TRS~\BITS (\tpdb{nontermin/AG01/\#4.28})
consisting of the following five rules:

For this TRS the complexity analyzer \CAT (cf.\ Section~\ref{EXP:main})
finds a proof by root-labeling followed by a TMI of dimension two,
establishing a quadratic upper bound 
within five seconds.
However, after 90 seconds the tool finds the following AMI~
that shows a linear upper bound:
\begin{xalignat*}{4}
\m{bits}_\ALG{A}(\vec x) &= \BM
0\NE 1\NE 2\NR
0\NE 4\NE 5\NR
0\NE 6\NE 7
\EM \vec x
&
\m{half}_\ALG{A}(\vec x) &= \BM
1\NE \minfty\NE \minfty\NR
1\NE \minfty\NE \minfty\NR
1\NE \minfty\NE \minfty
\EM \vec x
&
\m{s}_\ALG{A}(\vec x) &= \BM
1\NE 1\NE \minfty\NR
7\NE 0\NE 2\NR
1\NE 6 \NE 0
\EM \vec x
&
\m{0}_\ALG{A} &= \BM
 0\NR
 0\NR
 \minfty
\EM
\end{xalignat*}
So, whenever the tool is allowed more than 90 seconds the linear bound
can be reported and if the user sets the global timeout to less, then
still the quadratic bound can be output.
\end{exa}

In the modular setting this simple idea does not work because
two problems emerge. The first problem is that
the tool does not know how much time it may spend
in a single proof step. If it spends too much then it may not finish the
proof within the global time limit and if it spends too little then it
can miss a low bound.
The second problem is that in the modular setting
separate criteria may make statements about the complexity of different
rules. The question is then to identify the \emph{better} bound.
The next example demonstrates this scenario.

\begin{exa}
Consider the TRSs
\begin{xalignat*}{2}
1\colon \m{a}(\m{b}(x)) &\to \m{b}(\m{a}(x)) &
2\colon \m{g}(x,x) &\to \m{g}(\m{c},\m{d})
\end{xalignat*}
The TMI~ with 
and
\begin{xalignat*}{4}
\m{a}_\ALG{M}(\vec x) &= \BM
1\NE 1\NR
0\NE 1\NR
\EM \vec x
&
\m{b}_\ALG{M}(\vec x) &= \BM
1\NE 0\NR
0\NE 1\NR
\EM \vec x + \BM
0\NR
1\NR
\EM
&
\m{c}_\ALG{M}(\vec x) &= \BM
0\NR
0\NR
\EM
&
\m{d}_\ALG{M}(\vec x) &= \BM
0\NR
0\NR
\EM
\end{xalignat*}
establishes a quadratic upper bound on the complexity of

whereas match-bounds yield a linear upper bound for
.
The question now is with which remaining proof obligation
( or )
the tool should continue. Note that both bounds are tight.
\end{exa}

The following idea overcomes both problems:
First we establish \emph{some} complexity proof according to the procedure
described at the beginning of Section~\ref{IMP:est} to obtain a bound for
as many systems as possible. Afterwards we \emph{optimize} this bound.
The next example shows how the latter works.

\begin{exa}
\label{EX:opt}
Consider the TRS  of Example~\ref{EX:reverse} with the complexity
proof depicted in Figure~\ref{FIG:original}. In this exemplary
case one part in this proof, highlighted by a solid box, is overestimated
by a cubic upper bound. Hence the complexity of the whole system is at most
cubic. We remark that this proof step estimates the complexity of
. Now assume that the cubic bound
is not optimal, i.e., there exists a proof (that may be longer and
harder to find) that induces a quadratic upper bound on the complexity of
. Then the proof is optimized as illustrated
in Figure~\ref{FIG:optimized}, i.e.,  is
split into the problems
 and 
by an application of Theorem~\ref{THM:modeq}.
After that, the proof part of  is reused in the
optimized proof (cf.\ the dashed boxes in Figure~\ref{FIG:original} and
Figure~\ref{FIG:optimized}) whereas the original proof of
 is replaced by the new one, as
indicated by the solid box in Figure~\ref{FIG:optimized}.
Now, the proof in Figure~\ref{FIG:optimized} establishes a quadratic
upper bound on the complexity of~\TRS{R}. For completeness we state 
that the proof in Figure~\ref{FIG:original} can be obtained from the
linear proof tree shown in Figure~\ref{FIG:linear} by optimization. To show
the procedure on a non-linear proof tree this presentation was chosen.
\begin{figure}
\subfloat[Initial proof]{
\label{FIG:original}
\begin{tikzpicture}[node distance=13mm and 15mm,on grid]
\node (1)                         {};
\node (2)   [below=of 1]          {};
\node (21)  [below left=of 2]     {};
\node (211) [below=of 21]         {};
\node (22)  [below right=of 2]    {};
\node (221) [below=of 22]         {};
\node (222) [below=of 221]        {};
\node (223) [below=of 222]        {\phantom{}};
\draw[->] (1)   to node[right]      {{\scriptsize}}   (2);
\draw[->] (2)   to node[base left]  {{\scriptsize}}   (21);
\draw[->] (2)   to node[base right] {{\scriptsize}}   (22);
\draw[->] (21)  to node[left]       {{\scriptsize}} (211);
\draw[->] (22)  to node[right]      {{\scriptsize}} (221);
\draw[->] (221) to node[right]      {{\scriptsize}}   (222);
\node[draw,inner sep=0mm,rectangle,rounded corners,fit=(22) (221)]         {};
\node[draw,inner sep=0mm,rectangle,rounded corners,dashed,fit=(221) (222)] {};
\end{tikzpicture}
}
\qquad
\subfloat[Optimized proof]{
\label{FIG:optimized}
\begin{tikzpicture}[node distance=13mm and 15mm,on grid]
\node (1)                                                   {};
\node (2)    [below=of 1]                                   {};
\node (21)   [node distance=13mm and 18mm,below left=of 2]  {};
\node (211)  [below=of 21]                                  {};
\node (22)   [node distance=13mm and 18mm,below right=of 2] {};
\node (221)  [below left=of 22]                             {};
\node (2211) [below=of 221]                                 {};
\node (222)  [below right=of 22]                            {};
\node (2221) [below=of 222]                                 {};
\node (2222) [below=of 2221]                                {};
\draw[->] (1)    to node[right]      {{\scriptsize}}   (2);
\draw[->] (2)    to node[base left]  {{\scriptsize}}   (21);
\draw[->] (2)    to node[base right] {{\scriptsize}}   (22);
\draw[->] (21)   to node[left]       {{\scriptsize}} (211);
\draw[->] (22)   to node[base left]  {{\scriptsize}}   (221);
\draw[->] (22)   to node[base right] {{\scriptsize}}   (222);
\draw[->] (221)  to node[left]       {{\scriptsize}}   (2211);
\draw[->] (222)  to node[right]      {{\scriptsize}} (2221);
\draw[->] (2221) to node[right]      {{\scriptsize}} (2222);
\node[draw,inner sep=0mm,rectangle,rounded corners,fit=(222) (2221) (2222)] {};
\node[draw,inner sep=0mm,rectangle,rounded corners,dashed,fit=(221) (2211)] {};
\end{tikzpicture}
}
\caption{Tightening bounds}
\end{figure}
\end{exa}

As the previous example demonstrates the basic idea is to replace
single proof steps by new proofs that induce tighter bounds. This
procedure is repeated until either the global time limit is reached or
none of the bounds can be tightened further. Note that the transformation is
sound by Theorem~\ref{THM:imp}.

The final example in this section shows that it may be easier to find
proofs in the modular setting.
\begin{exa}
Recall the TRS from Example~\ref{EX:direct}. Corollary~\ref{COR:sli} with
an SLI that just counts function symbols allows to transform the initial
problem into . The AMI of dimension three with
\begin{xalignat*}{4}
\m{bits}_\ALG{A}(\vec x) &= \BM
0\NE 0\NE 0\NR
0\NE 3\NE 2\NR
0\NE 2\NE 2\NR
\EM \vec x
&
\m{half}_\ALG{A}(\vec x) &= \BM
0\NE \minfty\NE \minfty\NR
0\NE \minfty\NE \minfty\NR
0\NE \minfty\NE \minfty\NR
\EM \vec x
&
\m{s}_\ALG{A}(\vec x) &= \BM
0\NE \minfty\NE 0\NR
\minfty\NE \minfty\NE 3\NR
4\NE 0 \NE 0\NR
\EM \vec x
&
\m{0}_\ALG{A} &= \BM
 0\NR
 0\NR
 0\NR
\EM
\end{xalignat*}
allows to show linear derivational complexity of~\BITS. Note
that \CAT finds this interpretation within three seconds whereas it took
the tool 90 seconds to find a suitable interpretation for the direct setting.
\end{exa}

\section{Experimental Results}
\label{EXP:main}

The techniques described in the preceding sections are implemented in
the complexity analyzer \CAT (freely available from
\url{http://cl-informatik.uibk.ac.at/software/cat}) which is built on
top of \TTTT~\cite{KSZM09}, a powerful termination tool for TRSs.

Below we report on the experiments\footnote{\
\label{FOO:web}
Full details available from
\url{http://cl-informatik.uibk.ac.at/software/cat/10lmcs}.
}
we performed.
We considered the \TRSALLNUM TRSs in version 7.0.2
of the TPDB without strategy or theory annotation. The \TRSDCNUM
non-duplicating systems of this collection have been used for experiments
with derivational complexity (note that a duplicating system gives rise to
at least exponentially long derivations). For runtime complexity we
considered the \TRSRCNUM systems that are not trivial, e.g., where the
set of constructor-based terms is not finite and terminating.
In this collection there are \TRSRCNDNUM non-duplicating systems.
All tests have been performed on a server equipped with
eight dual-core AMD Opteron\textsuperscript{\textregistered}\xspace
processors 885 running at a clock rate of 2.6~GHz and 64~GB of main
memory. We remark that similar results have been obtained on a
dual-core laptop. If a tool did not report an answer within 60
seconds, its execution was aborted.

As complexity preserving transformations we employ
uncurrying~\cite{ZHM10} for applicative systems whenever it
applies and root-labeling~\cite{SM08} in parallel to the base
methods.
As base methods we use the match-bounds technique as well as
TMIs~\cite{MSW08,NZM10} and AMIs~\cite{KW09} of dimensions one to five.
The latter two are implemented by bit-blasting arithmetic operations to
SAT~\cite{EWZ08}.
All base methods are run in parallel and started upon program execution.

Our results are summarized in Tables~\ref{TAB:trs} and~\ref{TAB:trs_rc}.
Here, \direct refers to the conventional setting where all rules must be
oriented at once whereas \modular first transforms a TRS~\TRS{R} into a
relative TRS~\REL{\TRS{R}}{\varnothing} before the CP processors from
Section~\ref{IMP:est} (except Theorem~\ref{THM:modeq processor})
are employed. In the tables the postfix  indicates that after
establishing a bound it is tried to be tightened as explained in
Section~\ref{IMP:imp}.
The columns \linear, \quadratic, \dots, \poly give the number of
linear, quadratic, \dots, polynomial upper bounds that could be
established.
We also list the average time (in seconds) needed for
finding a bound in the last column.
For reference we also give the data for the winners of the corresponding 
categories in the 2010 edition of the termination competition.
For derivational complexity this is~\CAT and for runtime complexity
this is~\TCT~\cite{AMS08}.

Table~\ref{TAB:trs} shows the results for derivational complexity. Here
the modular approach allows to prove significantly more polynomial bounds
(column \poly) and furthermore these bounds are also smaller than for the
direct approach (especially if tightening of bounds is used). The modular
setting is slower since there typically more proofs are required to succeed.
The rows postfixed  prove that refining bounds is beneficial,
especially if all criteria are run in parallel, which is essential to
maximize the total number of upper bounds. The 2010 version of \CAT did
not use tightening of bounds. To maximize the number of low bounds the
tool executes criteria that yield larger complexity bounds slightly delayed.
This explains why for \CAT tightening bounds increases the global
performance less compared to \direct and \modular. On the contrary, \CAT
misses some proofs compared to \modular since (costly) criteria are not
executed for up to 60 seconds.

\begin{table}[t]
\caption{Derivational complexity of \TRSDCNUM~TRSs}
\label{TAB:trs}
\begin{center}
\begin{tabular}{@{}l@{\qquad}cccc@{\qquad}r@{}
}
\hline
& \poly & \linear & \quadratic & \cubic & \avg \0.1ex]
\hline
\direct        & 372 &  354 & 358 & 365 & 0.6 \\
 & 372 &  355 & 370 & 371 & 1.1 \\
\modular       & 376 &  358 & 359 & 364 & 0.5 \\
& 376 &  362 & 374 & 375 & 1.2 \\
\hline
            & 354 & 351 & 353 & 354 & 4.8 \\
 & 363 & 360 & 362 & 363 & 4.8 \\
\end{tabular}
\end{center}
\end{table}

For further comparison with other tools we refer the reader to the
international termination competition (referenced in Footnote~\ref{FOO:comp}
on page~\pageref{FOO:comp}).
Since 2008, when the complexity categories have been installed in the
termination competition, \CAT won the division for derivational complexity
every year.

\section{Conclusion}
\label{CON:main}

In this article we have introduced a modular approach for estimating the
complexity of TRSs by considering relative rewriting. We
showed how existing criteria (for full rewriting) can be lifted into the
relative setting. The modular approach is easy to
implement and has been proved strictly more powerful than traditional methods
in theory and practice. Since the modular method allows to combine different
criteria, typically smaller complexity bounds are achieved
than with the direct setting. Furthermore the modular treatment allows
to establish bounds for systems where each of the involved basic methods
alone fails.
Although originally developed for derivational complexity our
results directly apply to more restrictive notions of complexity,
e.g., runtime complexity (see also below).
Finally we remark that our setting allows a more fine-grained complexity
analysis, i.e., while traditionally quadratic derivational complexity
ensures that any rule is applied at most quadratically often, our approach
can make different statements about single rules. Hence even if a proof
attempt does not succeed completely, it may highlight the problematic rules.

We remark that complexity proofs using TMIs (for relative rewriting) can be
certified with \CETA~\cite{TS09b}.

\medskip

As related work we mention~\cite{HW06t} which also considers relative
rewriting for complexity analysis. However, there the complexity of
 is investigated by considering
\REL{\TRS{R}_1}{\TRS{R}_2} and . Hence~\cite{HW06t} also gives
rise to a modular reasoning but the obtained complexities are typically
beyond polynomials.
For runtime complexity analysis Hirokawa and Moser~\cite{HM08,HM08b}
consider weak dependency pair steps relative to the usable rules, i.e.,
\REL{\WDP(\TRS{R})}{\UR(\TRS{R})}.
However, since in the current formulation of weak dependency pairs
some complexity might be hidden in the usable rules they do not
really obtain a relative problem. As a consequence they can only apply
restricted criteria for the usable rules. Note that our approach can
directly be used to show bounds on \REL{\WDP(\TRS{R})}{\UR(\TRS{R})} by
considering~. Due to
Corollary~\ref{COR:sli} this problem can be transformed into an
(unrestricted) relative problem \REL{\WDP(\TRS{R})}{\UR(\TRS{R})} whenever
the constraints in~\cite{HM08} are satisfied.
Moreover, if somehow the \emph{problematic} usable rules could be determined
and shifted into the  component, then this
\emph{improved} version
of weak dependency pairs corresponds to a relative problem without
additional restrictions, admitting further benefit from our
contributions.

Recently two approaches were proposed which admit polynomially bounded
matrix interpretations going beyond TMIs. While~\cite{W10} considers
weighted automata, in~\cite{NZM10} (joint) spectral radius theory is employed.
For ease of presentation these criteria have not been considered in this
work but since both are based on matrix interpretations, they perfectly
suit our modular setting. 

\medskip 
For future work we plan to investigate criteria that allow to analyze
the complexity of a TRS~\TRS{R} by the complexities of  and
 where . We anticipate
that results from modularity~\cite{O94} are helpful for this aim.

\subsubsection*{Acknowledgments}

We thank Johannes Waldmann for directing our attention to
Example~\ref{EX:counterexample} and Martin Avanzini for providing a
binary of the 2010 competition version of~\TCT.



\bibliographystyle{lncs}
\selectlanguage{english}
\bibliography{references}

\end{document}
