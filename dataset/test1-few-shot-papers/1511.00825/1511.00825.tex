\documentclass[envcountsect,orivec]{llncs} \pdfoutput=1
\usepackage{etex} \usepackage[]{graphicx} \pagestyle{headings} \usepackage{times}
\usepackage[pdftex, colorlinks=true]{hyperref}
\newif\ifignore \ignorefalse
\newcommand{\auxproof}[1]{
\ifignore\mbox{}\newline
\textbf{BEGIN: AUX-PROOF} \dotfill\newline
{#1}\mbox{}\newline
\textbf{END: AUX-PROOF}\dotfill\newline
\fi}
\def\comment#1{\ifignore \marginpar[\renewcommand{\baselinestretch}{0.9}\raggedleft\sloppy{}#1]{\renewcommand{\baselinestretch}{0.9}\raggedright\sloppy{}#1}\fi}






\let\proof\relax
\let\endproof\relax

\usepackage{verbatimbox}
\usepackage{amsthm}
\usepackage{fancybox,amssymb,amsfonts,amstext,amsmath,stmaryrd,wasysym,cite,mathtools,mathrsfs}
\usepackage{xspace} \allowdisplaybreaks[1] 

\usepackage[pdftex,all]{xy}
\CompileMatrices
\xyoption{v2}
\xyoption{curve}
\xyoption{2cell}
\SelectTips{cm}{}  \UseAllTwocells
\SilentMatrices
\def\labelstyle{\scriptstyle}
\def\twocellstyle{\scriptstyle}
\newdir{ >}{{}*!/-8pt/@{>}}  
\newdir{|>}{!/1.6pt/@{|}*:(1,-.2)@^{>}*:(1,+.2)@_{>}}
\newdir{pb}{:(1,-1)@^{|-}}
  \def\pb#1{\save[]+<20 pt,0 pt>:a(#1)\ar@{pb{}}[]\restore}
\newcommand{\shifted}[3]{\save[]!<#1,#2>*{#3}\restore}
\usepackage{wrapfig}
\setlength{\intextsep}{.1\intextsep} \setlength{\columnsep}{.7\columnsep} 



\newtheorem{mythm}{Theorem}[section]
\newtheorem{mylem}[mythm]{Lemma}
\newtheorem{mycor}[mythm]{Corollary}
\newtheorem{myprop}[mythm]{Proposition}
\theoremstyle{definition}
\newtheorem{myexpl}[mythm]{Example}
\newtheorem{mydef}[mythm]{Definition}
\newtheorem{myrem}[mythm]{Remark}
\newtheorem{myasm}[mythm]{Assumption}
\newtheorem{myreq}[mythm]{Requirements}
\newtheorem{myproblem}[mythm]{Problem}
 
\spnewtheorem*{myproof}{Proof}{\itshape}{\rmfamily}





\def\myqed{\qed}



\newcommand{\hyper}[1]{{}^{*}{\kern-1.2pt}{#1}}
\newcommand{\dt}{\ensuremath{\mathtt{d\hspace{-.05em}t}}}
\newcommand{\While}{\textsc{While}}
\newcommand{\Whiledt}{\While^{\dt}}
\newcommand{\Assn}{\textsc{Assn}}
\newcommand{\Assndt}{\Assn^{\dt}}
\newcommand{\Hoare}{\textsc{Hoare}}
\newcommand{\Hoaredt}{\Hoare^{\dt}}

\newcommand{\Hytech}{\textsc{HyTech}}

\newcommand{\B}{\mathbb{B}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}

\newcommand{\Pow}{{\mathcal P}}

\newcommand{\nin}{{\ooalign{{}\crcr{\hss{/}\hss}}}}

\newcommand{\lfp}{{\rm lfp}}

\newcommand{\U}{\mathbb{U}}
\newcommand{\Upr}{\mathbb{U}'}


\newcommand{\F}{{\mathcal F}}

\newcommand{\Var}{\mathbf{Var}}

\newcommand{\AExp}{\mathbf{AExp}}
\newcommand{\BExp}{\mathbf{BExp}}
\newcommand{\Cmd}{\mathbf{Cmd}}

\newcommand{\aop}{\mathrel{\mathtt{aop}}}
\newcommand{\true}{\mathtt{true}}
\newcommand{\false}{\mathtt{false}}
\newcommand{\ttrue}{\text{t\hspace{-0.1em}t}}
\newcommand{\ffalse}{\text{ff}}

\newcommand{\SKIP}{\mathtt{skip}}
\newcommand{\IF}{\mathtt{if}}
\newcommand{\THEN}{\mathtt{then}}
\newcommand{\ELSE}{\mathtt{else}}
\newcommand{\WHILE}{\mathtt{while}}
\newcommand{\DO}{\mathtt{do}}

\newcommand{\skipCmd}{\mathtt{skip}}
\newcommand{\ifClause}[3]{\mathtt{if}\;#1\;\mathtt{then}\;#2\;\mathtt{else}\;#3}
\newcommand{\whileClause}[2]{\mathtt{while}\;#1\;\mathtt{do}\;#2}

\newcommand{\hsigma}{\boldsymbol{\sigma}}
\newcommand{\St}{\mathbf{St}}
\newcommand{\HSt}{\mathbf{HSt}}
\newcommand{\hS}{\mathbf{S}}

\newcommand{\Galois}[4]{#1 \overset{#4}{\underset{#3}\rightleftharpoons}
#2}
\newcommand{\GaloisMini}[2]{#1 \rightleftharpoons #2}

\newcommand{\Preord}{\mathsf{Preord}}
\newcommand{\Poset}{\mathsf{Poset}}
\newcommand{\Concr}{\mathsf{Concr}}
\newcommand{\AscCn}{\mathsf{AscCn}}
\newcommand{\Cpo}{\mathsf{Cpo}}
\newcommand{\Monotone}{\mathsf{Monotone}}
\newcommand{\Conti}{\mathsf{Conti}}
\newcommand{\Basis}{\mathsf{Basis}}
\newcommand{\Cover}{\mathsf{Cover}}
\newcommand{\Term}{\mathsf{Term}}
\newcommand{\Widen}{\mathsf{Widen}}
\newcommand{\WidenSeq}{\mathsf{WidenSeq}}\newcommand{\UnifTerm}{\mathsf{UnifTerm}}
\newcommand{\UnifWiden}{\mathsf{UnifWiden}}

\newcommand{\Intv}{{\sf Intv}}
\newcommand{\CP}{\mathbb{CP}}
\newcommand{\eq}{{\sf eq}}
\newcommand{\repr}{{\sf repr}}
\newcommand{\con}{{\sf con}}
\newcommand{\gen}{{\sf gen}}
\newcommand{\Constr}{{\sf Constr}}

\newcommand{\basis}{{\ooalign{{}\crcr{\hss{-}\hss}}}}

\newcommand{\sem}[1]{\llbracket #1 \rrbracket}
\newcommand{\semp}[1]{\llbracket #1 \rrbracket '}
\newcommand{\semintv}[1]{\llbracket #1 \rrbracket_{\Intv}}
\newcommand{\semcp}[1]{\llbracket #1 \rrbracket_{\CP}}

\newcommand{\filt}{\mathcal{F}}
\newcommand{\pow}{\mathcal P}
\newcommand{\num}{X}   \newcommand{\C}{\mathbb{C}}
\newcommand{\sh}{\mathrm{sh}}
\newcommand{\place}{\underline{\phantom{n}}\,} \newcommand{\rtuple}[1]{(#1)}  \newcommand{\co}{\mathbin{\circ}}
\newcommand{\SProc}{\textsc{SProc}}
\newcommand{\SProcdt}{\textsc{SProc}^{\dt}}
\newcommand{\iso}{\mathrel{\stackrel{
           \raisebox{.5ex}{}}{
           \raisebox{0ex}[0ex][0ex]{}}}}
\newcommand{\LU}{{\mathscr L}_{\R}}
\newcommand{\LUpr}{{\mathscr L}_{\hyper{\R}}}
\newcommand{\baseSet}{X}
\newcommand{\LX}{\mathscr{L}_{\baseSet}}
\newcommand{\LsX}{\mathscr{L}_{\hyper{\baseSet}}}
\newcommand{\SVar}{\mathbf{SVar}}
\newcommand{\NdName}{\mathbf{NdName}}
\newcommand{\CHypSt}{\hyper{(\C^{\infty})}}
\newcommand{\BHypSt}{\hyper{(\B^{\infty})}}
\newcommand{\LC}{\mathscr{L}_{\C}}
\newcommand{\cto}{\to_{\mathrm{ct}}} \newcommand{\clongto}{\longrightarrow_{\mathrm{ct}}} 
\newcommand{\scto}{\to_{\hyper{\mathrm{ct}}}} \newcommand{\dsup}{\bigsqcup} \newcommand{\Appr}{\mathsf{Appr}}
\newcommand{\LR}{\mathscr{L}_{\R}}
\newcommand{\LsR}{\mathscr{L}_{\hyper{\R}}}
\newcommand{\sect}[1]{|_{#1}}


\title{Abstract Interpretation with Infinitesimals
\thanks{
We thank Kohei Suenaga and the anonymous referees 
for useful discussions and comments.
This research was supported in part by Grants-in-Aid No.\ 24680001 \& 15KT0012,  JSPS; Grant-in-Aid for JSPS Fellows; NSF CAREER award \#1156059; and NSF award \#1162076.
}
\\
{\large Towards Scalability in \emph{Nonstandard Static Analysis}}
}
\author{
  Kengo Kido \inst{1, 2}
  \and
  Swarat Chaudhuri \inst{3}
  \and
  Ichiro Hasuo \inst{1}
}
\institute{
  University of Tokyo, Japan
  \and
  JSPS Research Fellow
  \and
  Rice University, USA
  }


\begin{document}

\maketitle

  \begin{abstract}
We extend abstract interpretation for the purpose of verifying hybrid systems.
Abstraction has been playing an important role in many verification methodologies for hybrid systems, but
some special care is needed for abstraction of continuous dynamics defined by ODEs.
We apply Cousot and Cousot's framework of abstract interpretation to
   hybrid systems, almost \emph{as it is}, by regarding continuous
   dynamics as an infinite iteration of \emph{infinitesimal} discrete jumps.
This extension follows the recent line of work by Suenaga, Hasuo and Sekine, where deductive verification is extended for hybrid systems by 1) introducing a constant  for an
  infinitesimal value; and 2) employing Robinson's \emph{nonstandard
  analysis (NSA)} to define mathematically rigorous semantics.
 Our theoretical results include soundness and termination via
 \emph{uniform} widening operators; and our prototype implementation
 successfully verifies some benchmark examples.


  \end{abstract}

\nocite{NSAI}

\section{Introduction}\label{sec:introduction}
\emph{Hybrid systems}  exhibit both discrete \emph{jump}
 and continuous  \emph{flow} dynamics. Quality assurance of such systems
 are of paramount importance due to the current ubiquity of
 \emph{cyber-physical systems (CPS)} like cars, airplanes, and many
 others.  
 For the formal verification approach to hybrid systems, the challenges are: 1) to incorporate
 flow-dynamics; and 2) to do so at the lowest possible cost, so that the
 existing discrete framework smoothly transfers to hybrid situations.  A large
 body of existing work uses \emph{differential equations} explicitly in the
 syntax; see the discussion of related work below.

In~\cite{Suenaga2011}, instead, an alternative approach of
\emph{nonstandard static analysis}---combining \emph{static analysis}
and \emph{nonstandard analysis}---is proposed. Its basic idea is
to introduce a constant
 for an \emph{infinitesimal} (i.e.\ infinitely small) value, and
\emph{turn flow into jump}. With , the continuous operation of
integration can be represented by a while-loop, to which
existing discrete techniques such as Hoare-style program logics readily
apply. For a rigorous mathematical development they employ
\emph{nonstandard analysis (NSA)} beautifully formalized by
Robinson~\cite{Robinson1966}. 


Concretely, in~\cite{Suenaga2011} they took the common combination of a
-language and a Hoare
logic (e.g.\ in the textbook~\cite{Winskel1993}); and added a constant 
to obtain a modeling and verification framework for hybrid systems.  Its
 components are called  and . 
The soundness of  is proved
against denotational semantics defined in the language
of NSA.
Subsequently in the \emph{nonstandard static analysis} program: in~\cite{Hasuo2012} they presented a prototype
automatic theorem prover for ;
and in~\cite{Suenaga2013} 
they applied the same idea to stream processing systems, realizing 
a verification framework for \emph{signal processing} as in Simulink.

  Underlying these technical developments is the idea of so-called \emph{sectionwise execution}.
Although this paper does not rely explicitly on it, it is still useful
for laying out the ``operational'' intuition of nonstandard static analysis.
See the following example.
\vspace*{1em}

\noindent
\begin{minipage}{.77\textwidth}
\begin{myexpl}\label{example:elapsedTime}
  Let  be the 
 program on the right.
The value of  is infinitesimal; therefore the
  loop will not terminate within finitely many steps.
 Nevertheless it is somehow intuitive to expect that after an ``execution'' of
 this program, the value of 
 should be infinitesimally close to  and larger than it.  
\end{myexpl}
\end{minipage}
\hfill




\begin{wrapfigure}{r}{7em}

\end{wrapfigure}

 One possible way of thinking is to imagine \emph{sectionwise execution}.  For each
 natural number  we consider the \emph{-th section} of the program
 , denoted by 
 and shown on the right.
 Concretely,  is obtained by replacing the
 infinitesimal  in  with .
Informally  is the ``-th approximation'' of
 the original .

 A section  does terminate within
 finite steps and
 yields  as the value of .
 Now we collect the outcomes of sectionwise executions and obtain
 a sequence 
 
 which is thought of as a progressive approximation of the actual
 outcome of the original program .  Indeed, in the
 language of  NSA, the  sequence~(\ref{equation:sequenceThatIsOnePlusDt}) represents a \emph{hyperreal number}
  that is infinitesimally close to . 


\vspace*{.0em}


We note that
a program in  is \emph{not} intended to be executed: the program 
does not terminate. 
It is however an advantage of
\emph{static} approaches to verification and analysis,  that programs need not be executed to prove their
correctness. Instead well-defined mathematical semantics suffices. This
is what we do here as well as in~\cite{Suenaga2011,Hasuo2012,Suenaga2013}, with the denotational
semantics of  exemplified in Example~\ref{example:elapsedTime}.


\vspace*{.2em} 
\noindent
\textbf{Our Contribution}
\quad
In the previous work~\cite{Suenaga2011,Hasuo2012,Suenaga2013} \emph{invariant
discovery} has been a big obstacle in scalability of the proposed
verification techniques---as
is usual in deductive verification. The current work, as a first step
towards scalability of the approach,
extends \emph{abstract interpretation}~\cite{Cousot1977} with
infinitesimals. The  abstract interpretation methodology is known for
its ample applicability (it is employed in model checking as
well as in many deductive verification frameworks) and scalability (the static
analyzer Astr\'{e}e~\cite{Cousot2005} has been successfully used e.g.\
for Airbus's flight control system).

Our theoretical contribution includes: the theory of \emph{nonstandard
abstract interpretation} where (standard) abstract domains are ``-transformed,'' in a rigorous NSA sense, to 
the abstract domains for hyperreals; their soundness in over-approximating
semantics of  programs and hybrid system modeling by them; and introduction of the notion of
\emph{uniform} widening operators. With the latter, inductive
approximation is guaranteed to terminate within finitely many
steps---even after extension to the nonstandard setting. We show that
many known widening operators, if not all, are indeed uniform.
Although we  focus on the domain of convex polyhedra in this paper, it
is also possible to extend other abstract domains like
ellipsoids~\cite{Feret2004} 
in the same way.

These theoretical results form a basis of our prototype
implementation,\footnote{The prototype is available on-line: \href{http://www-mmm.is.s.u-tokyo.ac.jp/~kkido/}{http://www-mmm.is.s.u-tokyo.ac.jp/\~{}kkido/}} that successfully analyzes: \emph{water-level monitor},
a common example of piecewise-linear hybrid dynamics; and also
\emph{thermostat} that is beyond piecewise-linear.
The prototype deals with the constant  as a truly infinitesimal number using computer algebra system.




\vspace*{.2em}
\noindent
\textbf{Related Work}
\quad
There has been a lot of research work for verification of hybrid systems
and it 
has led to quite a few system verification tools, including
 HyTech~\cite{Henzinger1997},
 PHAVer~\cite{Frehse05},
 SpaceEx~\cite{Frehse11},
 HySAT/iSAT~\cite{Franzle2007},
 Flow*~\cite{ChenAS13} and
 KeYmaera~\cite{PlatzerQ08}. All these rely on ODEs (or the explicit
 solutions of them) for expressing continuous dynamics, much like 
\emph{hybrid automata}~\cite{Alur1992} do.


Our nonstandard static analysis approach is completely different from
those in the following point: we do not use ODEs at all, and model
hybrid systems as an imperative program with an infinitesimal constant.
It enables us to apply static methodologies for discrete systems as they are.  For example, in HyTech and PHAVer, convex polyhedra is used to
over-approximate the reachable sets.  They need, however, some special
techniques such as linear phase-portrait~\cite{Henzinger95}, to reduce the dynamics into
piecewise linear one.  Our framework does not need such and usual
abstract interpretation works as it is.

There are many other works we rely on, such as
those on
abstract interpretation, nonstandard analysis, etc. These are discussed 
later when they become relevant. 




\vspace*{.2em}
\noindent
\textbf{Organization}
\quad
In~\S{}\ref{sec:exampleOfAnalysis} we start with the water-level monitor example and present how our nonstandard abstract interpretation framework works. Then we go on to its theoretical foundations.
In~\S{}\ref{sec:preliminaries} we review
preliminaries on: abstract
interpretation; nonstandard analysis; and the modeling language 
from~\cite{Suenaga2011}. 
In~\S{}\ref{sec:NSAI} we extend the theory of abstract
interpretation with infinitesimals and build the theory of nonstandard
abstract
interpretation. 
Its theorems include soundness of approximation, and
 termination guaranteed by (the -transform of) a \emph{uniform} widening
 operator. 
In~\S{}\ref{sec:implementation}
we present our prototype implementation and the experiment results with it.

Most proofs are deferred to Appendix~\ref{appendix:omittedProofs}.




\section{Leading Example: Verification of Water-Level Monitor}\label{sec:exampleOfAnalysis}
We shall start with an example of verification and let it exemplify how our
 framework---that extends abstract interpretation with infinitesimals,
 and handles continuous as well as discrete dynamics---works. We use the
 well-known example of the water-level monitor~\cite{Alur1992}.
In the current section, in particular, we will first revisit how the usual
 abstract interpretation workflow (without extension) would work, using
 a 
 discretized variant of the problem. Our emphasis is on the fact that
 our extended framework works just in the same manner: without any
 explicit ODEs or any additional theoretical infrastructure for ODEs;
 but only adding a constant .


\begin{wrapfigure}[4]{r}{0pt}
  \raisebox{-13mm}[0pt][0mm]{\includegraphics[width=.18\textwidth]{Figures/waterLevel.jpg}}
\end{wrapfigure}
 The concrete problem is as follows.
 See the figure on the right.  A water tank has a
 constant drain (~cm per second). When the water level  gets lower
 than ~cm the 
 switch is turned on, which eventually makes the pump work but only after 
 a time lag of two seconds. While the pump is working, the water level
 
 rises by ~cm per second. Once  reaches ~cm the switch is
 turned off, which will shut down the pump but again after a time lag of two seconds.
 Our goal is the \emph{reachability analysis} of this hybrid dynamics,
 that is, to see the water level  remains in a certain ``safe'' range (we will see
 that the range is ).
 






\begin{wrapfigure}[13]{r}{0.5\hsize}
\vspace{-1em}
 \begingroup
 \fontsize{7pt}{8pt}\selectfont
  \begin{verbatim}
(*Water-Level Monitor*)
l := 0; x := 1; p := 1; s := 0; 
dt' := 0.2;  
while true do {
   if p = 1 then x := x + dt' 
      else x := x - 2 * dt';
   if (x <= 5 && p = 0) then s := 1 
      else {if (x >= 10 && p = 1) 
               then s := 1 
               else s := 0
      };
   if s = 1 then l := l + dt'
      else skip;
   if s = 1 && l >= 2
      then {p := 1 - p; s := 0; l := 0}
      else skip
}
\end{verbatim}
\endgroup 
\vspace{-1.7em}
\caption{Discretized water-level monitor}
\label{fig:whileCodeCaseStudy}
\end{wrapfigure}
\subsection{Analysis by (Standard) Abstract Interpretation, as a Precursor}\label{subsec:waterLevel0.2}
Let us first revisit the usual workflow in reachability analyses by
abstract interpretation.
We will use the \emph{discretized} model of the water-level monitor
 in Fig.~\ref{fig:whileCodeCaseStudy}, where each iteration of its unique
loop amounts to the lapse of  seconds. The model in
Fig.~\ref{fig:whileCodeCaseStudy} is an imperative program
with while loops, a typical subject of analyses by abstract
interpretation. 

More specifically:
 is the water level,  is the counter for the time lag,
 stands for  the state of the pump 
 ( if the pump is off, and  if on) 
and  is for ``signals,'' 
meaning  if the pump has not yet responded to a signal from the
 switch (such as, when the switch is on but the pump is not on yet). 







The first step in the usual abstract interpretation workflow is 
to fix \emph{concrete} and \emph{abstract domains}. Here in~\S\ref{subsec:waterLevel0.2} we will use the followings.
\begin{itemize}
 \item \textbf{The concrete domain: .} 
       We have two numerical variables  and two Boolean ones 
       in Fig.~\ref{fig:whileCodeCaseStudy},
       therefore a canonical concrete domain would be . We have the powerset operation  in it since we
       are now interested in the \emph{reachable} set of memory states.

       However, for a better fit with our abstract domain  (namely
       convex polyhedra), we shall use the set
        that is isomorphic to the above set
.

\item \textbf{The abstract domain: .} 
 We use the domain of \emph{convex polyhedra}~\cite{Cousot1978},
       one of the most commonly-used abstract domains. 
       Recall that a convex polyhedron is a subset of a Euclidean space
       characterized by a finite conjunction of linear inequalities. 
       Specifically, we
       let , the set of 2-dimensional convex polyhedra, 
       approximate the set . Therefore, as an abstract
       domain for the program in Fig.~\ref{fig:whileCodeCaseStudy}, 
       we 
       take  (that approximates
       ). 

\end{itemize}




The next step in the workflow is to \emph{over-approximate} the set of
memory states that are reachable by the program in
Fig.~\ref{fig:whileCodeCaseStudy}---this  is a subset of the concrete domain
---using the abstract domain
. Since the desired set can be thought of as a least
fixed point, this over-approximation procedure involves: 1)
\emph{abstract execution} of the program in  (that is
straightforward, see e.g.~\cite{Cousot1978}); and 2) acceleration of
least fixed-point computation in  via suitable use of a
\emph{widening operator}. For convex polyhedra  several
 widening operators are well-known. We shall use here , so-called the
\emph{widening up
to } operator from \cite{Halbwachs1993, Halbwachs1997}. One big
reason for this choice is the \emph{uniformity} of the operator (a
notion we introduce later in~\S{}\ref{subsec:uniformWidening}), among
others. The set  of linear constraints is a parameter for this
widening operator; we fix it as usual, collecting the linear constraints
that occur in the program in question. That is, . 

This over-approximation procedure is depicted in the \emph{iteration
sequence} in Fig.~\ref{fig:iterseq}. Let us look at some of its
details. The graph  represents the initial memory state (before
the first iteration), where the pump is on and the water level  is precisely
. After one iteration the water level will be incremented by ~cm; as usual in abstract interpretation, however, at this moment we invoke the widening
operator
, and the next ``abstract reachable set'' is 
instead of . Here the 
upper bound  comes from
the constraint
 that is in the parameter  of the widening operator
. 
This
results in the graph 1 in Fig.~\ref{fig:iterseq}. 
















In the iteration sequence (Fig.~\ref{fig:iterseq}) the four 
polyhedra (in four different colors) gradually grow: in the graph 2 the water
level  can be ~cm so in the graph 3 appears a green polyhedron
(meaning that a
signal is sent from the switch to the pump); after the graphs 3 and 9 we
\emph{delay} widening, a heuristic commonly employed in abstract
interpretation~\cite{Cousot1981}. In the end, in the graph 12 we have a
prefixed point (meaning that the polyhedra do not grow any further). There
we can see, from the range of  spanned by the polyhedra, that the
water level never reaches beyond . 





\subsection{Analysis by \emph{Nonstandard Abstract
  Interpretation}}\label{subsec:waterLevelDt}
In the above ``standard'' scenario, we approximated the 
dynamics of the water level by discretizing the continuous notion of
time (). While this made the usual abstract interpretation
workflow go around, 
there is a price to pay---the analysis result is not
\emph{precise}. Specifically, the reachable region thus over-approximated is
, while the real reachable region is .\footnote{There are also examples in which 
discretization even leads to \emph{unsound} analysis results.}

\begin{wrapfigure}[13]{r}{0.5\hsize}
\vspace{-1em}
 \begingroup
 \fontsize{7pt}{8pt}\selectfont
\begin{verbatim}
(*Water-Level Monitor*)
l := 0; x := 1; p := 1; s := 0;
while true do {
   if p = 1 then x := x + dt 
      else x := x - 2 * dt;
   if (x <= 5 && p = 0) then s := 1 
      else {if (x >= 10 && p = 1) 
               then s := 1 
               else s := 0
      };
   if s = 1 then l := l + dt
      else skip;
   if s = 1 && l >= 2
      then {p := 1 - p; s := 0; l := 0}
      else skip
}
\end{verbatim}
\endgroup 
\vspace{-1.7em}
\caption{Water-level monitor in }
\label{fig:whileDtCodeCaseStudy}
\end{wrapfigure}
Obviously we can ``tighten up'' the analysis by making the value  smaller.
Even better, we can leave the expression  in
Fig.~\ref{fig:whileCodeCaseStudy} as a variable, and imagine the ``limit'' of
analysis results when the value of  tends to . However here is
a question: what is that ``limit,'' in mathematically rigorous terms?
Taking  obviously does not work: do so in
Fig.~\ref{fig:whileCodeCaseStudy}
and we have no dynamics whatsoever. The value of  must be strictly positive.

Our contribution is an extension of abstract interpretation that answers
the last question. In our framework, the same (hybrid) dynamics of
the water-level monitor is modeled
by a program in Fig.~\ref{fig:whileDtCodeCaseStudy}. Here the expression

is a new constant that stands for a \emph{positive} and \emph{infinitesimal}
(i.e.\ infinitely small) value. Therefore the modeling is not an
approximation by discretization; it is an \emph{exact} modeling.

It is important to notice that the program in
Fig.~\ref{fig:whileDtCodeCaseStudy} is the same as the one in
Fig.~\ref{fig:whileCodeCaseStudy}, except that now  is some strange
constant,
while  in Fig.~\ref{fig:whileCodeCaseStudy} stood for a real
number (namely ). This difference, however, does not prevent us
from applying the \emph{static}, \emph{symbolic} and \emph{syntax-based} analysis by abstract
interpretation. We can follow exactly the same path as 
in~\S{}\ref{subsec:waterLevel0.2}---taking the abstract domain of convex
polyhedra, executing the program in Fig.~\ref{fig:whileDtCodeCaseStudy}
on it, applying the widening operator , and forming an
iteration sequence much like in Fig.~\ref{fig:iterseq}---and this leads
 to the analysis result . Since 
is an infinitesimal number, the last result is practically as  good as
. We  have a prototype implementation that automates 
this analysis (\S{}\ref{sec:implementation}). 

What remains to be answered is the legitimacy of this extended abstract
interpretation framework. Is the outcome 
\emph{sound}, in the sense that it indeed over-approximates the true
reachable
set? Even before that, what do we mean by the ``true
reachable
set'' of the program in Fig.~\ref{fig:whileDtCodeCaseStudy}, 
with an exotic infinitesimal constant like ? Moreover,  are
iteration sequences via the widening operator  guaranteed to
terminate
within finitely many steps, as is the case in the standard
framework~\cite{Halbwachs1993, Halbwachs1997}?

The rest of the paper is mostly devoted to (answering positively to) the
last questions. In it we use Robinson's \emph{nonstandard analysis
(NSA)}~\cite{Robinson1966} and give  infinitesimal numbers---clearly
such do not exist in the set of (standard) real numbers---a status as first-class citizens. The program in
Fig.~\ref{fig:whileDtCodeCaseStudy} is in fact in the programming (or
rather \emph{modeling}) language  from~\cite{Suenaga2011,Hasuo2012};
and its semantics can be understood in the line of
Example~\ref{example:elapsedTime}. It turns out that the theory of
NSA---in particular its celebrated result of the \emph{transfer
principle}---allows us to ``transfer'' meta results from the standard
abstract interpretation to our extension. That is, what is true in the
world of standard reals (soundness, termination, etc.) is also true in 
that of \emph{hyperreals}. 










































\begin{figure}[tb]
\begin{tabular}{lll}
\begin{minipage}[t]{.32\textwidth}
\includegraphics[width=\textwidth]{Figures/watertank_graphs_new/0.pdf}
\includegraphics[width=\textwidth]{Figures/watertank_graphs_new/1.pdf}
\includegraphics[width=\textwidth]{Figures/watertank_graphs_new/2.pdf}
\includegraphics[width=\textwidth]{Figures/watertank_graphs_new/3.pdf}
\includegraphics[width=\textwidth]{Figures/watertank_graphs_new/4.pdf}
\end{minipage}
\begin{minipage}[t]{.32\textwidth}
\includegraphics[width=\textwidth]{Figures/watertank_graphs_new/5.pdf}
\includegraphics[width=\textwidth]{Figures/watertank_graphs_new/6.pdf}
\includegraphics[width=\textwidth]{Figures/watertank_graphs_new/7.pdf}
\includegraphics[width=\textwidth]{Figures/watertank_graphs_new/8.pdf}
\includegraphics[width=\textwidth]{Figures/watertank_graphs_new/9.pdf}
\end{minipage}
\begin{minipage}[t]{.32\textwidth}
\includegraphics[width=\textwidth]{Figures/watertank_graphs_new/10.pdf}
\includegraphics[width=\textwidth]{Figures/watertank_graphs_new/11.pdf}
\includegraphics[width=\textwidth]{Figures/watertank_graphs_new/12.pdf}
\end{minipage}
\end{tabular}
\caption{An iteration sequence for the water-level monitor example.\newline 
To save space, here we depict 
an element of ---i.e.\ a quadruple of convex
polyhedra---on the same plane . The four convex polyhedra come in different colors:
those in blue, green, red and yellow correspond to the values
 and  of the Boolean variables,
respectively. 
} 
\label{fig:iterseq}
\end{figure}













\section{Preliminaries}\label{sec:preliminaries}
In~\S{}\ref{sec:NSAI}  we will present our \emph{soundness} and
\emph{termination} results as a ``metatheory'' that justifies the
workflow described in~\S{}\ref{subsec:waterLevelDt}; 
in this section we recall some preliminaries that are needed for those theoretical developments.
 First, the general theory of abstract interpretation is introduced in~\S{}\ref{subsec:abstinterp} and the specific domain of convex polyhedra is presented in~\S{}\ref{subsec:convexpoly}.
Next, some basic notions in nonstandard analysis are explained in~\S{}\ref{subsec:preliminariesNSA}.
Finally, in~\S{}\ref{subsec:whiledt}, the modeling language  from~\cite{Suenaga2011} and its (denotational) collecting semantics based on nonstandard analysis are presented.

\subsection{Abstract Interpretation}\label{subsec:abstinterp}
\emph{Abstract interpretation}~\cite{Cousot1978} is a well-established
technique in static analysis.  We make a brief review of its basic
theory; it is
mostly for the purpose of fixing notations.
The goal of abstract interpretation is to over-approximate a \emph{concrete semantics} defined on an \emph{concrete domain} by an \emph{abstract semantics} on an \emph{abstract domain}.
We assume that the concrete semantics is defined as a least fixed point on the concrete domain.
The following proposition guarantee the over-approximation of the least fixed point in the concrete domain by a prefixed point in the abstract domain.
In the proposition, the order  on the domain  is extended to the order on  pointwisely.
And the \emph{least fixed point relative to }, denoted by , is the  
 least among the fixed points of  above ; by the cpo
 structure of  and the continuity of , it is given by . 
Note that we are using the concretization-based framework described in~\cite{Cousot1992a}.


\begin{myprop}\label{prop:concretization}
Let  be a cpo;
  be a continuous function;
 and  be such that .
Let  be a preorder;
  be a function (it is called \emph{concretization}) such that 
 for all ; and
  be a monotone function such that .
Assume further that   is a prefixed point of   
 (i.e.\ )
 such that .


Then  over-approximates , that is,
.
\myqed
\end{myprop}































In~\S{}\ref{subsec:waterLevel0.2} where we analyzed the discretized water-level monitor, the set  of subsets of memory states is used as a concrete domain ; and the \emph{domain of convex polyhedra} is used as an abstract domain . The interpretations  and  on each domains are defined in a standard manner.
Towards the goal of obtaining  in Prop.~\ref{prop:concretization}, (i.e.\ finding a prefixed point in the abstract domain), the following notion of
\emph{widening} is used (often together with \emph{narrowing} that we will not
be using).
Note that in the following definition and proposition, the domain  is the abstract domain, corresponding to  in Prop.~\ref{prop:concretization}.







\begin{mydef}[widening operator]\label{def:widen}
 Let  be a preorder.
 A function  is said to be a \emph{widening operator} if the following two conditions hold.
 \begin{itemize}
  \item (\emph{Covering}) For any ,  and .
  \item (\emph{Termination}) For any ascending chain , the chain  defined by

	 and
 for each 
is ultimately stationary.
 \end{itemize}
\end{mydef}
\noindent  A widening operator on a fixed abstract domain 
is not at all unique.  In this paper we will discuss three widening operators previously introduced for .

 The use of widening is as in the following proposition: the covering
 condition  ensures that the outcome is a prefixed point; and the
 procedure terminates thanks to the
 termination condition.
\begin{myprop}[convergence of iteration sequences]\label{prop:widen}
 Let  be a preorder;  be a monotone function;  be such that ;  be a widening operator; and  be the infinite sequence defined by
 
Then the sequence  is increasing and
 ultimately
 stationary; moreover its limit  is a prefixed
 point of  such that .
\myqed
\end{myprop}












\subsection{The Domain of Convex Polyhedra}\label{subsec:convexpoly}
The \emph{domain of convex polyhedra}, introduced in~\cite{Cousot1978},
is one of the most commonly used relational numerical abstract domains.
\begin{mydef}[domain of convex polyhedra ]\label{def:convexPoly}
An -dimensional \emph{convex polyhedron} is the intersection of
 finitely many (closed) affine half-spaces.
We denote the set of convex polyhedra in  by .
Its preorder   is given by the inclusion order (actually it is a partial order).
The concretization function  is defined in an obvious manner.
\end{mydef}

















\auxproof{
\begin{mydef}
A \emph{generator system} is a triple  of finite sets of
 vectors.
Here 
 
is the set of \emph{lines},  is the set of \emph{rays} and  is the
 set of \emph{points}.

A generator system  induces a
 convex polyhedron  in the following way, where
  is the set of nonnegative reals.

\end{mydef}
}









We will be studying three widening operators on . 
They are namely:
the \emph{standard widening operator} ~\cite{Halbwachs1979};\footnote{The name ``standard'' is
 confusing with the distinction between \emph{standard} and
 \emph{nonstandard} entities in NSA. The  use of ``standard'' in the
 former sense is scarce in
 this paper.}
the \emph{widening operator  up to }~\cite{Halbwachs1993, Halbwachs1997}; and
the \emph{precise widening operator} ~\cite{Bagnara2005}.
We  briefly describe the former two; the definition of the last is
omitted for the lack of space. In the following definitions, the function  maps a set of linear constraints (called a \emph{constraint system}) to the convex polyhedron induced by the conjunction of those linear constraints.


\begin{mydef}[standard widening ]\label{def:stdwiden}
 Let ; and  and  be constraints
 system that induce  and , respectively.
\emph{The standard widening operator}  is defined by

\scalebox{0.87}{\parbox{1.1\linewidth}{
 
}}
\end{mydef}
\noindent Intuitively  is represented by the set of those linear
constraints of  which are satisfied by every point of .



The following second widening operator  refines . This is
what we use in our implementation. Here  is a parameter.
\begin{mydef}[widening up to , ]\label{def:widenupto}
 Let , and  be a (given) finite set of linear inequalities.
The \emph{widening operator up to } is defined by
 
\end{mydef}
\noindent 
The parameter    is usually taken to be the set of linear
inequalities that occur in the  program under analysis.






\subsection{Nonstandard Analysis}\label{subsec:preliminariesNSA}
Here we list a minimal set of necessary definitions and results in
nonstandard analysis (NSA)~\cite{Robinson1966}.
Some further details 
can be found in Appendix~\ref{appendix:NSAPrimer}; 
fully-fledged and accessible expositions of NSA are 
found e.g.\ in~\cite{Hurd1985, Goldblatt1998}.

The following notions will play important roles.
\begin{itemize}
 \item 
 \emph{Hyperreals} that extends reals by infinitesimals, infinites,
       etc.;
 \item 
 The \emph{transfer principle}, a celebrated result in NSA that states
 that
 reals and hyperreals share ``the same properties''; 
 \item 
 The first-order language  that specifies formulas in which syntax, precisely,
 are preserved by the transfer principle; and finally
 \item 
 The semantical construct of \emph{superstructure} for
 interpreting -formulas.
\end{itemize}
What is of paramount importance is the transfer principle; in order to 
formulate it in a mathematically rigorous manner, 
the two last items (the language  on the syntactic side, and
superstructures on the semantical side) are used.
The first-order language  is essentially that of set theory and has
two predicates  and . The \emph{superstructure}  is
then a semantical ``universe'' for such formulas, constructed from the
base set : concretely  is the union of , ,
, and so on. Finally, when we take  then the
set  is that of \emph{hyperreals}; and the
transfer principle claims that  holds for reals if and only if
---a formula essentially the same as ---holds for
hyperreals.
 Its precise
statement is:
\begin{mylem}[the transfer principle]\label{lemma:transferPrinciplePreview}
 For any closed formula  in , the following are equivalent. 
\begin{itemize}
 \item The formula  is valid in the superstructure .
 \item The \emph{*-transform}  of ---this is a formula in the
       language ---is valid in the superstructure .
\end{itemize}
\end{mylem}

The transfer principle guarantees that we can employ the same abstract
 interpretation
framework, for reals and hyperreals alike---\emph{literally} the same, in the sense that we express the framework
 in the
 language . Concretely, various
constructions
and meta results (such as soundness and termination) in abstract
interpretation will be expressed as -formulas, and since they are valid
 in , they are valid in the ``nonstandard universe''
  too, by the transfer principle. 











\paragraph{Hyperreals}
We fix an \emph{index set} , and an \emph{ultrafilter}  that extends
 the cofinite filter . Its properties to be noted: 1)
 for any , exactly one of  and 
 belongs to ; 2) if  is \emph{cofinite} (i.e.\  is finite), then  belongs to .


\begin{mydef}[hyperreal
 ]\label{definition:hypernumber}
We define the set
  of \emph{hyperreal numbers} (or \emph{hyperreals})
by
 . It is therefore the set of infinite sequences on  modulo the
 following equivalence : we have
  if
 
A \emph{hypernatural}  is defined similarly.
 \end{mydef}
\noindent
It follows that:
two sequences  and  that
coincide except for finitely many indices  represent the
same hyperreal.  The predicates besides   (such as ) are defined in the same
way.
A notable consequence is the existence of infinite numbers in the set of hyperreals and hypernaturals:
 is a positive infinite since it is larger than any positive real  ( for almost every ).
In addition, the set of hyperreals includes infinitesimal numbers: a hyperreal
  is positive
 () but is smaller than any (standard) positive real
 .







\paragraph{Superstructure}


A \emph{superstructure} is a ``universe,'' constructed step by
step
 from
a certain base set  (whose typical examples are
 and ). We assume
 .
\begin{mydef}[superstructure]\label{definition:superstructure}
A \emph{superstructure}  over  is
 defined by , where
 and
.
\end{mydef}

The superstructure  might seem to be a closure of  only under powersets, but it accommodates many set-forming operations.
For example, ordered pairs  and tuples  are 
defined in  as is usually done in set theory, e.g.\
.The function space  is
thought of as a collection of special binary relations (i.e.\ ,  hence is in .

\paragraph{The First-Order Language }
We use the following 
first-order language , defined for each choice of the base set 
 like  and .
\begin{mydef}[the language ]\label{definition:languageLX}
 \emph{Terms} in  consist of: variables ;
 and a constant  for each entity . 

\emph{Formulas} in  are constructed as follows.
\begin{itemize}
 \item The predicate symbols are  and ; both are binary. The
       \emph{atomic formulas} are of the form  or  (where 
       and  are terms).
 \item We allow  Boolean combinations of formulas. We use the
       symbols
        and .
 \item Given a formula , a variable  and a term , the expressions
     and     
       are formulas. 
\end{itemize}
\end{mydef}
\noindent Note that
quantifiers always come with a bound .
 The language  depends on the choice of  (it
  determines the set of constants). 
We shall also  use
 the following syntax sugars in , as is common in set theory and NSA.  







\begin{mydef}[semantics of ]\label{definition:semanticsOfLX}
 We interpret  in the superstructure  in the obvious way.
Let  be a  closed formula;  we say  is \emph{valid}
if  is true in .
\end{mydef}


\paragraph{The -Transform and the Transfer Principle}
 As we mentioned the transfer principle says that a closed formula 
 in the language  is valid in  if and only if  in
  is valid in .
  We shall describe how we syntactically transform
 in  into
  in . 

 For that purpose, in particular in translating constants in  (for entities in
 ) to ,  we will need the following \emph{semantical} translation. 
 The so-called \emph{ultrapower construction} yields a canonical map

that is called the \emph{*-transform}. 
It is a map from the universe  of standard entities
to  of nonstandard entities.  The details of its
 construction are in Appendix~\ref{appendix:NSAPrimer} or in ~\cite{Hurd1985}. 



 The above map  becomes a \emph{monomorphism}, a notion in
 NSA.  Most notably it will satisfy
 the \emph{transfer principle} (Lem.~\ref{lemma:transferPrinciple}).


\begin{mydef}[*-transform of formulas]\label{definition:starTransformOfFormulas}
 Let  be a formula in . The \emph{*-transform} of , denoted
 by , is 
 a formula in  obtained by replacing each constant  occurring
 in  with the constant  that designates the element .
\end{mydef}



\begin{mylem}[the transfer principle]\label{lemma:transferPrinciple}
 For any closed formula  in ,  is valid (in ) if and
 only if  is valid (in ).  \myqed
\end{mylem}


We can prove, for instance, the following proposition using the transfer
principle (the proof is in Appendix~\ref{appendix:omittedProofs}). 
This proposition has a practical implication: our implementation relies
on it 
in simplifying formulas including the infinitesimal constant .

\begin{myprop}\label{prop:dtToQE}
 Let  be an -formula with a unique free variable ; to
 emphasize it we write  for . 
Then the validity of the formula

(in ) implies the validity of  in .
\myqed
\end{myprop}

\subsection{The Modeling Language }\label{subsec:whiledt}


, a modeling language for hybrid systems based on NSA, is introduced in \cite{Suenaga2011}.
It is an augmentation of a usual imperative language (such as  in~\cite{Winskel1993}) with a constant  that expresses an infinitesimal number.

\begin{mydef}Let  be the set of variables.
The syntax of  is as follows:

An expression  is an \emph{arithmetic expression},  is a \emph{Boolean expression} and  is a \emph{command}.
\end{mydef}

\begin{wrapfigure}[9]{r}{0.46\hsize}
\vspace{-1em}
\begingroup
 \fontsize{7pt}{8pt}\selectfont
  \begin{verbatim}
(*Thermostat*)
x := 22; p := 0;
while true do {
   if p = 0 then x := x - 3 * x * dt 
      else x := x + 3 * (30 - x) * dt;
   if x >= 22 then p := 0
      else {if x <= 18 then p := 1
               else skip
      }
}
\end{verbatim}
\endgroup 
\vspace{-1.7em}
\caption{Thermostat in }
\label{fig:thermostat} 
\end{wrapfigure}
As we explained in~\S{}\ref{sec:introduction}, the infinitesimal constant  enables us to model not only discrete dynamics but also continuous dynamics without explicit ODEs.
For example, the water-level monitor is modeled as a  program shown in Fig.~\ref{fig:whileDtCodeCaseStudy}.
As another example, the thermostat can be modeled as the program on the right.
One can see that the continuous dynamics modeled in this example is beyond piecewise-linear.
Even dynamics defined by nonlinear ODEs can be modeled in  in
the same manner. To go further to accommodate an arbitrary hybrid automaton we must
properly deal with \emph{nondeterminism}, a feature currently lacking in
. Although we expect that to be not hard, precise comparision
between  and hybrid automata in expressivity is future work.

In the usual, standard abstract interpretation (without ), a
command  is assigned its \emph{collecting semantics}
 (see e.g.~\cite{Cousot1977}). This is semantics by reachable sets of memory states,  as the concrete semantics.
Presence of  in the syntax of   calls for an
infinitesimal number in the picture.
The first thing to try would be to replace  with , and
let   commands interpreted as functions of  the type
. This however is not suited for the
purpose of interpreting recursion in presence of .\footnote{If we interpret commands
as functions  , the interpretation
 by a least fixed point
will be , not
 as we expect. The problem is that
\emph{internality}---an ``well-behavedness'' notion in
NSA---is not preserved in such a modeling.} We rely instead on our theory of
\emph{hyperdomains} that is used in~\cite{Suenaga2013} and
 described in Appendix~\ref{appendix:domainTheoryTransferred}
; see the
interpretation of while loops in Table~\ref{table:densem}. This calls
for the interpretation of commands to be of the type ,  a subset of 
. The last type will be used in the following definition.


\begin{mydef}\label{def:whiledtsem}
 \emph{Collecting semantics} for ,  
in Table~\ref{table:densem}, has the following
 types where  is : 
 for
 ;
 for
 ; and
 for .
\end{mydef}



In~\cite{Suenaga2011} and in~\S{}\ref{sec:introduction}, the
 semantics of a while loop is defined using the idea of
sectionwise execution, instead of as a least fixed point. This is not
suited for  employing abstract
interpretation---the latter is after all for computing least fixed points.
The collecting semantics in Def.~\ref{def:whiledtsem}
(Table~\ref{table:densem}) does use least fixed
points; it is based on the alternative  semantics 
introduced in~\cite{Kido2013} (it will also appear in the forthcoming full version
of~\cite{Suenaga2011, Hasuo2012}). The equivalence of the two semantics 
is established in~\cite{Kido2013}.






















\begin{table}[tbp]
 \centering
\scalebox{0.8}{\parbox{1.1\linewidth}{



 \vspace{-2.5em}
 
}}
\caption{ collecting semantics}
\label{table:densem}
\end{table}

















In the rest of the paper we restrict the set of variables  to be
finite. This as\-sump\-tion---a realistic one when we focus on the program
to be analyzed---makes our NSA framework much simpler. 
Therefore
 and  are equal to  and  for some  respectively; we prefer the latter notations in what follows.







\section{Abstract Interpretation Augmented with Infinitesimals}
\label{sec:NSAI} 
In the current section are our main theoretical contributions---a
metatheory of \emph{nonstandard abstract interpretation} that justifies 
the workflow in~\S{}\ref{subsec:waterLevelDt}. 

(Standard) abstract interpretation infrastructure such as Prop.~\ref{prop:concretization} and Prop.~\ref{prop:widen} is not applicable to  programs.
since  is not a cpo.\footnote{One can see that the ascending chain defined by  does not have the supremum in  since  is not \emph{internal}  (see Appendix~\ref{appendix:NSAPrimer})
.}
Thus, building on the theoretical foundations in the above, we now extend the abstract interpretation framework for the
analysis of  programs (and the hybrid systems modeled
thereby).  We introduce an \emph{abstract hyperdomain} over   as the transfer of
the 
(standard, over ) domain of convex polyhedra. We then interpret 
programs in them, and transfer the three widening operators mentioned in~\S{}\ref{subsec:abstinterp} to the
nonstandard setting. We classify them into \emph{uniform} ones---for
which termination is guaranteed even in the nonstandard setting---and
non-uniform ones.
The main theorems are Thm.~\ref{thm:hyperconcretization} and Thm.~\ref{thm:newunifwidenwithinfinitesimal}, for soundness (in place of Prop.~\ref{prop:concretization}) and termination (in place of Prop.~\ref{prop:widen}) respectively.





\subsection{The Domain of Convex Polyhedra over Hyperreals}
\label{subsec:abstractDomainOverHyperreals}


We extend   convex polyhedra to the current nonstandard setting.
\begin{mydef}[convex polyhedra over ]\label{def:hyperConvexPoly}
 A \emph{convex polyhedron} on  is an intersection of
 finite number of affine half-spaces  on , that is, the
 set of points  that satisfy a certain
 finite set of linear inequalities.
The set of all convex polyhedra on  is denoted by
 .
 
\end{mydef}



\begin{myprop}\label{prop:hyperconvexpoly}
The set  of all  convex  polyhedra over 
is a (proper) subset of
, the -transform of the (standard) domain of convex polyhedra over .
\myqed
\end{myprop}
What lies in the difference between the two sets
 is, for example, a disk as a
subset of  (hence of ). In  one can use a constraint system whose number of linear constraints is a hypernatural number ; using e.g.\

allows us to approximate a disk with progressive precision.

In the following development of nonstandard abstract interpretation,  we
will use  as an abstract domain since it allows transfer
of properties of .
 We note, however, that 
our over-approximation of
the interpretation  of a loop-free  program  
is always given in , i.e.\ with finitely many linear inequalities.




\subsection{Theory of Nonstandard Abstract Interpretation}
\label{subsec:theoryOfHyperAbstractInterp}


Our goal is to over-approximate the collecting semantics for  programs (Table~\ref{table:densem}) on convex polyhedra over .
As we mentioned at the beginning of this section, however, abstract interpretation infrastructure cannot be applied since  is not a cpo.
Fortunately it turns out that we can rely on the \emph{-transform}
(\S{}\ref{subsec:preliminariesNSA}) of
the theory in~\S{}\ref{subsec:abstinterp}, where it suffices to impose the cpo structure only on  and the \emph{-continuity}---instead of the (standard)
continuity---on
the function
 .
 This theoretical framework of \emph{nonstandard abstract
 interpretation}, which we shall describe here, is an extension of the
 \emph{transferred domain theory} studied
 in~\cite{BeauxisM11,Suenaga2013}. Part of the latter is found also in Appendix~\ref{appendix:domainTheoryTransferred}.













\begin{mythm}\label{thm:hyperconcretization}
Let  be a cpo;
  be a *-continuous function;
 and  be such that .
Let  be a preorder;
  be a function such that  for all ; and
  be a *-continuous function that is monotone with respect to  and satisfies .
Note that  is also a preorder.
Assume further that   is a prefixed point of   
 (i.e.\ )
 such that .

Then  over-approximates , that is,
.
\myqed
\end{mythm}

       






Our goal is
over-approximation of 
the semantics of iteration of a loop-free  program , 
relying on  Thm.~\ref{thm:hyperconcretization}.
Towards the goal, the next step
 is to find a suitable

that ``stepwise approximates'' , the collecting semantics of .
  The next result implies that the -transformation of 
 (defined in a usual manner in standard abstract interpretation, as mentioned in~\S{}\ref{subsec:abstinterp}) can be used in
 such .




 \begin{myprop}
Let
 satisfy the hypotheses in Thm.~\ref{thm:hyperconcretization}.
 Assume that a continuous function  is stepwise approximated by a monotone function
  , that is, 
.
 Then  the *-continuous function  is over-approximated by the monotone and internal function , i.e. .
 \myqed
 \end{myprop}
















We summarize what we observed so far on nonstandard abstract
interpretation by instantiating the abstract domain to .
In the following  is from Def.~\ref{def:whiledtsem}.
\begin{mycor}[soundness of nonstandard abstract interpretation on ]
\label{cor:soundnessOfHyperAbstractDomains}



 Let  be a loop-free  command;
       and let 
       and  be such that  and
       .
        Then we have .
\myqed
\end{mycor}

\subsection{Hyperwidening and Uniform Widening Operators}
\label{subsec:uniformWidening}
Towards our goal of using Thm.~\ref{thm:hyperconcretization}, the last
remaining step is to find a prefixed point ,
i.e.\
 .
This is where widening operators are standardly used; see~\S{}\ref{subsec:abstinterp}.



We can try -transforming a (standard) notion---a strategy that we have used repeatedly in the current section. This
yields the following result, that has a problem that is discussed shortly.
\begin{mythm}
\label{thm:widenwithinf}
Let  be a preorder and  be a widening operator on .
Let  
be a monotone and internal function;
and  
be such that .
 The  iteration \emph{hyper}-sequence 
---indexed by hypernaturals
 ---that is defined by
 
reaches its limit within some hypernatural number of steps and the limit
  is a prefixed point of  such that . \myqed
\end{mythm}
The problem of Thm.~\ref{thm:widenwithinf} is that the \emph{finite-step
 convergence} of iteration sequences for the original widening operator (described in Prop.~\ref{prop:widen})
 is now transferred to \emph{hyper\-finite-step convergence}. 
 This is not desired. All the entities from NSA that we have used so far
 are constructs in denotational semantics---whose only role is to ensure
 soundness of verification methodologies\footnote{Recall that 
 is a \emph{modeling} language and we do not execute them.} and on which
 we never actually operate---and therefore their
 infinite/infinitesimal nature has been not a problem. In contrast,
 computation of the iteration hypersequence  is what we actually compute to
 over-approximate program semantics; and therefore its termination
 guarantee within  steps (Thm.~\ref{thm:widenwithinf})
 is of no use.
 
 As a remedy we introduce a new notion of \emph{uniformity} of the (standard) widening
 operators. It strengthens the original termination condition
 (Def.~\ref{def:widen})
 by imposing a uniform bound  for stability of arbitrary chains
 . Logically the change means
 replacing  by .

\begin{mydef}[uniform widening]\label{def:unifwiden}
 Let  be a preorder.
 A function  is said to be a \emph{uniform widening operator} if the following two conditions hold.
 \begin{itemize}
  \item (Covering) For any ,  and .
  \item (Uniform termination) Let . There exists a
	\emph{uniform bound}  such that: for any ascending
	chain  starting from , there
	exists  at which the chain  , defined by  and , stabilizes (i.e.\ ). 
\end{itemize}
\end{mydef}
It is straightforward that uniform termination implies termination.


We investigate uniformity of some of the commonly-known widening operators on convex polyhedra.
\begin{mythm}\label{thm:uniformityOfKnownWidening}
 Among the three widening operators in~\S{}\ref{subsec:abstinterp},  (Def.~\ref{def:stdwiden}) and  (Def.~\ref{def:widenupto}) are uniform, but  (\cite{Bagnara2005}) is not.
\myqed
\end{mythm}
For example, the widening operator  is uniform because once the first element  of an iteration sequence is fixed, the length of the iteration sequence is at most the number of linear inequalities that define the convex polyhedra .
However,  is not uniform because an iteration sequence can be arbitrarily long even if the first element of it is fixed, 



The following theorem is a ``practical'' improvement of
Thm.~\ref{thm:widenwithinf};
its proof relies on instantiating the uniform bound  
 in a suitable -formula with a Skolem
constant, before transfer.


\begin{mythm}
\label{thm:newunifwidenwithinfinitesimal}
 Let  be a preorder and  be a uniform widening operator on .
Let  
be a monotone and internal function;
and  
be such that .
 The  iteration sequence
  defined by 
 
reaches its limit within some finite number of steps; and the limit
  is a prefixed point of  such that
 . \myqed
\end{mythm}


Note that uniformity of  is a \emph{sufficient condition} for
the termination of nonstandard iteration sequences (by
); Thm.~\ref{thm:newunifwidenwithinfinitesimal} does not
prohibit other useful widening operators in the nonstandard setting.
Furthermore, there can be a useful (nonstandard) widening operator
except for the ones  that arise
via standard ones .








 It is a direct consequence of Thm.~\ref{thm:newunifwidenwithinfinitesimal} and Thm.~\ref{thm:uniformityOfKnownWidening} that the analysis of  programs on  is terminating with  or .






\section{Implementation and Experiments}\label{sec:implementation}
\subsection{Implementation}
We implemented a prototype tool for analysis of  programs.
The tool currently supports:  as an abstract domain; and
, *-transformation of  in Def.~\ref{def:widenupto} as a widening operator.
Its input is a  program.
It outputs a convex polyhedron that over-approximates the set of reachable memory states for each modes (or the values of discrete variables).
Our tool consists principally of the following two components:
1) an OCaml frontend for parsing, forming an iteration sequence and making the set  for ; and
2) a Mathematica backend for executing operations on convex polyhedra.
The two components are interconnected by a C++ program, via MathLink.

There are some libraries such as Parma Polyhedra Library~\cite{BagnaraHZ08SCP} that are commonly used to execute operations on convex polyhedra.
They cannot be used in our implementation because we have to handle the infinitesimal constant  as an truly infinitesimal value.
Instead we implemented Chernikova's algorithm~\cite{Chernikova1964, Chernikova1965, Chernikova1968, LeVerge1992} symbolically, using \emph{computer algebra system (CAS)} on Mathematica based on Prop.~\ref{prop:dtToQE}.

Prop.~\ref{prop:dtToQE} ensures that the transformation from  \\to
 does not violate the soundness of the analysis.
When we have to evaluate a formula including , we instead resolve  using CAS (e.g. quantifier elimination).





\subsection{Experiments}\label{subsec:experiments}
We analyzed two  programs---the water-level monitor (Fig.~\ref{fig:whileDtCodeCaseStudy}) and the thermostat
(Fig.~\ref{fig:thermostat})---with our prototype.
The experiments were on Apple MacBook Pro with 2.6 GHz Dual-core Intel Core i5 CPU and 8 GB memory and the execution times are the average of 10 runs.

\noindent
\textbf{Water-Level Monitor} 
This is a piecewise-linear dynamics
and a typical example used in hybrid automata literature. Our tool
automates the analysis presented in~\S{}\ref{sec:exampleOfAnalysis};
the execution time was 22.151 sec.

\noindent
\textbf{Thermostat} 
The dynamics of this example is beyond piecewise-linear.
The nonstandard abstract interpretation
successfully analyzes this example without explicit piece\-wise-linear
approximation. We believe this result witnesses a potential of our approach. We skip how it analyzes this example since the procedure is the same as the water-level monitor case.
Our tool executes in 2.259 sec.\ and outputs an approximation from which 
we obtain an invariant .
 

\section{Conclusions and Future Work}






We presented an extended abstract interpretation framework in which
hybrid systems are \emph{exactly} modeled as programs with infinitesimals.
 The logical infrastructure by \emph{nonstandard analysis} (in particular
the \emph{transfer principle}) establishes its 
soundness.
Termination is also ensured for \emph{uniform} widening operators.
Our prototype analyzer automates the extended abstract interpretation on the domain of convex polyhedra.


 










Regrettably our current implementation is premature and does not
compare---in precision or scalability---with the state-of-art tools for
hybrid system reachability such as  SpaceEx~\cite{Frehse11} and Flow*~\cite{ChenAS13}.
In fact the two examples in~\S{}\ref{subsec:experiments} are the only
ones that we have so far succeeded to analyze. For other
examples---especially nonlinear ones, to which our framework is
applicable in principle---the analysis results are too imprecise to be useful.
 To improve
there are some possible directions of future work to enhance the precision and scalability.
Firstly, we could utilize trace partitioning~\cite{Mauborgne2005}, narrowing operators (the use of narrowing operators in the domain of convex polyhedra is indicated in~\cite[\S{3.4}]{Henriksen2007}) and other techniques that have been introduced to enhance the precision of the analysis.
Secondly, we believe  abstract domains such as
\emph{ellipsoids}~\cite{Feret2004}, or some new ones that are tailored
to nonlinear dynamics, 
can improve our analyzer.
Finally, the lack of scalability is mainly due to our current way of eliminating  (namely via
Prop.~\ref{prop:dtToQE}): it relies on \emph{quantifier elimination
(QE)} that is highly expensive. A faster alternative is desired. 







\bibliographystyle{splncs03} 
\bibliography{../../../library}
  
\newpage
\appendix
\section{Further on NSA in Superstructure}
\label{appendix:NSAPrimer}
The definitions and results  listed below are all well-established and commonly
used in NSA. We follow~\cite[Chap.~II]{Hurd1985}, in which
more details can be found.



\begin{myrem}[choice of the index set ]\label{remark:choiceOfNatAsI}
 In~\S\ref{subsec:preliminariesNSA} we used the set  of natural
 numbers as the index set . 
 It is common in NSA, however, to use  that is bigger than
 , and an ultrafilter  over . The merit of
 doing so is that the resulting monomorphism  (see below) can be
 chosen to be an \emph{enlargement}; see~\cite[Chap.~II]{Hurd1985}.
In what follows, however, we favor concreteness and keep using 
as the index set. 
\end{myrem}




The transfer principle is a powerful result and we  rely on
it in the subsequent developments. Here are the first
examples of its use; they are proved by transferring a suitable formula .


\begin{mylem}\label{lemma:firstUseOfTransfer}
\begin{enumerate}
 \item\label{item:*transformRestricted}
   For  we obtain an injective map
  
 as a restriction of  in~(\ref{equation:*TransferMap}).
 \item\label{item:starFiniteIsFinite} If   is a finite set, the 
      map~(\ref{equation:*TransferMapRestricted}) is an isomorphism
      .
 \item \label{item:functionSpaceTransformed} Let  be the
       set of functions from  to . We have
       .
 \item\label{item:productUnionTransformed}
      ; and  
      .
 \item\label{item:binaryRelTransformed} For a binary relation , we have
       . Moreover,   is
      an order if and only if  is an order. \myqed
\end{enumerate}
\end{mylem}



\paragraph{Internal Sets}
The distinction between \emph{internal} and \emph{external} entities is
central in NSA.  In this paper however it is much of formality, since
all the entities we use are internal.  Here we present only the relevant
definitions, leaving their intuitions to~\cite[\S{}II.6]{Hurd1985}.
In Appendix~\ref{appendix:domainTheoryTransferred}, 
 especially
 Rem.~\ref{remark:significanceOfInternal}, we will see that being
 internal is
  crucial 
 for transfer.

\begin{mydef}[internal entity]\label{definition:internalEntity}
 An element  is \emph{internal} with respect to
  if there is  such
 that . It is \emph{external} if it is not internal.
\end{mydef}

\begin{mylem}\label{lemma:charInternalFunction}
A function  is internal if and only if
 . \myqed
\end{mylem}


\paragraph{The Ultrapower Construction}
We collect some necessary facts about
the ultrapower construction of the monomorphism 
in~(\ref{equation:*TransferMap}). Its details are beyond our scope; they 
are found in~\cite[\S{}II.4]{Hurd1985}.

The map   in fact factorizes into the following three
steps.

The first factor  maps  to the constant
function  such that  for each ;
recall that we have chosen  (Rem.~\ref{remark:choiceOfNatAsI}). The second
  takes a quotient modulo the ultrafilter ;
finally the third factor  is the so-called \emph{Mostowski collapse}.

For an intuition let us exhibit these maps in the simple setting of~\S{}\ref{subsec:preliminariesNSA}.
The first factor   corresponds to forming constant streams:
. The second  is quotienting
modulo  of~(\ref{equation:defOfSimFilt}). The third map
 does nothing---it is a book-keeping function
that is only needed in the extended setting of superstructures.

The next result \cite[Thm.~4.5]{Hurd1985} is about ``starting from the lower-left corner'' in~(\ref{diagram:monomorphismFactorized}). It
follows from the definition of  and  is a crucial
step in the proof of the transfer principle (Lem.~\ref{lemma:transferPrinciple}). It serves as an important
lemma, too,  later for
the semantics of .
\begin{mylem}[\L{}o\'{s}' theorem]\label{lemma:sequenceAsHyperEntity}
Let  be a formula in  with its free variables contained in ; and . Then
 
 As a special case, let , then

\end{mylem}

\begin{mycor}\label{corollary:MFuncMArg}
Let ; and for each ,  and
 . Then  is an internal function
	; and . Moreover, 
 
\end{mycor}

\section{Appendix: Domain Theory, Transferred}\label{appendix:domainTheoryTransferred}
The collecting semantics of  is introduced by solving recursive equations on .
Here we present
necessary theoretical foundations---they are  like
in~\cite[\S{}2.2]{BeauxisM11} and~\cite{Suenaga2013}---identifying the
set  as a hyperdomain and *-transferring domain theory.

 The current section is an adaptation is what appeared in the appendix
 of~\cite{Suenaga2013}; and 
 the definitions and results  are similar to those
 in~\cite[\S{}2.2]{BeauxisM11}, where what we call a hyperdomain is
 called an \emph{internal domain}, and a *-continuous function is called
 an
 \emph{internal continuous function}. The way we formulate these notions
 is however a bit different: we favor more explicit use of *-transforms, since
 this aids deductive verification via the transfer principle.



\begin{mydef}\label{definition:baseSetOfCurrentPaper}
 In what follows we employ the theory of NSA presented
 in Appendix~\ref{appendix:NSAPrimer}. As
 the base set of a superstructure 
 (Def.~\ref{definition:superstructure}), we take
 .
\end{mydef}







\begin{mydef}[hyperdomain]\label{definition:hyperdomain}
 A \emph{hyperdomain} is  the pair of *-transforms
  of a cpo . 
\end{mydef}
\begin{myexpl}\label{ex:hyperdomainInCurrentWork}
 The set  is a complete lattice with respect to the
 inclusion order , therefore is a cpo. Its -transfer 
  constitutes a hyperdomain. 

We note that the set  coincides
 with the set of internal subsets of the space .
 Moreover, under the assumption that  is a finite set (e.g.\ the
 set of variables occurring in a program ), we can see that the last
 set

 coincides with the function space . For this we use 
Lem.~\ref{lemma:firstUseOfTransfer}.\ref{item:productUnionTransformed}.
\end{myexpl}

 Note that  is an order in 
 (Lem.~\ref{lemma:firstUseOfTransfer}.\ref{item:binaryRelTransformed}).
 Hyperdomain is the notion on which we wish to establish a suitable fixed point
 property.\footnote{We believe an even more general setting is possible, by defining a hyperdomain to be an internal set 
 that satisfies a suitable formula like
  in~(\ref{equation:CPOAndContinuityInLX}). Here we
 do not need such generality.}  Towards that goal, we first formulate
 the definitions of cpo and continuous function as
 -formulas, so that they can be transferred.

 Recall that the inclusion  is assumed
 (Def.~\ref{definition:superstructure}).  These formulas are used in:
 

\auxproof{
*** This notion is problematic since the formula
 cannot *-transformed easily.  In particular,
 the quantifier  is a syntax sugar and we do not know 
 how to *-transform it ****
\begin{mydef}[*-Cpo]\label{definition:*cpo}
Let  and  be an order on . The pair  is
 said to be
 a \emph{*-cpo} in  if the formula
 
 is valid in .
\end{mydef}


The *-transform of the prefix order  on 
(Lem.~\ref{lemma:streamsFormCpo}) 
is an order 
between hyperstreams (Lem.~\ref{lemma:firstUseOfTransfer}.\ref{item:binaryRelTransformed}).
\begin{mylem}\label{lemma:hyperstreamForm*CPO}
 The set  of hyperstreams, together with
 , constitutes a *-cpo in .
\end{mylem}
\begin{myproof}
 The formula  is closed and
 valid in  (Lem.~\ref{lemma:streamsFormCpo}). Thus by transfer,
 we have .
\myqed
\end{myproof}
}


\begin{mydef}[*-continuous function]\label{definition:*contiFunc}
 Let  and
 
be  hyperdomains. A function
  is
 \emph{*-continuous} if it is internal and satisfies the *-transform of the formula
 . That
 is 
 to be precise:
  is valid.\footnote{We note that the condition is different from
 (somewhat informal) `` is valid.'' In the former a chain  ranges over internal functions , while in the latter  can also be an external
 function .}
 The set of *-continuous functions from 
to  is denoted by .
\end{mydef}

\begin{mylem}\label{lemma:*contiFuncSpAsStarTransform}
 . Here
  denotes the set of continuous functions. 
\end{mylem}
\begin{myproof}
 Assume . The following closed formula is
 valid in :
 
 where  is short for
 . By
 transfer we have
 
 valid in . Thus  satisfies
 .  Obviously  is internal;
 therefore
 .

 Conversely, assume . By the
 definition of *-continuity,  is internal, hence by
 Lem.~\ref{lemma:charInternalFunction} we have .
 Moreover, using the definition of *-continuity and~(\ref{equation:1:lemma:*contiFuncSpAsStarTransform}), we have
 . \myqed
\end{myproof}

\begin{mylem}\label{lemma:fixedPtInHyperdomain}
 Let  be a hyperdomain. Then a
 *-continuous function 
 has a least
 fixed point. Moreover, the function  that maps  to its least fixed
 point  is *-continuous.
\auxproof{it is moreover described as the supremum
 .
}
\end{mylem}
\begin{myproof}
By the usual construction in a cpo, we obtain the map

Continuity of  is easy and standard.
As its *-transform
 we obtain a function
, where we used Lem.~\ref{lemma:*contiFuncSpAsStarTransform}
 and~\ref{lemma:firstUseOfTransfer}. 
The fact that  returns least fixed points is shown by the
 transfer
of the following -formula.
 
\auxproof{*** obsolete ***
 The  formula  below expresses the construction of  least
 fixed points in the cpo . It is closed and valid in .
 
 Thus its *-transform  is valid by transfer.  

By *-continuity, 
the given function 
  
is internal,  hence 
 (Lem.~\ref{lemma:charInternalFunction}); 
moreover it satisfies
 . The rest
 of the formula  states that  is the least
 fixed point of , and that it is the supremum of the internal
 hyperfunction , defined by
 
 (whose well-definedness is easily seen by transfer). \myqed
}
\end{myproof}

\begin{myrem}\label{remark:significanceOfInternal}
It is crucial  in the previous lemma that
  is an internal function. Specifically: recall that
 a formula  must be closed in order to be transferred
 (Lem.~\ref{lemma:transferPrinciple}); and that
in  only bounded quantifiers ( with some bound )
are allowed. For internal  we find such a bound by ; for external  this is not possible.

\end{myrem}


\section{Appendix: Omitted Proofs}\label{appendix:omittedProofs}




\subsection{Proof of Thm.~\ref{prop:dtToQE}}
\begin{myproof}
Assume that  is valid for some .
By transfer,  is also valid for that .
This implies  since  for any positive .
\myqed
\end{myproof}







Hereafter in the proofs we use the following -formulas.


\begin{mydef}\label{def:lunotations}
We define the following -formulas:
 
\end{mydef}

\subsection{Proof of Prop.~\ref{prop:hyperconvexpoly}}
\begin{myproof}
The constraint system  for a (standard) convex polyhedron  can be expressed by a pair  of an -matrix  and an -vector , where 
 is the number of linear inequalities in .
 The same applies to a (nonstandard) convex polyhedron
 .
 For each of ,  let us denote,
 by , the set of all
 convex polyhedra  over  that can be expressed with  linear inequalities.



Then  (with 
 expressed using an existential quantifier ) is a valid -sentence by Def.~\ref{def:convexPoly}.
By the transfer principle (Lem.~\ref{lemma:transferPrinciple}), we have a valid -sentence .
It has as its subset the set
 
since . This proves the claim.
\myqed
\end{myproof}


\subsection{Proof of Thm.~\ref{thm:hyperconcretization}}
\begin{myproof}
 Let  be sets,  and  be binary relations on  and  respectively,  and  be functions.
 Then, the following -sentence is valid (because it is equivalent to Prop.~\ref{prop:concretization}):
 
By applying Lem.~\ref{lemma:transferPrinciple} to this -sentence, we have the following valid -sentence:
 
This yields the statement of this theorem. 
For example, we can confirm that  holds from the following hypothesis in the theorem statement:
  for all .




\myqed
\end{myproof}

\subsection{Proof of Thm.~\ref{thm:widenwithinf}}
\begin{myproof}
 Let  be a set,  be a binary relation on  and  be a function.
 Then, the following -sentence is valid (because it is equivalent to Prop.~\ref{prop:widen}):
 
By applying Lem.~\ref{lemma:transferPrinciple} to this -sentence, we have the following valid -sentence:
 
This yields the statement of this theorem.
Note that the well-definedness of the iteration hyper-sequence (by
 induction on ) is implicit in the above transfer arguments.
\myqed
\end{myproof}

\subsection{Proof of Thm.~\ref{thm:newunifwidenwithinfinitesimal}}

\begin{myproof}
We can characterize uniform widening operators as an -sentence as follows (covering condition has been already expressed as an -formula in Def.~\ref{def:lunotations}):

 Let  be a set,  be a binary relation on  and  be a function.
 Then, we can see directly that the following -sentence is valid:
  
where


Assume that  is given. Then, by the -sentence~(\ref{fml:unif}), there exists  such that  holds.
Therefore, by transferring ,  holds for such .
Note that
 is the following -sentence ( and  are dealt with as constants in the following -sentence because  and  are defined outside the -sentence):
 
This yields Thm.~\ref{thm:newunifwidenwithinfinitesimal}.
\myqed
\end{myproof}

\subsection{Proof of Thm.~\ref{thm:uniformityOfKnownWidening}}
We prove the uniformity and nonuniformity of three widening operators (, , ) in this order.












       \begin{myproof}
	Let  be a iteration sequence defined by , a basis  and a monotone function .
Let  be the sequence of constraint systems that corresponds to .
	By definition of  and the construction of , regardless of the function ,  for all .
	Thus for any basis  and monotone function , we can reach a prefixed point by iterating the widening operator at most  times and this means the widening operator  is uniform.
\myqed
       \end{myproof}



        \begin{myproof}
	 The constraints in  may be added in the iteration sequence, but by the definition of the standard widening , a constraint in  will never appear once it is violated.
	 Therefore the number of steps for an iteration sequence to converge is at most  larger than the case of standard widening.
\myqed
	\end{myproof}





       \begin{myproof}
	Assume that ,  includes  and the linear equation ``'' is not included in .
	Then  holds because .
	The maximum number of steps for an iteration sequence starting from  to converge is .
	This is not limited uniformly because you can define  such that  is as large as you like.
\myqed
       \end{myproof}




 
















\begin{mydef}[Galois connection]\label{def:galois}
 Let  and  be posets, and
 and  be functions.
 A tuple  is said to be
 a \emph{Galois connection} if: for each  and
 , we have 
 .
This fact is denoted by  ;
 and we call  a \emph{concrete domain},  an
 \emph{abstract domain},  an \emph{abstraction function} and
  a \emph{concretization function}.
\end{mydef}
\begin{myprop}\label{prop:galoisExtendsToFuncSp}
A Galois connection  extends to monotone
 endofunctions. Concretely, it yields a Galois connection
 
where  and
  are
 the posets of monotone functions ordered by the pointwise extension of
  and . The functions 
 and  here are defined by:  and , respectively.
\myqed
\end{myprop}



\begin{myprop}\label{prop:galois}
In the above setting, assume further that:   be a monotone function such that
 ; and that 
 is a prefixed point of   
 (i.e.\ )
 such that .

Then  over-approximates , that is,
.
\myqed
\end{myprop}




\begin{mydef}[hyper-Galois connection]
\label{def:hyperGalois}
 A \emph{hyper-Galois connection}, denoted by
 ,
 is a quintuple
 
 of: the -transform of a poset ; that of a poset ;
 the -transform  of a
 function
 ; and  the -transform
  of . We require that the data
  forms a Galois connection (Def.~\ref{def:galois}).
\end{mydef}
The above  is an internal
function (i.e.\ );
see Appendix~\ref{appendix:NSAPrimer} for details.
The notion of \emph{-continuous function}  is defined analogously, namely that  is 
the -transform of some continuous function . See
Appendix~\ref{appendix:domainTheoryTransferred}. 

Here is the counterpart of Prop.~\ref{prop:galois}. As
announced, it only requires the cpo structure of  (not of ) and the -continuity of .

\begin{mythm}
\label{thm:newgaloiswithinf}
 Let  be a cpo, 
 be a poset such that , and
 consider the induced hyper-Galois connection 
 .
 Let  
 be a -continuous function;  
   be such that
, and 
  
 be an internal function
that is monotone with respect to .
 Assume that ;
 and that  is a prefixed
 point of , i.e.\
 .

Then  over-approximates , that is, 
 .
\myqed
\end{mythm}
\end{document}
