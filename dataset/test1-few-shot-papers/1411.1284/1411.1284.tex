\documentclass[12pt,draftcls,onecolumn]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{stmaryrd}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{cite}
\usepackage{multirow}
\usepackage{graphicx,color}
\usepackage{tabularx}
\usepackage{psfrag}
\usepackage{subfigure}
\usepackage{url}
\usepackage{stfloats}
\usepackage{amsmath}
\usepackage{array}
\usepackage[scriptsize]{caption2}
\usepackage{booktabs}
\makeatletter
\newcommand{\rmnum}[1]{\romannumeral #1}
\newcommand{\Rmnum}[1]{\expandafter\@slowromancap\romannumeral #1@}
\newcommand\figcaption{\def\@captype{figure}\caption}
\newcommand\tabcaption{\def\@captype{table}\caption}
\makeatother
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{remark}{Remark}
\newtheorem{lemma}{Lemma}
\newtheorem{assumption}{Assumption}
\newtheorem{note}{Note}

\begin{document}

\title{Kullback-Leibler divergence for interacting multiple model estimation with random matrices}

\author{Wenling Li and Yingmin Jia\thanks{This work was supported by the National Basic Research Program of
China (973 Program, 2012CB821200, 2012CB821201), the NSFC (61134005,
60921001, 61327807, 61203044, 61320106006) and the Beijing Natural
Science Foundation (4132040).}
\thanks{Wenling Li and Yingmin Jia are with the Seventh Research Division,
Beihang University (BUAA), Beijing 100191, China. (e-mail:
lwlmathgmail.com, ymjiabuaa.edu.cn).} }


\date{}
\maketitle
\begin{abstract}


This paper studies the problem of interacting multiple model (IMM)
estimation for jump Markov linear systems with unknown measurement
noise covariance. The system state and the unknown covariance are
jointly estimated in the framework of Bayesian estimation, where the
unknown covariance is modeled as a random matrix according to an
inverse-Wishart distribution. For the IMM estimation with random
matrices, one difficulty encountered is the combination of a set of
weighted inverse-Wishart distributions. Instead of using the moment
matching approach, this difficulty is overcome by minimizing the
weighted Kullback-Leibler divergence for inverse-Wishart
distributions. It is shown that a closed form solution can be
derived for the optimization problem and the resulting solution
coincides with an inverse-Wishart distribution. Simulation results
show that the proposed filter performs better than the previous work
using the moment matching approach.


\end{abstract}
\begin{keywords}
Interacting multiple model, Kullback-Leibler divergence, Random
matrix, Jump Markov system
\end{keywords}



\section{Introduction}


Jump Markov linear systems have received considerable attention due
to its applications in a wide variety of signal processing systems
and control systems \cite{2005mjls,book1,fd,train}. For
discrete-time jump Markov linear systems, the dynamics are
represented by a number of modes governed by a finite state Markov
chain and within each mode the continuous state is described by a
stochastic difference equation. Unfortunately, computing the optimal
state estimate of jump Markov linear systems requires exponential
complexity as time progresses. As a result, many suboptimal filters
have been proposed such as the generalized pseudo Bayesian
\cite{gpb}, the interacting multiple model (IMM) estimator
\cite{1988imm}, the particle filter
\cite{2000mmpf,2001ieeesp,2003immpf} and the array algorithms
\cite{2009ieeeacarray}. See the survey for more detailed discussions
on multiple model methods \cite{survey5}.



State estimation for jump Markov systems with unknown measurement
noise statistics has been investigated in recent years. In
\cite{2008rekfjmns}, a robust extended Kalman filter (EKF) has been
developed for jump Markov nonlinear systems with uncertain noise,
where the uncertainty of noise covariance matrix is limited by an
upper bound and the filter is derived by solving a nonlinear
programming problem with inequality constraints. In
\cite{1994taclmmse}, a linear minimum mean square error (LMMSE)
estimator has been proposed for jump Markov linear systems without
Gaussian assumptions on the noise and the estimator has been
extended to develop an optimal polynomial filter for stochastic
systems with switching measurements in \cite{2009germani}. In
\cite{2006ieeecs}, a minimax filter has been derived for stochastic
bimodal systems with unknown binary switching statistics. In
\cite{2010immhinf}, the  filter has been combined with the
IMM approach, where the purpose of the  filter is to
minimize the worst possible effects of the unknown noise to the
estimation errors. In addition, some weighting parameters should be
designed carefully to guarantee the existence and the performance of
the  filter.


Recently, the random matrix approach has been used for state
estimation of stochastic systems with unknown measurement noise
covariance \cite{2009ieeetac,2011ieeetaes}. By using different
conjugate prior distributions for the unknown measurement noise
covariance, state estimation for jump Markov linear systems with
unknown measurement noise covariance has been addressed in the
framework of Bayesian estimation. In \cite{ourwork1}, by treating
the conjugate prior for the noise variance parameters as the
inverse-Gamma distribution, an IMM estimator has been developed for
jump Markov linear systems. However, a serious limitation in this
filter is that the noise covariance is restricted as a diagonal
matrix. This assumption is used due to the fact that each diagonal
element of the matrix can be modeled by an inverse-Gamma
distribution but not the matrix itself. In fact, a matrix can be
considered as multivariate random variable and the inverse-Wishart
distribution can be used as the conjugate prior for the covariance
matrix of a multivariate Gaussian distribution \cite{1999mvd}. By
using the inverse-Wishart distribution as the conjugate prior for
the measurement noise covariance, an IMM estimator has been proposed
in \cite{ourwork2}. Due to the presence of the estimation of random
matrices, one difficulty encountered in the IMM estimation is the
combination of a set of weighted inverse-Wishart distributions. In
\cite{ourwork2}, an inverse-Wishart distribution is used to
approximate a set of weighted inverse-Wishart distributions by
matching the first order moment and the mean squared estimation
errors. However, it is not clear whether it is effective to
approximate a set of weighted inverse-Wishart distributions by using
the moment matching method.



In this paper, we attempt to propose a novel IMM estimator for jump
Markov linear systems with unknown measurement noise covariance. By
modeling the unknown measurement covariance as a random matrix
according to an inverse-Wishart distribution, the state and the
random matrix are estimated jointly in the framework of Bayesian
estimation. Instead of using the moment matching approach to address
the combination of a set of weighted inverse-Wishart distributions,
this difficulty is overcome by minimizing the weighted
Kullback-Leibler divergence for inverse-Wishart distributions. It is
shown that a closed form solution can be derived for the
optimization problem and the resulting solution coincides with an
inverse-Wishart distribution. A simulation study of maneuvering
target tracking is provided to illustrate the effectiveness of the
proposed filter. Simulation results show that the proposed filter
performs better than the previous work using the moment matching
approach.


The rest of this paper is organized as follows. In section
\Rmnum{2}, the problem of state estimation for jump Markov linear
systems is formulated. In section \Rmnum{3}, the weighted
Kullback-Leibler divergence is introduced and it is applied in the
IMM approach to develop a novel estimator. A numerical example is
provided in section \Rmnum{4}, followed by conclusions in section
\Rmnum{5}.

\section{Problem formulation}


Consider the following jump Markov linear system

where  and  denote the state
and the measurement vectors, respectively.  is a discrete
variable denoting the state of a Markov chain and taking values in
the set  according to the
transition probability matrix  with

The quantities ,  and  are known
matrices. Note that the measurement equation (2) does not evolve
with time according to the Markov state. This is a reasonable
condition since the measurement is generally insensitive to the
state of the model. The process noise  corresponding
to mode  and the measurement noise  are assumed to be
mutually uncorrelated zero-mean white Gaussian processes with
covariance matrices  and , respectively. The
measurement noise covariance  is assumed to be unknown and it
is modeled as a random matrix with the conjugate prior of an
inverse-Wishart distribution \cite{1999mvd}.


The aim of this paper is to derive the estimates of the state 
and the random matrix  in the framework of Bayesian estimation.
To this end, the IMM approach is adopted to derive the estimates
recursively. One cycle of the IMM estimator consists of four steps
including interacting of mode-conditioned estimates,
mode-conditioned filtering, mode probability update and fusion of
mode-conditioned estimates \cite{1988imm}. Specifically, at each
time step, the initial condition for the filter matched to a certain
model is derived by mixing the estimates of all filters at the
previous time step. This is followed by a regular filtering step,
performed in parallel for each model. Then, the mode probability is
updated by using the measurement and a combination of the updated
estimates of all filters yields the final estimates. For IMM
estimation with random matrices, one difficulty encountered is how
to combine a set of weighted inverse-Wishart distributions in the
interacting and fusion steps. Moreover, the combined probability
density function is expected to be an inverse-Wishart distribution
which facilitates to derive the Bayesian estimation recursion. This
is illustrated in the following formulation.



\emph{Problem Formulation}: Assume that the mode-conditioned
posterior density function at time step  is approximated by a
product of Gaussian and inverse-Wishart (GIW) distributions

where  is the cumulative
set of measurements up to time . 
denotes the probability density function of Gaussian distribution
with mean  and covariance matrix 

The notation  represents the
probability density function of an inverse-Wishart distribution with
degree  and scalar matrix 

with  being the multivariate Gamma function and
 being the trace function of a matrix.


Assume that the mode probabilities are also derived at time step




The problem considered in this paper is to, given a set of
mode-conditioned posterior density functions (5) and mode
probabilities (8), obtain a solution to the mixed probability
density function is of the same function form as (5), i.e.,

and the fusion of mode-conditioned posterior density function at
time 



\section{Proposed estimator}


In this section, the Kullback-Leibler divergence is briefly
reviewed, based on which the weighted Kullback-Leibler divergence is
defined to derive an optimal probability density function for a set
of weighted inverse-Wishart distributions. Then, the proposed
approach is utilized to address the problem of combination of
inverse-Wishart distributions in the IMM estimator.


\subsection{Kullback-Leibler divergence}


Let

denotes the set of probability density functions over
.


From the information-theoretic point of view, the difference between
two probability density functions  and  in 
can be measured by the following Kullback-Leibler divergence



In Bayesian statistics, the Kullback-Leibler divergence can be used
as a measure of the information gain in moving from a prior
probability density function  to a posterior probability
density function . The Kullback-Leibler divergence satisfies
 with equality if, and only if
. However, it is not a symmetrical quantity, that is to
say  \cite{prml}. Thus, the
Kullback-Leibler divergence should not be taken as a distance
rigorously. Nevertheless, the Kullback-Leibler divergence has been
shown to be geometrically important and it can be evaluated
numerically. In addition, the Kullback-Leibler divergence can be
considered an example of the Ali-Silvey class of information
theoretic measures \cite{alisil}, and it quantities how close a
probability distribution is to a candidate. The Kullback-Leibler
divergence can be used to find a probability distribution that best
approximates the candidate in the sense of minimizing the
Kullback-Leibler divergence. To represent the difference between a
probability density function and a set of probability density
functions, we adopt the following definition of the weighted
Kullback-Leibler divergence \cite{2014kld}.


\begin{definition}
Given  probability density functions , and
relative weights  satisfying

their weighted Kullback-Leibler divergence is defined as follows

\end{definition}


It can be seen that the weighted Kullback-Leibler divergence
 is the one that minimizes the sum of the information
gains from the initial probability density functions. Thus, it is
coherent with the Principle of Minimum Discrimination Information
(PMDI) according to which the probability density function best
represents the current state of knowledge is the one which produces
an information gain as small as possible \cite{it}. It has been
shown that the above weighted Kullback-Leibler divergence can be
derived explicitly as follows.
\begin{lemma}(\cite{2014kld})
The weighted Kullback-Leibler divergence defined in (14) turns out
to be

\end{lemma}



By applying the weighted Kullback-Leibler divergence to the
inverse-Wishart distributions, we can obtain a closed form solution
to (15), as shown in the following theorem.


\begin{theorem}
Given  inverse-Wishart probability density functions
 and weights  satisfying (13),
their weighted Kullback-Leibler divergence in (15) takes the form

where

\end{theorem}


\textbf{Proof}. From the definition of the inverse-Wishart
distribution (7), we have




Notice that the denominator of (15) is a constant, hence

where  is a normalizing constant,  and  are
given by (17)-(18), respectively.


Since  is a probability density function, we have

the result is proved. 


\begin{remark}
Theorem 1 states that the weighted Kullback-Leibler divergence
provides an optimal probability density function to a set of
weighted inverse-Wishart distributions. Moreover, the resulting
solution coincides with an inverse-Wishart distribution, where the
parameters  and  can be simply obtained by the
algebraic average. This strategy can be applied in the IMM
estimation with random matrices by treating mode-conditioned
posterior density functions and mode probabilities as a set of
weighted inverse-Wishart distributions.
\end{remark}

\subsection{IMM estimator by Kullback-Leibler divergence}


As the IMM approach has been well studied in the previous work
\cite{1988imm,ourwork1,ourwork2}, we present one cycle of recursion
in the following steps.


\emph{Step 1}. Interacting of mode-conditioned estimates


Since the state  and the random matrix  are
independent, the posterior density function (5) can be rewritten as



The mixed posterior density function for the state  is
given by

where the moment matching method is used to approximate the Gaussian
mixture terms



The mixed posterior density function for the random matrix 
is derived by



By using Theorem 1, the weighted Kullback-Leibler divergence is
given by

where




\emph{Step 2}. Mode-conditioned filtering


As in \cite{ourwork2}, taking the mixing estimates as inputs of
filters, the mode-conditioned posterior density function at time 
can be obtained by using variational Bayesian approximation




\emph{Step 3}. Update of mode probabilities


As in \cite{ourwork2}, the mode probabilities are updated by

where  the likelihood function.


\emph{Step 4}. Fusion of mode-conditioned estimates


The overall posterior density function for the state  is
given by

where the moment matching method is used to approximate the Gaussian
mixture terms



The overall posterior density function for the random matrix 
is derived by



By using Theorem 1, the weighted Kullback-Leibler divergence is
given by

where



Notice that the overall estimate of the random matrix is the
expectation of the inverse-Wishart distribution (39)



\begin{remark}
In the proposed filter, two different strategies are utilized to
fuse the mode-conditioned estimates of the state and the random
matrix. Specifically, for the probability density function of the
state , the moment matching approach is used to approximate a
set of weighted Gaussian distributions, which is widely used in the
IMM estimation. For the probability density function of the random
matrix , the weighted Kullback-Leibler divergence is adopted to
approximate a set of weighted inverse-Wishart distributions. The
weighted Kullback-Leibler divergence is adopted because only the
first order moment can be matched for a set of weighted
inverse-Wishart distributions by using the moment matching approach.
Moreover, the weighted Kullback-Leibler divergence provides a closed
form solution with an inverse-Wishart distribution.
\end{remark}




\begin{remark}
The difference between the proposed filter and the previous version
in \cite{ourwork2} is that the sum of weighted inverse-Wishart
distributions in \emph{Step 1} and \emph{Step 4} is approximated by
using the weighted Kullback-Leibler divergence instead of moment
matching method. Specifically, an inverse-Wishart distribution is
used to approximate the sum of weighted inverse-Wishart
distributions in \cite{ourwork2}, where the first order moment and
the mean-squared estimation error are matched to determine the
parameters of the inverse-Wishart distribution, e.g., the overall
estimate of the random matrix in \cite{ourwork2} is given by

It can be seen that the overall estimates of the random matrix in
(42) and (43) are not matched in general. However, they are matched
if  for all .
\end{remark}


\section{Numerical Example}


In this section, we compare the performance of the proposed filter
with the previous work via a two-dimensional (2-D) maneuvering
target tracking example. In order to produce a fair comparison, the
tracking parameters in \cite{ourwork2} are adopted. To be specific,
the target dynamics is described by the following coordinated turn
model

where  denotes the target
state.  denotes the coordinated turn rate and  is the
sampling time period. The process noise  is zero-mean white
Gaussian with covariance matrix

where  is the level of power spectral density and 
denotes the Kronecker product.


Three models corresponding to different turn rates are used in the
simulations, i.e., , 
and . The switching between three models is
governed by a first order time-homogeneous Markov chain with known
transition probabilities  () and
 (). It is assumed that only the target
positions are measured and the measurement noise is zero-mean white
Gaussian with unknown covariance matrix

where  is the level of power spectral density .



To evaluate the performance of the proposed filter, the IMM-KF with
known measurement noise covariance matrix is considered as the
baseline algorithm. For simplicity of notation, the proposed filter
with weighted Kullback-Leibler divergence is shortly denoted by
IMM-KL and the IMM estimation with moment matching approach is
shortly denoted by IMM-MM \cite{ourwork2}. Simulation results are
derived from 1000 Monte Carlo runs, where the root mean square error
(RMSE) in position and the estimation error of the random matrix
 defined in \cite{2012vbrtttsp} are used.


The initial inverse-Wishart distribution for  is chosen as
 and  .
The number of fixed iteration steps in the variational Bayesian
update is taken to be  to derive mode-conditioned estimates.
The level of the measurement noise density is taken to be .
The RMSE in position are shown in Fig.1. The simulation results show
that the IMM-KL outperforms the IMM-MM and the IMM-KL converges
faster than the IMM-MM at the beginning of the simulation intervals.
Especially, the IMM-KL generates almost identical results with the
IMM-KF as time progresses. The IMM-KF performs better than the
IMM-MM and IMM-KL at the beginning of the simulation intervals. This
is due to the fact that there is a large gap between the initial
prior distributions and the truth for covariance matrix. The
estimation errors with respect to the random matrix  are shown
in Fig.2. It can be seen that the IMM-KL achieves higher accuracy
than the IMM-MM.


To further evaluate the performance of the proposed filter with
respect to different levels , the averaged RMSE in position and
the averaged estimation errors with respect to the covariance matrix
are presented in Fig.3 and Fig.4, respectively. It can be observed
that the performance of the proposed IMM-KL is comparable to that of
the IMM-KF with known covariance matrix. The IMM-KL outperforms the
IMM-MM with respect to the estimation of covariance matrix.


\begin{figure}
\centering
\includegraphics[width=0.7\hsize]{fig1.eps}
\caption{RMSE in position versus time.} \label{fig1}
\end{figure}
\begin{figure}
\centering
\includegraphics[width=0.7\hsize]{fig2.eps}
\caption{Estimation error of the covariance matrix versus time.}
\label{fig2}
\end{figure}
\begin{figure}
\centering
\includegraphics[width=0.7\hsize]{fig3.eps}
\caption{Averaged RMSE in position versus different levels .}
\label{fig3}
\end{figure}
\begin{figure}
\centering
\includegraphics[width=0.7\hsize]{fig4.eps}
\caption{Estimation error of the covariance matrix versus different
levels .} \label{fig4}
\end{figure}

\section{Conclusion}


In this paper, we proposed a novel IMM estimation approach with
random matrices. Instead of using the moment matching method to
address of the combination of a set of weighted inverse-Wishart
distributions in the IMM estimation, the weighted Kullback-Leibler
divergence is applied and a closed form solution can be derived.
Simulation results show that the proposed filter outperforms the
previous work using the moment matching method. The proposed
approach can be expected to be used for maneuvering extended targets
tracking where the target extent is modeled via a random matrix
\cite{2008wkaes,2011etttsp,2014taekg,2012lan1,2012lan2,2014tsplan}.






\begin{thebibliography}{99}

\bibitem{2005mjls}
Costa, O.L.V., Fragoso, M.D., Marques, R.P., \emph{Discrete-Time
Markov Jump Linear Systems}. New York: Springer, 2005.

\bibitem{book1}
Y. Bar-Shalom, X.R. Li, T. Kirubarajan, \emph{Estimation with
Applications to Tracking and Navigation}, Wiley-Interscience, 2001.


\bibitem{fd}
Y. Zhang, X.R. Li, ``Detection and diagnosis of sensor and actuator
failures using IMM estimator'',  \emph{IEEE Trans. Aerosp. Electron.
Syst.}, vol. 34, no. 4, pp. 1293-1313, 1998.


\bibitem{train}
J. Moore, V. Krishnamurthy, ``De-interleaving pulse trains using
discrete-time stochastic dynamic-linear models'', \emph{IEEE Trans.
Signal Process.}, vol. 42, no. 11, pp. 3092-3103, 1994.


\bibitem{gpb}
G.A. Ackerson, K.S. Fu, ``On state estimation in switching
environments'', \emph{IEEE Trans. Automat. Contr.}, vol. 15, no. 1,
pp. 10-17, 1970.

\bibitem{1988imm}
Blom, H., Bar-Shalom, Y., ``The interacting multiple model algorithm
for systems with Markovian switching coefficients'', \emph{IEEE
Transactions on Automatic Control}, vol. 33, no. 8, pp. 780-783,
1988.

\bibitem{2000mmpf}
S. McGinnity, G. Irwin, ``Multiple model bootstrap filter for
maneuvering target tracking'', \emph{IEEE Trans. Aerosp. Electron.
Syst.}, vol. 36, no. 3, pp. 1006-1012, 2000.


\bibitem{2001ieeesp}
Doucet, A., Gordon, N.J., Krishnamurthy, V., ``Particle filters for
state estimation of jump Markov linear systems'', \emph{IEEE
Transactions on Signal Processing}, vol. 49, no. 3, pp. 613-624,
2001.

\bibitem{2003immpf}
Y. Boers, J. Driessen, ``Interacting multiple model particle
filter'', \emph{IEE Proc., Radar Sonar Navig.}, vol. 150, no. 5, pp.
344-349, 2003.


\bibitem{2009ieeeacarray}
Terra, M., Ishihara, J., Jesus G., ``Information filtering and array
algorithms for discrete-time Markovian jump linear systems'',
\emph{IEEE Transactions on Automatic Control}, vol. 54, no. 1, pp.
158-162, 2009.


\bibitem{survey5}
X. R. Li, V. P. Jilkov, ``Survey of maneuvering target tracking.
Part V: multiple-model methods'', \emph{IEEE Trans. Aerosp.
Electron. Syst.}, vol. 41, no. 4, pp. 1255-1321, 2004.



\bibitem{2008rekfjmns}
Zhu, J., Park, J., Lee, K., Spiryagin, M., ``Robust extended Kalman
filter of discrete-time Markovian jump nonlinear system under
uncertain noise'', \emph{Journal of Mechanical Science and
Technology}, vol. 22, no. 6, pp. 1132-1139, 2008.


\bibitem{1994taclmmse}
Costa, O.L.V., ``Linear minimum mean square error estimation for
discrete-time Markovian jump linear systems'', \emph{IEEE
Transactions on Automatic Control}, vol. 39, no. 8, pp. 1685-1689,
1994.

\bibitem{2009germani}
Germani, A., Manes, C., Palumbo, P., ``State estimation of
stochastic systems with switching measurements: a polynomial
approach'', \emph{International Journal of Robust and Nonlinear
Control}, vol. 19, no. 14, pp. 1632-1665, 2009.

\bibitem{2006ieeecs} Germani A.,
Manes, C., Palumbo, P., ``Filtering for bimodal systems: the case of
unknown switching statistics'', \emph{IEEE Transactions on Circuits
and Systems I: Regular Papers}, vol. 53, no. 6, pp. 1266-1277, 2006.


\bibitem{2010immhinf} Li, W., Jia,
Y., ``Distributed interacting multiple model  filtering
fusion for multiplatform maneuvering target tracking in clutter'',
\emph{Signal Processing}, vol. 90, no. 5, pp. 1655-1668, 2010.



\bibitem{2009ieeetac}
Srkk, S., Nummenmaa, A., ``Recursive noise
adaptive Kalman filtering by variational Bayesian approximations'',
\emph{IEEE Transactions on Automatic Control}, vol. 54, no. 3, pp.
596-600, 2009.

\bibitem{2011ieeetaes}
Gao, X., Chen, J., Tao, D., Li X., ``Multi-sensor centralized fusion
without measurement noise covariance by variational Bayesian
approximation'', \emph{IEEE Transactions on Aerospace and Electronic
Systems}, vol. 47, no. 1, pp. 718-727, 2011.


\bibitem{ourwork1}
Li, W., Jia Y., ``State estimation for jump Markov linear systems by
variational Bayesian approximation'', \emph{IET Control Theory and
Applications}, vol. 6, no. 2, pp. 319-326, 2012.

\bibitem{1999mvd}
Gupta, A.K., Nagar, D.K., \emph{Matrix Variate Distributions},
London: Chapman and Hall, 1999.


\bibitem{ourwork2}
Li, W., Jia Y., ``Adaptive filtering for jump Markov systems with
unknown noise covariance'', \emph{IET Control Theory and
Applications}, vol. 7, no. 13, pp. 1765-1772, 2013.





\bibitem{prml}
C. M. Bishop, \emph{Pattern Recognition and Machine Learning},
Springer, 2006.



\bibitem{alisil} S. M. Ali, S. D.
Silvey. ``A general class of coefficients of divergence of one
distribution from another'', \emph{J. Roy. Stat. Soc.}, vol. 28, no.
1, pp. 131-142, 1966.



\bibitem{2014kld}
G. Battistelli, L. Chisci, ``Kullback-Leibler average, consensus on
probability densities, and distributed state estimation with
guaranteed stability'', \emph{Automatica}, vol. 50, no. 3, pp.
707-718, 2014.


\bibitem{it}
H. Akaike, ``Information theory and an extension of the maximum
likelihood principle'', \emph{Proceedings of the Second
International Symposium on Information Theory}, pp. 267-281, 1973.



\bibitem{2012vbrtttsp}
Orguner, U., A variational measurement update for extended target
tracking with random matrices, \emph{IEEE Transactions on Signal
Processing}, vol. 60, no. 7, pp. 3827-3834, 2012.


\bibitem{2008wkaes}
Koch, W., ``Bayesian approach to extended object and cluster
tracking using random matrices'', \emph{IEEE Transactions on
Aerospace and Electronic Systems}, vol. 44, no. 3, pp. 1042-1059,
2008.


\bibitem{2011etttsp}
Feldmann, M., Franken, D., Koch, W., ``Tracking of extended objects
and group targets using random matrices'', \emph{IEEE Transactions
on Signal Processing}, vol. 59, no. 4, pp. 1409-1420, 2011.



\bibitem{2012lan1}
Lan, J., Li, X.R., ``Tracking of extended object or target group
using random matrix, part I: New model and approach'', In
Proceedings of the International Conference on Information Fusion,
Singapore, July 2012, pp. 2177-2184.

\bibitem{2012lan2}
Lan, J., Li, X.R., ``Tracking of extended object or target group
using random matrix, part II: Irregular object'', In Proceedings of
the International Conference on Information Fusion, Singapore, July
2012, pp. 2185-2192.

\bibitem{2014tsplan}
Lan, J., Li, X.R., ``Tracking of maneuvering non-ellipsoidal
extended object or target group using random matrix'', \emph{IEEE
Transactions on Signal Processing}, vol. 62, no. 9, pp. 2450-2463,
2014.


\bibitem{2014taekg}
K. Granstrom, U.'' Orguner, ``New prediction for extended targets
with random matrices, \emph{IEEE Transactions on Aerospace and
Electronic Systems}, vol. 50, no. 2, pp. 1577-1589, 2014.
\end{thebibliography}

\end{document}
