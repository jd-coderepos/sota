\documentclass{article}
\usepackage{spconf,amsmath,epsfig}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{algorithm}\usepackage{algpseudocode}\usepackage{graphicx}
\usepackage{bbold}
\usepackage{newclude}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{calc}

\include*{shortcutsNiclas}

\makeatletter
\newcommand*\@dblLabelI {}
\newcommand*\@dblLabelII {}
\newcommand*\@dblequationAux {}
\def\@dblequationAux #1,#2,{\def\@dblLabelI{\label{#1}}\def\@dblLabelII{\label{#2}}}
\newcommand*{\doubleequation}[3][]{\par\vskip\abovedisplayskip\noindent
    \if\relax\detokenize{#1}\relax
       \let\@dblLabelI\@empty
       \let\@dblLabelII\@empty
    \else \@dblequationAux #1,\fi
    \makebox[0.5\linewidth-1.5em]{\hspace{\stretch2}\makebox[0pt]{}\hspace{\stretch1}}\makebox[0.5\linewidth-1.5em]{\hspace{\stretch1}\makebox[0pt]{}\hspace{\stretch2}}\makebox[3em][r]{(\refstepcounter{equation}\theequation\@dblLabelI, 
  \refstepcounter{equation}\theequation\@dblLabelII)}\par\vskip\belowdisplayskip
}
\makeatother

\newcommand{\x}{x^\text{opt}_\lambda}
\newcommand{\xs}{x^\text{opt}_{\lambda^\star}}
\newcommand{\xsi}{x^\text{opt}_{\lambda^\star_i}}
\newcommand{\xtwo}{x^{\text{opt,rlx}}_\lambda}
\newcommand{\as}{a_{\lambda^\star}}
\newcommand{\aperp}{a_{\lambda^\star}\left(W^\perp\right)}
\newcommand{\asW}{a_{\lambda^\star}(W)}

\newcommand{\g}{g^\text{opt}_\lambda}
\newcommand{\gs}{g^\text{opt}_{\lambda^\star}}
\newcommand{\gsi}{g^\text{opt}_{\lambda^\star_i}}
\newcommand{\hs}{h_{\lambda^\star}}
\newcommand{\hperp}{h_{\lambda^\star}\left(W^\perp\right)}
\newcommand{\hsW}{h_{\lambda^\star}(W)}
\newcommand{\hsi}{h_{\lambda^\star_i}}
\newcommand{\ls}{\lambda^\star}
\newcommand{\lss}{\lambda^{\star\star}}
\newcommand{\gtwo}{g^{\text{opt,rlx}}_\lambda}
\newcommand{\Monegen}{M_\text{Alg1}}
\newcommand{\Mone}{M_\text{Alg1}^{W=0}}
\newcommand{\Mtwo}{M_\text{Alg2}}
\newcommand{\J}{J_\lambda^\text{opt,P1}}
\newcommand{\Js}{J_{\lambda^\star}^\text{opt,P1}}
\newcommand{\Jsi}{J_{\lambda^\star_i}^\text{opt,P1}}
\newcommand{\JJ}{J_\lambda^\text{opt,P2}}
\newcommand{\dg}{d_{\lambda^\star}(\lambda,W)}
\newcommand{\sg}{s_{\ls}(\lambda)}
\newcommand{\sgp}{s'_{\ls}(\lambda)}
\newcommand{\Cperp}{\mathcal{C}_{\lambda^\star}^\perp(\lambda)}


\title{Approximate Regularization Paths for Nuclear Norm Minimization Using Singular Value Bounds -- With Implementation and Extended Appendix}
\name{N. Blomberg, C.R. Rojas, B. Wahlberg \thanks{This work was supported by the European Research Council under the advanced grant
LEARN, contract 267381, and by the Swedish Research Council under contract 621-2009-4017.}}
\address{Department of Automatic Control and ACCESS Linnaeus Center, School of Electrical Engineering, \\ KTH--Royal Institute of Technology, SE-100 44 Stockholm, Sweden. .}
\begin{document}
\maketitle
\begin{abstract}
The widely used nuclear norm heuristic for rank minimization problems introduces a regularization parameter which is difficult to tune. We have recently proposed a method to approximate the regularization path, i.e., the optimal solution as a function of the parameter, which requires solving the problem only for a sparse set of points. In this paper, we extend the algorithm to provide error bounds for the singular values of the approximation. We exemplify the algorithms on large scale benchmark examples in model order reduction. Here, the order of a dynamical system is reduced by means of constrained minimization of the nuclear norm of a Hankel matrix.\end{abstract}
\begin{keywords}
Nuclear norm heuristic, regularization path, singular value perturbation, model order reduction.
\end{keywords}


\section{Introduction}

Rank minimization has important applications in e.g. signal processing, control, machine learning, system identification, and model order reduction. The matrix argument can e.g. be a covariance matrix (as in sensor array processing and multivariate statistical data analysis) or a structured matrix such as a Hankel matrix (as in system realization), \cite{Fazel:2002}. Specifically, application areas include spectrum sensing \cite{Meng:2010}, signal time delay estimation \cite{Jiang:2013}, phase retrieval of sparse signals \cite{Jaganathan:2012}, wireless network inference \cite{Papailiopoulos:2012}, channel equalization \cite{Konishi:2011}, etc.

In general, the rank minimization problem is non-convex and NP-hard \cite{Vandenberghe:1996}. However, a common convex heuristic for these problems is nuclear norm minimization. The nuclear norm , i.e., the sum of the singular values, is used as a convex surrogate for the non-convex rank function; this is so because the nuclear norm can be interpreted as a convex relaxation of the rank, since it is the pointwise tightest convex function (called a \textit{convex envelope} \cite{Fazel-Hindi-Boyd-01}) to lower-bound the rank, for matrices inside a unit spectral-norm ball.

Consider a general case of minimization of the nuclear norm of a linear map subject to a quadratic constraint:


where  is a linear map (for simplicity, from now on we treat the symmetric case, ),  is the decision variable, and  is the regularization parameter.

Note that the formulation in (\ref{problem1}) belongs to a subclass of regularized nuclear norm optimization problems. Other formulations include exchanging cost and constraint or the penalized version \cite{Rojas:2014}. In addition, our theory can readily be extended to weighted norms, . Then, the quadratic constraint is equivalent to the general quadratic inequality . 

\begin{figure*}
  \includegraphics[width=\textwidth,height=3cm]{fig1.pdf}
  \caption{Illustration of regularization path algorithm proposed in \cite{Blomberg:2014}. -axis: regularization parameter, . -axis: cost of (\ref{problem1}). The true regularization path (red) is guaranteed to lie in the shaded zone. The approximate path (blue) is guaranteed to differ by at most  from the true path.}
\end{figure*}

The key issue here is that, although regularized nuclear norm minimization has been thoroughly studied, it suffers from the fact that the dependence of the solution on the regularization parameter is difficult to predict. Without, in general, \textit{a priori} knowledge on how to choose , we are motivated to study the so called \textit{regularization path}, i.e., the optimal solution as a function of the regularization parameter. For problem (\ref{problem1}) the regularization path is defined on the domain

since for  the solution to (\ref{problem1}) is known, , and for  the constraint set is large enough to include the unconstrained minimum, . 

For practical purposes the domain of the regularization path must be discretized, which raises the question of how to choose the grid points. This is indeed an important question since problem (\ref{problem1}) can be computationally costly to solve. 

To address this problem, in \cite{Blomberg:2014}, we presented a method to choose the grid points based on a worst-case approximation error when the optimal solution for , , is approximated by  for . The idea is visualized in Figure 1. Given the solution for some , we increase  beyond  until the worst-case approximation error reaches a pre-specified tolerance, , and then we re-evaluate (\ref{problem1}). Iteratively, starting for , this procedure generates a set of grid points, , and an approximate regularization path such that the approximation error is within  for all .

The novelty of this paper consists of two new algorithms. The first gives a guarantee on the cost function of (\ref{problem1}). The second gives a guarantee on the singular values of , when  is approximated by . Furthermore, we derive upper bounds on the number of grid points needed by the algorithms to meet a tolerance .

\parskip = 0pt
\section{Error bounds for approximation of (1)}

In this section we derive error bounds that allow us to confine the true regularization path within a certain region (the shaded area in Figure 1).

Define the singular values of , where  is optimal for (\ref{problem1}) for parameter value , as

For further use in the below presented Algorithms 1 and 2, respectively, we derive upper bounds on the quantities:
\doubleequation[err_d,err_s]{\norm{\Ac\left(\xs\right)}_*-\norm{\Ac\left(\x\right)}_* \text{ and }}{\quad\qquad\qquad\qquad\sum\limits_i^p \left(\sigma^{\ls}_i - \sigma^\lambda_i \right)^2,}
\noindent
where  is given. The bounds can be viewed as worst-case approximation errors in the singular values when  is approximated by .

\subsection{Relaxation of (1) using subgradients}

We here relax problem (\ref{problem1}) using subgradients of the nuclear norm. The concept of subdifferentials (or sets of subgradients) is a generalization of the gradient that applies to functions whose gradient is undefined in some point or points, \cite{Rockafellar-70}. In the case of the nuclear norm, the subdifferential is (see e.g. \cite{Recht:2010}):

where  is a compact singular value decomposition .  implies that  and  must have orthogonal row and column spaces.

Now, assume that  solves (\ref{problem1}) for some parameter value . Then, since the nuclear norm is convex we can write, for any matrix , the inequality

where ,  is the standard inner product, and  is the adjoint operator of . For shorter notation we define


To sum up, the above inequality becomes

which implies that for  the optimal argument  must lie in the half-space .

Using the inequality in (\ref{ineq}) we can relax (\ref{problem1}) into

Problem (\ref{problem2}) is solved analytically in the following lemma:
\begin{lemma}
Problem (\ref{problem2}) has the optimal solution

and optimal cost

\end{lemma}
\begin{proof}
At optimum the constraint is tight and the negative gradient of the cost function, , is proportional to the outward pointing normal of the constraint set. This gives . Inserting  into the cost of (\ref{problem2}) gives (\ref{optcostP2}).
\end{proof}

\subsection{Bound on cost function approximation error, (\ref{err_d})}

Using (\ref{optcostP2}) we can upper bound the approximation error in (\ref{err_d}:
\begin{theorem}
The approximation error in (\ref{err_d}) (i.e., the cost function approximation error) for any  is upper-bounded by the function , as

\end{theorem}
\begin{proof}
The theorem follows from the fact that, for any ,  is lower bounded by the optimal cost in (\ref{optcostP2}).
\end{proof}
\begin{remark} \label{rem}
In Section \ref{implem} we present a Frank-Wolfe algorithm for optimizing (\ref{dg}) over . Furthermore, it can be verified that there is some  such that , by taking  according to (\ref{hperp}).
 \end{remark}
 \begin{remark}
In resemblance with \cite{Giesen:2012}, the function  can be interpreted as a \textit{duality gap}, since the relaxation made in (\ref{problem2}) relates to the Frank-Wolfe algorithm \cite{Jaggi:2013} when seen as a primal-dual method.
\end{remark}

\subsection{Bound on singular value approximation error, (\ref{err_s})}

Next, we derive an upper bound on the error in (\ref{err_s}). This bound will be the minimum of two separate bounds. The first of these is as follows:
\begin{lemma}

where  is the 'th unit vector, i.e.,  has zeros everywhere except at the 'th component which is one, and .
\end{lemma}
\begin{proof}
For , . Hence, (\ref{firstbound}) corresponds to the maximum of  subject to , which is reached by making  as large as possible and  for .
\end{proof}

Now, we derive a second upper bound, which is complementary to the above. To do this, consider the perturbation

which is valid since  is linear in . Then, according to Mirsky's theorem \cite{Horn-Johnson-85} the singular values of  obey

where, due to equivalence of finite-dimensional norms \cite{Luenberger-69},

for some constant  depending on .

Furthermore, we bound  in Lemma \ref{lem:bound} below. For this we need the following lemma:

\begin{lemma} \label{lem:perp}
There exists a  such that  (see (\ref{subgr})) is proportional to the error vector , i.e.,

for some scalar .
\end{lemma}
\begin{proof}
The proof is in the Appendix.
\end{proof}

\begin{lemma} \label{lem:bound}

\end{lemma}
\begin{proof}
Due to the existence of  in (\ref{hperp}),  is constrained by the convex set

so an upper bound is . This maximum can be solved geometrically. Since  is inside the ball of the first constraint of , this constraint has to be tight at the optima. Furthermore, with the first constraint being tight, the vectors , , and  form a triangle, with  and , so

according to the law of cosines, where  is the angle between  and the hyperplane

This expression is maximized for  giving the result . (In fact,  implies that the second constraint in  is also tight.)
\end{proof}

Combining (\ref{firstbound}), (\ref{normE}), and (\ref{bound}), we obtain the following upper bound on the approximation error in (\ref{err_s}):
\begin{theorem}
The approximation error in (\ref{err_s}) is upper bounded by the function :

\end{theorem}
\begin{proof}
The first argument in the  is given by (\ref{firstbound}). The second is obtained by combining (\ref{normE}) and (\ref{bound}).
\end{proof}




\section{Algorithms}

\subsection{Model order reduction}

In model order reduction, and approximative filter design, the aim is to reduce a high-order model description to a low-order model while preserving the properties according to some fit criterion.

We consider a known Finite Impulse Response (FIR) model of a stable scalar discrete-time linear time-invariant dynamical system, denoted by , which is a vector containing its impulse response coefficients. Furthermore, we denote the low-order candidates by , and consider the  model fit criterion . Note that other criteria commonly used in model order reduction are the - and Hankel norm-criteria (see \cite{Antoulas:2005} or \cite{Zhou-Doyle-Glover-96}), which are not considered here.

It can be shown \cite{Fazel-Hindi-Boyd-03} that the following Hankel matrix (here taken to be symmetric for simplicity)

has the property that its rank is equal to the order (McMillan degree) of the dynamical system which has  as impulse response. This motivates the Hankel matrix rank minimization problem to enforce a low system order.

Using the nuclear norm as surrogate for rank and the  model fit criterion, we formulate the following special case of (\ref{problem1}):

Note that in this setting  are the Hankel singular values of the system with  as impulse response.

The adjoint of the Hankel operator in (\ref{hankel}), , maps matrices  to vectors , by summing the anti-diagonals of , i.e.,


\subsection{The algorithms}

The algorithms are outlined in Algorithm 1 and 2. The idea is to adaptively choose a set of discretization points, for which problem (\ref{problem1}) is solved. In the intermediate intervals the regularization path is approximated by the previous solution (obtained on the infimum of the current interval). The resulting approximation errors are upper bounded in (\ref{dg}) for Algorithm 1 and (\ref{sg}) for Algorithm 2. The discretization points are chosen as the values of  for which the upper bound reaches a pre-specified error tolerance, . This is visualised in Figure 2.

Note that in Algorithm 1,  depends on . For simplicity, we can set , but in Section \ref{implem} we also demonstrate how to optimize  over . Also note that for a Hankel matrix the quantity  satisfies (\ref{sg}).

\begin{algorithm}                    \begin{algorithmic}                    \State \textbf{Algorithms 1 and 2.} Approximate regularization paths.
	\State \textbf{Input: } .
	\State \textbf{Output: } Approximate regularization paths such that errors (\ref{err_d})  (Alg. 1) or (\ref{err_s})  (Alg. 2) for .
\State Initialize . Set .
    \While{}
    	\State Solve (\ref{problem1}) for , giving .
        \State Solve  from  (Algorithm 1) or  (Algorithm 2).
        \State Accept  as approximate solution for .
        \State Set .
    \EndWhile
\end{algorithmic}
\end{algorithm}

\subsubsection{Number of evaluations for Algorithm 1} \label{cfrp_A}

Here we bound the number of evaluations of (\ref{problem1}), i.e., the number of iterations of the above algorithm needed to guarantee the error (\ref{err_d}) within the tolerance .
\begin{theorem} \label{Malg1}
The number of evaluations of (\ref{problem1}) needed by Algorithm 1 is at most

in general, and if :

where  is the tolerance and

in which ,  is a -matrix of ones, and the adjoint of the Hankel operator is defined in (\ref{Hadj}).
\end{theorem}
\begin{proof} The proof is in the Appendix.
\end{proof}


\subsubsection{Number of evaluations for Algorithm 2} \label{svrp_A}

Now, we bound the number of evaluations of (\ref{problem1}), i.e., the number of iterations of Algorithm 2 needed to guarantee the solution within the tolerance .

\begin{theorem} \label{Malg2}
The number of evaluations of (\ref{problem1}) needed by Algorithm 2, i.e., the number of iterations, is at most

\end{theorem}
\begin{proof} The proof is in the Appendix.
\end{proof}

\section{Implementation} \label{implem}
  
\begin{table*}[t]
\centering
\begin{tabular}{lrlrrr|rrr|rr}
&&&&&&\multicolumn{3}{|c|}{Algorithm 1}&\multicolumn{2}{|c}{Algorithm 2} \\
\text{benchmark} & order &  &  & \text{cpu ADMM} &  &  &  &  &  &  \\
\hline
\multirow{2}{*}{} & \multirow{2}{*}{348} & \multirow{2}{*}{1} & \multirow{2}{*}{1047} & \multirow{2}{*}{134.23} & \multirow{2}{*}{0.1233} & 0.2 & 5 & 3062 & 30 & 10\\
& & & & & & 0.3 & 3 & 4082 & 20 & 5\\
\hline
\multirow{2}{*}{} & \multirow{2}{*}{48} & \multirow{2}{*}{0.025} & \multirow{2}{*}{576} & \multirow{2}{*}{317.86} & \multirow{2}{*}{0.1607} & 0.2 & 7 & 1035 & 30 & 10 \\
& & & & && 0.3& 4 & 1379 & 20 & 5 \\
\hline
\multirow{2}{*}{} & \multirow{2}{*}{598} & \multirow{2}{*}{0.1} & \multirow{2}{*}{196} &\multirow{2}{*}{7.36} & \multirow{2}{*}{0.0958} & 0.2 & 5 & 643 & 30 & 9 \\
& & & & &&0.3 & 3 & 856 & 20 & 4 \\
\hline
\multirow{2}{*}{} & \multirow{2}{*}{200} & \multirow{2}{*}{0.5} & \multirow{2}{*}{139} & \multirow{2}{*}{11.78} & \multirow{2}{*}{0.7270}& 0.2 & 5 & 482 & 30 & 12 \\
& & & & && 0.3 & 3 & 642 & 20 & 7 \\
\hline
\multirow{2}{*}{} & \multirow{2}{*}{84} & \multirow{2}{*}{0.0001} & \multirow{2}{*}{242} & \multirow{2}{*}{39.80}& \multirow{2}{*}{0.1054} &  0.2 & 5 & 1193 & 30 & 7 \\
& & & & && 0.3 & 3 & 795 & 20 & 3 \\
\end{tabular}
\caption{Results of Algorithm 1 and 2.  is sampling time in Matlab's , giving impulse response lengths . 'cpu ADMM' is an average time in seconds with a standard laptop for solving (\ref{probHank}) using ADMM. The maximum cost .  is number of grid points needed, with upper bounds  (for Algorithm 1 we use (\ref{mmax1})).  is the minimum tolerance for which   for all . For Algorithm 2, .}
\end{table*}

For large scale problems (\ref{problem1}) we suggest an Alternating Direction Method of Multipliers (ADMM), c.f. \cite{Boyd:2010} and \cite{Yang:2012}. We will follow the method in \cite{Liu:2013} with a modification for the -update in (\ref{gupd}) below.

First, we rewrite (\ref{probHank}) as

Next, we form the following augmented Lagrangian

The strategy is to update the variables as

The variables can be initialized e.g. as . (Initialize  if it is adaptive as in \cite{Boyd:2010}).

The  update in (\ref{Hupd}) is accomplished in \cite{Liu:2013} using so called 'singular value soft-thresholding':

where  are given by the singular value decomposition


The second subproblem, (\ref{gupd}), we reformulate as

where ,  and , and  is defined in (\ref{Hadj}). This can be solved by using the facts that the optimal point, , lies on the boundary of the constraint set, and in this point the negative gradient of the cost function is normal to the constraint set, i.e., it is proportional to . This means that

where  is a scalar determined from solving  using Newton's method. This  is unique since

is a decreasing function with  and . The fact that  is true since  is the global minimum, which is located outside the constraint set. Summing up, we obtain


The stopping criterion is  and , where the primal and dual residuals ( and ) and tolerances ( and ) are computed from the definition in \cite[Sec.~3]{Boyd:2010} as


\subsection{Frank-Wolfe algorithm for optimizing (\ref{dg}) over }

The Frank-Wolfe algorithm (or \textit{conditional gradient method}) is a simple iterative method, suggested in \cite{Frank:1956} (1956) for minimizing convex, continuously differentiable functions  over compact convex sets. We here design a Frank-Wolfe algorithm for optimizing (\ref{dg}) over . Our algorithm is summarized in Algorithm 3.

To solve the argument minimizations at each iteration explicitly, we note that for the constraints in 

and

for some matrices  and  of appropriate size. Hence,

where . Then, in Algorithm 3, we parameterize , so that , and solve

This problem has the closed form solution 
where  is a compact singular value decomposition. Then,


Finally, when optimizing the duality gap (\ref{dg}) over  for a fixed , we have


\begin{algorithm}                    \begin{algorithmic}                    \State \textbf{Algorithm 3.} Frank-Wolfe for optimizing (\ref{dg}) over 
	\State Initialize 
    \For{k = 0,1,...,K}
    	\State Compute ; 
        \State Update , for 
    \EndFor
\end{algorithmic}
\end{algorithm}

\begin{figure}
\centering
\includegraphics[scale=0.7]{fig1ab.pdf}
\caption{True errors (red) and confidence zones (grey) for the model . Upper: Algorithm 1 with approximate regularization path (blue) for , where . Lower: Algorithm 2 for , where .}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.65]{figBeam1.pdf}
\caption{Plot of significant singular values  for . Vertical lines indicate grid points. Upper: Algortihm 1 (, where ). Lower: Algorithm 2 (, where ).}
\end{figure}
\begin{figure}
\centering
\includegraphics[scale=0.65]{figBeam2.pdf}
\caption{Plot of significant singular values  for . Vertical lines indicate grid points. Upper: Algortihm 1 (, where ). Lower: Algorithm 2 (, where ).}
\end{figure}
\begin{figure}
\centering
\includegraphics[scale=0.65]{figBuild1.pdf}
\caption{Plot of significant singular values  for . Vertical lines indicate grid points. Upper: Algortihm 1 (, where ). Lower: Algorithm 2 (, where ).}
\end{figure}
\begin{figure}
\centering
\includegraphics[scale=0.65]{figBuild2.pdf}
\caption{Plot of significant singular values  for . Vertical lines indicate grid points. Upper: Algortihm 1 (, where ). Lower: Algorithm 2 (, where ).}
\end{figure}
\begin{figure}
\centering
\includegraphics[scale=0.65]{figEady1.pdf}
\caption{Plot of significant singular values  for . Vertical lines indicate grid points. Upper: Algortihm 1 (, where ). Lower: Algorithm 2 (, where ).}
\end{figure}
\begin{figure}
\centering
\includegraphics[scale=0.65]{figEady2.pdf}
\caption{Plot of significant singular values  for . Vertical lines indicate grid points. Upper: Algortihm 1 (, where ). Lower: Algorithm 2 (, where ).}
\end{figure}
\begin{figure}
\centering
\includegraphics[scale=0.65]{figHeat-cont1.pdf}
\caption{Plot of significant singular values  for . Vertical lines indicate grid points. Upper: Algortihm 1 (, where ). Lower: Algorithm 2 (, where ).}
\end{figure}
\begin{figure}
\centering
\includegraphics[scale=0.65]{figHeat-cont2.pdf}
\caption{Plot of significant singular values  for . Vertical lines indicate grid points. Upper: Algortihm 1 (, where ). Lower: Algorithm 2 (, where ).}
\end{figure}
\begin{figure}
\centering
\includegraphics[scale=0.65]{figPde1.pdf}
\caption{Plot of significant singular values  for . Vertical lines indicate grid points. Upper: Algortihm 1 (, where ). Lower: Algorithm 2 (, where ).}
\end{figure}
\begin{figure}
\centering
\includegraphics[scale=0.65]{figPde2.pdf}
\caption{Plot of significant singular values  for . Vertical lines indicate grid points. Upper: Algortihm 1 (, where ). Lower: Algorithm 2 (, where ).}
\end{figure}

\section{Results}

Algorithm 1 and 2 are implemented on single-input-single-output model order reduction benchmarks\footnote{The model reduction benchmarks are avaliable at slicot.org/20-site/126-benchmark-examples-for-model-reduction}. The continuous-time impulse response sequences are discretized using the Matlab command  with sampling times listed in Table 1. We here set , but design a Frank-Wolfe algorithm for optimizing (\ref{dg}) over  in Section \ref{implem}. The tolerances  are chosen as a fraction the maximum possible cost of (\ref{probHank}) in Algorithm 1, and according to  for Algorithm 2.

For large scale problems (\ref{problem1}) we suggest an Alternating Direction Method of Multipliers (ADMM), c.f. \cite{Boyd:2010}, \cite{Yang:2012}. Our method is similar to \cite{Liu:2013} and provided in Section \ref{implem}.

The results are summarized in Table 1. We observe that, for Algorithm 1, the bound  is very loose. We also see the smallest possible  such that  for any . For the system  this extreme value is high, but we observe that for most part of the regularization path  is very low; it only increases very close to . For smaller values of  in Algorithm 1, we may optimize over . Then, it is possible to use arbitrarily small , since  (see Remark \ref{rem}).

In Figure 2 we illustrate the ideas in Algorithm 1 and 2.

In Figures 3-12 we visualize the grid points for Algorithm 1 and 2, respectively, when applied to the model the different benchmark models. For Algorithm 1, we generally see that the grid points are slightly more dense in for smaller values of . For Algorithm 2, the grid points are also more dense in the first part of the regularization path; it stops gridding when the first argument in (\ref{sg}) becomes active. Thus, the algorithms are suitable in cases where the singular value drops happen for low values of , which is a general observation we have made when studying these benchmark examples.

\section{Conclusion}

We have proposed a method to approximate the regularization path of a quadratically constrained nuclear norm minimization problem, with guarantees on the singular values of the matrix argument. The algorithms solve the problem for a finite, explicitly upper-bounded, number of values of the regularization parameter. We have also provided details regarding efficient implementation of the algorithms.

The results show that the algorithms generate grid points that are suitable for tracking changes in the singular values.

\section{Appendix}
\begin{proof}[Proof of Lemma \ref{lem:perp}]
The existence of vectors proportional to  can be proved using the optimality conditions of (\ref{problem1}), which imply that the minimizer of (\ref{problem1}), , minimizes the Lagrangian  for some Lagrange multiplier  \cite[pp.~217]{Luenberger-69}, i.e.,

The second term is computed explicitly as

so that

showing that there is a subgradient proportional to .
\end{proof}

\begin{proof}[Proof of Theorem \ref{Malg1}]
Consider the choice of  in (\ref{hperp}). Then, for ,

in which we will now bound . To do this, we can bound

where we have used in the first inequality twice the characterization of the nuclear norm as

with  such that , and  such that , and in the second last equality the unitary invariance of the nuclear norm.

Using the bound on  in  the sub-intervals of the algorithm are of length at most

Hence, we need at least

evaluations of (\ref{problem1}). Since  according to (\ref{lambda}), we obtain (\ref{mmax1gen}). If we set  in (\ref{proofineq}) we obtain (\ref{mmax1}).
\end{proof}

\begin{proof}[Proof of Theorem \ref{Malg2}]
If the first argument in (\ref{sg}) is ignored Algorithm 2 will use a greater or equal number of grid points. In this case, Algorithm 2 evaluates (\ref{problem1}) for , obtained from . As in (\ref{sg}), , which gives the relation

By induction in , with , this becomes

Given that , as in (\ref{lambda}), the largest integer  such that  obeys . Since this is a worst-case scenario we obtain the upper bound in (\ref{mmax2}).
\end{proof}

\bibliographystyle{IEEEbib}
\bibliography{niclas_SPW}

\end{document}
