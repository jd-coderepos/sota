\documentclass[copyright,creativecommons]{eptcs}
\providecommand{\event}{CCA 2010}
\usepackage{amssymb,amsmath,amsthm,graphicx}


\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{theorem}{Theorem}[section]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{assumption}{Assumption}[section]
\newtheorem{example}{Example}[section]


\newcommand{\CA}{{\cal A}}
\newcommand{\CR}{{\cal R}}
\newcommand{\In}{\subseteq}
\newcommand{\dom}{{\rm dom}}
\newcommand{\rng}{{\rm range}}
\newcommand{\IN}{\mathbb{N}}
\newcommand{\IZ}{\mathbb{Z}}
\newcommand{\IR}{\mathbb{R}}
\newcommand{\ld}{\mathrm{ld}}


\title{Computational Complexity of Iterated Maps on the Interval\\
(Extended Abstract)}
\author{Christoph Spandl
\institute{Institut f\"{u}r Theoretische Informatik, Mathematik und Operations Research}
\institute{Universit\"{a}t der Bundeswehr M\"{u}nchen\\
D-85577 Neubiberg, Germany}
\email{christoph.spandl@unibw.de}
}
\def\titlerunning{Computational Complexity of Iterated Maps on the Interval}
\def\authorrunning{Christoph Spandl}
\begin{document}
\maketitle


\begin{abstract}
The exact computation of orbits of discrete dynamical systems on the
interval is considered. Therefore, a multiple-precision floating point
approach based on error analysis is chosen and a general algorithm is
presented. The correctness of the algorithm is shown and the
computational complexity is analyzed. As a main result, the
computational complexity measure considered here is related
to the Ljapunow exponent of the dynamical system under consideration.
\end{abstract}


\section{Introduction}

Consider a discrete dynamical system  on some compact interval ,
called the phase space, given by a function , a recursion relation
 and an initial value . The sequence  of
iterates is called the orbit of the dynamical system in phase space corresponding
to the initial value . If such a dynamical system is implemented, that is
a computer program is written for calculating a finite initial
segment of the orbit for given , care has to be taken in choosing
the appropriate data structure for representing real numbers. Traditionally,
IEEE 754 {\tt double} floating point numbers \cite{ieee87} are used. However,
if the dynamical system shows chaotic behavior, a problem arises. The finite
and constant length of the mantissa of a {\tt double} variable causes round
off errors which are magnified after each iteration step. Only after a few
iterations, the error is so big that the computed values are actually
useless \cite{Mue01}. To put things right, a rigorous method for computations
with real numbers has to be used. In \cite{Bla05}, this issue is addressed
for the logistic map which is also consiedred as a starting point in the next
section. There, the exact real arithmetic in the form of centered intervals
with bounded error terms is used as described in \cite{bl06}. However, the
notation used in \cite{Bla05, bl06} is an algebraic one based on arbitrary
large integers. On the other hand, the aim of the present paper is to keep
the notation as close as possible to the standard in scientific computing
but being precise in the sense of exact real arithmetic. This has as a
consequence first that the basic data type is not an integer as considered
in \cite{Bla05, bl06}, but a floating point number with a definite
mantissa length. Second, the type of error considered here is the
relative error as is standard in floating point arithmetic - in contrast
to the absolute error considered in \cite{Bla05, bl06}. In practice, a
multiple precision floating point library providing floating point
numbers with arbitrary high mantissa length have to be used.
In the following, it is analyzed how the needed
mantissa length behaves in multiple-precision computations of
iterates of discrete dynamical systems. The mantissa length needed
for floating point numbers such that any computed point of the orbit
has a specified and guaranteed accuracy is examined. Therefore,
a precise mathematical framework for floating point computations
has to be established. The main result shows that the
ratio of mantissa length to iteration length in the limit of
iteration length to infinity is related to the Ljapunow exponent.
Comparing, in \cite{Bla05} only the logistic map is
considered explicitly and the connection to the Ljapunow exponent
is not stated, but observed numerically. In the present paper,
this connection is shown mathematically for a general discrete
dynamical system .
This result also gives some advice for economically designing exact
algorithms simulating one-dimensional discrete dynamical systems.

\section{Roundoff Error, Error Propagation and Dynamic Behavior}

In this section, the discrete dynamical system  with  and
,  for some control parameter 
is investigated. In the literature, the recursion relation  is
called the {\em logistic equation} \cite{ce80}. When implementing the logistic
equation on a real computer and demanding to obtain exact values for the
orbit , the analysis of roundoff errors and of error propagation
requires some care. This is due to the fact that for some values of 
the dynamics is highly chaotic and therefore inaccuracies are magnified
exponentially in time \cite{ce06, hsd04}.

In the following, for a given initial value , the true orbit is denoted by
, whereas the really computed orbit, suffering from roundoff errors
and error propagation, is denoted by . Note that even
 may differ form  since the conversion to a floating point
number may cause the very first roundoff error. One goal of this section
is to give a rigorous estimation of the total error in dependence of the
iteration step .

Calculating the orbit , two types of error are present.
First, error propagation due to the iteration scheme and second the
roundoff error caused by the calculation of . Now, let 
for some  be given. Then the true error after one iteration step
is . Since in reality not  is
calculated but some erroneous approximation ,
the true error can be written as
.
Hence, the true error can be written as a sum

of two terms. The first term describes solely the error propagation
while the second term gives exactly the newly produced error
due to the approximate calculation of .

To handle the exact values of both errors computationally, interval
arithmetic can be used \cite{ah83}. Interval arithmetic can be seen
in the setting here as a special case of the computational model
of TTE \cite{wh00}, which gives a precise notion for describing
computations over the real numbers. Another strongly related model,
which in some sense reflects the situation here more adequate is the
Feasible Real RAM model \cite{BH98}. For the sake of simplicity however,
an interval setting is used here. For any time step , let
the phase point  together with its error be represented by two
floating point numbers  and  () with
given mantissa length  forming an interval . The
interval is an enclosure of the real value , that is
. It is straightforward to transform
the interval to a floating point value  of
mantissa length  by setting

where  performs the rounding to nearest floating point number.
The absolute error  of  can
be estimated via the interval length  by

where  is an error introduced by the rounding operation  in
Equation \ref{val_def}. An upper bound on  will be discussed later, for
now it suffices to say that in general it is small compared to .

For doing an error analysis of the logistic equation analytically, some
idealizing assumptions are made. First, the value of  is assumed to be
given with such a high precision that no interval representation is needed. Second,
only the error propagation is considered caused by the initial error due to rounding
 to some floating point number of mantissa length . Third, the value
of  in Equation \ref{err_def} is neglected. The recursion relation then reads
in natural interval extension

with the interval length   given by the recursion relation

with the obvious solution . Finally the absolute error 
of  according to Equation \ref{val_def} can be bounded from
above by

Note that the above analysis only holds if the natural interval extension
for  is derived from the formula . If it is derived
from the formula  or
, the mathematical analysis
is more difficult. However, the problems described in the following also
appear, but in some different form.

The aim now is to calculate, for given , 
and mantissa length , the orbit up to time 
with relative error . That is, for
 should hold

The ideal assumptions require the somewhat unreal setting
that the mantissa length has to be set to some finite, but big enough value 
for representing  and a virtually infinite value  for doing the
iteration. Finally, some upper bound on  is needed. The value of 
is given as the roundoff error by representing  as a floating point number
of mantissa length . For that, the well known estimate

exists. Combining (\ref{prec_req}), (\ref{err_bound}) and (\ref{round_zero})
gives as a sufficient condition

for .

The minimal , fulfilling the precision requirement (\ref{prec_req}) on the
relative error of , which depends on ,  and , is
denoted by . So, the sufficient condition (\ref{res_cond})
gives an upper bound on  by

where  is the logarithm to base . At that stage, a central
quantity of this work is introduced which is a kind of complexity measure.
The {\em loss of significance rate} , which may depend on
the initial value  and the precision  is defined by

This quantity describes the limiting amount of significant mantissa length
being lost at each iteration step. Significant means here the part of
the places being exact. A general treatment of this complexity measure
is given in the next section. Roughly speaking,
 is the mantissa length
for any floating point number needed in an algorithm doing the iteration
starting with  and calculating up to , if the output should be precise
up to  decimal places. Formula \ref{ub_req} gives an upper
bound for the loss of significance rate by
.

It is interesting to see whether the upper bound calculated analytically,
which needed strong idealizations, is in the region of the real value.
So, the logistic equation was implemented using a multiple-precision
interval library. For that purpose, the interval library MPFI
\cite{ReRo02} based on the multiple-precision floating point number
library MPFR \cite{Fousse:2007:MMP}, both written in C, was used.
For each control parameter  ranging from  to  and a
step size of , the orbit for initial condition  was
calculated up to . For each , the minimum
mantissa length  needed to guarantee 
for  was searched. Then, 
was calculated. The result shows that  exceeds the
analytical bound  only slightly. So, the above made
ideal assumptions seem to be valid. In \cite{Mue01}, the logistic
equation was also investigated for  using the exact real
arithmetic package iRRAM based on the Feasible Real RAM model
\cite{BH98}. In the paper, also the precision needed
to guarantee the exactness of the first  decimal places
are reported up to . The values are in full
agreement with the simulation results performed here.

Hence, for , the interval length 
increases exponentially in time . This result should be interpreted
in terms of the dynamical behavior of the logistic equation. So, at
this point is worth having an analytical look at the behavior
of the dynamical system. Despite the fact that these results
are well known \cite{hsd04, de89}, they are reviewed here for the sake of
self containment. First, the equation possesses in the range 
exactly one
fixed point  if  and exactly two fixed points 
and  if . Since 
and ,  is a stable fixed point (an attractor,
) for  and an unstable fixed point
(a repeller, ) for .
If , the only fixed point  is hyperbolic ()
and a bifurcation occurs at that value of the control parameter .
If ,  becomes unstable
and the newly occurring fixed point  is stable. Finally,
 for  and
 if  holds for all .
If , this is a direct consequence
of the contraction mapping principle. If , observe that
 holds for all . Hence, any sequence ,
, is strictly decreasing and bounded from below. So it
converges to the only fixed point . For the case ,
the interested reader is referred to the literature: \cite{de89},
Proposition 5.3. At  a second bifurcation occurs
and for  the system goes into a region of periodic
behavior with period doubling bifurcations. Finally, for some
, chaotic behavior is reached.

This analysis shows that in the parameter range ,
the orbit converges to the stable fixed point for any initial value
. Furthermore, there exists some closed interval ,
which depends on , containing the stable fixed point such that
 holds and  is a contraction on . The interval
computation using a natural interval extension of the recursion 
formula , on the other hand, is not very compatible with
this picture. While for , the results are
in agreement with the dynamical analysis, the calculations for
 are not handled very well by interval arithmetic since
the interval approach would suggest an exponential divergence of
initially nearby orbits which is not true in reality. The reason is
that the natural interval approach implicitly, due to the dependency problem,
takes account only of the global behavior of  in the form of the global
Lipschitz constant . However, the local
Lipschitz constant  governs the
real error propagation at time step  and also describes the dynamic behavior.
This notion can be made precise and finally leads to a more efficient
algorithm for computing orbits.

Let us return to Equation \ref{main_err}. The true error is the sum of
the error propagation (first term) according to the iteration and the
roundoff error due to the computation of  (second term). The
first term of Equation \ref{main_err} can be handled using the mean
value theorem,

with . This gives directly the
bound

The second term can be estimated the following way. As discussed in
\cite{wi63}, the roundoff error produced in calculating  can be
estimated by

where  is the number of rounding operations performed in computing
 and  is the mantissa length of . In
the case considered here,  follows since there are 3 arithmetic
operations and the rounding of . It is further crucial to
mention that the factor  is only valid if 
holds so that the mantissa length must not be chosen too small.
Using the fact that  holds and 
if , the unknown value  can be eliminated.
This calculation shows that there exists a recursive equation
on an upper bound  on  for all :

with  and
 
The idea is now not to calculate intervals, but pairs of values 
and corresponding guaranteed error bounds . The difference to
the interval concept is not to compute the errors {\em implicitly},
so that only global behavior can be taken into account, but to compute
them {\em explicitly} and independent of the values of interest. It should be
mentioned that the approach described here is compatible with an interval
approach using special centered forms, namely mean value forms \cite{rr84}.
However, the approach here explicitly devises values and errors, describes
an automated error analysis, whereas an interval approach primarily does not
disclose any error. Furthermore, also the iRRAM package permits a more
elaborate way for computing the iteration, based on a similar algorithm as
described above \cite{mu10}. The rounded
values  are calculated as usual in floating point arithmetic except
that multiple-precision floats are used. The guaranteed error bounds are also
calculated using floating point according to (\ref{calc_err}), where
interval arithmetic is used for calculating . Only standard
precision is needed for calculating the error bounds.
Implementing this improved
algorithm using MPFR and MPFI, the setting as given in the interval case
produces the following result. 
In the parameter range , the dynamic behavior is reflected very
well. Furthermore, in the range , the curve suggests
a relation between the loss of significance rate and the Ljapunow
exponent  for the logistic map (for a curve of the Ljapunow
exponent of the logistic map see \cite{ce80}):
 for all . To be
complete, the definition of the Ljapunow exponent reads
\begin{definition}
\label{def:ljap}
Let  be a dynamical system,  compact and 
continuously differentiable on the interior of . Then the
{\em Ljapunow exponent} at  is defined by

if the limit exists.
\end{definition}
The Ljapunow exponent may depend on . However, the following
properties hold:
\begin{itemize}
\item[(a)]
If  has an {\em invariant measure} , then the limit in
Equation \ref{ljap_def} exists -almost everywhere.
\item[(b)]
Furthermore, if  is {\em ergodic} then 
is -almost everywhere constant and equal to

\end{itemize}
These properties are a direct consequence of the Birkhoff ergodic theorem,
see \cite{kh95}, Theorem 4.1.2 and Corollary 4.1.9.


\section{The General Algorithm and its Complexity}
Let  be a compact real interval and  a self mapping. In the following,
 is assumed to be continuous on , continuously differentiable on the interior
of  and  is bounded. Furthermore,  and  are assumed to be
computationally feasible. The precise definition of ``computationally feasible''
is given below.

In this section, a general algorithm for computing the iteration

is presented. To be more precise, for given  and ,
this algorithm computes a finite part of the orbit,
, exact in the sense that the relative
error at each point  does not exceed .
The correctness of the algorithm and its computational feasibility is shown.
Finally, its complexity is examined.


\subsection{Syntax, Semantics and the Algorithm}
The set of all computationally accessible real numbers are the floating
point numbers of arbitrary mantissa length denoted by .
In the following, by a floating point number any real number
is meant which can be expressed by normalized scientific notation.
Hence, the set  of all floating point 
numbers is countable infinite and therefore a natural basis for standard
computability considerations. Let  be some floating
point number, then  has as an essential property, its
{\em mantissa length} denoted by .
Any real number  is represented in an algorithm concerning real
computation by a pair  consisting of a floating
point number  approximating  and an upper bound on the
relative error, , also being a floating point number.
Furthermore, the inequality  holds. The pair
 is called a {\em finite precision representation} of .
Although  has the property mantissa length, it is irrelevant
in what follows. So, the mantissa length of  can be assumed
to be some big enough constant value. Analogously, a function ,
, is called {\em computationally feasible} if a pair
 exists of a computable (partial) function 
approximating  on  and a computable (partial) function
 giving an upper bound on the
absolute error of  in the sense
. Here, a partial function
 is called {\em computable}
if  is computable as a string function over some finite
alphabet where the floating point numbers are interpreted as
finite strings. Finally, computability over integers, computability
of functions with mixed arguments and computable predicates are
defined in a standard way.

The algorithm with the above described specification reads
\begin{tabbing}
{\tt\ 1}\ \= {\tt Input parameter:} , , \\
{\tt\ 2}\> {\tt Initialize mantissa length} \\
{\tt\ 3}\> {\tt do} \= \ \\
{\tt\ 4}\> \> {\tt Initialize value and error} \\
{\tt\ 5}\> \> {\tt for} \=  to  {\tt do}\\
{\tt\ 6}\> \> \> {\tt If} \=  {\tt is {\bf true} then}\\
{\tt\ 7}\> \> \> \> {\tt If not printed print } , ,  \\
{\tt\ 8}\> \> \> {\tt else break}\\
{\tt\ 9}\> \> \> \\
{\tt 10}\> \> {\tt end for}\\
{\tt 11}\> \> \\
{\tt 12}\> {\tt while}  {\tt is false}
\end{tabbing}
To initialize , a rounding function
 is needed where 
is a floating point number of mantissa length  being
the exactly rounded value of  to some rounding convention.
Clearly,  is an upper bound on the absolute
rounding error, e.g.\  if
the rounding mode is to nearest. The predicate

is a test whether the relative error of ,
 if , is bounded by . The
semantics reads: If  is a finite precision
representation of  and 
holds, then  follows.

In the following, some abbreviations are used occasionally.
The floating point numbers and functions are indicated by a
hat: 
and . An over-bar indicates an error bound:
 and . Hence,
 is equivalent to  and 
is equivalent to .

Finally a remark on optimization. The algorithm
is not optimized in the performance. Otherwise, in Line {\tt 10}
something like  should be used. Here, the aim is to
find the minimal  to guarantee some given upper bound on the
relative error of .


\subsection{Feasibility and Correctness}
It is clear, that the rounding function  is computationally
feasible. So lets begin with the predicate .
\begin{proposition}
The computationally feasible formula

fulfills the above described semantics.
\end{proposition}
\begin{proof}
Let  be a finite precision
representation of . So, if 
holds, then also  holds.
If , then
 holds. Hence, if
 and
 holds,
then also . Finally, if

holds, then also
.

Formula \ref{alg:prec} only uses the accessible floating point
values  and , basic arithmetics and
finite tests. Hence, this formula is computationally feasible.
\end{proof}
Note that the definition of the predicate this way
also gives  in the singular case where 
and  and hence .

An algorithm for computing  is by assumption possible.
To derive an algorithm for computing  on the absolute
error, return to Equations \ref{main_err} and \ref{calc_err}.
\begin{proposition}
\label{prop:ubound}
Assume that  computes  up to
a correctly rounded last bit in mantissa according to rounding convention.
Then there exists a constant  such that the absolute error of
 of the computation  is bounded from above by

if . Here,
 and  is the mantissa length of : .

Furthermore, this bound is computable.
\end{proposition}
\begin{proof}
Using Equation \ref{main_err} and following the calculations leading to
equation \ref{calc_err},
 follows. According to the assumption
on ,
 holds, with
a value  depending on the rounding convention. However,
 is unknown, only  is accessible.
To overcome this, set 
with . Since  holds, resolve to
. Hence,

follows. Since an upper bound on  can be
computed using global optimization techniques, e.g.\ with interval
arithmetic, the above described bound is computable.
\end{proof}

To summarize, the mathematical iteration (\ref{main_it}) is performed
in the algorithm by iterating a value  approximating 
with an upper bound on its absolute error  according to

where  is computable
upper bound on  as described in the
preceding proposition.
This is Line {\tt 9} in the inner {\tt for}-loop of the algorithm
which is executed with successively increasing mantissa length ,
controlled by the outer {\tt do-while}-loop. Finally, it has to
be shown that this outer loop eventually terminates. Therefore,
two more propositions are needed.
\begin{proposition}
Let  be a real number and 
a sequence of finite precision representations of  with
increasing mantissa length  such that
 holds and consequently
. Then
 follows for
all .
\end{proposition}
\begin{proof}
Since  there
exists some  such that 
and  holds for all
. Then,  holds for all
.
\end{proof}
The next proposition makes the link to Line {\tt 9}
in the algorithm.
\begin{proposition}
\label{prop:alg_halt}
Let  be the -th element of the orbit of Equation
\ref{main_it} and  a sequence given
according to  the recursion equations (\ref{comp_rec1}) and
(\ref{comp_rec2}) with increasing mantissa length
. Then
 holds and consequently
.
\end{proposition}
\begin{proof}
Let   and  be some computationally
accessible value using some global optimization technique. Then
Equation \ref{comp_rec2} leads to 
 where
 such that
 holds for all .
Iteration gives
.
Hence, for  fixed,  follows.
\end{proof}
These two propositions finish the correctness proof of the
algorithm. They show that, if  for ,
the outer loop eventually terminates for any .


\subsection{Computational Complexity}
After having presented the preliminary work, the main issue of the
paper is addressed - the computational complexity of the presented
algorithm. The complexity measure of interest here is the loss of
significance rate already introduced informally in the last section.
Here is the formal definition.
\begin{definition}
\label{def:losr}
The minimal mantissa length, for which the described algorithm
eventually halts is denoted by , where , 
and  are the corresponding input parameters. Then, the
{\em loss of significance rate}
 is defined by

\end{definition}
However, to achieve bounds on the loss of significance rate,
a technical difficulty has to be
circumvented. Therefore, one more assumption on the dynamical system
, additional to the ones already mentioned in the beginning
of this section, has to be made.
\begin{assumption}
\label{ass:main}
The dynamical system  is assumed to have the properties
already mentioned in the beginning of this section and
additionally .
\end{assumption}
It was already seen in the last subsection that 
makes difficulties such that it cannot be proven that
the algorithm eventually halts. However,
the restriction  is no loss of generality. If all
other conditions are fulfilled except that 
contains zero, consider the following dynamical system
 instead. Choose some  and
set  as well as
 for all . Then
 fulfills all required properties.
Furthermore  holds and therefore there
is no substantial difference in the complexity analysis of the
algorithm between the original system and the modified system.

First, the boundedness of  is shown.
\begin{proposition}
Let  be as in Assumption \ref{ass:main} and 
as in Definition \ref{def:losr}. Then, for given , there exist
some , dependent of , such that
 holds for all
, .
\end{proposition}
\begin{proof}
According to the requirements made on , there are some constants
 and  such that

holds for all  and all mantissa lengths . Without loss
of generality assume , otherwise set .
Analogous to the treatment in the proof of Proposition
\ref{prop:alg_halt}, iteration gives 
.
Since there exists some  with  for all ,

follows with  where  is the initial
mantissa length, Line {\tt 2} in the algorithm. Then, if
 holds,
 for all
. This leads to
.
\end{proof}
\begin{corollary}
Let  be as in Assumption \ref{ass:main} and  the loss
of significance rate. Then, for given , there exists some
constant  such that  holds for all
.
\end{corollary}
The treatment has now come to a stage that the main statements of
this paper can be formulated. A lower and an upper bound for the
loss of significance rate is given. Furthermore, these bounds
are strongly related to the Ljapunow exponent  defined
in the previous section.
\begin{theorem}
\label{thm:main}
Let  be as in Assumption \ref{ass:main},  the loss
of significance rate and  the Ljapunow exponent of
. Then  holds for all
,  if  exists.
\end{theorem}
\begin{proof}
First there are two constants  such that 
and  holds for all .
According to Equation \ref{comp_rec2} and Proposition
\ref{prop:ubound}, 
holds. Iteration gives
.
Hence,  follows.
A necessary condition for the algorithm to terminate is therefore
 which gives
. Following the definitions of the loss of significance rate
and the Ljapunow exponent,  follows.
\end{proof}

Before a realistic upper bound on the loss of significance rate
can be presented, one more definition is needed.
\begin{definition}
Let  then define a function  by

Furthermore, for any  define

\end{definition}
\begin{proposition}
For all  there exists some constant 
such that 
holds for all . Furthermore, if the Ljapunow
exponent  exists,
 holds.
\end{proposition}
\begin{proof}
Let  be the Lipschitz constant of  and .
Then for all ,
 holds. Hence it follows
.
The second assertion follows from the
fact that  holds for all ,
. 
\end{proof}
\begin{proposition}
Let  be given. If  exists, then
also the limit

exists and .
\end{proposition}
\begin{proof}
Since  holds
for all , , also
 follows. So if 
converges in a monotonic decreasing way to ,
, the assertion follows.

\end{proof}
\begin{theorem}
\label{thm:ubnd}
Let  be as in Assumption \ref{ass:main},  the loss
of significance rate and  as in
(\ref{ljap_sup}). Let  be given, then for any
 there is some  such that for all ,
 holds
if  exists.
\end{theorem}
The proof is similar to the proof of Theorem \ref{thm:main}
and can be found in the full version of this article \cite{sp10}.

\section{Conclusions}
In this paper, two main issues are addressed. First it is
shown that a mathematically precise treatment
of multiple-precision floating point computability is not hard
to do. Furthermore this
treatment is in a manner which is familiar to people working
in the field of numerical analysis or scientific computing and
also for theoretical computer scientists. Furthermore, the
formalism does not only allow exact answers concerning the
existence of a computationally feasible algorithm, but is also
allows a treatment of its complexity. As a consequence, the
described algorithm is formulated not only in an exact and
guaranteed way, but also enables a motivated reader the real
implementation and gives a practical performance analysis.

Second, the results show that the Ljapunow exponent, a central
quantity in dynamical systems theory, also finds its way into
complexity theory, a branch in theoretical computer science.
In dynamical systems theory, the Ljapunow exponent describes
the rate of divergence of initially infinitesimal nearby
points. For two points having a small but finite initial
separation, the Ljapunow exponent has only relevance for
short time scales \cite{ce06}. The reason is that due to the
boundedness of , any two different orbits cannot separate
arbitrarily far away. However, the loss of significance rate
shows that the Ljapunow exponent has on long time scales
not only an asymptotic significance but also a concrete
practical one.


\subsection*{Acknowledgments}

The author wishes to express his gratitude to Peter Hertling for helpful
discussions and comments.


\bibliographystyle{eptcs}

\begin{thebibliography}{10}
\providecommand{\bibitemstart}[1]{\bibitem{#1}}
\providecommand{\bibitemend}{}
\providecommand{\bibliographystart}{}
\providecommand{\bibliographyend}{}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{Available at }
\providecommand{\bibinfo}[2]{#2}
\bibliographystart

\bibitemstart{ah83}
\bibinfo{author}{G\"{o}tz Alefeld} \& \bibinfo{author}{J\"{u}rgen Herzberger}
  (\bibinfo{year}{1983}): \emph{\bibinfo{title}{Introduction to Interval
  Computations}}.
\newblock \bibinfo{publisher}{Academic Press}, \bibinfo{address}{New York}.
\bibitemend

\bibitemstart{Bla05}
\bibinfo{author}{Jens Blanck} (\bibinfo{year}{2005}):
  \emph{\bibinfo{title}{Efficient exact computation of iterated maps}}.
\newblock {\sl \bibinfo{journal}{The Journal of Logic and Algebraic
  Programming}} \bibinfo{volume}{64}, pp. \bibinfo{pages}{41--59}.
\bibitemend

\bibitemstart{bl06}
\bibinfo{author}{Jens Blanck} (\bibinfo{year}{2006}):
  \emph{\bibinfo{title}{Exacr real arithmetic using centred intervals and
  bounded error terms}}.
\newblock {\sl \bibinfo{journal}{The Journal of Logic and Algebraic
  Programming}} \bibinfo{volume}{66}, pp. \bibinfo{pages}{50--67}.
\bibitemend

\bibitemstart{BH98}
\bibinfo{author}{Vasco Brattka} \& \bibinfo{author}{Peter Hertling}
  (\bibinfo{year}{1998}): \emph{\bibinfo{title}{Feasible real random access
  machines}}.
\newblock {\sl \bibinfo{journal}{Journal of Complexity}}
  \bibinfo{volume}{14}(\bibinfo{number}{4}), pp. \bibinfo{pages}{490--526}.
\bibitemend

\bibitemstart{ce80}
\bibinfo{author}{Pierre Collet} \& \bibinfo{author}{Jean-Pierre Eckmann}
  (\bibinfo{year}{1980}): \emph{\bibinfo{title}{Iterated Maps on the Interval
  as Dynamical Systems}}.
\newblock \bibinfo{series}{Progress in Physics}.
  \bibinfo{publisher}{Birkh\"{a}user}, \bibinfo{address}{Boston,
  Massachusetts}.
\bibitemend

\bibitemstart{ce06}
\bibinfo{author}{Pierre Collet} \& \bibinfo{author}{Jean-Pierre Eckmann}
  (\bibinfo{year}{2006}): \emph{\bibinfo{title}{Concepts and Results in Chaotic
  Dynamics}}.
\newblock \bibinfo{series}{Theoretical and Mathematical Physics}.
  \bibinfo{publisher}{Springer-Verlag}, \bibinfo{address}{Berlin, Heidelberg}.
\bibitemend

\bibitemstart{de89}
\bibinfo{author}{Robert~L. Devaney} (\bibinfo{year}{1989}):
  \emph{\bibinfo{title}{An Introduction to Chaotic Dynamical Systems}}.
\newblock \bibinfo{publisher}{Addison-Wesley}, \bibinfo{address}{Redwood City,
  California}, \bibinfo{edition}{2nd} edition.
\bibitemend

\bibitemstart{Fousse:2007:MMP}
\bibinfo{author}{Laurent Fousse}, \bibinfo{author}{Guillaume Hanrot},
  \bibinfo{author}{Vincent Lef\`evre}, \bibinfo{author}{Patrick P\'elissier} \&
  \bibinfo{author}{Paul Zimmermann} (\bibinfo{year}{2007}):
  \emph{\bibinfo{title}{{MPFR}: A Multiple-Precision Binary Floating-Point
  Library with Correct Rounding}}.
\newblock {\sl \bibinfo{journal}{{ACM} Transactions on Mathematical Software}}
  \bibinfo{volume}{33}(\bibinfo{number}{2}), pp. \bibinfo{pages}{13:1--13:15}.
\newblock \urlprefix\url{http://doi.acm.org/10.1145/1236463.1236468}.
\bibitemend

\bibitemstart{hsd04}
\bibinfo{author}{Morris~W. Hirsch}, \bibinfo{author}{Stephen Smale} \&
  \bibinfo{author}{Robert~L. Devaney} (\bibinfo{year}{2004}):
  \emph{\bibinfo{title}{Differential Equations, Dynamical Systems and an
  Introduction to Chaos}}.
\newblock \bibinfo{publisher}{Elsevier Academic Press},
  \bibinfo{address}{Amsterdam}.
\bibitemend

\bibitemstart{ieee87}
\bibinfo{author}{{IEEE~1987}} (\bibinfo{year}{1987}):
  \emph{\bibinfo{title}{{IEEE} Standard 754-1985 for Binary Floating-Point
  Arithmetic}}.
\newblock \bibinfo{publisher}{IEEE}, \bibinfo{address}{New York}.
\bibitemend

\bibitemstart{kh95}
\bibinfo{author}{Anatole Katok} \& \bibinfo{author}{Boris Hasselblatt}
  (\bibinfo{year}{1995}): \emph{\bibinfo{title}{Introduction to the Modern
  Theory of Dynamical Systems}}.
\newblock \bibinfo{publisher}{Cambridge University Press},
  \bibinfo{address}{Cambridge New York Melbourne}.
\bibitemend

\bibitemstart{Mue01}
\bibinfo{author}{Norbert~Th. M{\"u}ller} (\bibinfo{year}{2001}):
  \emph{\bibinfo{title}{The {iRRAM}: Exact Arithmetic in {C}++}}.
\newblock In: \bibinfo{editor}{Jens Blanck}, \bibinfo{editor}{Vasco Brattka} \&
  \bibinfo{editor}{Peter Hertling}, editors: {\sl
  \bibinfo{booktitle}{Computability and Complexity in Analysis}}, {\sl
  \bibinfo{series}{Lecture Notes in Computer Science}} \bibinfo{volume}{2064},
  \bibinfo{publisher}{Springer}, \bibinfo{address}{Berlin}, pp.
  \bibinfo{pages}{222--252}.
\newblock \bibinfo{note}{4th International Workshop, CCA 2000, Swansea, UK,
  September 2000}.
\bibitemend

\bibitemstart{mu10}
\bibinfo{author}{Norbert~Th. M{\"u}ller}:
  \bibinfo{title}{Private communication}.
  \newblock \bibinfo{note}{See also the tutorial at
  \url{http://www.cc.kyoto-su.ac.jp/~yasugi/page/Kakenhi/mueller.pdf}}.
\bibitemend

\bibitemstart{rr84}
\bibinfo{author}{Helmut Ratschek} \& \bibinfo{author}{Jon Rokne}
  (\bibinfo{year}{1984}): \emph{\bibinfo{title}{Computer Methods for the Range
  of Functions}}.
\newblock \bibinfo{publisher}{Ellis Horwood Limited},
  \bibinfo{address}{Chichester}.
\bibitemend

\bibitemstart{ReRo02}
\bibinfo{author}{N.~Revol} \& \bibinfo{author}{F.~Rouillier}
  (\bibinfo{year}{2005}): \emph{\bibinfo{title}{{Motivations for an Arbitrary
  Precision Interval Arithmetic and the MPFI Library}}}.
\newblock {\sl \bibinfo{journal}{Reliable Computing}}
  \bibinfo{volume}{11}(\bibinfo{number}{4}), pp. \bibinfo{pages}{275--290}.
\bibitemend

\bibitemstart{wh00}
\bibinfo{author}{Klaus Weihrauch} (\bibinfo{year}{2000}):
  \emph{\bibinfo{title}{Computable Analysis}}.
\newblock \bibinfo{publisher}{Springer-Verlag}, \bibinfo{address}{Berlin
  Heidelberg New York}.
\bibitemend

\bibitemstart{wi63}
\bibinfo{author}{James~H. Wilkinson} (\bibinfo{year}{1963}):
  \emph{\bibinfo{title}{Rounding Errors in Algebraic Processes}}.
\newblock \bibinfo{publisher}{Prentice-Hall}, \bibinfo{address}{Englewood
  Cliffs, N.J.}
\bibitemend

\bibitemstart{sp10}
\newblock \urlprefix\url{http://arxiv.org/abs/1003.6036}.
\bibitemend

\bibliographyend
\end{thebibliography}


\end{document}