\documentclass[10pt,jounral]{IEEEtran}

\usepackage{graphics,
           psfrag,
           epsfig,
           amsmath,
           amsthm,
           cite,
           amssymb,
           url,
           dsfont,
algorithm,
           algorithmic,
           balance,
           enumerate,
           color,
           setspace,
           multirow,
           caption,
           subcaption,
           comment
}


\newtheorem{example}{Example}
\newtheorem{definition}{Definition}
\newtheorem{problem}{Problem}
\newtheorem{lemma}{Lemma}
\newtheorem{observation}{Observation}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{argument}{Argument}
\newtheorem{result}{Result}
\newtheorem{note}{Note}
\newtheorem{claim}{Claim}
\newtheorem{fact}{Fact}
\newtheorem{property}{Property}


\newcommand{\eref}[1]{(\ref{#1})}
\newcommand{\sref}[1]{Section~\ref{#1}}
\newcommand{\appref}[1]{Appendix~\ref{#1}}
\newcommand{\fref}[1]{Figure~\ref{#1}}
\newcommand{\dref}[1]{Definition~\ref{#1}}
\newcommand{\pref}[1]{Proposition~\ref{#1}}
\newcommand{\cref}[1]{Constraint~\ref{#1}}
\newcommand{\thref}[1]{Theorem~\ref{#1}}
\newcommand{\lref}[1]{Lemma~\ref{#1}}
\newcommand{\tref}[1]{Table~\ref{#1}}
\newcommand{\Fref}[1]{Fig.~\ref{#1}}
\newcommand{\algref}[1]{Algorithm~\ref{#1}}

\hyphenation{op-tical net-works semi-conduc-tor}

\def\define{\stackrel{\mbox{\tiny{}}}{=}}
\newcommand{\ignore}[1]{}

\newcommand{\bmu}{\mbox{\boldmath}}
\newcommand{\bsigma}{\mbox{\boldmath}}

\epsfxsize=3.0in
\pagestyle{plain}\IEEEoverridecommandlockouts




\begin{document}
\includecomment{doublecol}\excludecomment{singlecol} 

\title{Partially Blind Instantly Decodable Network Codes for Lossy Feedback Environment}
\author{Sameh~Sorour,~\IEEEmembership{Member,~IEEE,} Ahmed~Douik,~\IEEEmembership{Student Member,~IEEE,}
        Shahrokh~Valaee,~\IEEEmembership{Senior Member,~IEEE}, Tareq~Y.~Al-Naffouri,~\IEEEmembership{Senior Member,~IEEE} Mohamed-Slim~Alouini,~\IEEEmembership{Fellow,~IEEE}
\thanks{Sameh Sorour and Mohamed-Slim Alouini are with the Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Makkah Province, Saudi Arabia, email:@kaust.edu.sa}
\thanks{Ahmed Douik is with both Tunisia Polytechnic School (TPS), Tunisia, and the CEMSE Division at King Abdullah University of Science and Technology (KAUST), Thuwal, Makkah Province, Saudi Arabia, email: ahmed.douik@kaust.edu.sa}
\thanks{Shahrokh Valaee is with the Edward S. Rogers Sr. Department of Electrical and Computer Engineering,
    University of Toronto, Canada, e-mail: valaee@comm.utoronto.ca.}
    \thanks{Tareq Y. Alnaffouri is with both the CEMSE Division at King Abdullah University of Science and Technology (KAUST), Thuwal, Makkah Province, Saudi Arabia, and the Electrial Engineering Department at King Fahd University of Petroleum and Minerals (KFUPM), Dhahran, Eastern Province, Saudi Arabia, e-mail: tareq.alnaffouri@kaust.edu.sa.}
    \thanks{This work is an extension to the first and third authors' paper \cite{PIMRC11}, published in the IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC), September 2011.}
     }

\maketitle

\IEEEoverridecommandlockouts


\begin{abstract}
In this paper, we study the multicast completion and decoding delay minimization problems of instantly decodable network coding (IDNC) in the case of lossy feedback. In such environments, the sender falls into uncertainties about packet reception at the different receivers, which forces it to perform partially blind selections of packet combinations in subsequent transmissions. To determine efficient partially blind policies that handle the completion and decoding delays of IDNC in such environment, we first extend the perfect feedback formulation in \cite{GC10,TON10-CD} to the lossy feedback environment, by incorporating the uncertainties resulting from unheard feedback events in these formulations. For the completion delay problem, we use this formulation to identify the maximum likelihood state of the network in events of unheard feedback, and employ it to design a partially blind graph update extension to the multicast IDNC algorithm in \cite{TON10-CD}. For the decoding delay problem, we derive an expression for the expected decoding delay increment for any arbitrary transmission. This expression is then used to derive the optimal policy to reduce the decoding delay in such lossy feedback environment. Results show that our proposed solution both outperforms other approaches and achieves a tolerable degradation even at relatively high feedback loss rates.
\end{abstract}
\ignore{\begin{keywords}
Wireless Multicast, Instantly Decodable Network Coding; Lossy Feedback.
\end{keywords}}





\section{Introduction}
\IEEEPARstart{N}{etwork} coding (NC) has shown great abilities to substantially improve transmission efficiency, throughput and delay over broadcast erasure channels \cite{4895447,4476183,Drinea2009,4397057,5152148}. In \cite{ICC10,Sadeghi2010,5425315,GC10,Li2011,6030131}, an important sub-class of opportunistic NC was studied, namely the \emph{instantly decodable network coding (IDNC)}, in which received packets are allowed to be decoded only at their reception instant and cannot be stored for future decoding. IDNC was considered in these works due to its practicality and numerous desirable properties, such as instant packet recovery, simple XOR-based packet encoding and decoding, and no additional buffer to store un-decoded packets. According to its definition, the sender must select a network coded packet combination in each transmission, such that a selected subset of the receivers (or all of them if possible) can decode a new source packet once they receive this coded packet. The selection of the appropriate packet combinations, which are instantly decodable at specific sets or all the receivers, is done through what is known as the \emph{IDNC graph} \cite{ISIT09,ICC10,GC10,TON10-CD,6030131}.

The problem of minimizing the completion delay for IDNC was considered in \cite{ICC10,TON10-CD} for wireless networks with erasure channels on the forward links from the sender to the receivers. This problem was formulated as a stochastic shortest path (SSP) problem, which turned out to be very complex to solve in real-time. Nonetheless, the analysis of the properties and structure of this SSP was employed to design simple maximum weight clique search algorithms minimizing completion delay in IDNC. The designed algorithms were shown to almost achieve the optimal completion delay in wireless multicast and broadcast scenarios. In \cite{GC10}, the \emph{decoding delay} minimization problem in IDNC was considered for the same environment. In this work, an expression for the \emph{decoding delay} increments for any arbitrary IDNC transmission was derived and used to minimize the IDNC decoding delay, again using simple maximum weight clique search algorithms.

Nonetheless, the proposed algorithms in \cite{ICC10,TON10-CD,GC10}, and most other opportunistic network coding works, assume perfect feedback (PF) (i.e feedback from all the receivers always arrives at the sender and is not subject to loss). This assumption is not always practical in wireless networks, which suffer from similar wireless channel impairments on both the forward and reverse links. Consequently, even if a high level of protection for feedback packets can be employed in several network settings, such as cellular, WiFi and WiMAX systems, unavoidable occasions of deep fading over wireless channels can still expose them to loss events. Moreover, other network settings cannot guarantee the arrival of each feedback packet at the sender due to transmission power limitations and possible interference with other feedback.

In such lossy feedback scenarios, the sender may not receive feedback from a subset of the targeted receivers after any given transmission, due to erasure occasions on their reverse links. In this case, the reception status for this packet at these receivers becomes uncertain. For each of these receivers, the sender cannot determine whether its sent packet was lost on the forward link of this receiver or the feedback was lost on its reverse link. Despite this uncertainty, the sender is still required to perform subsequent IDNC transmissions, and thus must blindly estimate the status of all such receivers. In subsequent transmissions, the sender may receive feedback packets from some of these uncertain receivers but may not hear the feedback from others. Consequently, the sender may need to perform partially blind IDNC decisions in many transmissions until a completion feedback is received from all the receivers.


In this paper, we address the following question: \emph{How to perform partially blind selections of IDNC packet combinations to minimize the IDNC completion and decoding delays in lossy feedback (LF) scenarios?} To answer this question, we need to extend our formulations, derivations and proposed algorithms in \cite{ICC10,TON10-CD,GC10} by incorporating in them the uncertainties resulting from unheard feedback events. For the completion delay problem, we extend our SSP formulation for the perfect feedback scenario in \cite{TON10-CD} to a partially observable stochastic shortest path (POSSP) problem \cite{Patek99onpartially} in the lossy feedback environment. From this extended formulation, we derive the maximum likelihood estimate of the network state in case of unheard feedback events from one or multiple receivers. We then propose a partially blind IDNC algorithm that makes coding decisions\ignore{ as in \cite{TON10-CD},} after performing partially blind updates on the IDNC graph to follow the maximum likelihood state of the network. For the decoding delay problem, we derive the expected decoding delay increments for any arbitrary transmission in the presence of reception uncertainties. This derived expression is then used to define the new policy for decoding delay minimization in lossy feedback environment. Using extensive simulations, we compare the proposed algorithm with the several other approaches available in the literature.

The rest of the paper is organized as follows. In \sref{sec:model}, we introduce the system model
and parameters. The IDNC graph is illustrated in \sref{sec:IDNC-graph}. In \sref{sec:CD-extension}, we present the POSSP extension of the PF SSP formulation in the lossy feedback environment, derive the maximum belief state (i.e. maximum likelihood state) of the network state, and propose a partially blind IDNC algorithm to solve the completion delay problem in lossy feedback environments. In \sref{sec:DD-extension}, the expected decoding delay increments of any transmission is derived for the lossy feedback environment and is used to design a partially blind algorithm to minimize the decoding delay. The performance of the proposed algorithms is compared with several algorithms in the literature in \sref{sec:simulations}. Finally, \sref{sec:conclusion} concludes the paper.



\section{System Model and Parameters} \label{sec:model}
The system model consists of a wireless sender having a frame (denoted by ) of  source packets. Each receiver in the set (denoted by ) of  receivers is interested in receiving a subset of . We will refer to the requested and undesired packets by any receiver as its ``primary'' and ``secondary'' packets, respectively. The sender initially broadcasts the  packets uncoded over erasure channels to the  receivers. Each receiver listens to all the transmitted packets (even the ones that it does not want) and feeds back to the sender a positive acknowledgement (ACK) for each received (non-erased) packet and a negative acknowledgement (NACK) for each erased packet. These feedback packets are also subject to erasure on the reverse channels. We will refer to the packets, for which the sender did not receive a feedback from a given receiver, by the ``uncertain'' packets of that receiver. At the end of this initial transmission phase, the sender can attribute four feedback sets of packets to each receiver :
\begin{itemize}
\item The \emph{Has} set (denoted by ) is defined as the set of primary and secondary packets correctly received by receiver  and its feedback was successfully received by the sender.\ignore{ This set includes both desired and undesired packets by this receiver.}
\item The \emph{Lacks} set (denoted by ) is defined as the set of primary and secondary packets that were either acknowledged by a NACK to the sender by receiver  or are uncertain. In other words, .
\item The \emph{Wants} set (denoted by ) is defined as the subset of primary packets in  (i.e. packets in  that receiver  wants to receive).
\item The Uncertain set (denoted by  is defined as the subset of uncertain packets in .
\end{itemize}
The sender stores this information in a \emph{state feedback matrix (SFM)} , such that:

In the recovery phase, the sender exploits these feedback sets to transmit network coded packets, which consist of a binary XOR of a subset or all the source packets in . Each of these transmitted coded packets can be one of the following three options for each receiver :
\begin{itemize}
\item \emph{Non-Innovative}: A packet is non-innovative for receiver  if it does not contain any source packet that is both wanted by  and was not received by it in any previous transmission.
\item \emph{Instantly Decodable}: A packet is instantly decodable for receiver  if it contains \emph{only one source packet} that was not received by it in any previous transmission.
\item \emph{Non-Instantly Decodable}: A packet is non-instantly decodable for receiver  if it contains {two or more source packets} that were not previously received by it in any previous transmission..
\end{itemize}
The receivers for which the packet sent by the sender is instantly decodable are called \emph{targeted receivers}. The receivers that receive non-innovative and non-instantly decodable packets discard them and do not send any acknowledgements. On the other hand, the receivers that receive instantly decodable packets feed back an ACK packet to the sender with all their received packets. This process is repeated until all receivers obtain all their requested packets and the sender receives a completion feedback acknowledgement from all the receivers (i.e. a feedback from every receiver showing that it received all its requested packets). To be fair in comparison with the original perfect feedback formulation and algorithms in \cite{ICC10,TON10-CD}, in terms of feedback frequency, we will assume that a receiver does not send any feedback unless it is targeted by a packet.

Let  and  be the data packet erasure and success probabilities, respectively, observed by receiver  on the forward link within a frame of packets. Also, let  be the feedback erasure probability observed by receiver  on the reverse link. It is fair to assume that  due to the larger size of data packets compared to feedback packets, the stronger protection usually employed for control packets, and the stronger interference levels and fading levels experienced by the receivers (especially those at cell edges) compared to the sender. Also, let  be the demand ratio of receiver , defined as the ratio of its primary packets in the frame to the total frame size . Finally, define  as the average demand ratio of all receivers.

Finally, we define the completion and decoding delays as follows:
\begin{definition}[Completion Delay]
The completion delay of a frame is the number of recovery transmissions required until all receivers obtain all their requested packets.
\end{definition}
\begin{definition}[Decoding Delay]
For any transmission in recovery phase, a receiver , with non-empty Wants set, experiences one unit increase of \emph{decoding delay} if it successfully receives a packet that does not allow it to decode a non-previously received source packet in its Wants set. In other words, a received packet at receiver  does not increase its decoding delay if and only if both following conditions are satisfied:
\begin{itemize}
\item This received packet is instantly decodable for that receiver.
\item The decodable source packet from this received packet is in its Wants set.
\end{itemize}
\end{definition}
Note that the definition of decoding delay does not count channel inflicted delays due to erasures (i.e. an erased packet at a receiver does not add to its decoding delay), but rather counts sender inflicted delays when its coding algorithm is not able to provide instantly-decodable packets to the different receivers.


\section{The IDNC Graph} \label{sec:IDNC-graph}
The IDNC graph provides a framework to determine all possible combinations of source packets that are instantly decodable for any subset or all the receivers. This graph  is constructed by first generating a vertex  in  for each packet , and for all receivers (i.e. . Two vertices  and  in  are adjacent if one of the following conditions is
true:
\begin{itemize}
\item C1: , i.e. the two vertices are induced by the loss of the same packet  by two different receivers  and .
\item C2:  and , i.e. the requested packet of each vertex is in the Has set of the receiver that induced the other vertex.
\end{itemize}
Consequently, each edge between two vertices  and  in the graph means that the source packets  and  can be simultaneously received/decoded at receivers  and , respectively, by sending either packet  if  or the coded packet  otherwise. This property extends from two adjacent vertices to every clique in the graph. A clique in a graph is a subset of this graph whose vertices are all adjacent to one another. Thus, each clique in   defines a packet combination that can instantly serve all the receivers inducing this clique's vertices. Since we are concerned with not missing an opportunity of serving any possible receivers in any transmission, we only consider maximal cliques (i.e. cliques that are not a subset of any larger cliques).

According to receivers' packet requests, we can classify the vertices of this graph into two layers:
\begin{itemize}
\item Primary graph : It includes all the vertices of each receiver , , which are in its Wants sets.
\item Secondary graph : It includes all the vertices of each receiver , , which are in its Lacks set but not in its Wants set.
\end{itemize}
\fref{fig:IDNC-graph} depicts an example of SFM and its corresponding two-layered IDNC graph.
\begin{figure}[t]
\centering
\includegraphics[width=0.55\linewidth]{IDNC-Graph}\\
  \caption{Example of a state feedback matrix and its corresponding IDNC graph. Each vertex denoted by the two digits  in the graph represents a 1 or -1 entry in the -th row and -th column of feedback matrix. The light and dark shaded boxes and vertices represent the requested (1 entries) and undesired packets (-1 entries), respectively.}\label{fig:IDNC-graph}
\end{figure}
Since the primary graph is the one that needs to be depleted by the sender (as it is the one that represents the receiver requests), the sender needs to mainly serve the packet combination represented by the best maximal clique  in the primary graph for any given transmission, without considering the secondary graph. Nonetheless, it can also benefit from the secondary graph to deliver undesired packets to non-targeted receivers by  (i.e. receivers not having vertices in ) in the same transmission, without violating the instant decodability condition of the primary maximal clique . Serving these packets can increase the coding opportunities of these receivers in subsequent transmissions. This step can be done by finding the best secondary maximal clique  from the connected secondary subgraph to the primary maximal clique .

Thus, the sender generates a packet combination for any given transmission by building the IDNC graph representing the SFM just before this transmission, and XORing all the packets identified by the vertices of the selected clique  from this IDNC graph. In the rest of the paper, by ``the transmission of '' we mean the transmission of the XOR of the packets identified from clique  in the IDNC graph.


\section{Completion Delay Problem} \label{sec:CD-extension}
In this section, we study the effect of having feedback loss probabilities on the formulation and solution of the completion delay problem in IDNC. We will start by presenting the formulation and solution for the perfect feedback environment and then extend them to the lossy feedback environment.

\subsection{SSP Formulation for Perfect Feedback Environment}\label{sec:perfect-formulation}
The minimum completion delay problem in perfect feedback scenario is formulated in \cite{ICC10,TON10-CD} as an SSP. It consists of a state space  representing all SFM possibilities from the start of the recovery phase until completion. The action space of each state consists of all packet combinations identified by its SFM's IDNC graph. Transition probabilities between states reflect the taken action (in our case the chosen clique for transmission) and the different erasure probabilities of target receivers. Finally, the cost of each action is one transmission.

In \cite{TON10-CD}, the properties of this intractable SSP were analyzed and it has been shown that the best strategy to reduce the completion delay is to give more priority to the receivers with the largest Wants sets and erasure probabilities. This can be done by assigning weights  ( is a biasing factor) to the vertices of each receiver  in the IDNC graph, then running maximum weight clique algorithms on the primary graph and then on the secondary graph.


\subsection{Lossy Feedback Extension: Belief State}\label{sec:lossy-formulation}
The difference between perfect and lossy environments is the uncertainties introduced at the sender due to unheard feedback occurrences. In perfect feedback environment, unheard feedback events at the sender from a targeted receiver make the sender certain that the sent packet was lost on the receiver's forward link. However, the lossy feedback environment adds the other possibility of packet reception on the receiver's forward link and the loss of the feedback on its reverse link. Each of these possibilities happens independently for each of the targeted receivers with unheard feedback. In this case, the sender cannot determine the exact SFM state of the network, and thus cannot accurately select the subsequent IDNC packet. This notion of uncertainty is illustrated in \fref{fig:LF-example}, depicting an example of the system in \fref{fig:IDNC-graph} after performing action .

\begin{figure}[t]
\centering
  \includegraphics[width=0.9\linewidth]{LF-example}
    \caption{Belief state after taking action  for the example of \fref{fig:IDNC-graph} and receiving no feedback from receivers 1 and 2. This results in the  entries in the top right matrix. Consequently, there exists four different possibilities for the actual state of the matrix shown in the four bottom matrices. Thus, there exists a non-zero probability that the actual state of the matrix is one of these four bottom matrices. The belief state consists of these probabilities.}\label{fig:LF-example}
\end{figure}


This resulting uncertainty converts the SSP formulation of the perfect feedback environment into a partially observable SSP (POSSP) problem \cite{Patek99onpartially}. This POSSP formulation of the lossy feedback scenario is an extension to the SSP of the perfect feedback scenario, by adding to it the POSSP's belief state. In a POSSP, the belief state  of an SFM  is defined as the probability distribution vector over the state space , where each element  denotes the probability that the system is in state . This POSSP belief state reflects all possible realizations of the entries  in the SFM, as shown in \fref{fig:LF-example}. Since each of these  entries arises at element  of the SFM when the sender targets receiver  with packet  in a coded recovery transmission and does not hear a feedback from it, it could be equal to  if  did not receive  or  otherwise. Consequently, the states with non-zero values in  are those representing all possible combinations of replacing each  entry of  by 0 (assuming it is received) or  (assuming it is not received). The number of such states is equal to .



\subsection{Maximum Likelihood State} \label{sec:belief}
Since the only difference between the perfect and lossy formulations is the uncertainty introduced by unheard feedback events, the same solution proposed in \sref{sec:perfect-formulation} can be adapted to solve the POSSP problem, if we can find a good estimate of the SFM (and thus the IDNC graph) in these events. In this stochastic partially observable domain, the best state estimate of the SFM and the IDNC graph is the one representing the maximum likelihood (ML) state of the network, i.e. the state that has the highest probability in the belief state, defined as follows:


To derive the expression for this ML state, we define  and  as the sets of  entries in the -th row of the uncertain SFM  that need to be replaced by  and zeros, respectively, in order to reach a given realization  of state . Also, let  be the number of attempts (i.e. times) the sender targeted receiver  with packet  after the last time the sender heard a feedback from this receiver. Given these definitions, the following theorem introduces the expression for this ML state.
\begin{theorem}\label{th:ML}
The ML state of the network can be determined by the sender as:

where

\end{theorem}

\begin{proof}
As can be inferred from \eqref{eq:ML-rule}, we need to derive an expression for the different entries  (i.e. the probability distribution over the POSSP states) of the belief state in order to find the ML state of the network. Let  be the last timeslot at which the sender heard a feedback from receiver . Also, let   be the probability that an uncertain packet  of receiver  has been actually received (not received), given the event of unheard feedback from receiver  since time . Finally, define  as the actual hidden state of the network. Thus, we can express  as:
\begin{singlecol}

\end{singlecol}
\begin{doublecol}

\end{doublecol}

From \eqref{eq:belief-computation}, we can define  as the state satisfying the ML estimation, such that:

To find the state maximizing the right hand side, we need to derive expressions for  and . An unheard feedback occurrence from a targeted receiver  in any give transmission could mean one of the two following events:
\begin{enumerate}
\item Receiver  did not receive the packet and thus did not issue a feedback.
\item Receiver  received the packet and issued a feedback packet, which did not arrive at the sender.
\end{enumerate}
These events can occur with probabilities  and , respectively. Note that unheard feedback events are independent from each other even for the different attempts of the same packet to the same receiver. They are also independent from the transmitted packet to receiver  and independent from one receiver to another. Given the definition of  as the number of times the sender targeted receiver  with packet  after time , the probability that an  entry at position  of  is in fact  (i.e. packet  is actually not received at receiver ) is equal to the probability that this packet was lost on the forward channel for each of the  attempts. This happens with probability . On the other hand, this uncertain entry  will be 0 (i.e. packet  is actually received by receiver ) if this receiver has successfully decoded it in any one, several or all attempts out of the  attempts. This occurs with probability . Consequently, given  attempts of packet  to receiver  with no feedback from it on any of them,  and  can be expressed as:

\end{proof}

In case of reciprocal channels, in which , the ML expression can be simplified as defined by the following corollary.
\begin{corollary}\label{th:ML-reciprocal}
For reciprocal channels, the ML state of the network can be determined by the sender using \eqref{eq:ML}, where:

\end{corollary}
\begin{proof}
The proof can be easily obtained by a simple substitution of  in the analysis to derive \eqref{eq:ML-Loss} and \eqref{eq:ML-Receive}.
\end{proof}


\subsection{Complexity and Simple ML Rules}
The question now is whether the sender needs to compute  probabilities before each transmission in order to estimate the ML state of the network. The expressions in \eqref{eq:ML}, \eqref{eq:ML-individual} and \eqref{eq:ML-reciprocal-individual} in Theorem \ref{th:ML} and Corollary \ref{th:ML-reciprocal} show that the problem of estimating the ML state does not really need to go through all these computations after each transmission. These equations show that the independence of unheard feedback events for each receiver and between different receivers, as well as the independence of loss events on the forward and reverse channels, allow progressive computation of the ML state estimate of the network after each transmission as follows. When the sender experiences an unheard feedback event from receiver , after a given transmission targeting this receiver with packet , it can easily compute the individual ML state of this packet by computing . If this probability is larger than 0.5, then it can set the corresponding entry  to 1 or -1 (according to whether it is wanted or not by receiver , respectively). Otherwise, it sets  to zero. This update can be also simply done directly to the IDNC graph by keeping or eliminating the vertice  from the graph if  is larger or smaller that 0.5, respectively.

Once an estimate is made for the entry  and  after this transmission, their state need not be computed again for any subsequent transmission that does not involve them. In other words, if the sender does not target receiver  with packet  after this ML state estimate has been made, and if it did not receive any other feedback from this receiver, then it does not need to make any further estimates about this  entry. This allows the progressive construction of the ML state and avoids unnecessary computations for the entries and receivers with unchanged status.

In addition to the complexity of the above progressive ML state estimation after each transmission, the sender needs to store the variables , which require  entries in its memory. Finally note that, once a valid feedback is received from receiver , all its entries   can be updated in the SFM, its vertices can be eliminated or re-inserted in the graph accordingly, and the values of  of this receiver are all reset.


The following corollaries can be used to further simplify the computation of the ML estimates for the packets.

\begin{corollary}\label{th:ML-simple}
For any receiver , if any packet is attempted  times after time  (), the sender can set this packet as not received if:
 
 Otherwise, it can be set as received. For  (i.e. one attempt), the packet can directly be set as not received if \ignore{ } .
\end{corollary}
\begin{proof}
From \eqref{eq:ML-Loss}, the ML state of a packet that is attempted  times since  can be computed as follows:

In case of , the decision rule becomes:

If , then  and the corollary follows.
\end{proof}


\begin{corollary}\label{th:ML-simple-reciprocal}
For reciprocal channels, the sender can set all attempted packets with  for any receiver  as not received, regardless of the value of . For larger values of attempts (i.e. ) for any packet, it can be set as not received if:

and set as received otherwise.
\end{corollary}
\begin{proof}
The first statement follows directly from the fact that  is always greater than or equal to 0.5 for any value of . The second statement follows directly by setting  in \eqref{eq:MLbound}\ignore{ and re-arranging}.
\end{proof}

Clearly, the ML state estimation of the uncertain packets attempted only once requires no computations at all at the sender for both reciprocal channels and non-reciprocal channels with forward erasure probabilities larger than the reverse erasure probabilities (which is typically the case in wireless networks as explained earlier). For more than one attempt, we can see from both expressions in \eqref{eq:MLbound} and \eqref{eq:MLbound-receiprocal} that the left hand-side is a simple function of the erasure probabilities, which can be computed once per receiver. On the other hand, the right hand-side of both equations is a threshold function of  only. Thus, the sender can construct an offline table for all the values of \ignore{ } for the general or reciprocal case, indexed by the variable , and store it in its memory. When an unheard feedback event occur from receiver  for a given packet, the sender needs to compare the erasure probability function  (or ) in the general (or reciprocal) case to the entry in this table corresponding to the number of attempts of that packet, and determine the ML state estimate of this packet accordingly\ignore{to make the decision on updating the SFM and IDNC graph accordingly}.

Finally, it is important to note that the threshold function for both the non-reciprocal and reciprocal channel case is a monotonically decreasing function of . Hence, once the threshold function drops below the erasure probability function for a given packet attempted  times, which means that it is most likely to be received, the ML state for this uncertain packet will always remain the same for all future values of  as long as  and  are not changed. Consequently, once the sender makes an estimate that a packet is most likely to be received, this estimate will never change and thus the sender need not compute it any further for this packet.



\subsection{Partially Blind Algorithm based on ML Graph Updates} \label{sec:blind-update}
Having derived the ML decision rules, we can design our proposed partially blind algorithm to solve the completion delay problem in lossy feedback environment. When the sender has uncertain packets in its SFM, due to unheard feedback events, it can employ the above ML state estimation rules to update the IDNC graph as follows. If the packet  of vertex  is most likely to have been received at receiver  (according to the ML rule derived in the previous section), vertex  is made hidden inside the IDNC graph, which means that it is temporarily not considered for transmission. Otherwise it is kept in the graph as an active vertex considered for any subsequent transmission. To minimize the completion delay, the sender selects the IDNC packet for each transmission by applying the maximum weight clique approach described in \sref{sec:perfect-formulation} on this estimated graph.

The resulting hidden vertices of any given receiver are treated according to what happens later:
\begin{itemize}
\item If the sender receives a feedback from this receiver, it will know its actual state and can update the status of these hidden vertices. Vertices representing received packets are eliminated and those representing lost packets are brought back as active (i.e. non-hidden) vertices in the graph.
\item If a receiver has no more active vertices in the graph but still has hidden ones, all these vertices are brought back as active vertices and are re-attempted within subsequent IDNC packets until a feedback is received from this receiver.\ignore{ If later a feedback comes from this receiver, before all these re-activated vertices are attempted, their actual status is updated similar to the above case (i.e. removed if received and kept as active if lost).}
\end{itemize}

As clarified above, the proposed solution for the completion delay problem is a maximum weight clique problem over the ML estimate of the IDNC graph. However, it is well-known that the maximum weight clique problem is NP-hard to solve and approximate \cite{Garey1979,Ausiello1999}. Consequently, we propose to use the same heuristic algorithm proposed in \cite{ICC10,TON10-CD} to solve the completion delay problem\ignore{ in perfect feedback scenarios}. This algorithm consists of a maximum weight vertex search algorithm, with the difference that the weight  of each vertex  is modified to:

where  is the set of vertices in the graph that are adjacent to vertex . Consequently, these new weights reflect, not only the weight of the vertex, but also the weights of the vertices adjacent to it.\ignore{ This is done using the following procedure:} Thus, when these modified weights are employed, each iteration of the maximum weight vertex search algorithm will select the vertex that has both high initial weight and strong adjacency to high initial weight vertices, which was shown to achieve near optimal performance in \cite{TON10-CD}. The complexity of this algorithm has been proved to be  in \cite{TON10-CD}.



\section{Decoding Delay Problem} \label{sec:DD-extension}
In this section, we aim to study the effect of having feedback losses on the formulation of the decoding delay minimization problem in IDNC, and propose a new solution for this problem accordingly. As per its definition, the decoding delay increments occur after each transmission for the receivers that do not decode a new wanted packet from it. Consequently, we can derive an expression for the expected decoding delay increments in the presence of the uncertainties caused by unheard feedback occurrences, and then design a partially blind IDNC algorithm that minimizes this expression.\ignore{ Thus, we will start by deriving this expression in the next subsection.}

\subsection{Decoding Delay Expression in Lossy Feedback Environment}
Let  be the clique chosen for transmission at the current timeslot , and let  be the decoding delay increment experienced by receiver  after this transmission. We also define the following sets:
\begin{itemize}
\item  is the set of outstanding receivers that are perceived by the sender to have non-empty Wants sets,
\item  is the set of fully uncertain receivers, which includes any receiver  having . In other words, this set includes any receiver  that was targeted by the sender with all the packets remaining in its Wants set after time  (i.e. the last time a feedback was heard from it).
\item  is the set of receivers that are not targeted with a primary packet in .
\item  is the set of receivers that are targeted in  with a new primary packet (i.e an un-attempted primary packet after their last heard feedback).
\item  is the set of receivers that are targeted in  with one of their uncertain primary packets (i.e previously attempted primary packets after the last heard feedback from these receivers).
\end{itemize}
Let  be sum of all decoding delay increments of all receivers. Since only receivers in  may experience increments in decoding delay, we can write that . In the rest of this section, we only consider receivers in  in all derivations and formulae.

Defining  as the primary packet that receiver  can decode from the transmission of , the following theorem presents an expression for the expected sum decoding delay increments after this transmission.
\begin{theorem}\label{th:decoding-delay}
The expected sum decoding delay increment after the transmission of  at time  is:

\end{theorem}
\begin{proof}
Since any  in the definition of  can be only either 0 or 1, we have:
\begin{singlecol}

\end{singlecol}
\begin{doublecol}

\end{doublecol}
Consequently, to prove the theorem, we need to derive the probabilities of  for all the receivers in . According to the definition of decoding delay, and given the uncertainties arising from unheard feedback occurrences, any receiver , perceived by the sender as having a non-empty Wants set, can be classified into one of two sets (again as perceived by the sender):\\\textbf{Partially Uncertain Receivers}: \\
For any receiver  in this set, there exist some packets in its Wants set that have never been attempted after . For such receiver , we have the following possibilities:
\begin{itemize}
\item If this receiver , then it will have  if and only if it receives this transmission. Thus, we have:

\item If receiver  (i.e.  is targeted by a primary packet that has not been attempted after ), then  will never experience a decoding delay.
\item If receiver  (i.e.  is targeted by a primary packet that has been attempted after ), then receiver  will have  if and only if both following events are true:
\begin{itemize}
\item Receiver  receives the transmission, which occurs with probability .
\item Receiver  has received the attempted uncertain packet  in any one of its previous attempts after , which occurs with probability .
\end{itemize}
Clearly, these two events are independent and we thus get:

\ignore{where  is referred to as the innovation probability of packet  at receiver , defined as the probability that packet  was not previously received by this receiver in any previous attempts since .}
\end{itemize}
\textbf{Fully Uncertain Receivers}: \\
\ignore{As defined earlier,} This is the set of receivers for which the sender has previously attempted all their remaining wanted packets after their last heard feedback.
For any receiver , we have the following possibilities:
\begin{singlecol}
\begin{itemize}
\item If this receiver , then it will have  if and only if both following events are true:
    \begin{itemize}
    \item Receiver  receives this transmission.
     \item There exists at least one packet , which was not received by receiver  in all its attempts since . This event occurs with probability .
     \end{itemize}
     Since these two events are independent, we thus get:

\ignore{where  is referred to as the completion probability of receiver , defined as the probability that receiver  has completed the reception of all its wanted packets in previous attempts from the sender.}
\item If receiver , then it will have   if and only if all the following three events are true:
   \begin{itemize}
   \item E1: Receiver  receives the transmission.
   \item E2: There exists at least one packet , which was not received by receiver  in all its attempts after .
   \item E3: Receiver  has received the attempted uncertain packet  in any one of its previous attempts after 
   \end{itemize}
   Clearly, E1 is independent from both E2 and E3. However, E2 and E3 are dependent events because, for both E2 and E3 to be simultaneously true,  must not be among the packets that were not received by receiver \ignore{ for E2 to be true}. Consequently, we need to find the joint probability of these two events. Both E2 and E3 will be simultaneously true if and only if receiver  has received packet  in one of its previous attempts after  and at least one other packet  was not previously received in any previous attempts after . Since  and  are mutually exclusive sets of packets, and since the reception/loss events of mutually exclusive sets of packets are independent, this joint probability can be mathematically written as:
   
 Consequently, we get:

\end{itemize}
\end{singlecol}
\begin{doublecol}
\begin{itemize}
\item If this receiver , then it will have  if and only if both following events are true:
    \begin{itemize}
    \item Receiver  receives this transmission.
     \item There exists at least one packet , which was not received by receiver  in all its attempts since . This event occurs with probability .
     \end{itemize}
     Since these two events are independent, we thus get:

\ignore{where  is referred to as the completion probability of receiver , defined as the probability that receiver  has completed the reception of all its wanted packets in previous attempts from the sender.}
\item If receiver , then it will have   if and only if all the following three events are true:
   \begin{itemize}
   \item E1: Receiver  receives the transmission.
   \item E2: There exists at least one packet , which was not received by receiver  in all its attempts after .
   \item E3: Receiver  has received the attempted uncertain packet  in any one of its previous attempts after 
   \end{itemize}
   Clearly, E1 is independent from both E2 and E3. However, E2 and E3 are dependent events because, for both E2 and E3 to be simultaneously true,  must not be among the packets that were not received by receiver \ignore{ for E2 to be true}. Consequently, we need to find the joint probability of these two events. Both E2 and E3 will be simultaneously true if and only if receiver  has received packet  in one of its previous attempts after  and at least one other packet  was not previously received in any previous attempts after . Since  and  are mutually exclusive sets of packets, and since the reception/loss events of mutually exclusive sets of packets are independent, this joint probability can be mathematically written as:
   

 Consequently, we get:

\end{itemize}
\end{doublecol}
Given all the previous cases, we can\ignore{ summarize the probabilities of decoding delay increments equal to 1 as follows} express  as:

Substituting \eqref{eq:th2-proof3} in \eqref{eq:th2-proof1}, we get:
\begin{singlecol}

\end{singlecol}
\begin{doublecol}

\end{doublecol}
Now, since  and since , we can use these facts to group similar terms, which reduces the expression to:

Finally, since , we get:


\end{proof}

The right-hand side of the sum decoding delay expression in \eqref{eq:decoding-delay} can be intuitively interpreted as follows:
\begin{itemize}
\item The first summation represents the expected decoding delay increments of non-targeted receivers, when each receiver  receives this transmission .
\item The second summation represents the expected decoding delay increments for targeted receivers with uncertain packets, when each receiver  receives this transmission  and it turns out that it has previously received the packet  in one or more of its previous attempts since time  .
\item The last negative summation represents the fact that the decoding delays expressed in the previous two summations will not be experienced by both targeted and non-targeted receivers in  (i.e. receivers for which the sender has previously attempted all their remaining wanted packets after their last heard feedback), even if they receive this transmission , in case they have received all of these uncertain packets in one or more of their previous attempts .
\end{itemize}

\subsection{Decoding Delay Problem Formulation}
Given the previous result, we can now formulate the minimum decoding delay problem in lossy feedback environment in the following corollary.
\begin{corollary} \label{th:DD-formulation}
The problem of selecting an IDNC coded packet for a given transmission, which would result in the minimum expected sum decoding delay increments\ignore{ after this transmission}, is equivalent to a maximum weight clique problem over the IDNC graph, in which the weight  of every vertex  is set as follows:

\end{corollary}
\begin{proof}
From the derived expression \eqref{eq:decoding-delay} in \thref{th:decoding-delay}, the problem of selecting a clique  for a given transmission, so as to minimize the expected sum decoding delay increments after this transmission, can be expressed as:
\begin{singlecol}

\end{singlecol}
\begin{doublecol}

\end{doublecol}
The last summation term inside the braces is not dependent on , as it affects all receivers in  whether selected in  or not. Consequently, we can remove it from the braces without affecting the maximization problem. Similarly, adding inside the braces another term that is independent on , such as , will not affect the result of the maximization problem. But since , we get:

Clearly, the above expression in \eqref{eq:cl-proof1} is equivalent to the maximum weight clique problem over the IDNC graph given the weights  defined in \eqref{eq:weights}.
\end{proof}

\subsection{Low Complexity Algorithm}
Similar to the completion delay problem, the proposed solution for the decoding delay problem is a maximum weight clique problem over the IDNC graph, where all uncertain vertices are kept but weighted differently from the un-attempted vertices as shown in \eqref{eq:weights}. But again, this problem is NP-hard to solve \cite{Garey1979} and NP-hard to approximate \cite{Ausiello1999}. Consequently, we propose to use the same heuristic algorithm proposed in \cite{GC10} to solve the decoding delay problem\ignore{ in perfect feedback scenarios}. This algorithm is similar to the one proposed for the completion delay problem above, but uses the new weights defined in Corollary \ref{th:DD-formulation}. It consists of a weighted vertex search (WVS) algorithm, with modified weights defined as:

where  is the set of vertices adjacent to vertex . Consequently, the algorithm selects in each iteration the vertex that not only has the highest weight  but also has strong adjacency to other high weight vertices in the graph. Similar to the completion delay heuristic, the complexity of this algorithm is , and it was shown to achieve a small degradation compared to the complex optimal maximum weight clique solution \cite{GC10}.



\section{Simulation Results} \label{sec:simulations}
In this section, we compare, through extensive simulations, the performances of our proposed solutions for the completion and decoding delay problems, in lossy feedback environments, to both the perfect feedback (PF) scenario and two other blind graph update approaches described in \cite{ICC11}:
\begin{itemize}
\item Full Vertex Elimination (FVE): Each attempted vertex with unheard feedback is assumed to be hidden in the graph and is temporarily not considered for transmission. These hidden vertices are treated later similar to our proposed algorithm in \sref{sec:blind-update}.
\item No Vertex Elimination (NVE): Each attempted vertex with unheard feedback is kept in the graph.\ignore{ NVE rapidly re-attempts these uncertain vertices, thus giving the chance to the sender to receive feedback from their receivers and to determine their accurate reception status. This fast re-attempts of vertices and SFM update may be of greater importance in this lossy feedback context, especially at the end of the recovery phase, as it can help the sender make better coding decisions towards completion.}
\end{itemize}
We assume channel reciprocity and set  in the vertex weight. We also assume that the different receivers experience different erasure probabilities and different demand ratios, while maintaining the average erasure probability  and the average demand ratio  constant for each simulation point.

\subsection{Completion Delay Results}
Figures \ref{fig:P}, \ref{fig:D}, \ref{fig:M} and \ref{fig:N} depict the comparison of the average completion delay, achieved by the different algorithms, against  (for , , ),  (for , , ),  (for ,  and ), and  (for , , and ), respectively.
\begin{figure*}[t]
\centering
    \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=1\linewidth]{ML_CD_P}
    \caption{Average completion delay vs .} \label{fig:P}
    \end{subfigure}~
    \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=1\linewidth]{ML_CD_D}
    \caption{Average completion delay vs .} \label{fig:D}
    \end{subfigure}

    \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=1\linewidth]{ML_CD_M}
    \caption{Average completion delay vs .} \label{fig:M}
    \end{subfigure}~
    \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=1\linewidth]{ML_CD_N}
    \caption{Average completion delay vs .} \label{fig:N}
    \end{subfigure}
     \caption{Completion delay results}
\end{figure*}

From all figures, we can observe the better performance of the ML approach over the FVE and NVE approaches in reducing the average completion delay, especially for receivers with high erasure probabilities and also when . The result conforms with the analysis in \sref{sec:belief}, showing that the ML update approach of the graph represents the ML estimation of the actual graph, and thus the coding decisions deduced from this graph would on average achieve the best results compared to other graph update approaches.\ignore{ Moreover, we see that the average completion delay of (ML) is not greatly affected by both the non-innovative transmissions of received packets and the potential estimation errors, as long as it always follows the ML state of the network.}

We can also observe that FVE outperforms NVE and approaches ML performance at low demand ratios and small number of receivers, whereas NVE outperforms FVE and approaches ML performance at high demand ratios and large number of receivers. This can be explained from the characteristics of the two approaches. FVE re-attempts the remaining unacknowledged vertices only when all the graph vertices are blindly depleted. Since the primary graph sizes are relatively small for small numbers of receivers and low demand ratios, FVE tends to blindly deplete its graphs very fast and start the re-attempting of the uncertain vertices early. This allows it to finish faster than NVE, which re-attempts vertices a lot in low demand environment.

At large numbers of receivers and high demand ratios, the larger size of the IDNC primary graph increases the time for the FVE approach to blindly deplete the graph. Consequently, all receivers with remaining uncertain vertices will have to wait longer for FVE to re-attempt them, which results in a larger completion delay. This effect increases for the receivers with smaller Wants sets. On the other hand, FVE reduces this effect since it leaves these unacknowledged vertices in the graph, which gives them a chance to speed up their transmission re-attempt, their recovery and/or their feedback. Most importantly, we can see that the ML algorithm achieves a better or similar performance than both of them in all cases, without much addition in complexity.

Finally, we can observe a degradation in the average completion delay obtained in the LF environment, compared to the PF environment. However, for a relatively large network setting (, ), an average erasure probability of 0.25, and worst erasure probability of  (\fref{fig:M}), this degradation in the frame delivery duration (from the start of the frame transmission until its reception at all receivers) reaches , compared to the perfect feedback algorithm performance. For as high as 0.5 worst-case packet loss probability (\fref{fig:P}), we obtain a degradation of . These values are clearly tolerable in such very large networks and up to 50 loss rate of feedback, which is typically very high for signalling information.


\subsection{Decoding Delay Results}
Figures \ref{fig:PP}, \ref{fig:DD}, \ref{fig:MM} and \ref{fig:NN} depict the comparison of the average decoding delay, achieved by the different algorithms, against  (for , , ),  (for , , ),  (for ,  and ), and  (for , , and ), respectively.

\begin{figure*}[t]
\centering
    \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=1\linewidth]{ML_DD_P}
    \caption{Average decoding delay vs .} \label{fig:PP}
    \end{subfigure}~
    \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=1\linewidth]{ML_DD_D}
    \caption{Average decoding delay vs .} \label{fig:DD}
    \end{subfigure}

    \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=1\linewidth]{ML_DD_M}
    \caption{Average decoding delay vs .} \label{fig:MM}
    \end{subfigure}~
    \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=1\linewidth]{ML_DD_N}
    \caption{Average decoding delay vs .} \label{fig:NN}
    \end{subfigure}
    \caption{Decoding delay results}
\end{figure*}

From all figures, we can clearly observe that, for all ranges of the different metrics, our proposed WVS approach, which gives different weights to unattempted and uncertain vertices, outperforms both NVE and FVE, which strictly keeps and eliminates the uncertain vertices, respectively.

We can also observe that FVE performs better than NVE in most scenarios, except for large erasure probabilities. This can be interpreted as follows. In most cases, it is usually better for reducing the decoding delay to attempt new vertices rather than attempted uncertain ones, and keep these uncertain ones either for later or for feedback from the same receivers on new attempted packets. Since FVE eliminates such uncertain vertices for any given receiver as long as there are new ones to attempt for this receiver, it thus outperforms NVE, which keeps the uncertain vertices in the process.

However, when the erasure probability becomes larger, it becomes very likely that the uncertain vertices are actually lost, which makes NVE a much more likely candidate of reflecting the actual state of the network compared to FVE.\ignore{ follows a similar ML trend as the one proposed for the completion delay problem\footnote{The ML here is in the forward link sense only (without considering what happened to the feedback), because the decoding delay is affected by individual packet losses from each individual receiver and not the global state of the network. Consequently, ML do not follow the bounds derived in Corollaries \ref{th:ML-simple} and \ref{th:ML-simple-reciprocal} but rather the simple ML rule that the packet is received (lost) on the forward link if the erasure probability is smaller (larger) than 0.5}, whereas FVE falls away from this ML trend.} That is why we can observe in \fref{fig:PP} that the larger the erasure probability, the better the performance of NVE compared to FVE. This also appears in some scenarios in Figures \ref{fig:MM} and \ref{fig:NN}, when .



\section{Conclusion} \label{sec:conclusion}
In this paper, we extended the study of the multicast completion and decoding delay minimization problems of IDNC to the lossy feedback environment. For the completion delay problem, we first extended the SSP formulation in perfect feedback to a POSSP formulation, reflecting the uncertainties resulting from unheard feedback events in the lossy feedback environment. We then used this formulation to identify the ML state of the network in events of unheard feedback, and employed it to design a partially blind graph update extension to the multicast IDNC algorithm in \cite{TON10-CD}. For the decoding delay problem, we derived an expression for the expected sum decoding delay increments after any arbitrary transmission and used it to find the optimal policy to reduce the decoding delay in such lossy feedback environment. Simulation results showed that our proposed partially blind solutions both outperformed other approaches and achieved a tolerable degradation in performance (compared to the perfect feedback environment) even at relatively high feedback loss rates.


\ignore{In this letter, we extended the problem of minimizing the completion delay of IDNC to LF environment. We first extended our SSP formulation for the PF environment in \cite{TON10-CD} to a POSSP formulation in the LF environment, by defining the belief state that reflects the uncertainty effects resulting from unheard feedback events. From this extended formulation, we derived the ML estimation of the network state in case of unheard feedback events from any number of receivers. We then proposed a partially blind IDNC graph extension to the algorithms in \cite{TON10-CD}, which follows the ML state of the network. Simulation results showed that this ML graph update approach outperforms two other update approaches for all parameter ranges, especially for large number of receivers. Moreover, the proposed algorithm can achieve a tolerable degradation, compared to the PF environment performance, for considerably high feedback loss rates.}

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,bibfile}

\ignore{\begin{figure}[p]
\centering
\includegraphics[width=0.55\linewidth]{IDNC-Graph}\\
  \caption{Example of a state feedback matrix and its corresponding IDNC graph. The shaded and white boxes and vertices represent the requested and undesired packets, respectively.}\label{fig:IDNC-graph}
\end{figure}

\begin{figure}[p]
\centering
  \includegraphics[width=0.9\linewidth]{LF-example}
    \caption{Belief state after taking action  in the example of \fref{fig:IDNC-graph}}\label{fig:LF-example}
\end{figure}


\begin{figure}[p]
\includegraphics[width=1\linewidth]{LF_PMF}\\
  \caption{Conditional pmf variation as a function of the loss probability }\label{fig:LF-PMF}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=1\linewidth]{CD_P}
  \caption{Average completion delay vs  for , , 
  }\label{fig:LF_CD_P}
\end{figure}


\begin{figure}[t]
\centering
\includegraphics[width=1\linewidth]{CD_M}
  \caption{Average completion delay vs  for ,  , }\label{fig:LF_CD_M}
\end{figure}


\begin{figure}[t]
\centering
\includegraphics[width=1\linewidth]{CD_N}
  \caption{Average completion delay vs  for ,  , }\label{fig:LF_CD_N}
\end{figure}


\begin{figure}[t]
\centering
\includegraphics[width=1\linewidth]{CD_D}
  \caption{Average completion delay vs  for , , , }\label{fig:LF_CD_D}
\end{figure}
}

\ignore{\textbf{Partially Uncertain Receivers}: \\
For any receiver  in this set, there exists some packets in its Wants set that have never been attempted after . For such receiver , we have the following possibilities:
\begin{enumerate}
\item If this receiver , then two events can occur. Receiver  will not experience a decoding delay increment if and only if it does not receive this transmission. Thus, we have:

On the other hand, receiver  will experience a decoding delay increment if and only if it receives this transmission. Thus, we have:

\item If receiver  (i.e.  is targeted by a primary packet that has not been attempted after ), then  will never experience a decoding delay.
\item If receiver  (i.e.  is targeted by a primary packet that has been attempted after ), then two events can occur. Receiver  will not experience a decoding delay if and only if one or both of the two events occur:
\begin{itemize}
\item It does not receive the transmission.
\item It receives the transmission, but the attempted packet  was not previously received by this receiver in any previous attempts since .
\end{itemize}
Since these two events are independent and mutually exclusive, we have:

where  is referred to as the innovation probability of packet  at receiver , defined as the probability that packet  was not previously received by this receiver in any previous attempts since .

On the other hand, receiver  will experience an increment in its decoding delay if and only if both:
\begin{itemize}
\item Receiver  receives the transmission.
\item The attempted packet  was previously received in a previous attempt after .
\end{itemize}
Thus, we get:

\end{enumerate}
\\
\textbf{Fully Uncertain Receivers}: \\
As defined earlier, the sender has previously attempted all the remaining wanted packets of any such receiver  after .
For such receiver , we have the following possibilities:
\begin{enumerate}
\item If this receiver , then two events can occur. Receiver  will not experience a decoding delay increment if and only if either one of the following events is true:
\begin{itemize}
\item It does not receive this transmission.
\item It receives the transmission but has also already received all the packets in  in previous attempts.
\end{itemize}
Since these two events are independent and mutually exclusive, we have:

where  is referred to as the completion probability of receiver , defined as the probability that receiver  has completed the reception of all its wanted packets in previous attempts from the sender. On the other hand, receiver  will experience a decoding delay increment if and only if it both receives this transmission and it did not finish the reception of all its wanted packets in previous attempts. Thus, we have:

\item If receiver  (i.e.  is targeted by a primary packet that has been attempted after ), then the resulting decoding delay increment will depend on whether this receiver has actually finished reception or not. If yes, then it will never experience a decoding delay. If not, then its decoding delay increment will be 0 or 1 following the same events and probabilities in \eqref{eq:th2-proof1} or \eqref{eq:th2-proof2}, respectively. Thus, we have:

\end{enumerate}
}


\ignore{\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{samehsorour-bw}}]{Sameh Sorour} (S '98) received the B.Sc. and M.Sc. degrees in Electrical Engineering from Alexandria University, Egypt, in 2002 and 2006, respectively. In 2002, he joined the Department of Electrical Engineering, Alexandria
University, where he was a Teaching and Research Assistant for three years and was promoted to
Assistant Lecturer in 2006. He is currently working towards the Ph.D. degree at the Wireless and Internet
Research Laboratory (WIRLab), Department of Electrical and Computer Engineering, University of
Toronto, Canada. His research interests include opportunistic, random\ignore{ and instantly decodable} network coding applications in wireless networks, vehicular and high speed train networks, indoor localization, adaptive resource allocation, OFDMA, and wireless scheduling.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{valaee}}]{Shahrokh Valaee} (S '88, M '00, SM '02) holds the Nortel Institute Junior Chair of Communication Networks and is the director of the Wireless and Internet Research Laboratory (WIRLab), both in the Edward S. Rogers Sr. Department of Electrical and Computer Engineering, University of Toronto, Canada. Prof. Valaee was the Co-Chair for the Wireless Communications Symposium of IEEE GLOBECOM 2006, a Guest Editor for IEEE Wireless Communications Magazine, a Guest Editor for Wiley Journal on Wireless Communications and Mobile Computing, and a Guest Editor of EURASIP Journal on Advances in Signal
Processing. He is an Editor of IEEE Transactions on Wireless Communications and the TPC-Chair of
IEEE PIMRC 2011. His current research interests are in wireless vehicular and sensor networks,
location estimation and cellular networks.
\end{IEEEbiography}
}
\end{document}
