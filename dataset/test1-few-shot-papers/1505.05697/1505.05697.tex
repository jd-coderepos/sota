\documentclass[11pt]{article}

\usepackage{amsthm}
\usepackage{algorithm, algorithmic}
\usepackage{graphicx}
\usepackage{amssymb}


\def\denseformat{
\setlength{\textheight}{9in}
\setlength{\textwidth}{6.9in}
\setlength{\evensidemargin}{-0.2in}
\setlength{\oddsidemargin}{-0.2in}
\setlength{\headsep}{10pt}
\setlength{\topmargin}{-0.3in}
\setlength{\columnsep}{0.375in}
\setlength{\itemsep}{0pt}
}


\def\spacyformat{
\setlength{\textheight}{9.1in}
\setlength{\textwidth}{6.9in}
\setlength{\evensidemargin}{-0.2in}
\setlength{\oddsidemargin}{-0.2in}
\setlength{\headheight}{0.5in}
\setlength{\headsep}{10pt}
\setlength{\topsep}{0in}
\setlength{\topmargin}{0.0in}
\setlength{\itemsep}{0in}      \renewcommand{\baselinestretch}{2.3}
\parskip=0.080in
}

\denseformat
\begin{document}

\newtheorem{thm}{Theorem}[section]
\theoremstyle{definition}
\newtheorem{dfn}{Definition}[section]
\theoremstyle{remark}
\theoremstyle{plain}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{col}[thm]{Corollary}
\newtheorem{fact}[thm]{Fact}
\newtheorem{fig}[figure]{Fig.}

\def\MathN{\hbox{\rm I\kern-2pt I\kern-3.1pt N}}
\def\Expect{\hbox{\rm I\kern-2pt I\kern-3.1pt E}}
\title{A Fast Network-Decomposition Algorithm \\ and its Applications to Constant-Time \\ Distributed Computation}
\author{Leonid Barenboim\thanks{Open University of Israel.
 E-mail: {\tt leonidb@openu.ac.il}. 
 Part of this work has been performed while the author was a postdoctoral fellow at a joint program of the Simons Institute at UC Berkeley and I-Core at Weizmann Institute.} 
 \and Michael Elkin\thanks{Ben-Gurion University of the Negev. Email: {\tt elkinm@cs.bgu.ac.il} 
This research has been supported by the Israeli Academy of Science, grant 593/11, and by the Binational Science Foundation, grant 2008390.} \and Cyril Gavoille\thanks{LaBRI - Universite de Bordeaux. Email: {\tt gavoille@labri.fr}}}



\maketitle
\begin{abstract}


A partition  of  into clusters of strong (respectively, weak) diameter , such that the supergraph obtained by contracting each  is -colorable is called a strong (resp., weak) -network-decomposition. Network-decompositions were introduced in a seminal paper by Awerbuch, Goldberg, Luby and Plotkin in 1989. Awerbuch et al. showed that strong , -network-decompositions can be computed in distributed deterministic time . Even more importantly, they demonstrated that network-decompositions can be used for a great variety of applications in the message-passing model of distributed computing.

The result of Awerbuch et al. was improved by Panconesi and Srinivasan in 1992: in the latter result , and the running time is  as well. In another remarkable breakthrough Linial and Saks (in 1992) showed that {weak} -network-decompositions can be computed in distributed randomized time . Much more recently Barenboim (2012) devised a distributed randomized constant-time algorithm for computing strong network decompositions with . However, the parameter  in his result is .

In this paper we drastically improve the result of Barenboim and devise a distributed randomized constant-time algorithm for computing strong -network-decompositions. As a corollary we derive a constant-time randomized -approximation algorithm for the distributed minimum coloring problem, improving the previously best-known  approximation guarantee. We also derive other improved distributed algorithms for a variety of problems.

Most notably, for the extremely well-studied distributed minimum dominating set problem currently there is no known deterministic polylogarithmic-time algorithm. We devise a {\em deterministic} polylogarithmic-time approximation algorithm for this problem, addressing an open problem of Lenzen and Wattenhofer (2010). 








\end{abstract}

\pagenumbering {arabic}

\section{Introduction}
{\bf 1.1 Network-Decompositions\\}
In the distributed message-passing model a communication network is represented by an -vertex graph . The vertices of the graph host processors that communicate over the edges. Each vertex has a unique identity number (ID) from the range . We consider a synchronous setting in which computation proceeds in rounds, and each message sent over an edge arrives by the beginning of the next round. The running time of an algorithm is the number of rounds from the beginning until all vertices terminate. Local computation is free.














A {\em strong} (respectively, {\em weak}) {\em diameter} of a cluster  is the maximum distance  (resp., ) between a pair of vertices , measured in the induced subgraph  of  (resp., in ). A partition  of  into clusters of strong (resp., weak) diameter , such that the supergraph , ,  obtained by contracting each  is -colorable is called a {\em strong} (resp., {\em weak}) {\em -network-decomposition}.

Network-decompositions were introduced in a seminal paper by Awerbuch et al. \cite{AGLP89}. The authors of this paper showed that strong  -network-decompositions can be computed in distributed deterministic  time. Even more importantly they demonstrated that many pivotal problems in the distributed message passing model can be efficiently solved if one can efficiently compute -network-decompositions with sufficiently small parameters. In particular, this is the case for Maximal Independent Set, Maximal Matching, and -Vertex-Coloring.

The result of \cite{AGLP89} was improved a few years later by Panconesi and Srinivasan \cite{PS95} who devised a deterministic algorithm for computing strong  -network-decompositions in  time. Awerbuch et al. \cite{ABCP96} devised a deterministic algorithm for computing strong -network-decomposition in time .  Around the same time Linial and Saks \cite{LS92} devised a randomized algorithm for computing weak -network-decompositions in  time. More generally, the algorithm of \cite{LS92} can compute weak -network-decompositions or weak -network-decompositions in time .

Observe, however, that all these algorithms \cite{AGLP89,PS95,LS92} require super-logarithmic time, for all choices of parameters. In ICALP'12 the first-named author of the current paper \cite{B12} devised a randomized algorithm for computing strong -network-decomposition in  time. Unlike the algorithms of \cite{AGLP89,PS95,LS92}, the algorithm of \cite{B12} requires {\em constant} time. Its drawback however is its very high parameter . In the current paper we alleviate this drawback, and devise a randomized algorithm for computing strong -network-decomposition in time . In other words, the parameter  of our new decompositions can be made , for an arbitrarily small constant , while the running time is still {\em constant} (specifically, ).\\ 
{\bf 1.2 Constant-Time Distributed Algorithms}\\
In their seminal paper titled "What can be computed locally?" \cite{NS93} Naor and Stockmeyer posed the following question: which distributed tasks can be solved in {\em constant} time? 
This question is appealing both from theoretical and practical perspectives. From the latter viewpoint it is justified by the emergence of huge networks. The number of vertices in the latter networks may be so large that even mildest dependence of the running time on  may make the algorithm prohibitively slow.

Naor and Stockmeyer themselves \cite{NS93} showed that certain types of weak colorings can be computed in constant time. A major breakthrough in the study of distributed constant time algorithms was achieved though a decade after the paper of \cite{NS93} by Kuhn and Wattenhofer \cite{KW05}. Specifically, Kuhn and Wattenhofer \cite{KW05} showed that an -approximate minimum dominating set\footnote[1]{A subset  in a graph  is a {\em dominating set} if for every  there exists , such that . In the {\em minimum dominating set} (henceforth, MDS) problem the goal is to find a minimum-cardinality dominating set of .}
 can be computed in  randomized time. Here  is the maximum degree of the input graph , and  is a positive possibly constant parameter.

An approximation algorithm for another fundamental optimization problem, specifically, for the {\em minimum coloring} problem, was devised by Barenboim \cite{B12} as an application of his aforementioned algorithm for computing network-decompositions. Specifically, it is shown in \cite{B12} that an -approximation for the minimum coloring problem can be computed in  randomized time. (In the minimum coloring problem one wishes to color the vertices of the graph properly with as few colors as possible.) Observe that since approximating the minimum coloring problem up to a factor of  is NP-hard \cite{H96,FK98,Z07}, the algorithm of \cite{B12} inevitably has to employ very heavy local computations.

In the current paper we employ our improved network-decomposition procedure to come up with a significantly improved constant-time approximation algorithm for the minimum coloring problem. Specifically, our randomized algorithm provides an -approximation for the minimum coloring problem  in  time, for an arbitrarily small constant .  We also devise a randomized -approximation algorithm for the {\em minimum -spanner} problem with running time , for any arbitarily small constant . (A subgraph  of a graph , , is a {\em -spanner} of  if for every , . In the {\em minimum -spanner} problem the objective is to compute a -spanner of the input graph   with as few edges as possible.)

Ajtai et al. \cite{AKS80} showed that triangle-free -vertex graphs admit an -coloring. This existential bound was shown to be tight by Kim \cite{K95}. We devise a randomized -coloring algorithm for triangle-free graphs with running time . More generally, we devise a randomized -coloring algorithm for graphs of girth greater than , with running time . Both results apply for any arbitrarily small , and, in particular, they show that such graph can be colored with a reasonably small number of colors in constant time. Together with our drastically improved constant-time approximation algorithm for the minimum coloring problem, these results significantly expand the set of distributed problems solvable in constant time. 

Most our algorithms for constructing network-decompositions use only short messages\footnote[1]{The only exceptions are weak network-decompositions from Section \ref{sc:strongdecomp}.} (i.e., messages of size  bits), and employ only polynomially-bounded local computations. Although in general graphs our algorithms for -approximate minimum coloring require large messages, our -coloring and -coloring algorithms for triangle-free graphs and graphs of large girth employ short messages.  Hence the latter coloring algorithms are suitable to serve as building blocks for various tasks. Despite that the number of colors is superconstant, in many tasks it does not affect the overall running time, so the entire task can be performed very quickly. For example, if the colors are used for frequency assignment or code assignment tasks, the running time will not be affected by the number of colors. Instead, the range of frequencies or codes will be affected. However, this is unavoidable in the worst case, in view of the lower bounds on the chromatic number of triangle free graphs and graph of large girth.\\
{\bf 1.3 The Minimum Dominating Set Problem\\}
The MDS problem is one of the most fundamental classical problems of distributed graph algorithms. Jia et al. \cite{JRS01} devised the first efficient randomized -approximation algorithm for the MDS problem with running time . Their result was improved and generalized by Kuhn and Wattenhofer \cite{KW05} who devised an -time randomized -approximation algorithm for the problem.

The results of \cite{JRS01,KW05} spectacularly advanced our understanding of the distributed complexity of the MDS problem. However, both these algorithms \cite{JRS01,KW05} are randomized, and no efficient deterministic distributed algorithms with a non-trivial approximation guarantee for general graphs are currently known. Lenzen and Wattenhofer \cite{LW10} devised such algorithms for graphs with bounded arboricity. Below we provide a quote from their paper: \\
\textit{"To the best of our knowledge, the deterministic distributed complexity of MDS approximation on general graphs is more or less a blind spot, as so far neither fast (polylogarithmic time) algorithms nor stronger lower bounds are known"}.

\noindent \ \ \ \ \ In this paper we address this blind spot and devise a deterministic -approximation algorithm for the MDS problem with time . Similarly to our approximation algorithms for the minimum coloring and the minimum -spanner problems, this algorithm is also a consequence of our algorithms for constructing network-decompositions. However, for the MDS we use a deterministic version of these algorithms, while for the minimum coloring and minimum -spanner problems we use a randomized version. Also, we present a variant of our MDS approximation algorithm that employs only polynomially-bounded local computations, requires  time, and provides an  approximation.\\ 
{\bf 1.4 Additional Results \\}
We also use our algorithms for computing network-decompositions for devising algorithms for computing {\em low-intersecting partitions}. Low-intersecting partitions were introduced by Busch et al. \cite{BDRRS12} in a paper on universal Steiner trees.
A {\em low-intersecting -partition}  of a graph  is the partition of the vertex set  such that: 
(1) Every cluster  in  has strong diameter at most . \\
(2) For every vertex , a ball  of radius  around  intersects at most  clusters of . 

 \ \ \ Busch et al. showed that given a hierarchy of low-intersecting partitions with certain properties (see \cite{BDRRS12} for details) one can construct a universal Steiner tree. (See \cite{BDRRS12} for the definition of universal Steiner tree.) Also, vice versa, given universal Steiner tree they showed that one can construct a low-intersecting partition. They constructed a low-intersecting partition with , and arbitrary .


We devise a distributed randomized algorithm that constructs low-intersecting -partitions in time  in general graphs and in  time in graphs of girth  . This algorithm employs only short messages and polynomially-bounded local computations.

Comparing this result with the algorithm of Busch et al. \cite{BDRRS12} we note that the partition of \cite{BDRRS12} has smaller radius. (It is  instead of  in our case.) On the other hand, the intersection parameter  of our partitions is smaller. (It is  instead of .) In particular, the intersection parameter in the construction of \cite{BDRRS12} is always , while ours can be as small as one wishes. Finally, and perhaps most importantly, the algorithm of \cite{BDRRS12} is not distributed, and seems inherently sequential.

\noindent {\bf 1.5 Comparison of Our and Previous Techniques\\}
Basically, our algorithms for computing network-decompositions can be viewed as a randomized variant of the deterministic algorithm of Awerbuch et al. \cite{AGLP89}. The algorithm of Awerbuch et al. \cite{AGLP89} computes iteratively ruling sets for subsets of high-degree vertices in a number of supergraphs. These supergraphs are induced by certain graph partitions which are computed during the algorithm. (A subset  of vertices is called an -ruling set if any two distinct vertices  are at distance at least  one from another, and every  not in a ruling set has a "ruler"  at distance at most  from .)
As a result of the computation the algorithm of \cite{AGLP89} constructs a partition into clusters of diameter at most , such that the supergraph induced by this partition has arboricity at most . The algorithm of \cite{AGLP89} then colors this partition with  colors in time . (The running time of the algorithm is  when running on an ordinary graph. The running time is multiplied by a factor of , because the coloring algorithm is simulated on a supergraph whose vertices are clusters of diameter .) The fact that the running time in the result of \cite{AGLP89} is (roughly speaking) the product  of the parameters of the resulting network-decomposition is the reason that Awerbuch et al \cite{AGLP89} made an effort to balance these parameters, and set both of them to be equal to . The algorithm of Panconesi and Srinivasan \cite{PS95} is closely related to that of \cite{AGLP89} except that it invokes a sophisticated doubly-recursive scheme for computing ruling sets via network-decompositions, and vice versa.
 This ingenious idea enables \cite{PS95} to balance the parameters and running time better. Specifically, they are all equal to .

Our algorithm is different from \cite{AGLP89,PS95} in two respects. First, we replace a quite slow (it requires  time) deterministic procedure for computing ruling sets by a constant-time randomized one. Note that {\em generally} computing -ruling sets requires  time \cite{L92}, but we only need to compute them for {\em high-degree vertices} of certain supergraphs. This can be easily done in randomized constant time. Second, instead of coloring the resulting partition with  colors in  time, we color it in  colors in  time by a simple randomized procedure, or in  colors in  time, for a parameter , by a deterministic algorithm Arb-Linial \cite{BE08}. Hence the number of colors is somewhat greater than in \cite{AGLP89,PS95}, but the running time is constant.

The algorithm of Linial and Saks \cite{LS92} is inherently different from both \cite{AGLP89,PS95} and from our algorithm. It runs for  phases, each of which constructs a collection of clusters of diameter  at pairwise distance at least  which covers at least half of all remaining vertices. The running time of the algorithm of \cite{LS92}, similarly to \cite{AGLP89} and \cite{PS95}, is the product of the number of phases and clusters' diameter. Hence the approach of \cite{LS92} appears to be inherently incapable to give rise to a constant time algorithm.

\noindent \ \ \ \ \ Our deterministic variant of the network-decomposition procedure is the basis for our deterministic approximation algorithm for MDS. Our deterministic variant is closer to the algorithm of \cite{AGLP89} than our randomized one. The main difference between our deterministic variant and the algorithm of \cite{AGLP89} is that we use a different much faster coloring procedure for the supergraph induced by the ultimate partition.























\noindent {\bf 1.6 Related Work \\}
Network-decompositions for general graphs were studied in \cite{ABCP96,C93,AP90}. Dubhashi et al. \cite{DMPRS05} used network decompositions for constructing low-stretch dominating sets. Recently, Kutten et al. \cite{KNPR14} extended Linial-Saks network-decompositions to hypergraphs.  Many authors \cite{GV07,KMW05,SW08} studied network-decompositions for graphs with bounded growth. Distributed approximation algorithms is a vivid research area. See, e.g., \cite{N14} and the references therein. Distributed graph coloring is also a very active research area. See a recent monograph \cite{BE13}, and the references therein. Schneider et al. \cite{SEW13} devised a distributed coloring algorithm whose performance depends on the chromatic number of the input graph. However, the algorithm of \cite{SEW13} provides no non-trivial approximation guarantee. To the best of our knowledge there are no known distributed approximation algorithms for the minimum -spanner problem. Efficient distributed algorithms for constructing sparse undirected spanners can be found in \cite{E07,DGPV08}. For centralized approximation algorithms for the minimum -spanner problem, see \cite{KP94,EP05,BBMRY11}.   
\section{Preliminaries}  \label{sc:preliminaries}
\noindent For a subset , the graph  denotes the subgraph of  induced by .  The {\em degree} of a vertex  in a graph , denoted {\em }, is the number of edges incident on .  
A vertex  such that  is called a {\em neighbor} of  in . The {\em neighborhood} of  in , denoted , is the set of neighbors of  in . If the graph  can be understood from context, then we omit the underscript . For a vertex , the set  is denoted by . For a set , we denote by  the set . The {\em distance} between a pair of vertices , denoted , is the length of the shortest path between  and  in . 
The {\em diameter} of  is the maximum distance between a pair of vertices in .
The {\em chromatic number}  of a graph  is the minimum number of colors that can be used in a proper coloring of the vertices of . 
\section{Network Decomposition}
\subsection{Procedure Decompose} \label{sc:decompose}
In this section we devise an algorithm for computing an -network-decomposition in  rounds, for an arbitrarily small constant .  More generally, our algorithm computes a -network-decomposition   in  rounds, for any positive parameter , along with an -coloring  of the supergraph induced by . (The  term can be eliminated from the running time at the expense of increasing the number of colors used by  by a multiplicative factor of , for an arbitrarily large constant . We will later show that the multiplicative factor of  in the second parameter of the network decomposition can also be eliminated without affecting other parameters.)  The algorithm is called {\em Procedure Decompose}. 
The procedure runs on some supergraph  of the original graph . Each vertex   is a cluster (i.e., a subset of vertices) of the original graph , and different clusters are disjoint. Observe that generally it may happen that . The procedure accepts as input the supergraph , the number of vertices  of , the parameter , and an upper bound  on the number of vertices of the supergraph . It also accepts as input two numerical parameters  and . The parameter  is a sufficiently small positive constant and  is a sufficiently large integer constant. Initially the supergraph is  itself, with each vertex  forming a singleton cluster . Hence initially it holds that .
The procedure is invoked recursively. After each invocation the current  supergraph  is replaced with a supergraph on fewer vertices, and  is updated accordingly. The parameter , however, remains unchanged throughout the entire execution.) As a result of an execution of Procedure Decompose every vertex  in  is assigned a label . The value of  is equal to the color  of the cluster  of  which contains .

Procedure Decompose partitions the graph  into two vertex-disjoint subgraphs with certain helpful properties. Specifically, one of the subgraphs has a sufficiently small maximum degree that allows us to compute a network decomposition in it directly and efficiently. The other subgraph can be partitioned into a sufficiently small number of clusters with bounded diameter. The latter property is used to construct a supergraph whose vertices are formed from the clusters. Since the number of clusters is sufficiently small, the number of vertices of the supergraph is small as well. Then our algorithm proceeds recursively to compute a network decomposition of the new supergraph, using fresh labels that have not been used yet. The recursion continues for  levels. Then each vertex is assigned the label of the supernode it belongs to. (Supernodes of distinct recursion levels may be nested one inside the other. In this case an inner supernode receives the label of an outer supernode. A vertex of the original graph  receives the (same) label of all supernodes it belongs to. Notice that a vertex belongs to exactly one supernode in each recursion level.) This completes the description of the algorithm. Its pseudocode is provided below. (See Algorithm \ref{proced:decompose}.)

The algorithm employs two auxiliary procedures that we describe in detail in Section \ref{sc:pr}. The procedures succeed with high probability, i.e., with probability , for an arbitrarily large constant . The first procedure is called {\em Procedure Dec-Small}. It accepts a graph  with at most  vertices and maximum degree at most . Procedure Dec-Small accepts also as input two numerical parameters,  and , which are relayed to it from Procedure Decompose. Recall that  is a sufficiently small constant and  is a sufficiently large integer constant. The procedure computes an -coloring of  in  time. (The time is  if . Another variant of this procedure computes an -coloring in  time, for an arbitrarily large positive integer .) Observe that for any integer , a proper -coloring of a graph  is also a -network-decomposition of . (There are  labels, and each cluster consists of a single vertex. Thus the diameter of the decomposition is .)  Procedure Dec-Small returns a -network-decomposition  on line 5. It also returns a labeling function  for vertices of a subset . (We will soon describe how this subset is obtained.)  The labeling  also serves as a proper coloring for the supergraph induced by . 

The second procedure which is invoked by our algorithm is called {\em Procedure Partition}. This randomized procedure accepts as input an -vertex supergraph  and a parameter , and partitions  into two subsets  and , such that  and  have the following properties. The subgraph  has maximum degree . The subgraph  consists of  clusters of diameter at most  with respect to . The procedure contracts each such cluster into a supernode. Let  denote the resulting set of supernodes and  the resulting supergraph. Specifically, the vertex set of  is , and its edge set is    Procedure Partition returns the subset  and the set of supernodes .

 The clusters in  are obtained by computing a dominating set  of  of size . Each vertex in  becomes a leader of a distinct cluster. Each vertex in  selects an arbitrary neighbor in  and joins the cluster of this neighbor. Consequently, in all clusters all vertices are at distance at most  from the leader of their cluster. Hence all clusters have diameter at most . 
Initially, each vertex of  joins the set  with probability . Then the set  is formed by the vertices of  and their neighbors. Finally, the set  is formed by the remaining vertices, i.e., . In this stage the procedure returns the set of nodes  and the set of supernodes  which is obtained from , and terminates. This completes the description of Procedure Partition.

\begin{algorithm}[H]
\caption{Procedure Decompose()}
\label{proced:decompose}

\begin{algorithmic}[1] 

\IF {}

    \STATE return Dec-Small() 
 
    /* Compute directly a -network-decomposition of . (See Section \ref{sc:pr}.) */

\ELSE

    \STATE  := Partition()
				
		/* Partition  into  and . (See Section \ref{sc:pr}.) The maximum degree of  is .*/
		
		\STATE  := Dec-Small(, , )
		
		/* Compute directly a -network-decomposition of . (See Section \ref{sc:pr}.) */
		
	  \STATE  Decompose()
		
		/* A recursive invocation on the supergraph  that contains at most  supernodes.  */
		
		\FOR {each vertex  of , {\bf in parallel,}}
		
		    \IF {}
				   
					\STATE 
				
				\ELSIF {}
		
		    \STATE  
				
				/* , where  is a sufficiently large constant to be determined later. */
				
				\ENDIF
				
		/* The labeling function  on  is defined by: for a cluster  (respectively, ) it applies to it the function  (resp., ). */		
				
		\ENDFOR
		
		\STATE return 
		
\ENDIF

\end{algorithmic}
\end{algorithm}


The recursive invocation of Procedure Decompose on line 6 returns a network decomposition  for the supergraph . The for-loop (lines 7-13) adds (in parallel)  to the color of each cluster of the network decomposition  of , where  is a sufficiently large constant to be determined later. Since the number of colors used in each recursive level is at most , this loop guarantees that colors used for clusters created on different recursion levels are different. This is because the labeling returned by procedure Dec-Small on line 5 for clusters of  employs the palette  while the labeling computed in lines 10 - 12 for clusters of  employs labels which are greater than .
The termination condition of the procedure is the case , i.e., when the number  of vertices in the supergraph  is already small. At this point the maximum degree of  is small as well (at most ), and so coloring the supergraph (by Procedure Dec-Small) results in a sufficiently good network decomposition.



Observe that our main algorithm will invoke the procedure on the original graph . Hence in the first level of the recursion , and each supernode is actually a node of . In the second recursion level it is executed on the supernodes of nodes of the original graph . In the third level it is executed on supernodes of supernodes, etc. Consequently, starting from the second recursion level supernodes have to be simulated using original nodes of the network. To this end each cluster that forms a supernode selects a leader which is used for simulating the supernodes. Moreover, the leader is used to simulate all nested supernodes to which it belongs. Our supernodes are obtained by at most  levels of nesting. In each level of nesting a supernode is a cluster of diameter at most  in a graph whose nodes are lower-level supernodes. Hence a simulation of a single round on such a supergraph will require up to  rounds. 
Next we provide several lemmas that will be used for the analysis of the algorithm. We leave the parameters  and  unspecified in all lemmas in this section, because they have no effect on the analysis. \begin{lem} \label{decomposelevl}
Consider an invocation of Procedure Decompose on the original graph  with parameters , , and , for .
The number of recursion levels in the execution of this Procedure (i.e., Decompose()) is .
\end{lem}
\begin{proof}
In recursion level , , the parameter  is equal to . Hence, in recursion level  the parameter  is equal to , and the recursion reaches the termination condition. (See lines 1-2 of Algorithm \ref{proced:decompose}.)
\end{proof} 
\begin{lem} \label{numoflabels}
The number of labels used in the invocation of Procedure Decompose() is .
\end{lem}
\begin{proof}
We show that the number of labels is ,
where  is a sufficiently large constant.
Specifically, the constant  needs to be larger than the constants hidden by the -notation in comments on lines 2 and 5 of the algorithm. (Recall that line 2 computes a -network-decomposition, and line 5 computes a -network-decomposition.
The constant  appears in line 11 of Algorithm \ref{proced:decompose}.)  The proof is by induction on , where  is the recursion level. In other words, this is an inverse recursion on the number of recursion levels.
For each index , denote by  the supergraph on which Procedure Decompose is invoked on the th level of the recursion. Note that at this point . The inductive claim is that the th level invocation of Procedure Decompose (on the supergraph ) employs at most  labels.\\
{\bf Base (, i.e., )}: In this case , the termination condition of the recursion holds, and thus the number of labels used in the decomposition is . (See line 2 of Algorithm \ref{proced:decompose}.) By the choice of , the number of labels is at most . \\
{\bf Step}: Suppose that the invocation has returned from level  of the recursion, and it is now at level . By the induction hypothesis, line 6 of Algorithm \ref{proced:decompose} returns a labeling with  labels. Once line 11 is executed, the number of labels becomes
. 
This proves the inductive claim.

In the end of recursion level  the algorithm terminates (after returning from all recursive invocations). In this stage it holds that , and the claim follows.
\end{proof} 
\begin{lem} \label{dec}
Each cluster created by the invocation above has diameter at most .
\end{lem}
\begin{proof}
We prove by induction on  , where  is the recursion level, that level- clusters have diameter at most . \\
{\bf Base (, i.e., )}: In this case a -network-decomposition is computed directly, and thus the diameter of all clusters in the graph  on which it is executed is . (Recall that the argument  in the  level- invocation is a supergraph of the original input graph .)\\
{\bf Step:} First, observe that a -network-decomposition of  is computed directly in line 5 of Algorithm \ref{proced:decompose}. Hence  consists of clusters of diameter  (with respect to supernodes of the supergraph  of the current recursion level). Next, we analyze the diameter of clusters in . By the induction hypothesis, line 6 of Algorithm \ref{proced:decompose} (i.e., the recursive invocation of Procedure Decompose) returns a network decomposition in which all clusters have diameter at most . This is a decomposition of the supergraph . Consider a cluster  of diameter at most  in . 
Let  be a pair of vertices of  that belong to supernodes in . Let  be these two supernodes (clusters), such that , . Since the diameter of  in  is at most , there exist clusters , such that , and the following holds. There exist edges , such that 
for every , and for every , . 
(See Figure \ref{clustersvertices} for an illustration.)
By construction, each of the clusters  has diameter at most . Hence for , it holds that . Therefore, 

Since , it follows that .
Therefore, the diameter of  in  is at most . Hence all clusters in  have diameter at most  in . Since the number of recursion levels is , the claim follows.
\end{proof}
\includegraphics{clustersvertices3.eps}
\begin{fig} \label{clustersvertices}
The clusters .
\end{fig}
\begin{lem} \label{lemmac}
Suppose that all invocations of auxiliary procedures of Procedure Decompose have succeeded. Then the invocation computes a -network-decomposition.
\end{lem}
\begin{proof}
Consider a pair of distinct adjacent clusters . If  and  then , while . Hence .

If  then since Procedure Dec-Small returns on line 5 a network decomposition with a proper labeling , it follows that , and so .

Finally, if  then inductively we conclude that , and thus  too. (The induction base is the recursion level , where the correctness follows from the correctness of Procedure Dec-Small invoked on line 2 of Algorithm \ref{proced:decompose}.)

Hence Procedure Decompose returns a partition  into clusters of diameter at most  (by Lemma \ref{dec}), and a proper labeling  of this partition. By Lemma \ref{numoflabels}, the number of labels used by the labeling  is . Hence  is a -network-decomposition for , and  is a proper labeling for the network decomposition .
\end{proof}


Recall that the auxiliary procedures Dec-Small and Partition succeed with probability , for an arbitrarily large constant . Each of these procedures is invoked at most  times during the execution of Procedure Decompose. Therefore, the probability that all executions of Procedure Dec-Small and Procedure Partition succeed is at least . Since  is an arbitrarily large constant, all executions of the auxiliary procedures succeed, with high probability. Hence Procedure Decompose computes a -network-decomposition, with high probability.

The next lemma analyzes the running time of the algorithm. \begin{lem} \label{dectime}
Let  (respectively, ) denote the running time of Procedure Partition invoked with parameters  and  (resp., Procedure Dec-Small invoked with parameters  and ). We will assume that both these running times are monotone non-decreasing in both parameters. 
Then the running time of Procedure Decompose is .
\end{lem}
\begin{proof}
During the execution of Procedure Decompose the Procedure Dec-Small is executed  times, and Procedure Partition is executed  times. For , in recursion level  both procedures are executed on supergraphs whose supernodes constitute subgraphs of diameter at most  of the original graph. Thus, the number of rounds required in level  is the product of the number of steps required to execute the procedure on the supergraph and the maximum diameter of supernodes. This running time is at most . The running time of the last recursion level  in which the termination condition holds is . Therefore, the overall running time is \\
.
\end{proof}
Procedure Dec-Small and Procedure Partition are provided and analyzed in Section \ref{sc:pr}. Next we state the main results obtained by plugging these procedures into Procedure Decompose. See Section \ref{sc:pr} for the proofs.

\begin{thm} \label{dlarge}
For any parameter , Procedure Decompose computes a -network-decomposition along with the corresponding -labeling function in time , with high probability. Alternatively, one can also have the second parameter equal to  and the running time .
\end{thm}



It follows that, an -network-decomposition of an arbitrary -vertex graph along with a proper -labeling for it can be computed by a randomized algorithm, in  time, with high probability. See Section \ref{sc:refine}.



\subsection{Procedure Dec-Small and Procedure Partition} \label{sc:pr}
We start with the description of Procedure Dec-Small. This procedure accepts a graph  with at most  vertices and maximum degree at most , and computes an -coloring of , where  is a fixed arbitrarily small positive constant. In other words, if  then an -coloring is computed, and otherwise an -coloring is computed. For computing an -coloring, Procedure Dec-Small employs the deterministic algorithm of Linial \cite{L92} that computes an -coloring of graphs with maximum degree  within  time. For computing an -coloring, Procedure Dec-Small employs the randomized algorithm of Barenboim \cite{B12} that computes, with high probability, an -coloring in  time, for an arbitrarily small .  We henceforth refer to this algorithm as {\em Procedure Random-Color}. This completes the description of Procedure Dec-Small. Its pseudocode is provided below. 

For completeness, we provide a high-level description of the algorithm of Linial \cite{L92} and the algorithm of Barenboim \cite{B12}. The algorithm of Linial \cite{L92} starts with a legal -coloring of the input graph obtained from the IDs of the vertices. It proceeds in phases, each of which reduces the number of colors while preserving the legality of the coloring. In each round the number of colors is reduced from  to , where  is the number of colors in the beginning of a round. (Initially .) In the last round the number of colors is reduced from  to . Each phase requires just a single round, and the overall running time of the algorithm of Linial is .
(It is actually , but this precision is immaterial for our purposes.)

Observe also that one can run Linial's algorithm for just  rounds, for some positive integer parameter , and obtain an -coloring.
For a single phase of Linial's algorithm it employs -union free set systems from the paper by Erdos, Frankel and Furedi \cite{EFF85}. A family  of sets over a given ground-set  is said to be -union-free if for every  sets , it holds that . Erdos et al. showed that for any positive integers  and , , there exists a -union-free family  of  subsets over a ground-set  of size .

Let  be a proper -coloring of  in the beginning of a phase of Linial's algorithm. The algorithm associates a set  from  with each color  of . Every vertex  that runs the algorithm computes a new color . Such a color exists since  is a -union-free family, and  for every .) The vertex  sets its new color  by . Since , , it follows that  is an -coloring. Also, consider a pair of neighbors  and . Observe that , while . Hence , and thus  is a proper coloring.
See \cite{L92} or \cite{BE13} Chapter 3.10 for more details.


The algorithm of Barenboim \cite{B12} (Procedure Random-Color) proceeds in phases as well, however, each phase consists of a randomized procedure. In this procedure each vertex either succeeds in selecting a final color, or fails and continues to the next phase. Each vertex selects a color from the range  uniformly at random, where  is an arbitrarily small constant. A vertex succeeds if and only if it selects a color that has not been selected by any of its neighbors (either in the current round, or as a final color in a previous round). Otherwise, it fails, discards its color, and continues to the next phase. Hence, the probability that a vertex  fails
 to select a color that is different from the colors of its neighbors is at most . 
If we run this procedure for  rounds, for a sufficiently large constant , then the probability that a given vertex  fails on all these rounds is at most . Hence, by union bound, after  rounds all vertices succeed with probability at least , i.e., with high probability.
\begin{algorithm}[H]
\caption{Procedure Dec-Small()}
\label{proced:dec-small}

\begin{algorithmic}[1] 

\IF  {}
  
  \STATE compute an -coloring of  using the algorithm of Linial \cite{L92}
	
	/* alternatively, one can compute here an -coloring in  time */
  
\ELSE

  \STATE compute an -coloring of  using Procedure Random-Color
  
\ENDIF

\end{algorithmic}
\end{algorithm}

Observe that if  then  and an -coloring is computed. Otherwise, , and an -coloring is computed. Therefore, the number of colors is .
Recall also that the running time of the algorithm of Linial \cite{L92} is , and the running time of Procedure Random-Color is . Thus we obtain the following lemma.
\begin{lem} \label{dsmall}
Procedure Dec-Small invoked on a graph  with maximum degree at most  computes, with high probability, an -coloring, which is a -network-decomposition. If , the running time of Procedure Dec-Small is . Otherwise, it is .
\end{lem}
Another variant of the Procedure Dec-Small checks if , and if it is the case it invokes the -round version of Linial's algorithm. Otherwise it invokes line 4 of Algorithm \ref{proced:dec-small} (i.e., the algorithm from \cite{B12}).
This modified procedure always requires constant time. (Assuming that .) If , it computes an -coloring.
Otherwise (in this case ) it computes a -coloring. To summarize:
\begin{lem}
A modified variant of Procedure Dec-Small computes an -coloring in  time, with high probability. In particular, the running time is constant if .
\end{lem}

Next, we describe Procedure Partition. Procedure Partition accepts as input a graph  and a positive parameter , and partitions  into two subsets  and , such that  and  have the following properties. The subgraph  has maximum degree . The subgraph  consists of  clusters of diameter at most .
The procedure contracts the clusters of  into supernodes, which form the supergraph .  The clusters in  are obtained by computing a dominating set  of  of size . Each vertex in  becomes a leader of a distinct cluster. Each vertex in  selects an arbitrary neighbor in  and joins the cluster of this neighbor. Consequently, in all clusters all vertices are at distance at most  from the leader of their cluster. Hence all clusters have diameter at most . 

Initially, each vertex of  joins the set  with probability . Then the set  is formed by the vertices of  and their neighbors. Finally, the set  is formed by the remaining vertices, i.e., . In this stage the procedure returns the set of nodes  and the set of supernodes  which is obtained from , and terminates. This completes the description of the procedure. Its pseudocode is provided below.
\begin{algorithm}[H]
\caption{Procedure Partition()}
\label{proced:partitin}
An algorithm for each vertex .
\begin{algorithmic}[1] 

\STATE  joins  with probability  and informs its neighbors

\IF { has joined  or a neighbor of  has joined }

     \STATE  joins 
     
\ELSE
   
      \STATE  joins 
      
\ENDIF

\IF { }

      \STATE  initializes a singleton cluster , becomes the leader of , and sends  to all neighbors in 

\ENDIF

\IF { and  receives at least one message from a leader of a cluster in }

      \STATE  joins a cluster of an arbitrary neighbor in 
      
\ENDIF

\STATE  the set of supernodes obtained by contracting all clusters 

\STATE return 

\end{algorithmic}
\end{algorithm}
Note that the sets  and  are returned in a distributed manner. In other words, each vertex knows whether it belongs to  or to . If it belongs to , then it knows the identity of the leader of its cluster. The leaders of the clusters represent the supernodes formed by the clusters. Thus, when we say that a supernode performs some action, it is actually performed by the leader of the cluster that forms the supernode. (For nested supernodes the operations are performed by the leaders of the innermost clusters, which are vertices in the original input graph .)

In the next lemmas we prove that Algorithm \ref{proced:partitin} computes a partition with the properties described above.
\begin{lem}
Suppose that Procedure Partition is invoked on a graph  and a positive parameter . Then the subgraph  induced by the set  which is returned by the procedure has maximum degree , with high probability.
\end{lem}
\begin{proof}
Consider a vertex  such that  has at least  neighbors in , for a sufficiently large constant . Denote . Let  denote the neighbors of  in , and let . 
The probability that none of these neighbors join  is

Hence, by union bound, the probability that at least one vertex  with at least  neighbors does not have a neighbor in  is at most . Hence with probability at least , all high-degree vertices (vertices with ) end up in . Hence, with high probability, the maximum degree of a vertex in  is .
\end{proof}
The next lemma analyzes the number of supernodes and their diameters.


\begin{lem} \label{partitnscnd}
Suppose that Procedure Partition is invoked on a graph  and a parameter , for some constant . Then the set  returned by the procedure has the following properties. With high probability,  consists of  supernodes. All supernodes of  are clusters of diameter at most  in .
\end{lem}
\begin{proof}
Recall that the set  is created by contracting the clusters of  into supernodes. First, we prove that all clusters of  have diameter at most . Let  be a cluster of . Let  be any pair of vertices in the cluster. Then either one of these vertices is the leader of the cluster and  or both  and  are connected to the same leader, and so . (Since  and  belong to  they must have a leader neighbor, unless they are leaders themselves. Since  and  belong to the same cluster, and there is exactly one leader in each cluster, if  and  are not the leaders, they are connected to the same leader.) Next, we prove that  consists of  supernodes. Note that the number of supernodes in  is equal to the number of vertices in , since each vertex in  becomes a leader of a cluster (i.e., of a supernode). Let  denote a random variable that counts the number of vertices in . Since each vertex in  joins  with probability  independently of other vertices, it holds that . By Chernoff bound for upper tails (see, e.g., \cite{MU05}, Chapter 4),\\

\end{proof}
Finally, note that each line of Procedure Partition is either performed locally, or involves  sending messages to neighbors. The latter requires one time unit. Therefore, the running time of Procedure Partition is .
\begin{lem} \label{prptimecns}
Procedure Partition requires  time.
\end{lem}
Combining Lemmas \ref {dec} - \ref{dectime} with Lemmas \ref{dsmall} - \ref{partitnscnd} imply the following results.
\begin{thm} For any parameter , Procedure Decompose computes a -network-decomposition along with the corresponding -labeling function in time , with high probability.
\end{thm}
Consider now a variant of Algorithm \ref{proced:decompose} (Procedure Decompose) in which in Procedure Dec-Small we always invoke Procedure Random-Color with a parameter . (As opposed to Algorithm \ref{proced:dec-small} where we do it only when .) Also, in Algorithm \ref{proced:decompose} we now set .

Then, by the previous argument, this modified variant of Procedure Decompose computes a -network-decomposition along with a legal -labeling function in time . By substituting  we conclude:
\begin{thm} A -network-decomposition along with the appropriate proper (with respect to this decomposition) -labeling can be computed in  time, with high probability.
\end{thm}
 
In particular, by setting  to be an arbitrarily large constant we obtain an -network-decomposition along with a proper -coloring for it in randomized constant time, for an arbitrarily small constant .
\begin{col}
An -network-decomposition of an arbitrary -vertex graph along with a proper -labeling for it can be computed by a randomized algorithm, in  time, with high probability.
\end{col}
A yet another variant of Procedure Decompose (Algorithm \ref{proced:decompose}) is obtained if in Proc Dec-Small we always invoke the -round variant of Linial's algorithm \cite{L92}, for some positive integer parameter . (Again we do it regardless of the value of .) Also, for this variant we set , where  is a sufficiently large constant. (Specifically, the -round variant of Linial's algorithm computes an -coloring of the input -vertex graph with maximum degree . The constant  should be larger than the constant hidden by the -notation in .)

The resulting algorithm computes a -network-decomposition with a proper -labeling for it, in  time.
\begin{col}
For any -vertex graph  and parameters , one can compute a -network-decomposition (respectively, -network-decomposition) with an appropriate labeling function in  (resp., ) randomized time, 
\end{col}





\section{Refining the Algorithm} \label{sc:refine}
In this section we argue that one can save a factor of  in the number of labels, and compute a -network-decomposition (and a -network-decomposition) with an appropriate labeling in  (resp., in ) time. While this improvement is negligible when  is small, it becomes significant when  is superconstant. We remark, however, that in the context of the current paper we are mainly interested in the regime of small .

To describe this improvement we need the notions of arboricity and -partition. (We refer the reader to \cite{BE08} and \cite{BE13} for a more elaborate discussion on this topic.)

The {\em arboricity}  of a graph  is the minimum number  of edge-disjoint forests , such that . An {\em -partition}  of  with degree at most , for some number , is a partition of the vertex set  of  into vertex disjoint subsets ,  for every pair of distinct indices , , such that for every index  and every vertex , the number of neighbors  that  has in -sets  with an index  is at most .

Consider again Procedure Decompose. (See Algorithm \ref{proced:decompose}.) For , let  denote the supergraph on which the procedure is invoked in the th level of recursion. In particular,  is the original graph. Also, in all levels  the procedure enters lines 4 - 15, and in the last level  it enters the termination condition (line 2). In the former case Procedure Decompose invokes Procedure Dec-Small (in line 5), which returns the collection  of clusters. (It also returns the labeling function that is immaterial for the current discussion.) For , let  denote the set of clusters returned by Procedure Dec-Small on line 5 of the th level recursive invocation of Procedure Decompose. Finally, in level  of the recursion Procedure Dec-Small is invoked in line 2. Denote by  the decomposition that it returns.
\begin{lem} \label{sets}
 is the network decomposition that Procedure Decompose returns (in line 14 of the first level recursive invocation). Moreover, for any index , ,  is the network decomposition that the th level recursive invocation of Procedure Decompose returns.
\end{lem}
\begin{proof}
The proof is by induction on . \\
{\bf Base ()}: In this case Procedure Decompose returns the output  of an invocation of Procedure Dec-Small (on line 2 of Algorithm \ref{proced:decompose}).\\
{\bf Step}: Consider some . The th level recursive invocation returns  in line 14. Recall that  is a network decomposition for  computed in line 5 of Algorithm \ref{proced:decompose}. (In all levels except the first one  is actually equals to . In the first level .)
Also,  (computed by the st level recursive invocation of Procedure Decompose; see line 6 of Algorithm \ref{proced:decompose}) is a network decomposition for . By induction hypothesis the latter is  . Hence , as required.
\end{proof}
In the next lemma we show that  is an -partition with relatively small degree of the supergraph  induced by the network decomposition .
\begin{lem} \label{partitions}
 is an -partition with degree  of the supergraph .
\end{lem}
\begin{proof}
Again, by an induction on , , we show that  is an -partition of  with maximum degree .\\
{\bf Base ()}: In this case we need to show that the maximum degree in  is . By the termination condition of Algorithm \ref{proced:decompose} (line 1), , and thus the same upper bound applies to its maximum degree.\\
{\bf Step}: For some , , we argue that for any cluster  its degree in  is . By Lemma \ref{sets},  is the network decomposition for  that the th level recursive invocation of Procedure Decompose returns. By construction,  is the set of clusters with degree at most  in the supergraph . Since clusters of  are obtained by merging clusters of , it follows that the degree of  in  is no greater that its degree in , i.e., at most .
\end{proof}
To recap, Lemma \ref{partitions} shows that in addition to computing a network decomposition  of its input graph , Procedure Decompose also computes a low-degree -partition of the induced supergraph . (Here Q = , and the -partition is . The degree of the partition is .)

For the variant of Procedure Decompose that we describe in this section we do not actually need to explicitly compute the labeling function during the execution of the procedure. As a result Procedure Dec-Small can be greatly simplified. Specifically, if it is invoked on a supergraph , then it returns  as its output partition. If it is invoked on a subgraph  of the original graph , then it returns a partition of  into singleton clusters, i.e., . Observe that in this simplified form Procedure Dec-Small requires  time. As a result the overall running time of Procedure Decompose becomes  rather than  or .

Next, we utilize the -partition  of  for computing an -coloring of  in  time, or alternatively, an -coloring of  in  time. Such colorings can be viewed as labelings of the network decomposition . (For every vertex , its label will be equal to the color of the cluster  that contains it.)

To simplify presentation, consider an -vertex graph  and an -partition  for  with degree . We will argue that  can be efficiently colored. To implement this coloring in a supergraph , we will need to multiply the running time by the maximum diameter of a cluster in , i.e., by . We start with arguing that  can be colored in  colors in  time, by a deterministic algorithm. (This algorithm is closely related to Algorithm Arb-Linial from \cite{BE08}, based on Linial's algorithm \cite{L92}. The current algorithm is however more general than Algorithm Arb-Linial.) The algorithm starts by orienting all edges  in the following way: let  (respectively, ) be the index of the set  (resp., ) which contains  (resp., ). If  then the edge is oriented towards . If the opposite holds than it is oriented towards . If  then the edge is oriented towards the endpoint with a greater .

Observe that under this orientation each vertex  has at most  outgoing edges incident on it. The opposite endpoints of these edges will be referred to as the {\em parents} of . Let  denote the set of parents of .

Let  be a proper -coloring of . We argue that a legal -coloring  of  can be computed within one single round. To this end we again employ an -union-free family  of  sets (due to \cite{EFF85}, see also Section \ref{sc:pr} of this paper). Each color class  of  is associated with a set . A vertex  computes a color  which belongs to . Such a color necessarily exists, because  is an -union-free family. Also, for an edge , suppose without loss of generality that . Then , while , and so . By \cite{EFF85}, a family  over a ground-set of size  exists (and can be efficiently constructed). Thus,  is a proper -coloring. By repeating this recoloring step for  times, we obtain an -coloring in  rounds. (We start with an initial -coloring of . Specifically, each vertex uses its  as its initial color.)

\begin{col}
An -coloring of  can be computed in  time, for any .
\end{col}
Observe that this argument shows in fact that the arboricity of  is , and thus  is a -network-decomposition. We summarize these results in the following corollary.
\begin{col} \label{partdec}
Procedure Decompose, invoked on an -vertex graph  with a parameter , computes a -network-decomposition  and an -partition  of degree  and length  for  in  randomized time, with high probability. Moreover, for a parameter , one can compute in  time an -labeling for . In particular, by setting  one can get here time  and labeling with  labels.
\end{col}
Note that the -coloring algorithm for  that was described above does not require the fact that the -partition  has small number of sets. Next we show that this -partition can be used in a more explicit way to compute an -coloring of  in  time.

First, every vertex  of  tosses a color  uniformly at random from the palette . It checks if its color is different from the colors of all its neighbors in . If it is the case, it finalizes its color. Otherwise, it tosses its color from the same palette again. The process is repeated for  rounds, for a sufficiently large constant . As we have already seen (see Lemma \ref{dsmall} and the discussion preceding it), in  rounds we will obtain a legal -coloring  for , with high probability. (Recall that the maximum degree in  is at most A.) Define also . 

Suppose that we have already computed an -coloring  for , for some , . Next we show how to extend this coloring into an -coloring  for . To this end every vertex  tosses a color from  uniformly at random, and checks if its color is different from the colors (either tossed on this round, or finalized colors) of its neighbors in . If it is different from them, then  finalizes its color. Otherwise, it continues to the next round. The entire process continues for  rounds.

The key observation required for the analysis is that  has at most  neighbors in  Thus, a legal -coloring  for  will be computed, with high probability, within additional  rounds. It is then combined in a trivial way with the coloring  for  to obtain the -coloring  for .
\begin{thm} \label{arbc}
Given an -partition  with degree at most  for an -vertex graph , and a parameter , an -coloring of  can be computed in  rounds.
\end{thm}
By invoking this algorithm on the network decomposition  we obtain:
\begin{col}
Using a -network-decomposition  of the input graph  and an -partition  for  with degree , one can compute an -labeling for  within  randomized time.
\end{col}
By substituting  we get:
\begin{col} \label{improvement}
A -network-decomposition  along with an -labeling for it can be computed in  randomized time.
\end{col}




\section{Decompositions with a smaller number of labels} \label{sc:betterlabels}
When  is small the logarithmic factor in the number of labels () of the network decomposition  from Corollary \ref{improvement} is almost negligible. However, for large  (e.g., ) this logarithmic factor becomes dominant. In this section we describe a modification of our algorithm that produces -network-decomposition in  time. (For graphs of girth at least 6 the running time of this algorithm is even better, specifically .)
Observe that for , the overhead factor of  can be swallowed by the -notation in . This version of our algorithm is closely related to the deterministic algorithm of Awerbuch et al. \cite{AGLP89}; in fact, our algorithms in this section can be viewed as a randomized version of their algorithm. Their deterministic algorithm requires time , and so we essentially show here that their algorithm can be made faster by means of randomization.

The difference between the new variant of our algorithm (which we introduce here; we will refer to it as Procedure RS-Decompose) and the original version of our algorithm (described in Section \ref{sc:decompose}) is a different algorithm for Procedure Partition. (See Algorithm \ref{proced:partitin}.) The new variant of Procedure Partition which we will next describe will be called Procedure RS-Partition. (RS stands for the acronym of "ruling set".) 

In a graph  for a vertex set  and positive integer parameters  a subset  is called an {\em -ruling set} for  if the following two conditions hold: \\
(a) Every pair of distinct vertices  satisfy .\\
(b) For every vertex  there exists a "ruling vertex" (also called "ruler")  such that .\\

Observe that an MIS is a -ruling set. In the description of Procedure RS-Partition we will assume that we have an efficient distributed subroutine for computing -ruling sets for  and . We will later elaborate on this subroutine.
Procedure RS-Partition starts with computing a -ruling set  for the set  of high-degree vertices of . (Recall that  is an input parameter of Procedure RS-Partition.) Then every vertex  sends an exploration message to distance . Every vertex  that receives an exploration message from two distinct rulers  assigns himself to the ruler  which is closer to it. (Ties are broken in an arbitrary but consistent manner by comparing rulers' identities.)

As a result of these explorations clusters  are formed. Observe that these clusters all have strong radius at most , and that every  (i.e., every high-degree vertex) is assigned to some cluster. (This collection of clusters is often called a {\em ruling forest}. See, e.g., \cite{AGLP89}.) Procedure RS-Partition now forms the set  of supernodes by contracting these clusters , exactly as in line 13 of Algorithm \ref{proced:partitin}. Further, it creates the set  by setting , i.e., every vertex  which is not clustered is assigned to . Observe that for every , it holds that . Finally, Procedure RS-Partition returns the pair , exactly as in line 14 of Algorithm \ref{proced:partitin}.
\begin{lem} \label{rprulin}
Suppose that Procedure RS-Partition is invoked on a graph  and a positive parameter . Suppose further that it uses a subroutine for computing a -ruling set, for a positive integer parameter . The the subgraph  has maximum degree smaller . Moreover,  consists of at most  supernodes, each of which is a cluster of strong diameter at most .
\end{lem}
\begin{proof}
All the assertions of the lemma were already argued in the preceding discussion, except for the claim that . We next show this claim. Recall that every supernode of  originated from a cluster , , where  is a -ruling set for the set  of vertices with degree at least . Hence for two distinct clusters  from the collection , it holds that , and . All (immediate) neighbors of  (respectively, ) are assigned to the cluster  (resp., ), and these sets of neighbors are disjoint. Hence  for every , and .
\end{proof}

We now use Procedure RS-Partition instead of Procedure Partition within Procedure RS-Decompose. The diameter of clusters in the modified procedure becomes  instead of , but the factor  is shaved from the bound on arboricity.
 (This is because the bound on  for A returned by Procedure RS-Partition is  instead of .
Hence as a result we obtain a -network-decomposition  and an -partition  of degree  of length  for . (See Corollary \ref{partdec} for a comparison.)

To analyze the running time we need to specify the black-box procedure for computing a -ruling set  for the set  of high degree vertices. Barenboim et al. \cite{BEPS12} (based on \cite{KP12} and \cite{BKP14}) showed that -ruling sets can be computed in  randomized time in general graphs, and that -ruling sets can be computed in graphs with girth at least  in just  time.
By running their routine in  we guarantee that any two distinct vertices  are at distance at least  in , i.e., at distance at least  in . On the other hand, the domination parameter grows by a factor of , i.e., we obtain a -ruling set in  time in general graphs, 
and a -ruling set in  time in graphs of girth at least . 
Hence the running time of Procedure RS-Partition becomes now  for general graphs and  for graphs of girth at least , instead of the running time of  for Procedure Partition. (See Lemma \ref{prptimecns}.) Hence by Lemma \ref{dectime}, the overall running time of Procedure RS-Decompose becomes  for general graphs, and  for graphs of girth at least .
In the former case , while in the latter it is . To summarize, we have proved the following theorem.
\begin{thm} \label{rsdecom}
Procedure RS-Decompose invoked on an -vertex graph  with a parameter  computes an -network-decomposition  and an -partition  of degree  of length  for  in  randomized time for general graphs, and in  time in graphs of girth at least .
\end{thm}
See Corollary \ref{partdec} for the comparison between the result here and the result that we have for the original variant of our algorithm.

Also in a way analogous to Corollary \ref{improvement}, Theorem \ref{rsdecom} implies that we can also compute a labeling for the network-decomposition . The time required to compute an -coloring for  given an -partition as above is, by Theorem \ref{arbc}, at most . The number of labels (colors) is . We summarize the properties of the network-decomposition  in the next corollary.
\begin{col}
An -network-decomposition  along with an -labeling for it can be computed in  (respectively,  ) randomized time in general graphs (resp., in graphs of girth at least ).
\end{col}
Observe that randomization was used by the modified variant of Procedure Decompose only for computing a ruling set and for computing the labeling. There is a deterministic algorithm for computing -ruling sets in  time due to \cite{AGLP89}. If we plug it in the above algorithm the diameter of  grows from  to , and consequently, the running grows to  as well. (The most time-consuming step involves computing a -ruling set in the last phase of the algorithm, i.e., in a supergraph in which each cluster has diameter . This requires  time.)
Hence we obtain the following result, which is a generalization of the network decomposition of \cite{AGLP89}. (They arrived to the same result with , i.e., they obtained an )-network-decomposition.)
\begin{col} \label{polylgdecom}
An -network-decomposition  along with  an -partition  of degree  of length  for  can be computed in deterministic  time in general graphs.
\end{col}
This also gives rise to a construction of -spanner with  edges, in deterministic  time, in the CONGEST model. This is achieved by adding one edge for every pair of adjacent clusters of the decomposition of Corollary \ref{polylgdecom}. By setting , for a constant , one can get  time and  edges. In particular, this results in a sparse skeleton (with  edges), in time , for an arbitrarily small constant , in the deterministic CONGEST model.

Using the -decomposition of  from Corollary \ref{polylgdecom} an -labeling for it (i.e., -coloring) for  can be computed by Algorithm Arb-Linial within additional  deterministic time. (This is another point in which this deterministic routine is different from that of \cite{AGLP89}. To compute the coloring Awerbuch et al. \cite{AGLP89} used here  time, but the number of colors was only  instead of . Since we insist on having a deterministic polylogarithmic time, this modification is crucial.)
\begin{col} \label{polylogdecom}
For any positive integer , an -network-decomposition  along with an -labeling of it can be computed in  deterministic time.
\end{col}
By running a -round version of Algorithm Arb-Linial, for some positive integer constant , one can also have here running time , but the number of colors (labels) becomes .































\section{Applications}
\subsection{An Approximation Algorithm for the Coloring Problem}
The results described in the previous sections (Theroem \ref{dlarge}; see also Corollary \ref{improvement}) imply an approximation algorithm for the optimization variant of the coloring problem. 
A distributed approximation algorithm for the graph coloring problem (based on an -network decomposition) was given in \cite{B12}. We describe here a generalization of that algorithm which works with any network-decomposition.
The algorithm starts by computing a -network-decomposition  with an -labeling  for it. See Corollary \ref{improvement}. Then in each cluster  the entire induced subgraph  is collected into the leader vertex  of . The leader vertex  computes locally the optimum coloring  for . Finally,  broadcasts (a table representation of ) to all vertices of . Each vertex  that receives this broadcast computes its final color  by . The running time of this algorithm is the sum of the time required to compute the decomposition  (i.e., ) with the time required for the computation of the colorings . The latter is dominated by the diameter of , times a small constant. The overall running time is therefore .

The next lemma shows that the coloring  provides an -approximation to the optimal coloring for . \begin{lem} \label{appcol}
 is a proper -coloring.
\end{lem}
\begin{proof}
Consider an edge . If , for some cluster , then , and so . Otherwise, let  (respectively, ) be the cluster that contains  (resp., ), and . The clusters  and  are adjacent in , and thus . Hence , and so . 

Note also that , for every vertex subset . The coloring  employs  colors, i.e., .
\end{proof}We proved the following theorem:
\begin{thm} \label{mincol}
For any -vertex graph  and an integer parameter , an -approximation of the optimal coloring for  can be computed in  time.
\end{thm}
In particular, by setting the parameter  to be an arbitrarily large constant we can get a distributed -approximation algorithm for the coloring problem with a {\em constant} running time, for an arbitrarily small constant . (The running time is .)
This greatly improves the current state-of-the-art constant-time distributed approximation algorithm for the coloring problem due to \cite{B12}, which provides an approximation guarantee of . On the other hand, the dependence of the running time on  is only  in the result of \cite{B12}.


Note that the algorithm in Theorem \ref{mincol} requires very heavy (exponential in ) local computations and large messages. The heavy computations are inevitable, because unless , the coloring problem cannot be approximated up to a ratio of , for any constant  \cite{H96,FK98,Z07}.
\subsection{Coloring Triangle-Free Graphs and Graphs with Large Girth}
A result of Ajtai et al \cite{AKS80} shows that triangle-free -vertex graphs  admit an -coloring. (This existential bound was shown to be tight by Kim \cite{K95}.) Here we show that one can construct an -coloring of triangle-free graphs in distributed randomized  time. Moreover, unlike our algorithm from the previous section, this algorithm uses only {\em short} messages and does not rely on heavy local computations.

The algorithm starts with invoking the algorithm from Corollary \ref{partdec} on its input -vertex graph  with the parameter . We obtain a -network decomposition  in  time. Moreover, the algorithm also constructs an -partition  of the vertex set  of  into two sets. The degree of this -partition is . The clusters in  are singleton clusters. (Each such a cluster  contains a single vertex  such that .) Each cluster  is a star rooted at a center vertex . Also, since the graph is triangle-free, neighbors of  are not connected via edges one with another.

Centers of clusters of  now toss a color for their cluster from . If a color tossed by the root  of  is different from the colors of clusters incident on  in the supergraph , then  stops. Otherwise it continues. Overall, as we have seen, after  rounds, clusters of  will be colored in  colors. (The communication between centers of adjacent clusters can be executed efficiently using short messages.
This requires some care. The root  of each cluster informs all vertices of  of its choice of color. Then each vertex of  (including ) sends the root's color  over inter-cluster edges incident on them. Then every vertex  checks if one of its neighboring clusters chose a color  equal to . If it is the case, then it informs . In this case  abandons its color (and informs all vertices of  about it), and continues to the next round of the randomized coloring procedure.) Then clusters of  toss colors for them from the same range. Since each cluster of  has only  neighbors in , the coloring will be computed within additional  rounds.
Finally within each cluster  actually two colors are used. (One for the center, and another for its neighbors.) Hence the overall number of colors is at most . The factor  can be swallowed by slightly increasing the  in the exponent. To summarize:
\begin{thm} \label{colortrianglefree}
An -coloring of triangle-free -vertex graph can be computed in  distributed randomized time, using short messages and polynomially-bounded local computations.
\end{thm}
This result extends also to graphs with large girth. Specifically, consider a graph  with girth greater than , for some integer . The arboricity of  is at most . (See, e.g., \cite{B04}. Theorem 3.7.) By \cite{BE08}, an -partition , , of  with degree  can be computed in constant time, for an arbitrarily small . Hence, by Theorem \ref{arbc}, an -coloring of  can be computed in  time. By scaling  we obtain the following result.
\begin{thm} \label{colorlargegirth}
For a graph  with girth greater than , and an arbitrarily small constant , an -coloring can be computed in constant distributed randomized time (specifically, ),  using short messages and polynomially-bounded local computations.
\end{thm}


Note that the algorithm from Theorem \ref{colorlargegirth} does not employ a network decomposition. Observe also that for  (i.e., girth greater than ) the numbers of colors in Theorems \ref{colortrianglefree} and \ref{colorlargegirth} are the same, and both are existentially tight up to a slack factor of . On the other hand, their proofs are different. However, Theorem \ref{colortrianglefree} applies for  too, while Theorem \ref{colorlargegirth} applies only for . So the result of Theorem \ref{colorlargegirth} is mainly of interest for  (i.e., ).


















\subsection{Separated Decompositions} \label{sc:strongdecomp}
For the sake of some applications we need a stronger notion of network decompositions, called a {\em -separated -network-decomposition}, for positive parameters , , and  \cite{ABCP96}. An -network-decomposition  of a graph  is called {\em -separated} if the clusters of  can be -colored in such a way that every pair of clusters  which are colored by the same color are at distance at least  from one another, i.e., . Observe that an ordinary network decomposition is -separated.


It is very easy to convert any procedure that constructs an ordinary (-separated) -network-decomposition into a procedure that constructs a {\em weak} -separated -network-decomposition, for any parameter . (See Section \ref{sc:preliminaries} for the definition of weak decomposition.) Specifically, one just executes the procedure for computing an ordinary -network-decomposition on the graph . As a result one obtains a partition  of  such that each cluster  has diameter at most  in , and thus weak diameter at most   in .
Also, for any pair  of distinct clusters in  which are colored by the same color, the distance between them in  is at least , and so the distance between them in  is at least . Hence  is a weak -separated -network-decomposition of . Simulating a distributed algorithm for  in  increases the running time by a factor of . (Here we assume that message size is unbounded.) Therefore, Corollary \ref{partdec} implies the following result.
\begin{col} \label{sdecpr}
For a pair of positive integer parameters , a -separated weak -network-decomposition  and an  partition  of length  and degree  for  can be computed in randomized  time, with high probability. Moreover, for an integer parameter , one can compute an -labeling for  in  time.
\end{col}
We remark that this simple approach for converting network-decompositions into weak separated ones is not new. It was used, e.g., by Dubhashi et al. \cite{DMPRS05}.

Next we show that our algorithm for constructing ordinary -network-decompositions can be adapted to compute {\em strong} -separated -network-decomposition in randomized time , for an arbitrary integer parameter .


In what follows we describe Procedure Sep-Decompose which generalizes Procedure Decompose (Algorithm \ref{proced:decompose}). It accepts as input all the parameters of Procedure Decompose, and also the separation parameter . Consider again Procedure Decompose (Algorithm \ref{proced:decompose}). The termination condition of the procedure (lines 1-2, the case when the size  is small, i.e., ) stays unchanged. In the general case (the "else" case of the procedure, lines 3-15) Procedure Decompose starts with invoking Procedure Partition, which decomposes the input graph  into  and . In the original procedure the subgraph  induced by  has a small maximum degree (at most , where  is an input parameter of Procedure Partition.) The generalized variant of the procedure (Procedure Sep-Decompose) invokes instead a generalized variant of Procedure Partition, called {\em Procedure Sep-Partition}. The latter procedure accepts as input all the parameters of Procedure Partition, but also the separation parameter . It also decomposes the input graph  into  and , but  has the property that  has maximum degree , i.e., for every vertex , there are at most  other vertices of  at distance at most  from . (The distance is with respect to .) Similarly to Procedure Partition, in Procedure Sep-Partition too the set  is a collection of at most  clusters of small diameter in . However, the diameter grows from  in the case of Procedure partition, to  in Procedure Sep-Partition.

Then Procedure Sep-Decomposition invokes Procedure Dec-Small. (See line 5 of Algorithm \ref{proced:decompose}.)
Procedure Dec-Small converts every vertex  into a separate cluster. (If  is the original graph  then every vertex  gives rise to a cluster . Otherwise  is a supergraph of the original graph , and a vertex  is a cluster of .) The resulting set of clusters is denoted by . Procedure Dec-Small also returns a labeling for clusters of , but similarly to the case of Section \ref{sc:refine}, this labeling is immaterial for our discussion.

On line 6 of algorithm \ref{proced:decompose} Procedure Sep-Decompose invokes itself recursively on the supergraph  induced by the set  of clusters. The rest of the procedure stays unchanged.

At this point we are interested in a version of Procedure Sep-Decompose which only computes a separated network-decomposition without a labeling function for it. (See the beginning of Section \ref{sc:refine}.) To recap, this procedure returns a network-decomposition , where  is an -partition of the supergraph  induced by this decomposition. (See Lemmas \ref{sets} and \ref{partitions}.) Moreover, it is easy to verify that decompositions  produced by Procedure Sep-Decompose satisfy a stronger property than decompositions produced by Procedure Decompose. Specifically, by construction, for every index , a cluster  has at most  other clusters  at distance at most  from it in . This fact is summarized in the next lemma.
\begin{lem} \label{partitionofgraph}
 is an -partition with degree  of the supergraph , where .
\end{lem}
By invoking one of the algorithms from Section \ref{sc:refine} for coloring low-arboricity graphs (for which a short low-degree -partition is provided) we can obtain an -labeling for , which has the property that any two distinct clusters  which receive the same label are at distance at least  from one another in , and thus at distance at least  from one another in . The running time of this step is . (See Theorem \ref{partdec}.) Alternatively, one can have an -labeling with this property in time . (See Corollary \ref{improvement}.)

Next we analyze . To do it we first describe Procedure Sep-Partition. (See Algorithm \ref{proced:partitin} for Procedure Partition.) The procedure accepts the same parameters as Procedure Partition, but also the separation parameter . (In fact, Procedure Partition is a special case of Procedure Sep-Partition, where .) Similarly to Procedure Partition, in Procedure Sep-Partition every vertex  selects itself (joins ) independently at random with probability . Then every selected vertex  sends an exploration message to distance  from it in . Every vertex  which is not selected () and receives at least one exploration message joins the cluster centered by the closest originator of an exploration message received by . (Ties are broken in an arbitrary but consistent way according to the identities of originators. If originators themselves are clusters, then each of them has its own leader whose identity serves as the identity of the cluster. The consistent rule for breaking ties may be, for example, to prefer an originator with a smaller identity.) Other vertices join the set . The procedure returns the set  and the set  of clusters which are created in the way described above. Observe that if  is not the original graph but rather a supergraph of it then the algorithm is executed by clusters rather than by single vertices. In other words, in this case the center of each cluster simulates all the operations that need to be performed by the cluster.

The next lemma shows that clusters created by Procedure Sep-Partition are connected and have bounded diameter.
\begin{lem} \label{invokepartition}
Consider an invocation of Procedure Sep-Partition(), where  is a parameter and  is an integer parameter. Then each vertex  has degree  in , and each cluster  has (strong) diameter at most  in .
\end{lem}
\begin{proof}
Let  be a sufficiently large fixed constant, and consider a vertex  such that a -neighborhood  of  in  contains at least  vertices. Then with probability at least  at least one of the vertices  joins , and the vertex  becomes clustered. Hence with probability at least  all vertices  with  become clustered, and so each unclustered vertex  satisfies .

Consider a cluster . It is centered around an originator  of an exploration message. (The vertex  belongs to , i.e., it is selected.) Consider a vertex , and let  be a shortest  path in . Let  be a vertex on this path. (Note that  are vertices of , i.e., they are possibly clusters themselves.) It follows that  is the closest selected vertex to , and if there exists another selected vertex  which satisfies , then  has a smaller identity than . (As otherwise  would rule  as well.) Hence . Consequently all vertices of  are in , and the length of  is at most . Hence the cluster  has strong radius at most , i.e., strong diameter at most .
\end{proof}
Observe also that by the same argument as in Lemma \ref{partitnscnd}, the number of clusters in  is, with high probability, . We are now ready to analyze the diameter  of the ultimate network-decomposition . The following lemma generalizes Lemma \ref{dec}.
\begin{lem}
Let  be a -separated network-decomposition produced by the invocation Sep-Decompose() on an input graph . Then for each , .
\end{lem}
\begin{proof}
We prove by induction on  that in the th level recursive invocation of Procedure Sep-Decompose each vertex  of the input graph  of this invocation is a cluster of the original graph  with diameter at most .
Since for each , clusters of  are vertices of  the assertion of the lemma follows from the inductive claim.\\
{\bf Base:} .\\
{\bf Step:} Consider an index . By Lemma \ref{invokepartition}, each cluster  created by the th level invocation of Procedure Sep-Decompose has strong diameter at most  in . It follows that

By induction hypothesis it follows that

Since vertices  of  are clusters which were formed by the th level invocation of Procedure Sep-Decompose, the assertion of the lemma follows.
\end{proof}

We summarize this discussion with the following corollary.
\begin{col} \label{separatedcol}
Consider an invocation of Sep-Decompose(), where  are integer parameters. It produces a -separated strong -network-decomposition , along with an -partition  for . The running time of this invocation is .
\end{col}
As was discussed in the paragraph following Lemma \ref{partitionofgraph}, using this network-decomposition one can compute an -labeling for  within additional  rounds, or alternatively, an -labeling within additional  rounds. In both cases the labeling satisfies that any two distinct clusters  which receive the same label are at distance at least  one from another in .

































One can also improve the parameters of the network-decomposition from Corollary \ref{separatedcol} from  to  at the expense of increasing the running time from  to  in general graphs, and  in graphs with girth at least . This is done by introducing to Procedure Sep-Decompose a modification analogous to the one that we introduced to Procedure Decompose in Section \ref{sc:betterlabels}.
Recall that the difference between Procedure RS-Decompose and Procedure Decompose is that the former invokes Procedure RS-Partition as a subroutine, while the latter invokes Procedure Partition.

Procedure RS-Partition computes a -ruling set  for the set  of high degree vertices of its input graph , for a parameter . The variant of this procedure that we are now describing, called Procedure Sep-RS-Partition, accepts as input also the separation parameter , and computes a -ruling set  for the set  of vertices that have at least  vertices in their -ball. The clusters  are then created in the same way as in Procedure RS-Partition. In particular, their strong radii are still bounded by . Also, every vertex  is assigned to some cluster. The sets  and  are now formed as in Procedure RS-Partition. Every vertex  now satisfies . The following lemma is analogous to Lemma \ref{rprulin}, and its proof is very similar to that of Lemma \ref{rprulin}.
\begin{lem} \label{rpinv}
Suppose that Procedure Sep-RS-Partition is invoked on a graph  and positive parameters  and . Suppose further that it uses a subroutine for computing a -ruling set, for a positive integer parameter . Then in the subgraph  every vertex  satisfies . Moreover,  consists of at most  supernodes, each of which is a cluster of strong diameter at most .
\end{lem}
It follows now that Procedure Sep-RS-Decompose computes a -separated -network-decomposition . For the running time we need again to specify the running time required for computing a -ruling set. By running the algorithms for computing a ruling set due to Barenboim et al. \cite{BEPS12} and Kothapalli and Pemmaraju \cite{KP12} respectively in  we obtain a -ruling set in the case of general graphs, and a -ruling set in the case of graphs of girth at least . In both cases , and the running time is  in the former case and  time in the latter.
The rest of the analysis is identical, except that the overall running time of Procedure Sep-RS-Decompose becomes  and  in the cases of general graphs and graphs of girth at least , respectively.
\begin{thm}
Procedure Sep-RS-Decompose invoked on an -vertex graph  with positive integer parameters  and  computes a -separated strong -network-decomposition  in randomized time  in general graphs and in  randomized time in graphs of girth at least .
\end{thm}
One application of strong separated network-decomposition is {\em low-intersecting partitions}. Low-intersecting partitions were introduced by Busch et al. \cite{BDRRS12}, in their work on universal Steiner trees. A {\em low-intersecting -partition}  of a graph  is the partition of the vertex set  such that \\
(1) Every cluster  in  has strong diameter at most . \\
(2) For every vertex , a ball  of radius  around  intersects at most  clusters of .\\

Busch et al. showed that given a hierarchy of low-intersecting partitions with certain properties (see \cite{BDRRS12} for details) one can construct a universal Steiner tree. (See \cite{BDRRS12} for the definition of universal Steiner tree.) Also, vice versa, given universal Steiner tree they showed that one can construct a low-intersecting partition. They constructed a low-intersecting partition with , and arbitrary .

We next argue that a -separated strong -network-decomposition  is also a low-intersecting partition with parameters ). Indeed, every cluster  of  has strong diameter at most . Moreover, consider a vertex  and a ball  of radius  around . Observe that for every color class  of , the ball  can intersect at most one cluster  colored by . (This is because for every two -colored clusters , it holds that .)
Hence altogether  may intersect up to  clusters of . This proves the claim.

Therefore, our distributed algorithm for computing a -separated strong -network-decomposition in distributed randomized time  in general graphs and in \\  in graphs of girth at least  provides also a distributed algorithm with the same running time for constructing a low-intersecting -partition.
We summarize:
\begin{col}
For any pair of positive integer parameters , a low-intersecting -partition can be constructed in  randomized time in general graphs and in  randomized time in graphs of girth at least .
\end{col}
We remark that this construction can be implemented using short messages. \\ Comparing this result with the algorithm of Busch et al. \cite{BDRRS12} we note that the partition of \cite{BDRRS12} has smaller radius. (It is  instead of  in our case.) On the other hand, the intersection parameter  of our partitions is smaller. (It is  instead of .) In particular, the intersection parameter in the construction of \cite{BDRRS12} is always , while ours can be as small as one wishes. Finally, the algorithm of Busch et al. \cite{BDRRS12} is not distributed, and seems inherently sequential.
































\subsection{Approximation Algorithms for the Minimum Dominating Set and Minimum -Spanner Problems}
In this section we employ our network-decomposition algorithm in order to derive approximation algorithms for the minimum dominating set and minimum -spanner problems.
Suppose that we are given a -separated -network-decomposition  of a graph . For each cluster , we compute in parallel a dominating set  of , such that  has minimum cardinality among all dominating sets  of . The computation of  is performed by collecting the topology of the clusters and their neighborhoods by the leaders of respective clusters, performing the computation locally using exhaustive search\footnote[1]{We note that once can employ polynomial-time local computations instead of exhaustive search in the expense of increasing the approximation ratio by a factor of . See Section \ref{sc:fast}.} , and broadcasting the results to the vertices of the clusters and their neighbors. Since the weak diameter of the clusters is at most , this requires  rounds. We next show that the resulting set obtained by taking the union of the dominating sets in all clusters constitutes an -approximate minimum dominating set of the input graph .
\begin{lem} \label{dset}
For a -separated -network-decomposition , suppose that we have computed a minimum dominating set  of , for each cluster . Then .
\end{lem}
\begin{proof}
For , let  denote the set of all vertices with label  in the network-decomposition . Let . We claim that ,
where  is a minimum dominating set of . (Note that in the current proof the notation  stands for a {\em cluster}  that belongs to , rather then just a subgraph of , since  is defined only for clusters.) 
Let  be a cluster of label , . 
Then . Observe that  is a dominating set of . (Since  is a dominating set of , and any vertex in  does not dominate any vertex in .) Therefore, . Note also that for any cluster  of label  it holds that . Indeed,  is a -separated network-decomposition, and thus, for any  it holds that . Hence for any , it holds that , and thus . Consequently,  
Therefore,

\end{proof}



Recall that by Corollary \ref{polylgdecom}, there is a routine that computes an -network-decomposition in deterministic time , for any . As was discussed above, this routine can also be adapted to compute a weak -separated network-decomposition with the same properties within the same running time. (See Section \ref{sc:strongdecomp}; both the diameter parameter and the running time grow by a constant factor .) Also, similarly to Corollary \ref{separatedcol}, one can adapt this routine so that it will compute a strong network-decomposition with the same parameters and the same running time. (The diameter and the running time grow by a factor of , which is however swallowed by the notation .) Using this network-decomposition in conjunction with Lemma \ref{dset} we obtain the following theorem.
\begin{thm}
For an -vertex graph , and a positive integer parameter  an -approximation for the minimum dominating set problem can be computed in deterministic time .
\end{thm}
Another problem for which an efficient approximation algorithm can be obtained using network-decompositions is the {\em minimum -spanner} problem. Given an (unweighted) graph  and a positive integer parameter , a subgraph , , is a {\em -spanner} of  if for every pair  of vertices, . In the {\em minimum -spanner} problem the objective is to find a -spanner of the input graph with as few edges as possible.

Suppose that we are given a -separated -network-decomposition  of an input graph .
Let  be a single color class of this labeling, i.e.,  for each , and , for every pair of distinct indices , . Let , for every . Note that , for every pair of distinct indices . Denote , and consider a minimum -spanner  for  which is allowed to use edges from . Let also  be a minimum -spanner for .
\begin{lem} \label{tspan}
.
\end{lem}
\begin{proof}
Observe that the restriction  of  to  is a -spanner for . Indeed, consider an edge . Let  be the cluster such that . Then  contains a path of length at most  between  and , and so this path belongs to .

The lemma now follows as  is the minimum -spanner for  which is allowed to use edges from , while  is a -spanner for  of this type. Hence .
\end{proof}
Denote also by  the minimum -spanner for  which is allowed to use edges of .
\begin{lem} \label{tspansetsmall}
.
\end{lem}
\begin{proof}
Obviously,  is a -spanner for  which uses only edges of . Hence by optimality of , .

In the opposite direction, for every index , let . By optimality of , . Also, for every pair of distinct indices , . (This is because .)
Hence
 
(The last inequation is, in fact, equality.)
\end{proof}
In other words, to compute a minimum -spanner  for  one can compute minimum -spanners  for  (which are allowed to use edges of , respectively), and take their union.
Our distributed algorithm will do precisely this. In each cluster  of  it computes a minimum -spanner for  using edges of , . This computation is done by collecting the entire topology of  into a vertex in , doing a local (possibly very heavy) computation, and informing all vertices of  about the results of this computation. The union of all these -spanners will be our ultimate spanner. Hence the algorithm returns a spanner , where for each index ,  is a minimum -spanner for , where  is the set of all vertices labeled by  in the network decomposition . (In other, words, they belong to clusters of color . Note, however, that to execute the algorithm we do not need to know these colors/labels.) Since by Lemma \ref{tspansetsmall}, for every , , it follows that the algorithm returns an -approximation. The running time of the algorithm is . To summarize:
\begin{thm}
For any pair of positive integer parameters  an -approximation of the minimum -spanner problem in -vertex graphs can be computed in  randomized time.
\end{thm}
Observe that the same result applies to the -spanner problem in {\em directed} graphs, by the same argument. Note that even though the graph is directed, we assume that the communication over every edge is bidirectional. 







\section{Removing heavy local computations from the minimum dominating set and minimum -spanner algorithms} \label{sc:fast}
It is well known that an -approximation of minimum dominating set can be computed in polynomial time in the sequential setting. (See, e.g., \cite{W04}.) However, this approach cannot be applied directly to our algorithms since we compute minimum dominating sets  of clusters , such that  rather than .
On the other hand, this problem reduces to the Set Cover problem with both the degree parameters (i.e., the maximum cardinality of a set and the maximum number of sets that share an element) bounded by . Hence this problem admits a polynomial-time -approximation algorithm. (See, e.g., \cite{SS12}.) One can also extend the classical centralized -approximation algorithm for the MDS problem directly to our slightly more general problem. This extension is described below.
Consequently, we can obtain a dominating set whose size is at most  the size of the minimum dominating set of  consisting of vertices of . This can be achieved in the following way. Initially . We proceed in phases, each time selecting a vertex  from  such that  is maximal, and adding  to .  (Ties are broken by preferring vertices that belong to , and if this does not solve the tie, it is broken arbitrary.)  Once no uncovered vertex remains we are done.

Let  be a minimum dominating set of . We claim that . The proof is by amortized analysis. Each time a vertex  is added to  we assign a weight  to each vertex of . Observe that the sum of all weights assigned during this procedure is . Next, (for analysis) let each vertex of  select a single vertex from  that dominates it. Consider a vertex  and the set  of all neighbors of  in  that selected .
Next, we analyze the sum of weights of . For each  it is assigned a weight once a neighbor of  (or  itself) joins the dominating set . Let  be the number of the phase in which it happens, and  denote the number of neighbors of  in  that are not covered in the beginning of phase . Also, let  denote the neighbor that dominates , for which  obtained its weight. Since in each phase a vertex  with maximal  is selected, it holds that . Consequently,  is assigned a weight at most . Therefore, the sum of weights of  is at most . Therefore, the sum of all weights in the graph is . This completes the proof. 

A similar idea can be applied in the case of the minimum -spanner problem. Again, we need a centralized polynomial-time approximation algorithm for the minimum -spanner for edges of  (for a cluster ), while the spanner is allowed to use edges of . This is an instance for the {\em client-server -spanner} problem, and for the case  it was devised in \cite{EP01}. By plugging it in our distributed algorithm for approximating spanners we obtain a distributed -approximation algorithm with running time  for the directed and undirected -spanner problem. The latter algorithm only employs polynomially-bounded local computations. To the best of our knowledge, there are no existing centralized algorithms with a non-trivial approximation guarantee for the client-server -spanner problem for . It is however likely that the LP-based approaches to the minimum -spanner problem (such as \cite{BBMRY11,DK11}) extend to this more general problem.
 

\begin{thebibliography}{10}

\bibitem{ABCP96}
B.~Awerbuch, B.~Berger, L.~Cowen, and D.~Peleg.
\newblock  Fast Distributed Network Decompositions and Covers.
\newblock {\em Journal of Parallel and Distributed Computing}, 39(2):105-114, 1996.

\bibitem{AKS80}
M.~Ajtai, J.~Komlos, and E.~Szemeredi.
\newblock A note on Ramsey numbers.
\newblock {\em Journal of Combinatorial Theory, Series A}, 29:354-360, 1980.







\bibitem{AGLP89}
B.~Awerbuch, A.~V. Goldberg, M.~Luby, and S.~Plotkin.
\newblock Network decomposition and locality in distributed computation.
\newblock In {\em Proc. of the 30th Annual Symposium on Foundations of Computer Science}, pages 364--369, 1989.

\bibitem{AP90}
B.~Awerbuch, and D,~Peleg.
\newblock Sparse partitions.
\newblock In {\em Proc. of the 31st IEEE Symp. on Foundations of Computer Science.} pages  503–513, 1990.

\bibitem{B12}
L.~Barenboim.
\newblock On the locality of some NP-complete problems.
\newblock In {\em Proc. of the 39th International Colloquium on Automata, Languages, and Programming}, part II, pages 403-415, 2012.

\bibitem{BE08}
L.~Barenboim, and M.~Elkin.
\newblock Sublogarithmic distributed MIS algorithm for sparse graphs using Nash-Williams decomposition.
\newblock In {\em Proc. of the 27th ACM Symp. on Principles of Distributed Computing}, pages 25--34, 2008.

\bibitem{BE09}
L.~Barenboim, and M.~Elkin.
\newblock Distributed -coloring in linear (in ) time.
\newblock In {\em Proc. of the 41th ACM Symp. on Theory of Computing}, pages 111-120, 2009.

\bibitem{BE10}
L.~Barenboim, and M.~Elkin.
\newblock Deterministic distributed vertex coloring in polylogarithmic time.
\newblock In {\em Proc. 29th ACM Symp. on Principles of Distributed Computing}, pages 410-419,  2010.


\bibitem{BE13}
L.~Barenboim, and M.~Elkin.
\newblock {\em Distributed Graph Coloring: Fundamentals and Recent Developments.}
\newblock Morgan-Claypool Synthesis Lectures on Distributed Computing Theory, 2013.

\bibitem{BEPS12}
L.~Barenboim, M.~Elkin, S.~Pettie, and J.~Schneider.
\newblock The locality of distributed symmetry breaking.
\newblock In {\em Proc. of the 53rd Annual Symposium on Foundations of Computer Science}, pages 321-330, 2012.



\bibitem{BBMRY11}
P.~Berman, A.~Bhattacharyya, K.~Makarychev, S.~Raskhodnikova, and G.~Yaroslavtsev.
\newblock Improved approximation for the directed spanner problem. 
\newblock In {\em Proc. of the 38th International Colloquium on Automata, Languageas, and Programming}, pages 1-12, 2011.

\bibitem{BKP14}
T.~Bisht, K.~Kothapalli , S.~Pemmaraju.
\newblock Super-fast t-ruling sets (Brief Announcement).
\newblock In {\em Proc. of the 33th ACM Symposium on Principles of Distributed Computing}, pages 379-381,  2014.

\bibitem{B04}
B.~Bollobas.
\newblock {\em Extremal Graph Theory.}
\newblock Dover Publications, 2004.


\bibitem{BDRRS12}
C.~Busch, C.~Dutta, J.~Radhakrishnan, R.~Rajaraman, and S.~Srinivasagopalan.
\newblock Split and join: strong partitions and universal Steiner trees for graphs.
\newblock in {\em Proc. of the 53rd Annual IEEE Symposium on Foundations of Computer Science}, pages 81 - 90, 2012. 




\bibitem{CV86}
R.~Cole, and U.~Vishkin.
\newblock Deterministic coin tossing with applications to optimal parallel list ranking.
\newblock {\em Information and Control}, 70(1):32--53, 1986.

\bibitem{C93}
L.~Cowen.
\newblock On Local Representations of Graphs and Networks. {\em Ph.D. Thesis, MIT.} 1993.







\bibitem{DGPV08}
B.~Derbel, C.~Gavoille, D.~Peleg, and L.~Viennot.
\newblock On the locality of distributed sparse spanner construction.
\newblock In {\em Proc. of the 27th ACM Symp. on Principles of distributed Computing}, pages 273-282, 2008.

\bibitem{DK11}
M.~Dinitz, and R.~Krauthgamer.
\newblock Directed spanners via flow-based linear programs.
\newblock In {\em Proc. of the 43rd ACM Symp. on Theory of Computing}, pages 323-332, 2011.


\bibitem{DMPRS05}
D.~Dubhashi, A.~Mei, A.~Panconesi, J.~Radhakrishnan, and A.~Srinivasan.
\newblock Fast distributed algorithms for (weakly) connected dominating sets and linear-size skeletons.
\newblock {\em Journal of Computer and System Sciences}, 71(4):467-479, 2005.




\bibitem{E07}
M.~Elkin.
\newblock A near-optimal distributed fully dynamic algorithm for maintaining sparse spanners.
\newblock In {\em Proc. of the 26th ACM Symp. on Principles of Distributed Computing}, page 185-194, 2007.

\bibitem{EP01}
M.~Elkin, and D.~Peleg.
\newblock The client-server 2-spanner problem with applications to network design. 
\newblock In {\em Proc. of the 8th International Colloquium on Structural Information and Communication Complexity}, pages 117-132, 2001.




\bibitem{EP05}
M.~Elkin, and D.~Peleg.
\newblock Approximating -spanner problems for .
\newblock {\em Theoretical Computer Science}, 337(1-3): 249-277, 2005.


\bibitem{EFF85}
P.~Erd\H{o}s, P.~Frankl, and Z.~F\"uredi.
\newblock Families of finite sets in which no set is covered by the union of  others.
\newblock {\em Israel Journal of Mathematics}, 51:79--89, 1985.

\bibitem{FK98}
U.~Feige, and J.~Kilian.
\newblock Zero Knowledge and the chromatic number.
\newblock {\em Journal of Computer and System Sciences} 57:187--199, 1998.


\bibitem{GV07}
B.~Gfeller, and E.~Vicari.
\newblock A randomized distributed algorithm for the maximal independent set problem in growth-bounded graphs.
\newblock In {\em Proc. of the 26th ACM Symp. on Principles of Distributed Computing}, pages 53-60, 2007.

\bibitem{GPS87}
A.~Goldberg, S.~Plotkin, and  G.~Shannon.
\newblock Parallel symmetry-breaking in sparse graphs.
\newblock {\em SIAM Journal on Discrete Mathematics}, 1(4):434--446, 1988.







\bibitem{H96}
J.~Hastad.
\newblock Clique is Hard to Approximate Within . 
\newblock In {\em Proc. of the 37th Annual Symposium on Foundations of Computer Science}, pages 627-636, 1996.




\bibitem{JRS01}
L.~Jia, R.~Rajaraman, and R.~Suel.
\newblock An efficient distributed algorithm for constructing small dominating sets.
\newblock In {\em Proc. of the 20th ACM Symp. on Principles of Distributed Computing}, pages 33-42, 2001.




\bibitem{K95}
J.H.~Kim.
\newblock The Ramsey number  has order of magnitude .
\newblock {\em Random Structures and Algorithms}, 7:173-207, 1995.


\bibitem{KP94}
G.~Kortsarz, and D.~Peleg.
\newblock Generating sparse 2-spanners.
\newblock {\em Journal of Algorithms}, 17(2): 222-236, 1994.


\bibitem{KP12}
K.~Kothapalli, and S.~Pemmaraju.
\newblock Super-fast -ruling sets.
\newblock In {\em Proc. of the nd IARCS International Conference on Foundations of Software Technology and Theoretical Computer Science}, pages 136 - 147, 2012.



\bibitem{K09}
F.~Kuhn.
\newblock Weak graph colorings: distributed algorithms and applications. 
\newblock In {\em Proc. of the 21st ACM Symposium on Parallel Algorithms and Architectures},  pages 138--144, 2009.



\bibitem{KMW05}
F.~Kuhn, T.~Moscibroda, and R.~Wattenhofer.
\newblock On the locality of bounded growth.
\newblock In {\em Proc. of the 24th ACM Symp. on Principles of Distributed Computing}, pages 60 -68, 2005.



\bibitem{KW05}
F.~Kuhn and R.~Wattenhofer.
\newblock Constant-time distributed dominating set approximation.
\newblock {\em Distributed Computing}, 17(4): 303-310, 2005.


\bibitem{KNPR14}
S.~Kutten, D.~Nanongkai, G.~Pandurangan, P.~Robinson.
\newblock Distributed Symmetry Breaking in Hypergraphs.
\newblock In {\em Proc. of the 28th International Symposium on Distributed Computing}, pages 469-483, 2014.

\bibitem{LOW08}
C.~Lenzen, Y.~Oswald, and R.~Wattenhofer.
\newblock What Can Be Approximated Locally? Case Study: Dominating Sets in Planar Graphs.
\newblock In {\em Proc 20th ACM Symp. on Parallelism in Algorithms and Architectures}, pages 46-54, 2008.
\newblock See also {\em TIK report number 331}, ETH Zurich, 2010.

\bibitem{LW10}
C.~Lenzen, and R.~Wattenhofer.
\newblock Minimum dominating set approximation in graphs of bounded arboricity.
\newblock In {\em Proc. of the 24th Symp. on Distributed Computing}, pages 510 -524, 2010.



\bibitem{L92}
N.~Linial.
\newblock Locality in distributed graph algorithms.
\newblock {\em SIAM Journal on Computing}, 21(1):193--201, 1992.

\bibitem{LS92}
N.~Linial and M.~Saks.
\newblock Low diameter graph decomposition.
\newblock {\em Combinatorica} 13: 441 - 454, 1993.



\bibitem{L86}
M.~Luby.
\newblock A simple parallel algorithm for the maximal independent set problem.
\newblock {\em SIAM Journal on Computing}, 15:1036-1053, 1986.



\bibitem{MU05}
M.~Mitzenmacher, and E.~Upfal.
\newblock {\em Probability and Computing: Randomized Algorithms and Probabilistic Analysis.}
\newblock Cambridge University Press, 2005.

\bibitem{N14}
D.~Nanongkai.
\newblock Distributed approximation algorithms for weighted shortest paths.
\newblock In {\em Proc. of the 46th ACM Symp. on Theory of Computing}, pages 565-573, 2014.



\bibitem{NS93}
M.~Naor, and L.~Stockmeyer.
\newblock What can be computed locally?
\newblock In {\em Proc. 25th ACM Symp. on Theory of Computing}, pages 184-193, 1993.



\bibitem{PR01}
A.~Panconesi, and R.~Rizzi.
\newblock Some simple distributed algorithms for sparse networks.
\newblock {\em Distributed Computing}, 14(2):97--100, 2001.

\bibitem{PS95}
A.~Panconesi, and A.~Srinivasan.
\newblock On the complexity of distributed network decomposition.
\newblock {\em Journal of Algorithms}, 20(2):581-ֵ92, 1995.







\bibitem{SS12}
R.~Saket, and M.~Sviridenko.
\newblock New and improved bounds for the minimum set cover problem.
\newblock {\em Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques 
Lecture Notes in Computer Science},  7408:288-300, 2012.

\bibitem{SEW13}
J.~Schneider, M.~Elkin, and R.~Wattenhofer.
\newblock Symmetry breaking depending on the chromatic number or the neighborhood growth.
\newblock {\em Theoretical Computer Science}, 509: 40-50, 2013.


\bibitem{SW08}
J.~Schneider, and R.~Wattenhofer.
\newblock A log-star distributed Maximal Independent Set algorithm for Growth Bounded Graphs.
\newblock In {\em Proc. of the 27th ACM Symp. on Principles of Distributed Computing}, pages 35--44, 2008.



\bibitem{Z07}
D.~Zuckerman.
\newblock Linear Degree Extractors and the Inapproximability of Max Clique and Chromatic Number.
\newblock {\em Theory of Computing}, 3(1):103--128. 2007.

\bibitem{W04}
www.disco.ethz.ch/lectures/ss04/distcomp/lecture/chapter12.pdf


\end{thebibliography}

\end{document}
