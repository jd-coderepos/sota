\documentclass[runningheads, envcountsame, a4paper]{llncs}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{boxedminipage}
\usepackage{url}

\begin{document}
\newcommand{\bs}{\mathcal{B}} \newcommand{\np}{\mathbf{0}} \newcommand{\pc}{\ |\ } \newcommand{\lpc}{\ \Big|\ } \newcommand{\ip}[2]{#1( #2 )} \newcommand{\op}[2]{\overline{#1}\langle #2 \rangle} \newcommand{\ol}[1]{\overline{#1}} \newcommand{\subs}[2]{\{#1/#2\}} 
\newcommand{\nt}{N} \newcommand{\at}{M} \newcommand{\pbt}[1]{[\![#1]\!]} 
\newcommand{\dotsim}{\ \dot{ \sim }\ } \newcommand{\ra}{\rightarrow} \newcommand{\Ra}{\Rightarrow} \newcommand{\xra}[1]{\xrightarrow{#1}} \newcommand{\xRa}[1]{\xRightarrow{#1}} 
\newcommand{\lc}{::} \newcommand{\dom}[1]{\texttt{dom}(#1)} \newcommand{\len}[1]{\texttt{|}#1\texttt{|}} \newcommand{\kw}[1]{\texttt{#1}} \newcommand{\mt}{\mapsto} \newcommand{\de}{\stackrel{def}{=}} \newcommand{\cf}[1]{\langle #1 \rangle} \newcommand{\tts}[1]{\texttt{\textsc{#1}}} \newcommand{\laop}{\texttt{<\!-}} \newcommand{\raop}{\texttt{-\!>}} 
\newcommand{\vs}{\vspace{1mm}} 
\newcommand{\nl}{\kw{nil}} \newcommand{\tsg}[1]{[\![#1]\!]_g} \newcommand{\tsgs}[1]{\mathcal{T}_{#1}} \newcommand{\lag}{\hookrightarrow_g} \newcommand{\lagx}[1]{\xhookrightarrow{#1}_g} \newcommand{\letg}{\mapsto_g} \newcommand{\letgx}[1]{\xmapsto{#1}_g} \newcommand{\gag}{\rightarrow_g} \newcommand{\gagx}[1]{\xrightarrow{#1}_g} \newcommand{\gagX}[1]{\xRightarrow{#1}_g} \newcommand{\kt}[1]{\underline{#1}} 
\newcommand{\gotype}[1]{\mathfrak{{#1}}} \newcommand{\gl}[1]{\mathtt{#1}} 
\newcommand{\lae}{\hookrightarrow_e} \newcommand{\laex}[1]{\xhookrightarrow{#1}_e} \newcommand{\gae}{\rightarrow_{e}}
\newcommand{\gaex}[1]{\xrightarrow{#1}_{e}}
\newcommand{\gaeX}[1]{\xRightarrow{#1}_e} \newcommand{\tse}[1]{[\![#1]\!]_e} \newcommand{\tses}[1]{\mathcal{T}_{#1}} \newcommand{\mb}{\mathfrak{m}} \newcommand{\MB}{\mathcal{M}} \newcommand{\erl}[1]{\mathtt{#1}} 



\title{The Buffered -Calculus: A Model for Concurrent Languages}
\titlerunning{The Buffered -Calculus}

\author{Xiaojie Deng\inst{1} \and Yu Zhang\inst{2} \and Yuxin Deng\inst{1} \and Farong Zhong\inst{3}}
\authorrunning{X. Deng, Y. Zhang, Y. Deng, and F. Zhong}

\institute{Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China
  \email{lvchaxj, yuxindeng@gmail.com}
\and Institute of Software, Chinese Academy of Sciences, Beijing, China
  \email{yzhang@ios.ac.cn}
\and Department of Computer Science, Zhejiang Normal University, Zhejiang, China
  \email{zfr@zjnu.cn}
}

\maketitle
\setcounter{footnote}{0}


\begin{abstract}
Message-passing based concurrent languages are widely used in developing large distributed and coordination systems.
This paper presents the buffered -calculus --- a variant of the -calculus where channel names
are classified into buffered and unbuffered: communication along buffered channels is asynchronous,
and remains synchronous along unbuffered channels.
We show that the buffered -calculus can be fully simulated in the polyadic -calculus with respect to strong bisimulation.
In contrast to the -calculus which is hard to use in practice, the new language enables easy and clear modeling
of practical concurrent languages. We encode two real-world concurrent languages in the buffered -calculus:
the (core) Go language and the (Core) Erlang. Both encodings are fully abstract with respect to weak bisimulations.

\keywords{process calculus, formal model, full abstraction}
\end{abstract}


\section{Introduction}
\label{sec:intro}

Concurrent programming languages become popular in recent years thanks to the large demand of distributed computing and
the pervasive exploitation of multi-processor architectures. Unlike the shared-memory concurrency model, which is now mainly
used on multi-processor platforms, message passing based concurrent languages are particularly popular in developing
large distributed, coordination systems.
Indeed, quite a few real-world concurrent languages are intensively used in industry.
The most well-known languages are probably Erlang, developed by Ericsson~\cite{Armstrong1997},
and the much younger language Go, developed by Google~\cite{GoSpec2012}.
Both languages achieve their asynchronous communication via order-preserving message passing.

On the other side, the -calculus~\cite{Milner1992,Sangiorgi2001} has shown its success
in modeling and verifying both specifications and implementations.
Its asynchronous variant~\cite{Boudol1992,Honda1991} is a good candidate as the target formal model.
Despite the fact that it is called asynchronous, communication in the asynchronous -calculus is however synchronous.
It is shown in \cite{Beauxis2008} that the communication modelled by the asynchronous -calculus
is equivalent to message passing via bags --- senders put messages into some bags, and
receivers may get arbitrary messages from these bags.
This result indicates that additional effort should be made to respect the order of the messages,
which is adopted in the implementation of many concurrent languages.

In view of this, we may expect a formal model where asynchronous communication is supported natively.
In fact, our primary goal is to achieve a formal model by which we can easily define a formal semantics of Go
and do verification on top of it.
The developers of Go claim that the concurrency feature of Go is rooted in CSP~\cite{Hoare1978},
while we show that the -calculus should be an appropriate model for Go
as CSP does not support transmission of channel names over channels.

In the spirit of the name passing mechanism of the -calculus and the channel type of the Go language,
we extend the -calculus by introducing a special kind of names, each associated with a first-in-first-out buffer.
We call these names {\em buffered names}. Communication along buffered names is asynchronous,
while that along unbuffered (normal) names remains synchronous.
We call this variant language the buffered -calculus, and abbreviate it as the -calculus.

We develop the -calculus by defining its operational semantics as a labelled transition system and
supplying an encoding into the polyadic -calculus.
We also present translations of the languages Go and Erlang into the -calculus
and show that the model is sufficient and relatively easier for modeling real-world concurrent languages.

\subsection{Related Work}

Beauxis \emph{et al} introduced the -calculus in order to
study the asynchronous nature of the asynchronous -calculus~\cite{Beauxis2008}.
Their asynchronous communication is achieved via explicit use of buffers.
In case that the buffers are ordered structures such as queues or stacks, the asynchronous communication
modelled by  differs from that by the asynchronous -calculus.
While communication in the -calculus is always asynchronous,
we keep both synchronous and asynchronous communication in the -calculus, through different types of names.

Encoding programming languages in process calculus have been studied by many researchers.
Milner defines the semantics of a non-trivial parallel programming language by a translation into CCS in \cite{Milner1989}.
In \cite{Walker1995}, a translation from a parallel object oriented language to the minimal -calculus is presented.
The correctness of the translation is justified by the operational correspondence between units and their encodings.
Our treatments to the Go language follows the approach in \cite{Walker1995}.
In addition, we show a full abstraction theorem, namely equivalent Go programs are translated into equivalent  processes.

For functional languages, Noll and Roy~\cite{Noll2005} presented an initial translation mapping
from a Core Erlang~\cite{Carlsson2000} to the asynchronous -calculus.
Later on they~\cite{Roy2006} improved the translation by revising the non-deterministic encoding of pattern matching based expressions,
and by adding the encoding for tuples.
Their translations, however, are not sound in the sense that the order of messages is not always respected.
By modelling the mailbox structure explicitly by buffered names in the -calculus,
we obtain a more accurate encoding which is fully abstract with respect to weak bisimulation.

\subsection{Outline}
The rest of the paper is structured as follows.
Section~\ref{sec:pib} presents the syntax and semantics of the -calculus and a simple encoding
in the polyadic -calculus~\cite{Milner1991}. We show that this encoding preserves the strong bisimulation relation.
In Section~\ref{sec:go} we define a formal semantics for Go and present an encoding of Go in the -calculus.
Section~\ref{sec:erlang} is devoted to Core Erlang, in which an improved encoding is presented.
And finally, Section~\ref{sec:con} concludes the paper.




\section{The -Calculus}
\label{sec:pib}

We assume an infinite set  of names, ranged over by .
Processes are defined by the following grammar.

where .

Most of the syntax is standard:
 is the guarded choice ( is finite), which behaves nondeterministically
as one of its components  for some ; composition  acts as  and  running in parallel;
 is the replication of process ;
Prefixes  and  are input and output along name ; and  is the silent action.
We write  for the empty guarded choice, it is the process which can do nothing.

The -calculus extends the -calculus in the fact that names can be buffered or unbuffered.
Unbuffered names are names in the -calculus, and buffered names have the buffer attribute specified by a \emph{buffer store}.
A buffer store, denoted by , is a partial function from buffered names to pairs ,
where  is a positive integer representing the capacity of the buffer,
and  is a list of names in the buffer, with the same order.
Both  and  are called {\em new processes}.
The (standard) new process  specifies that  (whether buffered or unbuffered) is a local name in .
The extended new process  creates a local buffered name ,
whose associated buffer has the capacity  for asynchronous communication inside .
Notice that  only says that the name  is local and does not imply that  is unbuffered ---
 can be a buffered name whose buffer is already created in the buffer store.

Input process  and output process  can communicate with each other along name  when they run in parallel.
If  is an unbuffered name, the communication is synchronous and happens as in the -calculus: the object  is passed from the
output side to the input side.
If  is a buffered name, then the communication becomes asynchronous: the output process simply puts  into the buffer of 
if it is not full and continues, or blocks if the buffer is full; the input process retrieves the oldest value from the buffer of 
if it is not empty and continues, or blocks if the buffer is empty.

As usual, we write  for a sequence of names, and abbreviate  to .
A name  is bound if it appears in input prefix, otherwise it is free.
We write  for the process resulting from simultaneously substituting  for each free  in .
The newly created name  in  or  are local names. A name is global if it is not localized
by any new operator. We use  and  for the set of local names and global names occurring in .

Throughout the development of the paper, we assume the following {\em De Barendregt name convention}:
\begin{center}{\em Local names are different from each other and from global names.}\end{center}
For instance, we shall never consider processes like   or .
We note that this convention is dispensable and we simply adopt it to make the presentation of the calculus simple and clean.
One can also remove the convention and use syntactic rules to manage name conflicts, but dealing with names in buffers
can be very subtle.

A process can send a local name into a buffer.
The fact that a name stored in buffers is local must be tracked, because it may affect the name scope when another process
retrieves this name from the buffer. The convention also works for buffer stores.
We shall discuss more on this when defining the operational semantics.
Inside a buffer store, a value of the form  indicates that the name  was sent into the buffer when it was local.
Given a buffer store , we write  for the set of global names that occur in 's buffer,
and . Similarly  and  for local names in  and .
The buffer store  is obtained by substituting  for each  in .

We say a process  is guarded in , if every occurrence of  in  is within some prefix process.
Intuitively, a guarded process cannot affect the behavior of its host process until the action induced by its guarding prefix is performed.
New operators are guarded in  if all new processes are guarded in .

The structural congruence  with respect to the buffer store  is defined as the smallest congruence relation
over processes satisfying the laws in Table~\ref{tab:pbsc}.
\begin{table}
\begin{enumerate}  \setlength{\itemsep}{0ex}
  \item , if  is obtained from  by renaming bound names, or local names not occurring in .
  \item .
  \item .
  \item .
  \item .
  \item 
\end{enumerate}
\caption{Structural Congruence}
\label{tab:pbsc}
\end{table}
Structural congruence allows us to pull unguarded new operators to the ``outermost'' level.

Buffer store  is \emph{valid} for process  if each local name of  appears in some new operator occurring
at the outermost level of , i.e., for every ,  for some .



\subsection{Operational Semantics}

\begin{table}
  
  \caption{Operational Semantics of }
  \label{tab:pbos}
\end{table}

The (early) transition semantics of  is given in terms of a labelled transition system generated
by the rules in Table~\ref{tab:pbos}.
The transition rules are of the form , where  are processes,  are buffer stores
and  is an action,  which can be one of the forms:
the silent action , free input , free output  or bound output .
We write  for the set of names occurring in .

These rules are compatible with the transition rules for the -calculus.
\tts{IU} and \tts{OU} are rules for unbuffered names and synchronous communication is specified by \tts{Com}.
\tts{IB} and \tts{OB} define the asynchronous communication along buffered names:
 performs a  action by receiving the ``oldest'' name  from 's buffer,
while  performs a  action by inserting  into 's buffer.
Communication along buffered names is asynchronous because it involves two transitions (\tts{IB} and \tts{OB})
and other actions may occur between them.

\tts{IBG} and \tts{OBG} indicate that a buffer store itself may have actions.
If  is a global buffered name, that is  does not occur in , then we can insert names to or receive names
from 's buffer directly.
In \tts{New} and \tts{Open}, the substitutions on the buffer store are for the sake of validity.
\tts{NewB} is the rule for the extended new process. After creating an empty buffer for ,
the capacity parameter  is dropped, leaving the new operator indicating that  is a local name.

The \tts{Par} rule describes how processes can progress asynchronously, which typically happens with buffered names.
However, unlike in the -calculus, where we have open/close rules to manage name scope extension,
in the -calculus, it is hard (perhaps impossible) to define an appropriate close rule because when a local name
is exported to a buffer, it becomes hard to track which process will retrieve the name so as to determine the name scope.
For instance, consider the process  where , ,
 and a valid buffer store .
In the -calculus,  inserts the local  into 's buffer by a  action,
then it can possibly be received by  or , hence tracking the scope of  becomes very hard.
Our solution here is to prevent processes from inserting local names into buffers when they are running in parallel with other processes.
For processes like the above example, we extend the scope of  to the entire process by structural congruence laws
and obtain a process in the form  thanks to the name convention.
This avoids the scope problem.

We have adopted the name convention which simplifies the definition of the labeled transition system.
Dealing with names with buffers is subtle and the transition rules without the name convention are discussed in the next subsection.

The following proposition says that transition rules preserve buffer validity:
\begin{proposition}
If  is valid for process  and we have the transition , then  is valid for .
\end{proposition}

As in the -calculus, strong bisimulation over the set of  processes can be defined as follows.
\begin{definition}
  A symmetric binary relation  over  processes is a \emph{bisimulation}, if whenever  and ,
  
  Strong bisimilarity  is the largest strong bisimulation over the set of  processes.  and  are strongly bisimilar, written as , if they are related by some strong bisimulation.
\end{definition}


\subsubsection{Transition Rules without Name Conversion}
As mentioned above, some transition rules require extra conditions to deal with name conflict without the name conversion.
These rules are shown in Table~\ref{tab:pbos2}.

\begin{table}
  
  \caption{Operational Semantics without Name Conversion}
  \label{tab:pbos2}
\end{table}

The problem is how can we determine a local name in the buffers refers to which local name of the process.
For instance, suppose  with valid buffer store .
We have no idea the  in  refers to which one of the two local s in .
Therefore we first assume the local names in buffers are localized by the ``outermost'' and ``\emph{leftmost}'' new operator of the process,
and add additional conditions to transition rules to respect the assumption.

In \tts{New*}, for those global  in , they are semantically different from the local  in .
For example , with .
A  transition inserts the global  into 's buffer, and we have , with .
At this point, we intend to insert the local  into 's buffer, this local 
is apparently different from the global  already in the buffer.
We add the condition  to enforce an renaming of the local  of  before the insertion.
The same discussion applies to the same extra condition of \tts{Open*}.

In rare cases, another condition is required for \tts{New*}.
Suppose, for instance, , with .
According to existing \tts{New} rule,
the process may perform a  action inserting a local  into 's buffer and become ,
with buffer store changed to  where the local  is actually localized by the second .
But by our assumption, it would refer to the first local  of the process.
We avoid this inconsistency by introducing the condition .

The condition  in \tts{NewB*} guarantees that
a fresh buffered name is used.


\subsubsection{Examples}

We demonstrate these transition rules by showing some examples.
The following example illustrates the asynchronous communication by buffered names.

\begin{example}
 and 

\end{example}

 is a parallel composition, we may not use \tts{Par} immediately as it contains an unguarded new process.
After moving the new operator to the outermost level, we may apply the \tts{New} rule
which induces a  transition `sending' the local  into 's buffer.
Notice that the local  is not directly inserted into the buffer, but in a substituting way ---
 is inserted into 's buffer in the premise of \tts{New}, then  is replaced by  in the conclusion.
The second  step describes the `receiving' of a local name from a buffer.

The next three examples illustrate the extra \tts{New*} rule.
\begin{example}
 and 

\end{example}
The first  step follows from \tts{IB}.
At this point, the local name  occurs free in buffer store, hence an -conversion is required.
After renaming  to , a second  transition `sending' the local name to 's buffer.

\begin{example}
 and 

\end{example}
After inserting the local  into the buffer, the process contains two outermost new operators
and they are syntactically the same (semantically different).
Following \tts{New*}, we first determine the action of  with .
Since the local name  occurs free in the buffer store, an -conversion is required.
After that, a  transition results in  with buffer store .
Finally, all the  in buffer store are modified back to .

\begin{example}
 and 


\end{example}
 contains two outermost new operators at the beginning.
We first determine the action of  with buffer .
A  transition leads to  with 
where the local  actually refers to the second  of the original process.
Hence an -conversion of the second  is required to distinguish itself with the first one.
This requirement is captured by  in \tts{New*}.



\subsubsection{An interlude of Close Rule and Structure Congruence}
In  calculus, including which law in structure congruence and which other rule in transition rules is a trade-off. This phenomenon also exists in our  calculus. One may ask for including a similar  rule, which generates a  action by synchronizing an input and a bound output action, and omitting those scope extension laws in structure congruence.

In , the local name moves to the action in the premise and to the outermost level in the conclusion.
What should the rule be in ?

Suppose  performs a  action sending a local name  to 's buffer and becomes ,
and at some point in the future  performs a  action receiving this local name from the buffer and becomes ,
the scope of  should contain both  and .
But if  derives to other process during the period between the two silent actions,
how can we determine which processes we should encompass by the new operator .

In the -calculus, communications are synchronous, input process would proceed unless a
complement (bound) output process is ready, and vice verse.
However, in the -calculus, communications along buffered names are asynchronous,
other actions may occur between the two transitions.
For this reason, we choose scope extension laws instead of some  rules.



\subsection{Encoding in the Polyadic -Calculus}

We demonstrate an encoding of the -calculus in the polyadic -calculus.

Intuitively, a  name  is encoded into a pair of  names  by the injective \emph{name translation function} .
In the name pair,  is called the \emph{input name} and  the \emph{output name} of .
In addition, input and output names for unbuffered names are identical, but not for buffered names.
The two translation names of buffered name  are exactly the names along which a buffer process
modelling the buffer of  receives and sends values.
\begin{table}
    \begin{enumerate}
      \item If  is a unbuffered name, then  where .
      \item If  is a buffered name, then  where .
      \item For any two names , .
    \end{enumerate}
    \caption{Name Translation Function }
    \label{tab:pbnt}
\end{table}

The buffer process is defined in Table~\ref{tab:pbbp}.
Intuitively speaking,  is the  representation of 's buffer, where  denotes the capacity and  is a list of  name \emph{pairs}.
This process may further receive a pair of names along its second parameter  if  is not full ()
or send a pair of names along its first parameter  providing  is not empty.
\begin{table}

\caption{Buffer Process }
\label{tab:pbbp}
\end{table}


The \emph{translation function}  takes a  process and a valid buffer store as parameter
and returns a single  process.
The encoding of a buffer store is a composition of buffer processes each representing a buffered name's buffer.
For processes, the encoding differs from the original process in the new operators and prefixes.
A new operator is encoded into two new operators localizing the pair of translation names.
The encoding of input prefix  is also an input prefix
but the subject is 's input name ,
while the encoding of output prefix  has the output name  as the subject.
Finally, in the encoding of an extended new process , a buffer process representing 's buffer is added.

The \emph{action translation function}  maps  actions to corresponding  actions,
it is defined similar to the encoding of prefixes.

With an abuse of notation, we also write  and  for the encoding of  and  respectively.
The translation function , along with the bijective action translation function  are defined in Table~\ref{tab:pbt}.

\begin{table}
  
  \caption{ Translation Function  and Action Translation Function }
  \label{tab:pbt}
\end{table}

The following properties are apparent.
Substitutions can be postponed until after the translation.
\begin{proposition}
  For a process , and the translation function 
  
  where  and 
  \label{lem:subs}
\end{proposition}

And structure congruent processes have the 'same' encodings.
\begin{proposition}
  If , then 
  \label{lem:sctrans}
\end{proposition}

These propositions can by proved by induction on the structure of 


\subsubsection{Full Abstraction}

The following two lemmas show that transitions of a  process can be simulated by its encoding,
and no more transition is introduced by the encoding.

\begin{lemma}
  Suppose , then .
  \label{lem:gosim1}
\end{lemma}

\begin{lemma}
  Suppose , then  and .
  \label{lem:gosim2}
\end{lemma}

Strong bisimulation relation is retained in the translation.

\begin{lemma}
  If , then .
  \label{lem:complete}
\end{lemma}
\begin{proof}
  We show the following relation  is a strong bisimulation.
  
  Suppose , then by lemma~\ref{lem:gosim2}
  
  Since , by lemme~\ref{lem:gosim1}
  
  and also  because 

  The other direction is the same. \qed
\end{proof}

\begin{lemma}
  If , then ,
  \label{lem:sound}
\end{lemma}
\begin{proof}
  We show the following relation  is a strong bisimulation.
  
  Suppose , then by lemma~\ref{lem:gosim1}
  
  Since , by lemme~\ref{lem:gosim2}
  
  and also  because 

  The other direction is the same. \qed
\end{proof}

It follows that the encoding preserves strong bisimulation.
\begin{theorem}
   if and only if .
\end{theorem}




\section{The Go Programming language}
\label{sec:go}

The Go programming language is a general purpose language developed by Google to support
easy and rapid development of large distributed systems.
\footnote{Goole has claimed that Go is used in production now.
Specifically, the website of Go (\url{golang.org}) and the download site (\url{dl.google.com}) are written in Go.}
This relatively young language inherits many good qualities of its ancestor while at the same time
introduces dozens of innovations for efficient and effective programming.
One of the most fascinating innovations is the concurrency feature which extremely simplifies
the construction of concurrent applications.
This section presents a formal operational semantics of the (core) Go language and a fully abstract
encoding in the -calculus.

The syntax of a core of Go is presented in Table~\ref{tab:gosyn}.
An online specification of Go can be found at its website~\cite{GoSpec2012}.

\begin{table}
Types:

Expressions:

Statements:


where

\caption{Syntax of the (core) Go}
  \label{tab:gosyn}
\end{table}

The \emph{channel type}, coupled with the concept called \emph{Go-routine}, constitutes the core of
Go's concurrency system.
Channel types are of the form , where  is called the \emph{element type}.
Channels () are first-class values of this language,
and they  are created by the make expression ,
where  specifies the channel type and the integer  specifies the size of the channel buffer.
Notice that  must be non-negative and if it is zero, the created channel will be a synchronous channel.

Go-routines are similar to OS threads but much cheaper.
A Go-routine is launched by the statement .
The function body of  will be executed in parallel with the program that executes the  statement.
When the function completes, this Go-routine terminates and its return value is discarded.

Communication among Go-routines is achieved by sending and receiving operations on channels.
Sending statement  sends  to channel , while receiving ,
regarded as an expression in Go, receives a value from .
Communication via unbuffered channels are synchronous.
Buffered (non-zero sized) channels enable asynchronous communication.
Sending a value to a buffered channel can proceed as long as its buffer is not full
and receiving from a buffered channel can proceed as long as its buffer is not empty.

\kw{select} statements introduce non-deterministic choice, but their clauses refer to only communication operations.
A \kw{select} statement randomly selects a clause whose communication is ``ready'' (able to proceed),
completes the selected communication, then proceeds with the corresponding clause statement.

Without loss of generality, we stipulate that a Go program is a set of function declarations,
each of the form

A Go program must specify a main function, which we shall refer to as  in the sequel, as the entry point ---
running a Go program is equivalent to executing  with appropriate arguments.
For the sake of simplicity, we only consider function calls in go statements and we assume that
all functions do not return values and  their bodies contain no local variables other than function arguments.

\subsection{Operational Semantics}
The structural operational semantics of Go is defined by a two-level labelled transition system:
the local transition system specifies the execution of a single Go-routine in isolation,
and the global transition system describes the behavior of a running Go program.

We first define the evaluation of expressions.
An expression configuration is a triple ,
where  is the expression to be evaluated,
 is the {\em local store} mapping local variables to values,
and  is the {\em channel store} mapping channels to triples ,
where  is the capacity of the channel's buffer,  is a list of values in the channel buffer,
and  is a tag indicating whether the channel is local () or global ().
The transition rules between expression configurations  are defined in Table~\ref{tab:golocexp},
where actions can be either silent action , or  denoting receive action.
We often omit  from silent transitions.

\begin{table}

\caption{Transition Rules for Expressions}
\label{tab:golocexp}
\end{table}

\tts{Var} retrieves the value of  from local store .
\tts{Mak} creates a fresh local channel .
Other rules concern receiving from channels.
Once the channel expression is fully evaluated, the real receive begins following rules \tts{RvU} and \tts{RvB}.
The value received from an unbuffered channel is indicated in the label, while the value received
from a buffered channel is the ``oldest'' value of the channel's buffer.

The local transition system defines transition rules between local configurations.
A local configuration is a tuple , where  is the statement to be executed,
 is the {\em local store} and  is the {\em channel store}.
Each Go-routine has its own local store, but the channel store is shared by all Go-routines of a running program.
The local transition relation  is presented in Table~\ref{tab:goloc}.
Two additional actions can occur in local transition rules:  for message sending over channels
and  for Go-routine creation.

\begin{table}

\caption{Local Transition Rules of Go}
\label{tab:goloc}
\end{table}

Subexpression evaluation in Go is strict and leftmost, and this evaluation strategy is specified by
\tts{AsE}, \tts{SdE1}, \tts{SdE2}, \tts{GoE} and \tts{SlE}.
For select statement, its subexpressions are those in its communication operations ---
the  in  and the  in .

Rules \tts{SdU} and \tts{SdB} capture the behavior of sending over unbuffered and buffered channels respectively.
Sending a value  over an unbuffered channel  carries a sending label ,
while sending over buffered channels is silent and can proceed as long as the target channel buffer is not full.
The \tts{Go} rule says that a go statement does nothing locally and can always proceed with a transition
with the  label ---  the label is here simply for notifying the global configuration to
generate corresponding Go-routines.
\tts{Ass} assigns  to variable . \kw{Seq1} and \kw{Seq2} specify the sequential execution.
In \tts{SlR} and \tts{SlS}, the select statement picks the -th clause.


Global transitions happen between global configurations which contain information of all running Go-routines.
A global configuration, denoted by , is defined as a tuple ,
where  is a multi-set of statement/local store pairs , of all running Go-routines,
and  is the channel store.

A global transition takes the form

where  is a mapping from function names to function definitions.
A Go program will start from an initial configuration
, where  is the body of the main function ,
 is the local store of , and  is the initial channel store.
The global transition rules are listed in Table~\ref{tab:goglo}.
A global action can be either ,  or .

\begin{table} {
 }
\caption{Global Transition Rules of Go}
\label{tab:goglo}
\end{table}

\tts{Loc} specifies the independent transition of a single Go-routine.
Asynchronous communication will also take this transition since \tts{RvB} and \tts{SdB} are both silent transitions.
\tts{LGo} creates a new Go-routine.
\tts{Com} defines the synchronous communication between two Go-routines over unbuffered channels.
The rules \tts{Loc}, \tts{LGo} and \tts{Com} all specify internal actions of a running program.

A Go program can communicate with the environment via global channels.
\tts{GRU}, \tts{GSU1} and \tts{GSU2} describe how a Go program interact with the environment via unbuffered channels,
and \tts{GRB}, \tts{GSB1} and \tts{GSB2} describe interactions via buffered channels.
Because communication over buffered channels are asynchronous, the labels in \tts{GRB}, \tts{GSB1} and \tts{GSB2}
indicate how a global channel interacts with the environment.
For instance, in \tts{GRB} the label  means that the channel (buffer)  receives a value 
from the environment.
The two rules \tts{GSU2} and \tts{GSB2} also describe how a local channel is exposed to the environment and
becomes a global channel, by communication upon global channels.
The  in the label is required only when the value is a local channel ().

Let  where each  is a global action, we write  for the action sequence obtained by eliminating all the occurrences of  in . We write  if , and  if , where  is the reflexive and transitive closure of .

\begin{definition}
  A symmetric binary relation  over global configurations is a \emph{(weak) bisimulation} if
  
  Two global configurations are bisimilar, written as , if they are related by some bisimulation.
\label{def:gcwb}
\end{definition}
Two Go programs  are bisimilar, if their initial global configurations (with the same ) are bisimilar.


\subsection{Encoding}
The encoding of Go in the -calculus is achieved by the translation function ,
which maps Go expressions and statements to  processes.
The parameter  is the name along which the result of an expression is returned or the termination of a statement is signaled.
The translation function  is defined in Table~\ref{tab:goenc}.

\begin{table}

\caption{ Encoding of Go }
\label{tab:goenc}
\end{table}

In the encoding, we use synchronous communication via local names to arrange the evolution order of  processes.
For instance, in \tts{Recv}, the right hand side of the composition will not proceed
unless the left hand side outputs along local name .

Process  denotes variable  whose current value is .
After inputting a pair of local names , one can retrieve the associated value by communicating on 
or update the variable by communicating on .
Process  evaluates these non-fully evaluated expressions in an expression sequence in left-to-right order
by synchronous communication on local names.

\tts{Make} returns the local name denoting the newly created channel.
A receive operation corresponds to an input prefix in \tts{Recv}, while a send operation corresponds to an output prefix in \tts{Send}.
For the go statement, after evaluating the argument expressions, these arguments are sent to the function to which  refers.
The statement does not wait for the function, rather it outputs the termination signal along  immediately.

For select, suppose  is these (fully and non-fully evaluated) subexpressions appearing
in the communication operation of its clauses listed in lexical top-to-bottom and left-to-right order.
The encoding first evaluates this expression sequence, followed by a guarded choice each of its constituent denotes a select clause.
The use of guarded choice here seems unavoidable.

In the encoding, some prefixes and extended new operators are underlined.
They are the most significant part and will be discussed later.

The translation function can be extended to a mapping from global configurations (with ) to  processes.
We write  for the pair , where  is the encoding of  and , and  is a valid buffer store inferred from channel store .
The extended translation function is shown in Table~\ref{tab:goenc2}.

\begin{table}

\caption{Extended  }
\label{tab:goenc2}
\end{table}

The encoding of a function declaration is a replication of input prefix process.
Each replica starts by inputting the argument lists along , followed by a composition of processes
denoting function parameters and function body.
Since function does not return anything and a normal function call is forbidden, the termination signal
is worthless, therefore a local name  is used in the encoding of the function body.

 represents a Go-routine in which  is to be executed with local store .
Each  in  refers to a local variable.
In the encoding of a global configuration, the names referring to local channels ()
and functions () are local names.

The valid buffer store  is obtained from the channel store  in three steps:
Firstly, prefix a  symbol to the names referring to local channels in all buffers;
Secondly, remove these unbuffered channels from the domain of ;
And finally, for any buffered channel  in the domain of , eliminate the third element  from .



\subsection{Correctness}

The correctness of the encoding is demonstrated by a full abstraction theorem with respect to (weak) bisimulation.
The following lemma says that a global transition may be simulated by a nontrivial sequence of transitions of its encoding.
Usually, the encoding will perform some internal adjustments before and after the real simulation.
\begin{lemma}
  If , then 
  \label{lem:gocomp}
\end{lemma}
The lemma is proved by detailed analyze of the global transition rules one by one.

\begin{proposition}
  Suppose the transition is inferred by global transition rule \tts{Loc}, that is
  
  then
  
  where  are local channels.
\end{proposition}
\begin{proof}
Consider the local transition rules which can be applied in the last step of the inference of premise.

Suppose the premise is an instance of local transition rule \tts{Ass} or \tts{SdB},
the results follows by a detailed analyze on the actions of the encoding.

Suppose the premise is an instance of \tts{AsE}, and the premise of this instance is an instance
of local expression rule \tts{Var}, \tts{Mak} or \tts{RvB}, the results follows by a detailed analyze.
If the premise of this instance is an instance of local expression rule \tts{RvE},
we prove by induction on the depth of the inference of the premise of the instance.
Suppose  where  by a shorter inference.
By induction

From the definition of encoding for  and , it follows that

\tts{SdE1}, \tts{SdE2}, \tts{GoE}, \tts{SlR}, or \tts{SlE} are similar to \tts{AsE}.

Suppose the premise is an instance of \tts{SlS}, \tts{SeQ1} or \tts{SeQ2},
then we prove by induction on the depth of the inference of the premise.
For \tts{SeQ1}  where
 by a shorter inference. By induction

From the definition of encoding for , it follows that

\tts{SlS} and \tts{SeQ2} are similar to \tts{SeQ1}.

  This completes the proof. \qed
\end{proof}

\begin{proposition}
  Suppose the transition is inferred by global transition rule \tts{LGo}, that is
  
  where  and , then
  
  where  are local channels.
\end{proposition}
\begin{proof}
Consider the local transition rules which can be applied in the last step of the inference of premise.

Suppose the premise is an instance of local transition rule \tts{Go},
the results follows by a detailed analyze on the actions of the encoding.

Suppose the premise is an instance of \tts{SeQ1} or \tts{SeQ2},
then we prove by induction on the depth of the inference of the premise.
For \tts{SeQ1}  where
 by a shorter inference. By induction

From the definition of encoding for , it follows that

\tts{SeQ2} are similar to \tts{SeQ1}.

This completes the proof. \qed
\end{proof}

For other global transition, it is similar.

Conversely, a sequence of transitions of  should reflect certain global transitions of .
However it is not always possible, since the simulation may not yet complete, even worse
the transition sequence simulating one global transition may interleave with transition sequences simulating others.
Fortunately, by observing the proof of the previous lemma, we find that actually only one transition in the sequence
plays the crucial role, as this transition uniquely identifies a global transition.
Other  transitions, whether preceding or following this special transition, are internal adjustments
which prepare for the special transition immediately after them.
We call the special transition a \emph{simulating transition}, and the other non-special  transitions \emph{preparing transitions}.

Preparing transitions are local synchronous communication between subprocesses of one single Go-routine
(e.g. synchronous communication making subprocesses evolve in order).
To postpone or to advance preparing transitions would not affect the behavior of other Go-routines.

These observations are formulated by the following definitions and lemmas.

\begin{definition}
  A transition  is a simulating transition if the action  is induced by
  the underlined prefixes and extended new operators specified in the encoding in Table~\ref{tab:goenc}.
  Otherwise, it is a preparing transition.
  \label{def:gosim}
\end{definition}

\begin{definition}
  Let  be a global configuration, the set  is defined as follows:
  \begin{enumerate} \setlength{\itemsep}{0ex}
    \item 
    \item If  and  is a preparing transition, then 
    \item If  and  is a preparing transition, then 
  \end{enumerate}
  \label{def:gotsset}
\end{definition}

\begin{proposition}
  Let  be a global configuration, and . Suppose , then
  
  where  () is (subprocess of) a descendant of ,  () corresponds to a newly created Go-routine.
  Also,  and ,
  where  refers to a global channel when  happens.
  Each name in  denotes newly created channels during .
  \label{prop:gosimstru}
\end{proposition}

\begin{proposition}
  If  is a preparing transition, then
  \begin{enumerate} \setlength{\itemsep}{0ex}
    \item  = 
    \item It is a preparing transition of -th Go-routine, i.e.  and  differs only on  for some .
\item The transition is induced by  where .
  \end{enumerate}
  \label{prop:goprepare}
\end{proposition}

\begin{lemma}
  If , and only  is a simulating transition, then there exists  such that
  
  \label{lem:gosound}
\end{lemma}
\begin{proof}
  By the Definition~\ref{def:gosim} and Propositions~\ref{prop:gosimstru} and \ref{prop:goprepare}. \qed
\end{proof}

Any of the processes in  can be seen as the encoding of .
\begin{lemma}
  If  and , then we have .
  \label{lem:gotsgs}
\end{lemma}
\begin{proof}
  The following relation is a bisimulation.
  

   is trivial.

  Suppose  is a simulating transition. By Lemma~\ref{lem:gosound}, there exists  such that
  
  Suppose this  involves the -th (and -th) Go-routine. For , perform the preparing transitions of the -th (and -th) Go-routine, followed by , we have
  

  The other direction is similar. \qed
\end{proof}

As a consequence, bisimulation is preserved by the encoding.
\begin{theorem}
   if and only if .
  \label{thm:gofull}
\end{theorem}
\begin{proof}
  : The following relation is a bisimulation up to .
  
Suppose  is a simulating transition. By Lemma~\ref{lem:gosound} and \ref{lem:gotsgs}, there exists  such that
  
  Since , there exist  such that
  
  By Lemma~\ref{lem:gocomp}
  
  The other direction is similar.

  : The following relation is a bisimulation.
  
  Suppose , by Lemma~\ref{lem:gocomp}
  
  Since , there exist  such that
  
  For each simulating transitions of , by Lemma~\ref{lem:gosound}, there exists , such that
  
  The other direction is similar. \qed
\end{proof}



\section{Core Erlang}
\label{sec:erlang}
We improve the translation mapping showed in \cite{Noll2005} by a fully abstract encoding in the -calculus.

\subsection{Syntax of Core Erlang}
\label{sec:erlsyn}
The syntax of a subset of Core Erlang is presented in Table~\ref{tab:cesyn}.

\begin{table}
Functions:

Expressions:

where

\caption{Syntax of Core Erlang}
\label{tab:cesyn}
\end{table}

\kw{let} binds values to variables, and functions are bound to function names by function definitions in the form


The counterpart of Go-routine in Erlang is the \emph{Erlang process}.
Each Erlang process is identified by an unique process .
Moreover every Erlang process is associated with a mailbox which is an unbounded ordered sequence.
The Erlang process is created by the \emph{spawn} expression.
This expression acts almost the same as the go statement except that
it is an expression and takes the newly created Erlang process's  as result.

Communication in Erlang is asynchronous.
Send expression  appends message , which is also the result of this expression,
to the mailbox of the Erlang process identified by .
Receive operation is based on pattern matching.
The receive clause is deliberately simplified to ``'', where  is an ``always march'' pattern.
Once a receive expression occurs, messages reside in the mailbox of the Erlang process evaluating this expression
are tried in first-to-last order against the clauses  from left to right.
For message  and clause , pattern marching results in  binding to  in  and .
If the guard expression  evaluates to the Erlang atom \kw{'true'}, matching succeeds,
message  is deleted (received) from the mailbox, and the result of the expression is the result of .
Otherwise, the next clause will be tried by .
If no more clause left for , that is  does not march any clause, then the next message
in mailbox will be used for marching, with  remains in the mailbox.
Sometimes none of the existing messages matches any clause, in this case receive blocks until new message arrives.

Without loss of generality, we stipulate a Core Erlang program is a set of function definitions,
in which a function named  is defined.
Running a program is equivalent to evaluate  with appropriate arguments.
For the sake of simplicity, we assume the function bodies contain no local variables other than function arguments.
Note that function name may appear only at the function position of spawn or apply expressions
in this subset language --- high-order is not considered.



\subsection{Operational Semantics}
The structural operational semantics of Core Erlang is also defined by a two-level labelled transition system:
the local transition system specifies the evaluation of a single Erlang process in isolation,
and the global transition system describes the behavior of a running Erlang program.

The local transition system defines transition rules between local configurations.
A local configuration is a tuple  where  is the expression to be evaluated
by Erlang process whose mailbox is .
The local transition rules, defined in Table~\ref{tab:celoc}, are of the form

where  is a mapping from function names to functions,
and  identifies the Erlang process evaluating the expression.
Actions can be either silent action ,  denoting send action,
or  denoting Erlang process creation

\begin{table}

\caption{Local Transition Rules of Core Erlang}
\label{tab:celoc}
\end{table}
Subexpression evaluation in Core Erlang is strict, however, in which order a sequence of subexpressions are evaluated is not defined.
This evaluation strategy is specified by \tts{LtE}, \tts{ApE}, \tts{SpE}, \tts{SdE1} and \tts{SdE2}.

\tts{Let} and \tts{App} is straightforward.
In \tts{Spa}, the  label indicates that the new Erlang process is identified by 
and the expression it will evaluate is the function application .
Sending a message to an Erlang process carries the sending label , while receiving is silent.
The premise of \tts{Rcv} indicates that the first suitable message is the -th message, and it marches the -th clause.

Global transitions happen between global configurations which contain information of all running Erlang processes.
A global configuration, denoted by , is defined as a tuple ,
where  and  are the sets of s and expressions, respectively, of all running Erlang processes, and  is the mailbox store.
A mailbox store  is a mapping from process s to pairs , where  is a mailbox (a list)
and  is a tag indicating whether (the mailbox of) the Erlang process is accessible by an observer () or not ().

We say an Erlang process is local if it is created during the evaluation of a program.
The set of local Erlang process s is exactly the  of a global configuration.
All the Erlang processes in the environment (context) are global.
An local Erlang process is accessible if the environment knows its process .

A global transition takes the form

An Erlang program will start from an initial configuration

where  is a fresh process ,
 is the expression obtained from the body of  by simultaneously substituting
supplied arguments for parameters of the function,
and  is the initial mailbox store.
The global transition rules are listed in Table~\ref{tab:ceglo}.
A global action can be either ,  for sending, or  for receiving.

\begin{table}

\label{tab:ceglo}
\caption{Global Transition Rules of Core Erlang}
\end{table}

\tts{Loc} specifies the independent evaluation of an Erlang process.
Receive operation will also take this transition since \tts{Rcv} is a silent local transition.
\tts{LSp} creates a new Erlang process.
\tts{LSd} defines the sending operation between two \emph{local} Erlang processes.
The rules \tts{Loc}, \tts{LSp} and \tts{LSd} all specify internal actions of a running program.

The labels in \tts{GSD1}, \tts{GSD2} and \tts{GRV} indicate how an Erlang program interacts with the environment.
An Erlang program can send values to the environment via global Erlang process s,
this behavior is captured by \tts{GSD1} and \tts{GSD2}.
The latter also describe how an inaccessible Erlang process becomes an accessible one.
Note that the  symbol in the label  in \tts{GSd2} is required only when  denotes an unaccessible Erlang process, i.e., .
The environment can also send values to an accessible Erlang program via its s.
In \tts{GRv} the label  actually means that the accessible Erlang process  ``receives'' a value 
from the environment.

\begin{definition}
  A symmetric binary relation  over global configurations is a \emph{(weak) bisimulation} if
  
  Two global configurations are bisimilar, written as , if they are related by some bisimulation.
\label{def:ecwb}
\end{definition}
Two Erlang programs  are bisimilar, if their initial global configurations (with the same ) are bisimilar.




\subsection{Encoding of Core Erlang}
\label{app:ceenc}
The encoding of Core Erlang in  calculus is achieved by the translation function . This function, defined in Table~\ref{tab:ceenc}, takes three parameter:
the first parameter  stands for the  and the ``input port'' of the mailbox of the Erlang process evaluating ;
the ``output port'' of the mailbox is obtained from the second parameter ;
and the result of  is returned along the last parameter .

\begin{table}

\caption{Encoding of Core Erlang}
\label{tab:ceenc}
\end{table}

In \tts{Spaw}, the input port (also the process ) and the output port of the new Erlang process's mailbox is  and  respectively.
Result of the function application is returned via local name  and hence simply dropped.

\subsubsection{Receive}
We use the following algorithm to simulate one receive operation.
\begin{table}
  \begin{enumerate}
      \item Suppose the previous buffered name is . Create a new buffered name .
      \item \label{algo:recv:2} Retrieve a message  from , pattern match  against the first clause.
      \item \label{algo:recv:3} Pattern match  against clause (), substitute  for each free  in  and . If  evaluates to , goto~\ref{algo:recv:4}; otherwise pattern match  against the next clause, goto~\ref{algo:recv:3}. If no clause remains, insert  into  and goto~\ref{algo:recv:2}.
      \item \label{algo:recv:4} Set the previous buffer to , copy all remaining messages from  to , evaluate .
    \end{enumerate}
    \caption{Receive Algorithm}
\end{table}

The algorithm uses two buffered names for each receive --- a newly created buffered name
and the buffered name created by a previously receive.
From the viewpoint of a receiver, the latter is the output port of the mailbox from which messages are retrieved.
Once the receive operation succeeds, the former will become the output port of the mailbox.
The encoding of receive expression is basically the implementation of the algorithm in the -calculus

In \tts{Recv}, the previous buffered name, say , is saved in the second parameter of the translation function ().
After creating a new buffered name , process  is triggered.
Receive handle process  fetches a message from mailbox  and passes it to the first clause process for matching.
Clause process  gets the message from its first parameter.
If guard expression evaluates to , matching succeeds.
The corresponding clause body process begins its evaluation with the previous buffered name changed to  and a copying process  carries all remaining messages from the old mailbox to the new one.
Otherwise, the message is passed along the second parameter to the next clause process for matching.
If the message does not match the last clause, it is passed back to  which then
inserts the message to the new mailbox  and starts the matching of the next message.
In the encoding,  is guarded by its first parameter ,
and all s are chained together by local names .
A clause process cannot proceed unless the matching of the previous clause failed.

In general, we have the following proposition concerning the mailbox.
\begin{proposition}
A mailbox is explicitly modelled as follows

where  and  are input and output ports of the mailbox.
Each \emph{buffered}  () is created by one receive operation,
and the first \emph{buffered}  is created by the spawn expression.
Send expressions insert messages into the mailbox via input port ,
while receive expressions retrieve messages from the mailbox via output port .
\end{proposition}

\subsubsection{Configuration}
The translation function can be extended to a mapping from global configurations (with ) to  processes.
We write  for the pair , where  is the encoding of  and ,
and  is a valid buffer store inferred from mailbox store .
The extended translation function is shown in Table~\ref{tab:ceenc2}.

\begin{table}

\caption{Extended  }
\label{tab:ceenc2}
\end{table}

The encoding of a function definition is a replication of input prefix process.
Each replica starts by inputting the argument lists along , followed by the processes denoting the function body.

 represents an Erlang Process () ready to evaluate expression  with mailbox  whose input port is .
In the encoding of a global configuration, the names referring to local Erlang Processes
which are not accessible () and functions () are local names.




\subsection{Correctness}
The correctness of the encoding can be demonstrated by a similar analyze as Go.
The following lemma says substitution for free variables can be postponed to after the encoding.

\begin{lemma}
  
  \label{lem:cedelaysubs}
\end{lemma}
\begin{proof}
  Simple induction on the structure of .
\end{proof}

\begin{theorem}
  If , then 
  \label{thm:cesim}
\end{theorem}

\begin{proposition}
  Suppose the transition is inferred by global transition rule \tts{Loc}, that is
  
  then
  
  where  are local non-accessible Erlang Processes, and .
\end{proposition}
\begin{proof}
We prove by simultaneous induction on the depth of inference of the premises.
Consider the local transition rules applied in the last step of the inference of premise.

For \tts{Rcv}: Suppose , where

by a shorter inference. By induction

From the definition of encoding for , it follows that


Other cases are similar. \qed
\end{proof}

\begin{proposition}
  Suppose the transition is inferred by global transition rule \tts{LSp}, that is
  
  where  and , then
  
\end{proposition}

For other global transition, it is similar.

Although argument evaluation is strict in Core Erlang, the evaluation order of a sequence of argument expressions is undefined.
In the encoding, besides the interleaving between transitions of many Erlang processes, interleaving also exists
inside one single Erlang process --- between the transitions simulating argument evaluation.
This interleaving is not serious, since except for receive and send, expression evaluation has no side effect,
the transitions of one argument process will not affect the behavior of others.
For receive, the input prefix  also acts as a semaphore which prevents two receive operations run in parallel.
For send, it may only affect the behavior of receive. But according to the operational semantics,
receive expression would proceed unless a legal message is already in the mailbox.
Hence the interleaving of transition simulating send and receive expression can be rearranged in a non-interleaving way.


\begin{definition}
  A transition  is a simulating transition if the action 
  is induced by underlined prefixes specified in Table~\ref{tab:ceenc}.
  Otherwise, it is a preparing transition.
  For receive, only the transition  induced by  is a simulating transition.
  \label{def:cekey}
\end{definition}

\begin{definition}
  Let  be a global configuration, the set  is defined as follows:
  \begin{enumerate}
    \item 
    \item If  and  is a preparing transition, then 
  \end{enumerate}
  \label{def:cetsset}
\end{definition}

\begin{lemma}
  If , and only  is a simulating transition,
  then there exists  such that
  
  \label{lem:ceexist}
\end{lemma}

Any of the processes in  can be seen as the encoding of .
\begin{lemma}
  If  and , then we have 
\end{lemma}

As a consequence, bisimulation is preserved by the encoding.
\begin{theorem}
   if and only if 
\end{theorem}


\section{Conclusion and Future Work}
\label{sec:con}

We have presented the -calculus which extends the -calculus by buffered names.
Communication along buffered names is asynchronous, i.e. native support of asynchronous communication.
After presenting its syntax and semantics, we give out a full abstract encoding of the  calculus in the traditional poayadic -calculus
with respect to strong bisimulation.
It is obvious that the new calculus does not increase the expressive power.
However, in contrast to the -calculus which is hard to use in practice, it enables easy and clear modeling of practical concurrent languages.
Specifically, we have provided encodings of two real-world concurrent languages --- the (core) Go language and the Core Erlang --- in the buffered -calculus.
Both encodings are fully abstract with respect to weak bisimulations.

The transition rules of the -calculus are a bit complicated compared with that of the -calculus.
We aim at applying the new language for modeling and verifying large distributed and concurrent systems
with asynchronous message passing-like communication by automatic computer programs.
One line of future work is to develop such programs.
We may extend existing tools such as Pict~\cite{Pierce2000}, MWB~\cite{Victor1994} or the HD Automata Laboratory~\cite{Ferrari2003}
to handle the -Calculus.

Since weak bisimulation is not sufficient to demonstrate program equivalence, we may expect some full abstraction encodings
with respect to branching bisimulation, or even strong bisimulation.


\section*{Acknowledgement}
The authors are partially supported by Natural Science Foundation of China (61173033, 61033002, 61100053).
They would like to thank the members of BASICS for their interest in this work.
They are also grateful to the three anonymous referees for their detailed comments on the previous version of the paper.


\bibliographystyle{splncs03}
\bibliography{bpi}


\newpage

\appendix
\section{Proofs}

Proof of Lemma~\ref{lem:gosim1}

\begin{proof}
  We prove by induction on the depth of inference tree of the condition. Consider each rule in Table~\ref{tab:pbos}.

  \tts{IU}, \tts{OU}, \tts{IB}, \tts{OB}, \tts{IBG}, \tts{OBG} and \tts{NewB*} are the base step.

  \tts{IU} 
  

  \tts{OU} 
  

  \tts{IB} 
  
  

  \tts{OB} 
  
  

  \tts{IBG} 
  
  where .
  Since  and , then 
  

  \tts{OBG} 
  
  

  \tts{NewB*}  where  \\

  where  and .
  Since , then 
  

  \tts{Sum} . By induction,
  
  

  \tts{Par} . By induction
  
  Since new operators are guarded in , the transition does not involve any local names, hence  does not contain any local names either.
  

  \tts{Com} . By induction,
  
  
  Hence
  

  \tts{New*} . Suppose , the encoding is as follows
  
  where ,  and . Since , we can move the  to the outermost level.
  
  By induction,
  
  , since , then
  
  The last  is because  and .

  \tts{Open*}  \\
  As in \tts{New*},
  
  By induction,
  
  

  \tts{Stru} The result follows from Lemma~\ref{lem:sctrans} \qed
\end{proof}

Proof of Lemma~\ref{lem:gosim2}

\begin{proof}
  We prove by induction on the size of . Consider the structure of :

  For input prefix.  and .
  
  If ,
  
  If , the encoding may also perform this action.
  However, only the buffer process  is able to perform the complementary  action,
  hence if  is a buffered names, we only need to consider the following transition:
  
  where .

  For output prefix.  and .
  
  If ,
  
  If  and  where 
  

  For summation.  and .
  
  This  may be an action of  alone, or communication between  and . In any case, suppose , then
  
  By induction,  and . By \tts{Sum}
  

  For parallel composition.  and 
  
  This  may be induced by (or ) alone, or communication between  and . For the former, suppose
  
  By induction
  
  Consider the following cases regarding : if , this means  sends a local name  to  . Then ,  and
  
  Suppose  does not occur in  (if it does, rename  to a name not occur in ), we have
  
  
  where . If , then
  
  
  
  If  is a communication action between  and . Suppose
  
  By induction
  
  Therefore
  
  


  For new process. , Suppose 
  
  If , we have
  
  By induction,  and . Since . Suppose , by rule \tts{New*}
  
  
  Suppose , this means  outputs a new name  (not the outermost  of ) to the buffer, then  since , also  is not a free name of . Choose a fresh name  such that  and  are fresh names in , then  \\
  
  
  
  If  i.e. , we have
  
  By induction,  and . By rule \tts{Open*}
  
  Suppose  (), the above equations are also valid after appropriate -conversiton of , and this -conversion corresponds to renaming of  in .
  
  where  is a fresh name.


  For extended new process. .
  
  where . The process the following transition
  
  Suppose , then ,
  
  
  Suppose , the equations are also valid after appropriate -conversion of , and this -conversion corresponds to renaming of  in .


  For replication.  and .
  

  For any process , if  and , then
  
  Suppose  and , then
  
  
  Suppose , then
  
  

  This completes the proof. \qed
\end{proof}



\end{document}
