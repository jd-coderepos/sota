\documentclass{llncs}

\usepackage[usenames,dvipsnames]{color}

\let\iint\undefined 
\let\iiint\undefined 
\let\iiiint\undefined 
\let\idotsint\undefined

\usepackage{amsmath} 
\usepackage{amsxtra} 
\usepackage{amssymb}
\usepackage{mathabx}
\usepackage{mathtools}
\usepackage{textcomp}

\usepackage{latexsym}
\usepackage{pslatex}
\usepackage{epsfig}
\usepackage{wrapfig}
\usepackage{enumerate}
\usepackage{cancel}

\usepackage{paralist}

\usepackage{ listings }

\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}
\let\Asterisk\undefined


\pagestyle{empty}

\clearpage{}\newcounter{cntlem}[section]


\spnewtheorem{ass}[theorem]{Assumption}{\bfseries}{\itshape}
\spnewtheorem{fact}[theorem]{Fact}{\bfseries}{\itshape}

\newcommand{\vspacetab}{\vspace{2mm}}
\renewcommand{\iff}{\Leftrightarrow}




\DeclareMathOperator{\pre}{pre}
\DeclareMathOperator{\post}{post}
\DeclareMathOperator{\wrs}{wrs}
\DeclareMathOperator{\wnt}{wnt}
\DeclareMathOperator{\llcm}{lcm}
\DeclareMathOperator{\vars}{vars}

\newcommand{\zedN}[0]{\zed^N}
\newcommand{\zedNval}[0]{\zed^{\x}}
\newcommand{\zedTwoN}[0]{\zed^{2N}}
\newcommand{\zedTwoNTwoN}[0]{\zedTwoN\!\times\!\zedTwoN}
\newcommand{\zedNN}[0]{\zedN \!\times\! \zedN}
\newcommand{\zedNNval}[0]{\zedNval \!\times\! \zedNval}
\newcommand{\relRFa}[0]{(\exists \x' . R^b) \wedge R}
\newcommand{\relRFb}[0]{\mathcal{R}^{-5^n}(\top) \wedge \mathcal{R}}
\newcommand{\relRFc}[0]{(\exists \x' . R^B) \wedge R}
\newcommand{\relRFm}[0]{(\exists \x' . R^m) \wedge R}
\newcommand{\relRFcOverline}[0]{(\exists \x' . \overline{R}^{\overline{B}}) \wedge \overline{R}}

\newcommand{\x}[0]{\vec{x}}
\newcommand{\xk}[1]{\vec{x}^{(#1)}}
\newcommand{\xki}[2]{\vec{x}^{(#1)}_{#2}}
\newcommand{\xxki}[2]{x^{(#1)}_{#2}}
\newcommand{\y}[0]{\vec{y}}
\newcommand{\yk}[1]{\vec{y}^{(#1)}}
\newcommand{\yki}[2]{\vec{y}^{(#1)}_{#2}}
\newcommand{\yyki}[2]{y^{(#1)}_{#2}}
\newcommand{\z}[0]{\vec{z}}

\newcommand{\topleft}[1] {{~}^{\scriptscriptstyle{\blacksquare}} \! M}
\newcommand{\botleft}[1] {{~}_{\scriptscriptstyle{\blacksquare}} \! M}
\newcommand{\topright}[1] {M^{\scriptscriptstyle{\blacksquare}}}
\newcommand{\botright}[1] {M_{\scriptscriptstyle{\blacksquare}}}

\newcommand{\ttop}{\top\!\!\!\!\top}
\newcommand{\bbot}{\bot\!\!\!\!\bot}

\newcommand{\Z}{{\mathbb Z}}
\newcommand{\N}{{\mathbb N}}
\newcommand{\relmat}[1] { \{\!\!\{#1\}\!\!\}}
\newcommand{\matrel}[1] { [\!\![#1]\!\!]}
\newcommand{\key}[1]{\underline{#1}}

\newcommand{\abs}[1]{\mbox{abs}(#1)}
\newcommand{\bi}[1]{{}^\omega\!{#1}^\omega}
\newcommand{\rbr}{{\bf ]\!]}}
\newcommand{\lbr}{{\bf [\![}}
\newcommand{\sem}[1]{\lbr #1 \rbr}
\newcommand{\model}[2]{\sem{#1}_{#2}}
\newcommand{\lfp}[1]{\mbox{fix}\ {#1}}
\newcommand{\wpr}{\widetilde{pre}}
\newcommand{\cceil}[1]{\lfloor #1 \rfloor + 1}

\newcommand{\thd}{\mbox{Th}(\mathcal{D})}
\newcommand{\smallthd}{\mbox{\tiny Th}(\mathcal{D})}
\newcommand{\modelsthd}{\models_{\mbox{\tiny Th}(\scriptscriptstyle\mathcal{D})}}
\newcommand{\notmodelsthd}{{\cancel{\models}}_{\mbox{\tiny Th}(\scriptscriptstyle\mathcal{D})}}
\newcommand{\cform}[1]{\Upsilon\!\left({#1}\right)}
\newcommand{\pivot}[2]{P_{#1}\!\!\left(#2\right)}
\newcommand{\abstr}[2]{{#2}^{\!\!\!\!\!\!{\raisebox{1pt}{}}}}

\newcommand{\paths}[1]{\langle\!\!\langle {#1} \rangle\!\!\rangle}
\newcommand{\leaves}[1]{\mbox{Fr}({#1})}
\newcommand{\yield}[1]{\mbox{Yd}({#1})}

\renewcommand{\vec}[1]{{\bf {#1}}}
\newcommand{\sumabs}[1]{\nabla\!({#1})}

\newcommand{\alias}{\Diamond}
\newcommand{\may}[2]{{\langle #1 \rangle}{#2}}
\newcommand{\must}[2]{{\lbrack #1 \rbrack}{#2}}
\newcommand{\defd}[1]{\delta({#1})}

\newcommand{\pal}{}
\newcommand{\wal}{}
\newcommand{\kal}{}
\newcommand{\true}{\top}
\newcommand{\false}{\bot}

\newcommand{\sgn}{\mbox{sgn}}
\newcommand{\lcm}{\mbox{lcm}}
\newcommand{\weight}[1]{\omega({#1})}
\newcommand{\llen}[1]{{|\!|{#1}|\!|}}
\newcommand{\card}[1]{\mbox{card}({#1})}
\newcommand{\minimum}[2]{\mbox{min}({#1},{#2})}
\newcommand{\maximum}[2]{\mbox{max}({#1},{#2})}
\newcommand{\minset}[2]{\mbox{min}\{{#1}\ |\ {#2}\}}
\newcommand{\maxset}[2]{\mbox{max}\{{#1}\ |\ {#2}\}}
\newcommand{\divs}[1]{\mbox{div}({#1})}
\newcommand{\maxmin}{\mbox{\textsc{MaxMin}}}

\newcommand{\sumnorm}{\scriptstyle{\mathbf{card}}}
\newcommand{\maxnorm}{\scriptstyle{\mathbf{max}}}

\newcommand{\auth}[1]{{\mathcal A}_{#1}}
\newcommand{\lang}[1]{{\mathcal L}({#1})}
\newcommand{\langk}[2]{{\mathcal L}_{{\leq #2}}({#1})}
\newcommand{\runs}[1]{{\mathcal R}({#1})}
\newcommand{\val}[1]{{\mathcal V}({#1})}
\newcommand{\trace}[1]{{Tr}({#1})}
\newcommand{\state}[1]{{\Sigma}({#1})}
\newcommand{\trans}[1]{{\Theta}({#1})}
\newcommand{\access}[3]{{\mathcal L}_{{#1},{#2}}({#3})}\newcommand{\eats}{\rightarrow}
\newcommand{\Eats}[1]{\stackrel{#1}{\longrightarrow}}


\newcommand{\arrow}[1]{\xrightarrow{{\scriptscriptstyle #1}}}
\newcommand{\word}{\mathit{word}}
\newcommand{\form}{\mathit{form}}

\newcommand{\nat}{{\bf \mathbb{N}}}
\newcommand{\zed}{{\bf \mathbb{Z}}}
\newcommand{\bool}{{\bf \mathbb{B}}}
\newcommand{\rat}{{\bf \mathbb{Q}}}
\newcommand{\real}{{\bf \mathbb{R}}}
\newcommand{\complex}{{\bf \mathbb{C}}}
\newcommand{\linzed}{{\bf \mathcal{L}\mathbb{Z}}}

\newcommand{\pow}[1]{{\mathcal P}(#1)}
\newcommand{\pown}[2]{{\mathcal P}^{#1}(#2)}

\newcommand{\bydef}{\stackrel{\Delta}{=}}

\newcommand{\lift}[2]{{#1}\!\!\uparrow_{{#2}}}

\newcommand{\forw}[1]{\stackrel{\rightarrow}{#1}}
\newcommand{\back}[1]{\stackrel{\leftarrow}{#1}}

\newcommand{\eqnfigx}[1]{
\begin{minipage}{3in}
\begin{center}

\end{center}
\end{minipage}}

\newcommand{\twoeqnfigx}[2]{
\eqnfigx{#1}
\eqnfigx{#2}
}

\newcommand{\threeeqnfigx}[3]{
\eqnfigx{#1}\\
\eqnfigx{#2}\eqnfigx{#3}
}

\newcommand{\eqnfig}[1]{
\begin{minipage}{3in}
\begin{center}

\end{center}
\end{minipage}}

\newcommand{\twoeqnfig}[2]{
\eqnfig{#1}
\eqnfig{#2}
}

\def\vr{\kern-\arraycolsep & \kern-\arraycolsep}
\def\VR{\kern-\arraycolsep\strut\vrule}

\newcommand{\storetrans}[1]{\stackrel{#1}{\leadsto}}
\newcommand{\storetransx}[1]{\stackrel{#1}{\leadsto^*}}
\newcommand{\storetransprime}[3]{{#1} \storetrans{#2} {#3}}
\newcommand{\gammatrans}[1]{\stackrel{#1}{\hookrightarrow}}
\newcommand{\gammatransprime}[3]{{#1} \gammatrans{#2} {#3}}
\newcommand{\gammatransx}[1]{\stackrel{#1}{\hookrightarrow^*}}
\newcommand{\run}[3]{{#1} \stackrel{#2}{\Longrightarrow} {#3}}
\newcommand{\sosrule}[2]{\frac{\begin{array}{c}#1\end{array}}{#2}}
\newcommand{\hoare}[3]{\{#1\}\ {\bf #2}\ \{#3\}}

\newcommand{\derivone}[3]{\mbox{\infer[#3]{#2}{#1}}}
\newcommand{\derivtwo}[4]{\mbox{\infer[#4]{#3}{{#1} & {#2}}}}
\newcommand{\derivdot}[4]{\mbox{\infer[#4]{#3}
{\begin{array}{l} {#1} \\ \vdots \\ {#2} \end{array}}}}

\newcommand{\mypar}[1]{\vspace*{\baselineskip}\noindent\emph{#1}}

\newcommand{\arith}{\langle \zed, +, \cdot, 0, 1 \rangle}
\newcommand{\hilbert}{\langle \zed, +, \cdot, 0, 1 \rangle^\exists}
\newcommand{\presbg}{\langle \zed, \geq, +, 0, 1 \rangle}
\newcommand{\lipshitz}{\langle \zed, \geq, +, |, 0, 1 \rangle^\exists}
\newcommand{\dioph}[1]{\mathfrak{D}(#1)}

\def\age#1{\left[#1\right]}
\def\set#1{{\left\{ #1 \right\}}}
\def\ntset#1{\mathbf{nt}(#1)}
\def\tuple#1{{\langle #1 \rangle}}
\def\nats{{\mathbb{N}}}
\def\zed{\mathbb{Z}}
\def\card#1{{|\!|{#1}|\!|}}
\def\len#1{{|{#1}|}}
\def\prod{\Delta}
\def\pat{{\mathbf{b}}}
\def\patt{{\widetilde{\mathbf{b}}}}
\def\patg{{\Gamma_\pat}}
\def\pattg{{\Gamma_\patt}}
\def\df#1{\mathbf{df}(#1)}
\def\fin#1{\mathop{\mathcal{F}}(#1)}
\def\nf#1{\mathop{n\!\mathcal{F}}(#1)}
\def\pr#1{\mathbf{pr}_{#1}}
\def\Sigmat{\ensuremath{\widetilde{\Sigma}}}
\def\Vars{\ensuremath{\Xi}}
\def\calls{\langle\!\!\!\langle\!}
\def\rets{\!\rangle\!\!\!\rangle}

\def\Bystar#1{\overset{\!\!\!\!(#1)}{=\!\Longrightarrow^\star}}
\def\By#1{\overset{(#1)}{\!\Longrightarrow}}

\def\size{\sharp}
\def\loc{\sharp\mbox{loc}}

\DeclareFontFamily{U}{mathx}{\hyphenchar\font45}
\DeclareFontShape{U}{mathx}{m}{n}{
      <5> <6> <7> <8> <9> <10>
      <10.95> <12> <14.4> <17.28> <20.74> <24.88>
      mathx10
      }{}
\DeclareSymbolFont{mathx}{U}{mathx}{m}{n}
\DeclareFontSubstitution{U}{mathx}{m}{n}
\DeclareMathAccent{\widecheck}{0}{mathx}{"71}
\DeclareMathAccent{\wideparen}{0}{mathx}{"75}

\def\cs#1{\texttt{\char`\\#1}}

\def\Varsi{\ensuremath{\Xi_{\widecheck{\text{\tiny 1..d}}}}}
\def\Varse{\ensuremath{\Xi_{\widehat{\text{\tiny 1..d}}}}}
\def\Varsil{\ensuremath{\Xi_{\widecheck{\text{\tiny ..r}}}}}
\def\Varsel{\ensuremath{\Xi_{\widehat{\text{\tiny ..r}}}}}
\newcommand{\birth}[2]{\mathbf{bd}_{#2}(#1)}
\newcommand{\quot}[2]{\left[#1\right]_{#2}}

\newcommand{\cycles}[2]{\Omega_{{#1}}({#2})}
\newcommand{\cyclestar}[2]{(\Omega_{{#1}}({#2}))^*}

\def\bdwords{\Upsilon}

\renewcommand{\vec}[1]{{\mathbf {#1}}}
\newcommand{\seq}[1]{\overrightarrow{\vec{#1}}}



\newcommand{\aproof}[1]{\noindent {\em Proof}: {#1}}


\def\proj{\mathbin{\downarrow}}
\newcommand{\mbracel}{{\{\!\text{\textlquill}}}
\newcommand{\mbracer}{{\text{\textrquill}\!\}}}
\newcommand{\mset}[1]{{ \mbracel #1 \mbracer }}

\newcommand{\old}{{\mathit{old}}}
\newcommand{\new}{{\mathit{new}}}
\clearpage{}

\definecolor{darkgreen}{rgb}{0,0.6,0}


\newcommand{\redtext}[1]{{\color{red}{#1}}}
\newcommand{\bluetext}[1]{{\color{blue}{#1}}}
\newcommand{\blueemph}[1]{{\color{blue}{#1}}}
\newcommand{\pinkemph}[1]{{\color{magenta}{#1}}}
\newcommand{\greentext}[1]{{\color{green}{#1}}}

\begin{document}


\title{Abstraction Refinement and Antichains for Trace Inclusion of Infinite
State Systems}

\author{Radu Iosif \and Adam Rogalewicz \and Tom\'{a}\v{s}~Vojnar}
  
\institute{CNRS/Verimag, France and FIT BUT, Czech Republic}

\maketitle

\begin{abstract}A \emph{data automaton} is a finite automaton
equipped with variables (counters or registers) ranging over infinite data
domains. A trace of a data automaton is an alternating sequence of alphabet
symbols and values taken by the counters during an execution of the automaton.
The problem addressed in this paper is the inclusion between the sets of traces
(data languages) recognized by such automata. Since the problem is undecidable
in general, we give a semi-algorithm based on abstraction refinement, which is
proved to be sound and complete, but whose termination is not guaranteed. We
have implemented our technique in a~prototype tool and show promising results on
several non-trivial examples.\end{abstract}

\section{Introduction}



In this paper, we address a \emph{trace inclusion} problem for
infinite-state systems. Given \begin{inparaenum}[(i)]
\item a network of \emph{data automata}
     that communicate via a set of
    shared variables , ranging over an infinite
    data domain, and a set of input events , and
\item a~data automaton  whose set of variables  is a
    subset of ,
\end{inparaenum} does the set of (finite) traces of  contain the traces of
? Here, by a \emph{trace}, we understand an alternating sequence of
valuations of the variables from the set  and input events
from the set , starting and ending
with a valuation. 
Typically, the network of automata  is an implementation
of a concurrent system and  is a specification of the set of good
behaviors of the system.

\begin{figure}[t]
\begin{center}
  \begin{picture}(0,0)\includegraphics{running-example.pdf}\end{picture}\setlength{\unitlength}{1973sp}\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup \begin{picture}(11166,1570)(586,-713)
\put(5401,-361){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(976,-361){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(7051,-361){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(6151,-211){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(6151,-511){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\bfdefault}{\updefault}{\color[rgb]{0,0,0}init}}}}}
\put(7951,-511){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(7126,164){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(7951,-211){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(8776,164){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(11401,164){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(10651,-511){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(10501,-211){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(11326,-361){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(9451,-361){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(2776,-361){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1726, 14){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1726,-511){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\bfdefault}{\updefault}{\color[rgb]{0,0,0}init}}}}}
\put(1726,-211){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(7126,689){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(8701,-361){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(8776,689){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(11401,689){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(3376,-436){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(5101,-361){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(646,-361){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(601,614){\makebox(0,0)[lb]{\smash{{\SetFigFont{9}{10.8}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(5251,614){\makebox(0,0)[b]{\smash{{\SetFigFont{9}{10.8}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(3376,464){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(4201,164){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(3526,164){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(2701,164){\makebox(0,0)[b]{\smash{{\SetFigFont{6}{7.2}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\end{picture}   \caption{An instance of the trace inclusion problem.}
  \label{fig:running-example}
\end{center}
\end{figure}

Consider, for instance, the network  of data
automata equipped with the integer-valued variables  and  shown
in Fig.~ \ref{fig:running-example}--left. The automata synchronize on
the  symbol and interleave their
 actions.  Each automaton  increases the
shared variable  and writes its identifier  into the shared
variable  as long as the value of  is in the interval
, and it is inactive outside this interval,
where  is an unbounded parameter of the network. A
possible specification for this network might require that each firing
sequence is of the form  for some , and that  is increased
only on the first occurrence of the events
, in this order. This condition is
encoded by the automaton 
(Fig. \ref{fig:running-example}--right). Observe that only the 
variable is shared between the network  and
the specification automaton ---we say that  is \emph{observable}
in this case.  An example of a trace, for  and , is:
. Our problem is to check that this, and all other traces of
the network, are included in the language of the specification
automaton, called the \emph{observer}. The trace inclusion problem
has multiple applications,
e.g.:\begin{itemize}\setlength{\itemsep}{1mm}

    \item Decision procedures for logics describing array structures
      within imperative programs \cite{lia,lpar08} that use a
      translation of array formulae to integer counter automata which
      encode the set of array models of a formula. The expressiveness
      of such logics is currently limited by the decidability of the
      emptiness (reachability) problem for counter automata. If we
      give up on decidability, we can reduce an entailment between two
      array formulae to the trace inclusion of two integer counter
      automata, and use the method presented in this paper as a
      semi-decision procedure. To assess this claim, we have applied
      our trace inclusion method to several verification conditions
      for programs with unbounded arrays of integers \cite{cav09}.

    \item Timed automata and regular specifications of timed languages
      \cite{AlurDill94} can be both represented by finite automata
      extended with real-valued variables
      \cite{fribourg:timedAutomata}. The verification problem boils
      down to the trace inclusion of two real-valued data automata.
      In this context, our method has been tested on several timed
      verification problems, including communication protocols and
      boolean circuits \cite{stavros-thesis}.
\end{itemize} 

When developing a method for checking the inclusion between trace
languages of automata extended with variables ranging over infinite
data domains, the first problem is the lack of determinisation and/or
complementation results. In fact, certain classes of infinite state
systems, such as timed automata \cite{AlurDill94}, cannot be
determinized and are provably not closed under complement. This is the
case due to the fact that the clock variables of a timed automaton are
not observable in its timed language, which records only the time
lapses between successive events. However, if we require that the
values of all variables of a data automaton be part of its trace
language, we obtain a determinisation result, which generalizes the
classical subset construction by taking into account the data
valuations. Building on this first result, we define the complement of
a data language and reduce the trace inclusion problem to the
emptiness of a product data automaton . It is crucial, for this reduction, that
the variables  of the right-hand side data automaton 
(the one being determinized) are also controlled by the left-hand side
automaton , in other words, that  has no hidden variables.

The language emptiness problem for data automata is, in general,
undecidable \cite{minsky67}. Nevertheless, several semi-algorithms and
tools for this problem (better known as the \emph{reachability}
problem) have been developed
\cite{fast,blast,mcmillan06,rybal-pldi11}. Among those, the technique
of \emph{lazy predicate abstraction} \cite{blast} combined with
\emph{counterexample-driven refinement} using \emph{interpolants}
\cite{mcmillan06} has been shown to be particularly successful in
proving emptiness of rather large infinite-state systems. Moreover,
this technique shares similar aspects with the antichain-based
algorithm for language inclusion in the case of a finite alphabet
\cite{abdulla}. An important similarity is that both techniques use a
partial order on states, to prune the state space during the search.

The main result of this paper is a semi-algorithm that combines the
principle of the antichain-based language inclusion algorithm
\cite{abdulla} with the interpolant-based abstraction refinement
semi-algorithm \cite{mcmillan06}, via a general notion of
language-based subsumption relation. We have implemented our
semi-algorithm in a prototype tool and carried out a~number of
experiments, involving hardware, real-time systems, and array logic
problems. Since our procedure tests inclusion within a set of good
traces, instead of empty intersection with a set of error traces, we
can encode rather complex verification conditions concisely, using
automata of relatively small size.

\subsection{Overview}


\begin{figure}[htb]
\begin{center}
  \begin{picture}(0,0)\includegraphics{refinement.pdf}\end{picture}\setlength{\unitlength}{1579sp}\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup \begin{picture}(7603,7008)(735,-6973)
\put(2026,-2011){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(7846,-1741){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(7351,-2836){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(3901,-5386){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(2476,-4036){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1351,-5086){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(2776,-5086){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(3001,-6811){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(5251,-5011){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(7351,-5386){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(7426,-5611){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1051,-586){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(2026,-886){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1876,-1411){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(6076,-961){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(6901,-1411){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(5701,-1411){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(4201,-961){\makebox(0,0)[lb]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0} }}}}}
\put(4951,-2011){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(7201,-2011){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(5101,-2836){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}(b)}}}}}
\put(976,-2836){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}(a)}}}}}
\put(6976,-2386){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1951,-4561){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(3151,-5686){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(2776,-6211){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1201,-5686){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1426,-5911){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(751,-3736){\makebox(0,0)[lb]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(5851,-4486){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(7051,-6661){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(5251,-5611){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(5401,-5836){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(6676,-4861){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(7201,-6136){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(7426,-6886){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(901,-6811){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}(c)}}}}}
\put(5026,-6736){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}(d)}}}}}
\put(6376,-3961){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1951,-3361){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(5926,-3436){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(2026,-136){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(6376,-136){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(2326,-436){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(6676,-511){\makebox(0,0)[b]{\smash{{\SetFigFont{5}{6.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\end{picture} \caption{Sample run of our semi-algorithm.}
  \label{fig:refinement}
\end{center}
\end{figure}

We introduce the reader to our trace inclusion method by means of an
example. Let us consider the network of data automata
 and the data automaton  from
Fig.~\ref{fig:running-example}. We prove that, for any value of
, any trace of the network , obtained as an
interleaving of the actions of  and , is also a~trace of the
observer . To this end, our procedure will fire increasingly longer
sequences of input events, in search for a counterexample trace. We
keep a set of predicates associated with each state
 of the product automaton where  is a state
of  and  is a~set of states of . These predicates are
formulae that define over-approximations of the data values reached
simultaneously by the network, when  is the state , and by
the observer , in every state from .

The first input event is , on which  and 
synchronize, moving together from the initial state  to . In response,  can chose to
either\begin{inparaenum}[(i)]
\item move from  to , matching the only
  transition rule from , or
\item ignore the transition rule and move to the empty set. 
\end{inparaenum}
In the first case, the values of  match the relation of the rule
, while in the second case, these
values match the negated relation . The second case is
impossible because the action of the network requires . The only successor state is thus
 in Fig. \ref{fig:refinement}
(a). Since no predicates are initially available at this state, the
best over-approximation of the set of reachable data valuations is the
universal set ().

The second input event is , on which  moves from
 back to itself, while  makes an idle step because no
transition with  is enabled from . Again,  has
the choice between moving from  either to  or
. Let us consider the first case, in which the successor
state is . Since  and
 are final states of  and , respectively, and no
final state of  is present in , we say that the state is
accepting. If the accepting state (in dashed boxes in
Fig. \ref{fig:refinement}) is reachable according to the transition
constraints along the input sequence , we
have found a counterexample trace that is in the language of
 but not in the language of .

\enlargethispage{4mm}


To verify the reachability of the accepting state, we check the
satisfiability of the path formula corresponding to the composition of
the transition constraints  () and 
() in Fig. \ref{fig:refinement} (a). This formula is
unsatisfiable, and the proof of infeasibility provides the interpolant
. This formula is an explanation for the infeasibility of
the path because it is implied by the first constraint and it is
unsatisfiable in conjunction with the second constraint. By
associating the new predicate  with the state
, we ensure that the same spurious
path will never be explored again.

We delete the spurious counterexample and recompute the states along
the input sequence  with the new
predicate. In this case,  is
unreachable, and the outcome is . However, this state was first encountered after the
sequence , so there is no need to store a second
occurrence of this state in the tree. We say that the node
 is subsumed by , and
indicate this by a dashed arrow in Fig. \ref{fig:refinement} (b).

We continue with  from the state . In this case,  makes an idle step and 
moves from  to itself. In response,  has the choice between
moving from  to either\begin{inparaenum}[(i)]
\item  with the constraint , 
\item  with the constraint , 
\item  with the constraint  (this possibility is discarded),
\item  for  data values that satisfy .
\end{inparaenum} 
The last case is also discarded because the value of  after
 constrained to  and the  imposes further the
constraint  and . Hence, the only
-successor of  is
, in Fig. \ref{fig:refinement}
(b).

By firing the event  from this state, we reach
, which is, again, accepting. We
check whether the path  is
feasible, which turns out not to be the case. For efficiency reasons,
we find the shortest suffix of this path that can be proved
infeasible. It turns out that the sequence 
is infeasible starting from the state , which is called the \emph{pivot}. This proof of
infeasibility yields the interpolant , and a new
predicate  is associated with . The refinement phase rebuilds only the subtree rooted
at the pivot state, in Fig.  \ref{fig:refinement} (b).

The procedure then builds the tree on Fig. \ref{fig:refinement} (c)
starting from the pivot node and finds the accepting state
 as the result of firing
the sequence . This path is
spurious, and the new predicate  is associated with the location
. The pivot node is the same as in
Fig. \ref{fig:refinement} (b), and, by recomputing the subtree rooted
at this node with the new predicates, we obtain the tree in
Fig. \ref{fig:refinement} (d), in which all frontier nodes are
subsumed by their predecessors. Thus, no new event needs to be fired,
and the procedure can stop reporting that the trace inclusion holds.

\subsection{Related Work}


The trace inclusion problem has been previously addressed in the
context of timed automata \cite{ouaknine-worrell-lics04}. Although the
problem is undecidable in general, decidability is recovered when the
left-hand side automaton has at most one clock, or the only constant
appearing in the clock constraints is zero. These are essentially the
only known decidable cases of language inclusion for timed automata.

The study of \emph{data automata}
\cite{Bojanczyk:2011:TLD,habermehl-data} usually deals with the
complexity of decision problems in logics describing data languages
for simple theories, typically infinite data domains with equality.
Here we provide a semi-decision procedure for the language inclusion
between data automata controlled by generic first-order theories,
whose language-theoretic problems are undecidable.

Data words are also studied in the context of \emph{symbolic visibly pushdown
automata} (SVPA) \cite{symbVisPushDown:CAV14}. Language inclusion is decidable
for SVPAs with transition guards from a~decidable theory because SVPAs are
closed under complement and the emptiness can be reduced to a finite number of
queries expressible in the underlying theory of guards. Decidability comes here
at the cost of reducing the expressivity and forbidding comparisons between
adjacent positions in the input (only comparisons between matching call/return
positions of the input nested words are allowed).

Finally, several works on model checking infinite-state systems against CTL
\cite{existQuantHornCl:CAV13} and CTL* \cite{infStCTLstarVer:CAV15}
specifications are related to our problem as they check inclusion between the
set of computation trees of an infinite-state system and the set of trees
defined by a branching temporal logic specification. The verification of
existential CTL~formulae~\cite{existQuantHornCl:CAV13} is reduced to solving
forall-exists quantified Horn clauses by applying counterexample guided
refinement to discover witnesses for existentially quantified variables. The
work~\cite{infStCTLstarVer:CAV15} on CTL* verification of infinite systems is
based on partial symbolic determinization, using prophecy variables to summarize
the future program execution. For finite-state systems, automata are a strictly
more expressive formalism than temporal logics\footnote{For (in)finite words,
the class of LTL-definable languages coincides with the star-free languages,
which are a strict subclass of (-)regular languages.}. Such a comparison
is, however, non-trivial for infinite-state systems. Nevertheless, we found the
data automata considered in this paper to be a natural tool for specifying
verification conditions of array programs \cite{lia,lpar08,cav09} and regular
properties of timed languages \cite{AlurDill94}.

\section{Preliminary Definitions}


Let  denote the set of non-negative integers including zero. For
any , , we write  for the set
. We write  and  for the
boolean constants \emph{false} and \emph{true}, respectively. Given a
possibly infinite data domain , we denote by
 the set of syntactically
correct first-order formulae with function symbols . A
variable  is said to be \emph{free} in a~formula , denoted as
, iff it does not occur under the scope of a quantifier.

Let  be a finite set of variables. A
\emph{valuation}  is an
assignment of the variables in  with values from
. We denote by  the set of such
valuations. For a formula , we denote by  the fact that substituting each variable  by  yields a valid formula in the theory . In
this case,  is said to be a~\emph{model} of . A formula is
said to be {\em satisfiable} iff it has a model. For a~formula
 where  and two valuations ,
we denote by  the fact that the formula
obtained from  by substituting each  with  and each
 with  is valid in .

\subsubsection{Data Automata.}


\emph{Data Automata} (DA) are extensions of non-deterministic finite
automata with variables ranging over an infinite data domain
, equipped with a first order theory . Formally, a
DA is a tuple , where:
\begin{compactitem}
\item  is a finite alphabet of input events and  is a special padding symbol,
\item  is a set of variables,
\item  is a finite set of {\em states},  is an
  \emph{initial} state,  are {\em final} states, and
\item  is a set of {\em rules} of the form  where 
  is an alphabet symbol and  is a formula in
  .
\end{compactitem}
A \emph{configuration} of  is a pair . We say that a configuration  is 
a~\emph{successor} of  if and only if there exists a rule  and . We denote the successor relation by , and we omit writing  and 
when no confusion may arise. We denote by 
 the set of successors of a configuration .

A \emph{trace} is a finite sequence  of pairs 
taken from the infinite alphabet . A \emph{run} of  over the \emph{trace}  is a sequence
of configurations . We say
that the run  is \emph{accepting} if and only if , in
which case  \emph{accepts} . The \emph{language} of , denoted
, is the set of traces accepted by .

\subsubsection{Data Automata Networks.}


A \emph{data automata network} (DAN) is a non-empty tuple  of data automata ,
 whose sets of states are pairwise disjoint. A DAN is a
succint representation of an exponentially larger DA
, called the \emph{expansion}
of , where:
\begin{compactitem}
\item  and
  ,
\item ,  and , 
\item  if and only if \begin{inparaenum}[(i)] \item for all , , \item for all , ,
  and \item , 
\end{inparaenum} where  is the set of DA that can move from  to
 while reading the input symbol , and  propagates the values of the local variables
in  that are not updated by .
\end{compactitem} 
Intuitively, all automata that can read an input symbol synchronize
their actions on that symbol whereas the rest of the automata make an
idle step and copy the values of their local variables which are not
updated by the active automata. The language of the DAN 
is defined as the language of its expansion DA,
i.e.\ .



\subsubsection{Trace Inclusion.}


Let  be a DAN and
 be its expansion. For a set of variables
, we denote by  the restriction of a~valuation  to the variables in
. For a trace , we denote by 
the trace . We lift this notion to sets of words in the natural
way, by defining .

We are now ready to define the trace inclusion problem on which we
focus in this paper. Given a DAN  as before and a DA
 such
that , the \emph{trace
  inclusion problem} asks whether ? The right-hand side DA
 is called \emph{observer}, and the variables in  are
called \emph{observable} variables.

\section{Boolean Closure Properties of Data Automata} \label{sec:boolean-closure}


We show first that data automata are closed under the boolean
operations of union, intersection and complement and that they are
amenable to determinisation. Clearly, the emptiness problem is, in
general, undecidable, due to the result of Minsky on 2-counter
machines with integer variables, increment, decrement and zero test
\cite{minsky67}.

Let  be
a DA for the rest of this section.  is said to be
\emph{deterministic} if and only if, for each trace ,  has at most one run over . The first result of
this section is that, interestingly, any DA can be determinized while
preserving its language. The determinisation procedure is a
generalization of the classical subset construction for Rabin-Scott
word automata on finite alphabets. The reason why determinisation is
possible for automata over an infinite data alphabet
 is that the successive values
taken by \emph{each variable}  are tracked by the
language . This assumption is crucial: a typical example of
automata over an infinite alphabet, that cannot be determinized, are
timed automata \cite{AlurDill94}, where only the elapsed time is
reflected in the language, and not the values of the variables
(clocks).

Formally, the \emph{deterministic} DA accepting the language
 is defined as , where ,
,  and  is the set of rules  such that:
\begin{compactitem}
\item for all  there exists  and a rule 
  , 
\item -2mm]
      \scriptscriptstyle{p \in P}
  \end{array}}
  \psi \wedge 
  \bigwedge_{\scriptscriptstyle{p' \in Q \setminus P'}}
  \bigwedge_{\begin{array}{l}  
      \scriptscriptstyle{p \arrow{\sigma,\varphi}{} p' \in \prod} \
\end{compactitem}
The main difference with the classical subset construction for
Rabin-Scott automata is that here we consider \emph{all sets}  of
states that have a predecessor in , not just the maximal such set.
This refined subset construction takes into account not just the
alphabet symbols in , but also the valuations of the variables
in . Observe, moreover, that  can be built for any
theory  that is closed under conjunction and negation. The
following lemma states the main properties of .

\begin{lemma}\label{lemma:determinism}
  Given a DA , 
  \begin{inparaenum}[(1)]
  \item\label{it1:determinism} for any  and ,  has exactly one run on  that starts in , and
\item\label{it2:determinism} .
  \end{inparaenum}
\end{lemma}
\proof{ (\ref{it1:determinism}) Let  be an arbitrary trace
  and  be a state of . We first build a run  of  such that
  , by induction on . If , then
   and  is trivially a run of
   over . For the induction step, let  and suppose that
   has a run  such that . We extend this run to a run
  over , by considering:
  -2mm]
      \scriptscriptstyle{p \in P_{n-1}}
  \end{array}}
  \psi \wedge 
  \bigwedge_{\scriptscriptstyle{p' \in Q \setminus P_n}}
  \bigwedge_{\begin{array}{l}  
      \scriptscriptstyle{p \arrow{\sigma,\varphi}{} p' \in \prod} \
  It is not hard to see that ,
  thus  is indeed a run of  over
  . To show that  is unique, suppose, by contradiction, that
  there exists a different run  such that
  . Notice that the relation labeling any transition rule
   is entirely determined by
  the sets  and , so two runs are different iff they
  differ in at least one state, i.e.\ and , for some . Let  denote the smallest such  and suppose that
  there exists  such that  (the symmetrical
  case  and  is left to the reader). By the
  definition of , there exists  such
  that . Since
  , we
  obtain that  and
  ,
  contradiction. Thus  is the only run of  over ,
  starting in .

  (\ref{it2:determinism}) Let  be a
  trace. ``'' If , then  has a run
   such that 
  and . By point (\ref{it1:determinism}),  has a unique
  run  over . We prove
  that , by induction on . For , we have
  , by the definition of . For the induction
  step, suppose that  and . By
  contradiction, assume that . Since
  , we obtain
  , contradiction. Thus
   for all , and , hence . Then , and . ``'' If , then
   has a (unique) run 
  over , such that  and . Then there exists  and, by the
  definition of , there exists  such that
   and
  . Continuing this argument
  backwards, we can find a run  of  over
  , such that , for all . Since
   and , we obtain that . \qed}


The construction of a deterministic DA recognizing the language of 
is key to defining a DA that recognizes the complement of . Let
. In other words,  has the same structure
as , and the set of final states consists of those subsets that
contain no final state, i.e.\ . Using Lemma \ref{lemma:determinism}, it is not
difficult to show that .

Next, we show closure of DA under intersection. Let  be a DA and
define , where  if and only if ,  and . It is easy to show that
. DA are
also closed under union, since .



Let us turn now to the trace inclusion problem. The following lemma
shows that this problem can be effectively reduced to an equivalent
language emptiness problem. However, note that this reduction does not
work when the trace inclusion problem is generalized by removing the
condition . In other words, if the
observer uses local variables not shared with the network\footnote{For
  timed automata, this is the case since the only shared variable is
  the time, and the observer may have local clocks.}, i.e.\ , the generalized trace inclusion
problem  has a negative answer
iff \emph{there exists a~trace}  such that, \emph{for all
  valuations} , we have
. This kind of quantifier alternation cannot be
easily accommodated within the framework of language emptiness, in
which only one type of (existential) quantifier occurs.

\begin{lemma}\label{lemma:inclusion-emptiness}
  Given DA  and  such
  that . Then
   if and only if 
  . 
\end{lemma}
\proof{ We have  iff  iff . \qed}

The trace inclusion problem is undecidable, which can be shown by
reduction from the language emptiness problem for DA (take  such
that ). However the above lemma shows that
any semi-decision procedure for the language emptiness problem can
also be used to deal with the trace inclusion problem.

\section{Abstract, Check, and Refine for Trace Inclusion}
\label{sec:algorithm}


This section describes our semi-algorithm for checking the trace
inclusion between a~given network  and an observer
. Let  denote the expansion of ,
defined in the previous. In the light of Lemma
\ref{lemma:inclusion-emptiness}, the trace inclusion problem
,
where the set of observable variables  is included in the
set of network variables, can be reduced to the language emptiness
problem .

Although language emptiness is undecidable for data automata
\cite{minsky67}, several cost-effective semi-algorithms and tools
\cite{lazy-abstraction,mcmillan06,rybal-pldi11,fast} have been
developped, showing that it is possible, in many practical cases, to
provide a yes/no answer to this problem. However, to apply one of the
existing off-the-shelf tools to our problem, one needs to build the
product automaton  prior to the
analysis. Due to the inherent state explosion caused by the
interleaving semantics of the network as well as by the
complementation of the observer, such a solution would not be
efficient in practice.

To avoid building the product automaton, our procedure builds
\emph{on-the-fly} an over-approximation of the (possibly infinite) set
of reachable configurations of . This over-approximation is defined using the approach
of \emph{lazy predicate abstraction} \cite{lazy-abstraction}, combined
with \emph{counterexample-driven abstraction refinement} using
\emph{interpolants} \cite{mcmillan06}. We store the explored abstract
states in a structure called an \emph{antichain tree}. In general,
antichain-based algorithms
\cite{henzinger06} store only states
which are incomparable w.r.t. a partial order called
\emph{subsumption}. Our method can be thus seen as an extension of the
antichain-based language inclusion algorithm \cite{abdulla} to infinite
state systems by means of predicate abstraction and
interpolation-based refinement. Since the trace inclusion problem is
undecidable in general, termination of our procedure is not
guaranteed; in the following, we shall, however, call our procedure an
algorithm for the sake of brevity.

\vspace*{-1mm}\subsection{Antichain Trees}


In this section, we define antichain trees, which are the main data
structure of the trace inclusion (semi-)algorithm. Let  be a network of automata where , for
all , and let  be an
observer such that . We
also denote by  the
expansion of the network  and by  the product
automaton used for checking language inclusion.

An \emph{antichain tree} for the network  and the
observer  is a tree whose nodes are labeled by \emph{product
  states} (see Fig. \ref{fig:refinement} for examples). Intuitively, a
product state is an over-approximation of the set of configurations of
the product automaton  that share
the same control state. Formally, a \emph{product state for
   and } is a tuple 
where\begin{inparaenum}[(i)]
\item  is a~state of 
  with  being a state of the network
  expansion  and  being a set of states of the
  observer , and
\item  is a formula which
  defines an over-approximation of the set of valuations of the
  variables  that reach the state
   in .
\end{inparaenum}
A product state  is a finite representation of a
possibly infinite set of configurations of 
, denoted as .



To build an over-approximation of the set of reachable states of the product
automaton, we need to compute, for a product state , an over-approximation of
the set of configurations that can be reached in one step from . To this end,
we define first a finite abstract domain of product states, based on the notion
of \emph{predicate map}. A predicate map is a partial function that associates
sets of facts about the values of the variables used in the product automaton,
called \emph{predicates}, with components of a product state, called
\emph{substates}. The reason behind the distribution of predicates over
substates is two-fold. First, we would like the abstraction to be \emph{local},
i.e.\ the predicates needed to define a certain subtree in the antichain must be
associated with the labels of that subtree only. Second, once a predicate
appears in the context of a substate, it should be subsequently reused whenever
that same substate occurs as part of another product state.

Formally, a \emph{substate} of a state  of the product automaton  is a
pair  such
that \begin{inparaenum}[(i)]
\item  is a subsequence of
  , and
\item  only if . 
\end{inparaenum}
We denote the substate relation by . The substate relation
requires the automata  of the network
 to be in the control states 
simultaneously, and the observer  to be in at least some state of
 provided  (if , the state of  is
considered to be irrelevant). Let  be the set
of substates of a state of .

A \emph{predicate map}  associates each substate  with a set of
formulae  where \begin{inparaenum}[(i)]
\item  if , and
\item  if .
\end{inparaenum}
Notice that a predicate associated with a substate refers only to the
local variables of those network components  and of the observer  that occur in the particular
substate.

\begin{example}\label{ex:predicate-map} 
The antichain in Fig. \ref{fig:refinement} (d) uses the predicate map
,
. 
\end{example}

We are now ready to define the abstract semantics of the product
automaton , induced by a given
predicate map. For convenience, we define first a set
 of \emph{concrete successors} of a product state
 such that  if and
only if\begin{inparaenum}[(i)]
\item the product automaton  has a
  rule  and
.
\end{inparaenum}
The set of concrete successors does not contain states with empty set
of valuations because these states are unreachable in .

Given a predicate map , the set  of
\emph{abstract successors} of a product state  is defined as
follows:  if and
only if \begin{inparaenum}[(i)]
\item there exists a product state  and
\item . 
\end{inparaenum}
In other words, the set of data valuations that are reachable by an
abstract successor is the tightest over-approximation of the concrete
set of reachable valuations, obtained as the conjunction of the
available predicates from the predicate map that over-approximate
this set.

\begin{example}(\emph{contd. from Ex. \ref{ex:predicate-map}}) 
Consider the antichain from Fig. \ref{fig:refinement} (d). The
concrete successors of  are
 and
:

\vspace*{-1mm}With predicate map  from Ex. \ref{ex:predicate-map}, 
:

\end{example}

Finally, an \emph{antichain tree} (or, simply antichain) 
for  and  is a tree whose nodes are labeled with
product states and whose edges are labeled by input symbols and
concrete transition relations. Let  be the set of finite
sequences of natural numbers that denote the positions in the
tree. For a tree position  and , the
position  is a \emph{child} of . A set  is
said to be \emph{prefix-closed} if and only if, for each  and
each prefix  of , we have  as well. The root of the
tree is denoted by the empty sequence .

Formally, an antichain  is a set of pairs ,
where  is a product state and  is a tree position, such
that\begin{inparaenum}[(1)]
\item for each position  there exists at most one
  product state  such that ,
\item the set  is
  prefix-closed, 
\item  where
   is the label of the root, and 
\item for each edge  in ,
  there exists a predicate map  such that .
\end{inparaenum}
For the latter condition, if  and
, there exists a~unique rule , and we shall
sometimes denote the edge as  or simply
 when the tree positions are not important.

Each antichain node  is naturally
associated with a path from the root to itself . We denote by  the node 
for each , and by  the length of the path.
The \emph{path formula} associated with  is  where

is a~set of indexed variables for each .

\begin{example} \label{ex:path-formula} Consider the path  in
  the antichain from Fig. \ref{fig:refinement} (c). The path formula
  of  is  where:\vspace*{-1mm}
  
\end{example}

\subsection{Counterexample-driven Abstraction Refinement}\label{sec:cex}


A \emph{counterexample} is a path from the root of the antichain to a
node which is labeled by an \emph{accepting} product state. A product
state  is said to be \emph{accepting} iff
 is an accepting state of the product automaton
, i.e.\  and . A counterexample is
said to be \emph{spurious} if its path formula is unsatisfiable,
i.e.\ the path does not correspond to a concrete execution of
. In this case, we need
to \begin{inparaenum}[(i)]
\item remove the path  from the current antichain and
\item refine the abstract domain in order to exclude the occurrence of
   from future state space exploration. 
\end{inparaenum}

Let 
be a spurious counterexample in the following. For efficiency
reasons, we would like to save as much work as possible and remove
only the smallest suffix of  which caused the spuriousness. For
some , let 
be the formula defining all sequences of data valuations that start in
the set  and proceed along the suffix  of . The
\emph{pivot} of a path  is the maximal position  such
that , and  if  is not spurious.



\begin{example}\label{ex:spurious-ce}(\emph{contd. from Ex. \ref{ex:path-formula}}) 
The path formula  from Ex.  \ref{ex:path-formula} is unsatisfiable, thus
 is a spurious counterexample. Moreover, we have 
because of the unsatisfiable subformula . Since  is satisfiable, the pivot of
 is .  \end{example}

Finally, we describe the refinement of the predicate map, which
ensures that a given spurious counterexample will never be found in a
future iteration of the abstract state space exploration. The
refinement is based on the notion of \emph{interpolant}
\cite{mcmillan06}. 

\begin{definition}\label{def:interpolant}
  Given a formula  and a sequence
   of formulae, an \emph{interpolant} is
  a sequence of formulae  where:\begin{inparaenum}[(1)]
  \item , 
  \item , and
  \item  for all .
  \end{inparaenum}
\end{definition}
\vspace*{-0.5mm}Any given interpolant is a witness for the unsatisfiability of a
(suffix) path formula . Dually, if \emph{Craig's
  Interpolation Lemma} \cite{craig} holds for the considered
first-order data theory , any infeasible path formula is
guaranteed to have an interpolant.

\begin{example}(\emph{contd. from Ex. \ref{ex:spurious-ce}}) 
The path formula  in Ex. \ref{ex:spurious-ce} has
the interpolant .  \end{example}

Given a spurious counterexample  with pivot , an
interpolant  for the
infeasible path formula  can be used to refine the
abstract domain by augmenting the predicate map . As an effect of
this refinement, the antichain construction algorithm will avoid every
path with the suffix  in a~future iteration. If  is a
conjunctive normal form (CNF) of the -th component of the
interpolant, we consider the substate  for
each  where :\begin{compactitem}
\item  where  is the largest sequence of indices
  such that  for
  each  and the
  set  of variables of the network component DA ,
\item  if , and , otherwise.
\end{compactitem} 

A predicate map  is said to be \emph{compatible} with a spurious
path 
with pivot  if  and there is an
interpolant  of the suffix
 wrt.  such that, for each
clause  of some equivalent CNF of , , it holds
that  for some substate . The
following lemma proves that, under a predicate map compatible with a
spurious path , the antichain construction will exclude further
paths that share the suffix of  starting with its pivot.

\begin{lemma}\label{lemma:refinement}
  Let  be a spurious
  counterexample and  be a predicate map compatible with
  . Then, there is no sequence of product states
   such
  that:\begin{inparaenum}[(1)]
  \item  and
  \item  for all
  .
  \end{inparaenum}
\end{lemma}
\proof{ Let  be the pivot of . Since  is
  spurious, there exists an interpolant
   for  and
  . It is sufficient to prove that
   for all . Since , we obtain , and consequently
  . By the
  definition of , we have
  , which
  contradicts with the definition of . We show that
   for all , by induction on
  . For the base case , we have . For the induction step, we assume
   for all  and prove
  . By the induction hypothesis, we
  have: 
  Let  be the CNF of . Since
   is compatible with , for each clause , there exists
  a substate  such that . By the definition of , we obtain that
   for each , hence
  . 
  \qed}


Observe that the refinement induced by interpolation is \emph{local}
since  associates sets of predicates with substates of the states
in , and the update impacts only
the states occurring within the suffix of that particular spurious
counterexample.

\subsection{Subsumption}


The main optimization of antichain-based algorithms \cite{abdulla}
for checking language inclusion of automata over finite alphabets is
that product states that are \emph{subsets} of already visited states
are never stored in the antichain. On the other hand, language
emptiness semi-algorithms, based on \emph{predicate abstraction}
\cite{mcmillan06} use a similar notion to cover newly generated
abstract successor states by those that were visited sooner and that
represent larger sets of configurations. In this case, state coverage
does not only increase efficiency but also ensures termination of the
semi-algorithm in many practical cases.

In this section, we generalize the subset relation used in classical
antichain algorithms with the notion of coverage from predicate
abstraction, and we define a more general notion of \emph{subsumption}
for data automata. Given a state  of the product
automaton  and a valuation , the \emph{residual language}
 is
the set of traces  accepted by 
from the state  such that  is the first valuation
which occurs on . This notion is then lifted to product states as
follows: 
where  is the set of configurations of the product automaton
 represented by the given product
state .

\begin{definition}\label{def:subsumption}
  Given a DAN  and a DA , a partial order
   is a \emph{subsumption} provided that, for any two
  product states  and , we have  only if
  .
\end{definition}

A procedure for checking the emptiness of 
needs not continue the search from a product state  if it has already visited
a product state  that subsumes . The intuition is that any counterexample
discovered from  can also be discovered from . The trace inclusion
semi-algorithm described below in Section~\ref{sec:trace-inclusion-algorithm}
works, in principle, with any given subsumption relation. In practice, our
implementation uses the subsumption relation defined by the lemma below:

\begin{lemma}\label{lemma:img-subsumption} The relation defined s.t.
 is a
subsumption.\end{lemma}
\proof{ For any valuation , we have
  . Since , we have
  , thus
  . We obtain that
  .
  Since moreover , we have that
  . \qed}

\begin{example} In the antichain from Fig. \ref{fig:refinement} (d), 
  because , , and .  \end{example}

As a remark, the language inclusion algorithm for non-deterministic
automata on finite alphabets \cite{abdulla} uses also a more
sophisticated subsumption relation based on a pre-computed simulation
\cite{milner} between the states of the automata. We have defined
a~similar notion of simulation for data automata and an algorithm for
computing such simulations \cite{tech-report}. The integration of data
simulations within the framework of antichain-based abstraction
refinement and its practical assessment are considered as future work.

\subsection{The Trace Inclusion Semi-algorithm}
\label{sec:trace-inclusion-algorithm}


With the previous definitions, Algorithm~\ref{alg:trace-inclusion} describes the
procedure for checking trace inclusion. It uses a classical worklist iteration
loop (lines \ref{ln:beginWhile}-\ref{ln:endWhile}) that builds an antichain tree
by simultaneously unfolding the expansion  of the network
 and the complement  of the the observer , while
searching for a counterexample trace . Both  and  are built on-the-fly,
during the abstract state space exploration. 

\begin{algorithm}[t!]
{\scriptsize\begin{algorithmic}[0]
  \State {\bf input}: 
  \begin{compactenum}
    \item a DAN  such that 
      for all ,
\item a DA 
      such that  .
  \end{compactenum}
  \State {\bf output}: true if , otherwise a trace  .
\end{algorithmic}

\begin{algorithmic}[1]
  \State  , , 
  , 
  \label{ln:init}

  \While {}\label{ln:beginWhile}

  \State chose  and move
   from  to
  \label{ln:move}

  \State match  with 

  \If{ is an accepting product state}\label{ln:ifAccepting}

  \State let  be the path from the root to  and  be the pivot of \label{ln:pivot}

  \If{}\label{ln:spuriousnessCheck}

  \State \label{ln:updateMap}

  \State \label{ln:subTree}

  \For{}\label{ln:forSubRem}

  \State move  from  to \label{ln:moveNext}

  \EndFor

  \State remove  from \label{ln:removeSubTree}

  \State add  to \label{ln:addPivot}

  \Else 
  
  \State return \label{ln:realCEXreport}

  \EndIf 

  \Else

  \State 

  \For{}\label{ln:post}

  \If{there exists }

  \State add  to \label{ln:addSubsume}

  \Else

  \State \label{ln:rem}

  \State \label{ln:buildSucc}

  \State 

  \For{}

  \State add  to \label{ln:addSuccSubsume}

  \EndFor

  \For{}
  
  \State add  to \label{ln:addSubSubsume}

  \EndFor

  \State remove  from \label{ln:removeRem}

  \State add  to \label{ln:addNext}

  \EndIf

  \EndFor

  \EndIf

  \EndWhile\label{ln:endWhile}
\end{algorithmic}}
\caption{Trace Inclusion Semi-algorithm}\label{alg:trace-inclusion}
\end{algorithm}

The processed antichain nodes are kept in the set ,
and their abstract successors, not yet processed, are kept in the set
. Initially,  and
. The algorithm
uses a predicate map , which is initially empty (line
\ref{ln:init}).



We keep a set of subsumption edges  with the following meaning:
 for two antichain
nodes, where  are product states and  are tree
positions, if and only if there exists an abstract successor  such that  (Definition
\ref{def:subsumption}). Observe that we do not explicitly store a
subsumed successor of a product state  from the antichain; instead,
we add a~subsumption edge between the node labeled with  and the
node that subsumes that particular successor. The algorithm terminates
when each abstract successors of a~node from  is
subsumed by some node from .



An iteration of Algorithm \ref{alg:trace-inclusion} starts by chosing a current
antichain node  from  and moving it to
 (line~\ref{ln:move}). If the product state  is accepting
(line~\ref{ln:ifAccepting}) we check the counterexample path , from the
root of the antichain to , for spuriousness, by computing its
pivot . If , then  is a~spurious counterexample
(line~\ref{ln:spuriousnessCheck}), and the path formula of the suffix of ,
which starts with position , is infeasible. In this case, we compute an
interpolant for the suffix and refine the current predicate map  by adding
the predicates from the interpolant to the corresponding substates of the
product states from the suffix (line \ref{ln:updateMap}).

The computation of the interpolant and the update of the predicate map are
done by the  function using the
approach described in Section \ref{sec:cex}. Subsequently, we remove (line
\ref{ln:removeSubTree}) from the current antichain the subtree rooted at the
pivot node , i.e.\ the -th node on the path 
(line~\ref{ln:subTree}),~and~add  to  in order to trigger
a recomputation of this subtree with the new predicate map. Moreover, all nodes
with a successor previously subsumed by a node in the removed subtree are moved
from  back to  in order to reprocess
them~(line~\ref{ln:moveNext}).

On the other hand, if the counterexample  is found to be real
(), any valuation  that
satisfies the path formula  yields a counterexample
trace , obtained by ignoring all variables from
 (line
\ref{ln:realCEXreport}).

If the current node is not accepting, we generate its abstract
successors (line \ref{ln:post}). In order to keep in the antichain
only nodes that are incomparable w.r.t. the subsumption relation
, we add a successor  of  to  (lines
\ref{ln:buildSucc} and \ref{ln:addNext}) only if it is not subsumed by
another product state from a node . Otherwise,
we add a subsumption edge  to the set
 (line \ref{ln:addSubsume}). Furthermore, if  is
not subsumed by another state in , we remove from
 all nodes  such that  strictly
subsumes  (lines \ref{ln:rem} and \ref{ln:removeRem}) and add
subsumption edges to the node storing  from all nodes with a
removed successor (line \ref{ln:addSuccSubsume}) or a removed
subsumption edge (line \ref{ln:addSubSubsume}).

The following theorem states the soundness of our trace inclusion
semi-algorithm. The theorem is proved in the appendix together with
the other results presented above.

\begin{theorem}\label{thm:trace-inclusion-soundness}
  Let  be a DAN such that 
  for all , and let  be a
  DA such that . If
  Algorithm \ref{alg:trace-inclusion} terminates and returns true on
  input  and , then
  . 
\end{theorem}

The dual question ``if there exists a counterexample trace ,
will Algorithm~\ref{alg:trace-inclusion} discover it?'' can also be
answered positively, using an implementation that enumerates the
abstract paths in a systematic way, e.g.\ by using a~breadth-first
path exploration. This can be done using a queue to implement the
 set in Algorithm \ref{alg:trace-inclusion}.

\subsection{Proof of Theorem \ref{thm:trace-inclusion-soundness}}


Given a network  where  for
all  and an observer , we
recall that a configuration of the product automaton  is a tuple , and a node of the antichain
 is a pair  where  is a product state for
 and  and  is a tree position. Moreover,
 is the product
state that labels the root of .  In the following, let
 be an
\emph{antichain state} where  is the predicate map, and
, , and  are the
sets of antichain nodes handled by Algorithm
\ref{alg:trace-inclusion}.

We say that  is a \emph{closed
  antichain state} if and only if, for all nodes  and every successor  of 
a~configuration of the product automaton  represented by the product state , there exists a
node  such that
 and one of
the following holds: \begin{compactitem}
  \item  for some , i.e.\  is a
    child of  in the antichain
    , or
\item .
  \end{compactitem}
In other words, the current antichain , defined as the
union of the sets  and , is in a
closed state, if the residual language of every successor of a
configuration of the product automaton  that is covered by a visited product state must be
included in the residual language of a product state stored in the
antichain, either as a direct successor in the tree or via a
subsumption edge.

For a product state , we define , and  if and only if
. For a
finite non-empty set of antichain nodes , we define
 with . 

\begin{lemma}\label{lemma:succ-sem}
  Given a network  and an observer , for any product
  state  of  and , we have
  .
\end{lemma}
\proof{ Let . ``'' Let
   be a configuration of  for which there exists  such that . Then there exists a unique rule  such that
  . Moreover, if , we have . Let  where . We
  have , hence . ``'' Let  for some
  . Then we have  where
  . Since , there exists  such that
  . Hence
  , thus . \qed}\bigskip
 
\begin{lemma}\label{lemma:post-abs}
  Given a network , an observer , and a predicate map
  , for any product state  of  and any
  product state  there exists  such that .
\end{lemma}
\proof{ Let . By the
  definition of , we have
  , where , thus . \qed}\bigskip

\begin{lemma}\label{lemma:succ-post}
  Given a network , an observer , and a predicate map
  , for each product state  and each configuration
   there exists a product state  such that .
\end{lemma}
\proof{ We use the fact that 
  (Lemma \ref{lemma:succ-sem}) and that for each  there exists  such
  that  (Lemma
  \ref{lemma:post-abs}). \qed}\bigskip

The proof of soundness of Algorithm \ref{alg:trace-inclusion} relies
on the inductive invariants () and ()
from the following lemma.

\begin{lemma}\label{lemma:invariants}
  The following invariants hold each time line \ref{ln:beginWhile} is
  reached in Algorithm \ref{alg:trace-inclusion}:
  \begin{compactitem}
  \item ()
    
    is closed,
\item ()
    .
  \end{compactitem}
\end{lemma}
\proof{Initially, when coming to line \ref{ln:beginWhile} for the first time,
  we have , thus
  , and both invariants hold
  trivially. For the case when coming to line \ref{ln:beginWhile} after
  executing the loop body, we denote by:
  
  the antichain states before and after the execution of the main
  loop. We assume that both invariants hold for .

  \vspace*{\baselineskip}\noindent () Let  and . We
  distinguish two cases according to the control path taken inside
  the main loop:
  \begin{compactenum}[(1)]
  \item If the test on line \ref{ln:ifAccepting} is positive, the
    predicate map is augmented, i.e.\ 
    (line \ref{ln:updateMap}). Let 
    be the next antichain state. Clearly  is closed provided
    that  is. Next, let  be the pivot of the path to the current
    node (line \ref{ln:pivot}) and define the following sets of nodes:
    
    Then we obtain (lines \ref{ln:forSubRem}--\ref{ln:addPivot}):
    
    Since  is closed, there exists a node  such that
     and
    either  for some  or
    . We
    distinguish two cases:
    \begin{compactenum}[(a)]
    \item . Then  and, because
      , we obtain that  is closed as
      well.
\item . Then we distinguish two further cases:
      \begin{compactenum}[(i)]
      \item If  for some , since we have assumed that
        , we have . The only possibility is then
         and  is the
        parent of . In this case, we have
        . 
\item If ,
        then , which contradicts the assumption
        . 
      \end{compactenum}
    \end{compactenum}
\item Otherwise, the test on line \ref{ln:ifAccepting} is negative,
    in which case we have  and
    . For each  there
    exists  such that
     (by
    Lemma \ref{lemma:succ-post}). We distinguish two cases:
    \begin{compactenum}[(a)]
    \item . In this case, either\begin{inparaenum}[(i)]\item there is  such
        that , and then we also have
         (Definition \ref{def:subsumption}) and
         (added
        on line \ref{ln:addSubsume}), or
\item  for some 
        (added on lines \ref{ln:buildSucc} and \ref{ln:addNext}).
        \end{inparaenum}
\item Otherwise . As
       is closed, there is  such that
       and either  for some  or
      .  We
      distinguish two sub-cases: \begin{compactenum}[(i)]
        \item  (line \ref{ln:rem}).
          Then 
          (Definition \ref{def:subsumption}), hence
          . If , then
           for
          some  (added on line
          \ref{ln:addSuccSubsume}). Else, if
          , we
          have 
          for some  (added on line
          \ref{ln:addSubSubsume}). In both cases, we obtain that
           is closed.
\item . Then
          . Since , we obtain
          that  is closed.
        \end{compactenum}
    \end{compactenum}
  \end{compactenum}

  \vspace*{\baselineskip}\noindent () We distinguish two cases:
  \begin{compactenum}
  \item If , it is
    sufficient to show that . Suppose, by contradiction, that
    , hence
    , and since , we obtain
    ,
    contradiction. 
\item Otherwise,  and
    there exists a node  such
    that . Let  be a trace such that
    . Then there exists a
    run  of  over  such that  and  a final state of . Since  is closed due to
    () and , there
    exists a node  such that
    . If , we
    obtain that , and we
    are done. Otherwise, ,
    and we can repeat the same argument inductively, to discover a
    sequence of nodes  such that
     for all . Since  is a
    final state of , we have
    , thus , and 
    is an accepting product state. But this contradicts with the fact
    that accepting product states are never stored in the antichain.
  \end{compactenum}
\qed}\bigskip

Back to the proof of Theorem \ref{thm:trace-inclusion-soundness}:

\proof{ If Algorithm \ref{alg:trace-inclusion} terminates and reports
  true, this is because , hence
  . By Lemma
  \ref{lemma:invariants} (), we obtain that
  .
  Suppose, by contradiction, that
  . By Lemma \ref{lemma:inclusion-emptiness}, there
  exists a trace  Thus we have a run of  over :
   where
  , ,
   is final in , . But, since , we have . Hence,
  , which
  is in contradiction with the fact that
  . Consequently,
  it must be the case that . \qed}

\section{Computing Simulations of Data Automata}
\label{sec:simulations}


In the case of classical Rabin-Scott finite automata over finite
alphabets, a \emph{simulation} \cite{milner} is a relation
on the states of an automaton, which is invariant with respect to the
transition relation of the automaton. The simulation-based approach
for checking language inclusion between two automata  and  first
computes a simulation relation on the union of the states of  and
, then checks whether the pair of initial states is a member of the
simulation relation. This method is not complete because there exist
automata, such that , but the
initial state of  is not simulated by the initial state of . A
pre-computed simulation relation can be used however to speed up the
convergence of the antichain-based method, by weakening the
subsumption relation used by the antichain construction algorithm
\cite{abdulla}.

In this section, we define a notion of simulation between data
automata and give an algorithm that computes useful
under-approximations of the weakest simulation on a data
automaton. The simulation relation can be used to enhance the
convergence of Algorithm \ref{alg:trace-inclusion}, similar to the way
in which classical simulations are integrated with the antichain-based
language inclusion algorithm for automata over finite alphabets
\cite{abdulla}.

\begin{definition}\label{def:data-simulation}
  A relation  is
  a \emph{data simulation} for a DA  if and only if, for all  the following hold: \begin{compactenum}
  \item\label{it1:data-simulation}  only if , and
\item\label{it2:data-simulation} for all  and all
     such that  there exists  such that
     and .
  \end{compactenum}
\end{definition}
Observe that, while a classical simulation is a binary relation on
states, a data simulation is a ternary relation involving also a
valuation of the variables. The following lemma shows that a data
simulation preserves residual languages.

\begin{lemma}\label{lemma:simulation-residual}
  Given a DA  and  a
  data simulation for , for any tuple  we have
  . 
\end{lemma}
\proof{ Let  be a run of  such that . By induction on  we find a run
   of , such that
  , for all . Moreover, since
  , we also obtain . \qed}

Let ,
where , for some , be a DA for the rest
of this section. The data simulation algorithm (Algorithm
\ref{alg:data-simulation}) given in this section manipulates sets of
valuations from  that are definable by
first-order formulae in . A relation  is said to be \emph{definable} if and
only if there exists a matrix  of
formulae  such that . For , we denote by
 the -th row of the matrix .

Algorithm \ref{alg:data-simulation} is a refinement algorithm which
handles two matrices of formulae that define the relations
. In the following we shall use the
same names to denote the relations and their matrix representations.
Intuitively,  is the previous candidate for
simulation, whereas  is a entry-wise stronger relation,
that refines . The refinement step is performed
backwards, with respect to each transition rule  of the automaton. Namely, for each pair
of valuations such that  and
 for some state , we add
the tuple  for all predecessors 
of , such that  and . This update guarantees that, for every transition
, where  there exists a state  such that  and . The algorithm stops when  and
 define the same relation, which is, moreover, a
simulation.

To define the update, we use the following
function:  We define also the sets
 and . With this notation, Algorithm
\ref{alg:data-simulation} describes the procedure that computes a data
simulation for a given data automaton.

\begin{algorithm}[htb]
\begin{algorithmic}[0]
\State {\bf input}: a data automaton , where  and a constant 

\State {\bf output}: a data simulation  for  

\State {\bf global vars} ,
, 
\end{algorithmic}
\begin{algorithmic}[1]
\For{}
\For{}

\State \label{ln:initPrevSim}

\State \label{ln:initCnt}

\EndFor

\For{}

\EndFor

\If{}

\State \label{ln:simInitFalse}

\Else

\State \label{ln:simInit}

\EndIf

\EndFor

\For{all  such that }\label{ln:simBeginWhile}

\For{}

\For{}

\For{}

\State \label{ln:simUpdate}

\EndFor

\EndFor

\EndFor

\For{all  such that }

\If{}

\State \label{ln:simFalse}

\Else

\State \label{ln:cntDec}

\EndIf

\EndFor

\State \label{ln:prevSimUpdate}

\EndFor\label{ln:simEndWhile}

\State {\bf return} 
\end{algorithmic}
\caption{Data Simulation Algorithm}\label{alg:data-simulation}
\end{algorithm}


Initially, the matrix  is true everywhere (line
\ref{ln:initPrevSim}). The current simulation candidate 
is initialized to false for all  such that 
and  (line \ref{ln:simInitFalse}). Observe that, in
this case  cannot simulate , by Definition
\ref{def:data-simulation} (\ref{it1:data-simulation}). Otherwise, we
initialize  to the strongest pre-simulation with
respect to  (line \ref{ln:simInit}). In the
iterative loop (lines \ref{ln:simBeginWhile}--\ref{ln:simEndWhile})
the algorithm choses a state  for which the current simulation
candidate  is not equivalent to the previous one
 (line \ref{ln:simBeginWhile}) and sharpens the
set , with respect to the transition rule , for all input symbols 
and all peer states  (line \ref{ln:simUpdate}).
The following invariants are key to proving the correctness of
Algorithm \ref{alg:data-simulation}.

\begin{lemma}\label{lemma:sim-invariants}
  The following invariants hold each time Algorithm
  \ref{alg:data-simulation} reaches line \ref{ln:simBeginWhile}:
  \begin{compactitem}
  \item () 
\item () 
  \end{compactitem}
\end{lemma}
\proof{ Let  and  denote the global
  matrices after one iteration of the loop on lines
  \ref{ln:simBeginWhile}--\ref{ln:simEndWhile}.  

  \vspace*{\baselineskip}\noindent () When line
  \ref{ln:simBeginWhile} is reached for the first time,
  , for all , thus
   holds initially. Since  is modified
  only at lines \ref{ln:simUpdate} or \ref{ln:simFalse}, we have
  , for all
  . Moreover, either , or , for all  (line
  \ref{ln:prevSimUpdate}). Thus , for all
  , by an application of the induction hypothesis.

  \vspace*{\baselineskip}\noindent () We show
  that this invariant holds the first time the control reaches line
  \ref{ln:simBeginWhile}. Let , 
  and  such that  and . Since  (thus
  ) and
   we have that , where . Since  we obtain that , and consequently , for some , such that . Hence 
  holds when the control first reaches line \ref{ln:simBeginWhile}.

  For the induction step, let us assume that  holds at
  line \ref{ln:simBeginWhile} and we prove that it holds also after
  executing line \ref{ln:prevSimUpdate}. Let ,
   and  such
  that  and . We distinguish two cases:
  \begin{compactenum}
  \item if  on line
    \ref{ln:simBeginWhile}, since , then  was
    updated at line \ref{ln:simUpdate}. Since , we obtain . Moreover,
     is updated to  at
    line \ref{ln:prevSimUpdate}, hence  as well.
    Since , we obtain that
    , for some  such
    that , thus  and . Thus  holds
    for  and .
\item else  on line
    \ref{ln:simBeginWhile},  because the update on line
    \ref{ln:prevSimUpdate} is skipped, and for all  and all , we have
    . Then 
    holds for  and  because it holds
    for  and , by the induction
    hypothesis. 
  \end{compactenum}
\qed}

The algorithm iterates the loop on lines
(\ref{ln:simBeginWhile}--\ref{ln:simEndWhile}) until 
and  define the same relation. Since, in general the
data constraints , at each iteration step, might
form an infinitely decreasing sequence, we use the matrix
 of integer counters, initially set to some input value
 (line \ref{ln:initCnt}). Observe that each entry
 decreases every time  (line \ref{ln:cntDec}). When the counter
 reaches zero, we set  to false
(line \ref{ln:simFalse}), which guarantees that  always in the future. Since the number of
entries in the counter matrix is finite, the algorithm is guaranteed
to terminate. The following theorem summarizes the main result of this
section.

\begin{theorem}\label{thm:simulation}
  Let  be a
  DA. Then Algorithm \ref{alg:data-simulation} terminates on input 
  and the output is a data simulation  for . 
\end{theorem}
\proof{ Let  and  denote the
  matrices  and  at the -th
  iteration of the loop on lines
  \ref{ln:simBeginWhile}--\ref{ln:simEndWhile}, for
  . Algorithm \ref{alg:data-simulation} terminates whenever
  , for all
   (line \ref{ln:simBeginWhile}). Suppose, by
  contradiction, that this never happens, thus there exist
   such that , for all . Then
   (line \ref{ln:cntDec}) and
  
  (lines \ref{ln:simFalse} and \ref{ln:prevSimUpdate}). Since
  , by Lemma
  \ref{lemma:sim-invariants} (), we obtain that
  ,
  contradiction. 

  To prove that the output of Algorithm \ref{alg:data-simulation} is a
  data simulation for , we use Lemma \ref{lemma:sim-invariants}
  () and the fact that, upon termination, we
  have , for all
  . \qed}

\subsection{Simulation and Subsumption}


Finally, we explain how a data simulation relation computed by
Algorithm \ref{alg:data-simulation} can be used to optimize the trace
inclusion semi-algorithm. Let 
be DAN, where , for
all , and  be an
observer DA such that .

The main problem in using data simulation to enhance the convergence
of our trace inclusion semi-algorithm is related to the fact that
simulation relations are, in general, not compositional w.r.t.  the
interleaving semantics of the network. In other words, if we have 
data simulations , then their cross-product 
defined as:  is not necessarily a
simulation on the network expansion . The reason for
this can be seen for . Let , such that  and
. The execution of  on the
sequence of input symbols  is . Suppose that
, . Then there exists
 such that  and . In order to use the simulation and build the continuation
, we would need that
, which is not necessarily
ensured by the hypothesis .

We propose a partial solution to this problem, based on a restriction
concerning the distribution of the network variables
 over the
components : for each , we have , where  is a set of
\emph{global} variables, and  are the \emph{local}
variables of . In other words, the only variables shared between
more than one component are , which, moreover, are visible
to all components.

Then the problem can be bypassed if none of the simulation relations

may constrain the global variables:

\begin{ass}\label{ass:global-unrestricted}
For each  and each  we also have
 for each 
such that .
\end{ass}

Under this assumption, we use pre-computed data simulations  and  to generalize
the basic subsumption relation between product states (defined by
Lemma \ref{lemma:img-subsumption}) thus speeding up the convergence of
Algorithm \ref{alg:trace-inclusion}.

\begin{lemma}\label{lemma:sim-subsumption}
  Under assumption \ref{ass:global-unrestricted}, the relation defined
  as:  
  is a subsumption relation. 
\end{lemma}
\proof{ Let  and
   be two product states, such that
  . According to Definition
  \ref{def:subsumption}, we need to prove that
  . To this end, it
  is sufficient to prove that for each  such that :
  \begin{compactenum}
    \item , and
\item for all  there exists  such that
      . 
  \end{compactenum}
  Assuming that the above statements hold, we have:
   and we are done. Moreover, the second point
   above is a direct consequence of the second point of the definition
   of  and Definition
   \ref{def:subsumption}. We are left with proving the first
   point. Let  be a transition of 
   and let  be a configuration of
    such that ,
   for each . Let  be an arbitrary component,
   and distinguish two cases: \begin{compactitem}
   \item if  and
     ,
     i.e.\ , then, since
      there exists  s.t.\  and
     .
\item otherwise,  and
     . By
     Assumption \ref{ass:global-unrestricted}, we obtain
     . By chosing
     , we obtain .
   \end{compactitem}
   Hence , for all . Thus, the relation defined as:
    is a data simulation (Definition \ref{def:data-simulation}),
   thus, by Lemma \ref{lemma:simulation-residual}, we obtain that
   , for all
   , such that , and the first point above holds. \qed}


\section{Experimental Results}\label{sec:experiments}


We have implemented Algorithm \ref{alg:trace-inclusion} in a prototype
tool\footnote{{\tt http://www.fit.vutbr.cz/research/groups/verifit/tools/includer/}}
using the \textsc{MathSat} SMT solver \cite{mathsat} for answering the
satisfiability queries and computing the interpolants. The results of
the experiments are given in Tables~\ref{TaExpRes} and
~\ref{TaExpResProd}. The results were obtained on an Intel i7-4770 CPU
@ 3.40GHz machine with 32GB RAM.

\begin{table}
\begin{center}
{\fontsize{8}{9}\selectfont
  \caption{Experiments with single-component networks.}
  \label{TaExpRes}
\begin{tabular}{||l|c|c|c|c||c|c||}
  \hline
  Example &  (/) &  (/) & Vars. & Res.  & Time \\
  \hline \hline
Arrays shift        & 3/3  & 3/4 & 5 &ok           &   \\
  \hline
Array rotation 1 &  4/5  & 4/5 & 7 &ok    &  \\ 
  \hline
Array rotation 2 &  8/21 & 6/24& 11 &ok    &   \\ 
  \hline
Array split      &  20/103 & 6/26& 14 &ok    &   \\ 
  \hline
HW counter 1      &  2/3 & 1/2 & 2 &ok           &   \\
  \hline
HW counter 2            &  6/12 & 1/2 & 2 &ok           &   \\
  \hline
Synchr. LIFO       &  4/34 & 2/15 & 4 &ok           &   \\
  \hline
ABP-error              & 14/20 & 2/6& 14 &cex  &     \\
  \hline
ABP-correct          &  14/20 & 2/6& 14&ok           &   \\
\hline
\end{tabular}
}
\end{center}
\end{table}

Table ~\ref{TaExpRes} contains experiments where the network
 consists of a single component. We applied the tool on
several verification conditions generated from imperative programs
with arrays \cite{cav09} (Array shift, Array rotation 1+2, Array
split) available online \cite{ntslib}. Then, we applied it on models
of hardware circuits (HW Counter 1+2, Synchronous LIFO)
\cite{smrcka}. Finally, we checked two versions (correct and faulty)
of the timed Alternating Bit Protocol \cite{abp}.

Table ~\ref{TaExpResProd} provides a list of experiments where the
network  has  components. First, we have the example
of Fig. \ref{fig:running-example} (Running). Next, we have several
examples of real-time verification problems \cite{stavros-thesis}:
a~controller of a railroad crossing \cite{henzinger:RealTimeSystems}
(Train) with  trains, the Fischer Mutual Exclusion protocol with
deadlines  and  (Fischer), and a~hardware
communication circuit with  stages, composed of timed NOR gates
(Stari). Third, we have modelled a Producer-Consumer example
\cite{AmitThesis} with a fixed buffer size . Fourth, we have
experimented with several models of parallel programs that manipulate
arrays (Array init, Array copy, Array join) with window size
.

\begin{table}[t]
\begin{center}
{\fontsize{8}{9}\selectfont
  \caption{Experiments with multiple-component networks (e.g.,
     in column  means that
     is a~network with  components, of which  DA with 2 states
    and  rules, and  DA with  states and  rules).}
\label{TaExpResProd}
\begin{tabular}{||l|c|c|c|c|c|c||c|c||}
  \hline
  Example & N & (/) &  (/) & Vars. & Res.  & Time \\
  \hline \hline
Running & 2 & 22/2  & 3/4& 3 &ok & \\
\hline
Running & 10 & 102/2  & 11/20& 3 &ok & \\
\hline
Train () & 7 & 53/3 + 4/4 + 4/4  & 2/38& 1 &ok & \\
\hline
Train () & 22 & 203/3 + 4/4 + 4/4  & 2/128& 1 &ok & \\
\hline
Fischer (, )  & 2 & 25/6  & 1/10& 4 &ok & \\
\hline
Fischer (, )  & 3 & 35/6  & 1/15& 4 &ok & \\
\hline
Fischer (, )  & 2 & 25/6  & 1/10& 4 &cex & \\
\hline
Fischer (, )  & 3 & 35/6  & 1/15& 4 &cex & \\
\hline
Stari ()  & 5 &  4/5 + 2/4 + 5/7 + 5/7 + 5/7  & 3/6 & 3&ok & \\
\hline
Stari ()  & 8 &  4/5 + 2/4 + 25/7 + 25/7 + 25/7  & 3/6 & 3&ok & \\
\hline
Prod-Cons ()  & 2 & 4/4 + 4/4  & 2/7 & 2 &ok & \\
\hline
Prod-Cons ()  & 2 & 4/4 + 4/4  & 2/7 & 2 &ok & \\
\hline
Array init () & 5 & 52/2  & 2/6 & 2 &ok & \\
\hline
Array init () & 15 & 152/2  & 2/16 & 2 &ok & \\
\hline
Array copy () & 20 & 202/2  & 2/21 & 3 &ok & \\
\hline
Array copy () & 150 & 1502/2  & 2/151 & 3 &ok & \\
\hline
Array join ()  & 4 & 22/2 + 23/3  & 2/3 & 2 &ok & \\
\hline
Array join ()  & 6 & 32/2 + 33/3  & 2/4 & 2 &ok & \\
\hline

\end{tabular}
}
\end{center}
\end{table}

For the time being, our implementation is a proof-of-concept prototype
that leaves plenty of room for optimization (e.g.\ caching
intermediate computation results) likely to improve the performance on
more complicated examples. Despite that, we found the results from
Tables~\ref{TaExpRes} and \ref{TaExpResProd} rather encouraging.

\section{Conclusions}


We have presented an interpolation-based abstraction refinement method
for trace inclusion between a network of data automata and an
observer where the variables used by the observer are a subset of
those used by the network. The procedure builds on a new
determinization result for DAs and combines in a novel way predicate
abstraction and interpolation with antichain-based inclusion checking.
The procedure has been successfully applied to several examples,
including verification problems for array programs, real-time systems,
and hardware designs. Future work includes an extension of the method
to data tree automata and its application to logics for heaps with
data. Also, we foresee an extension of the method to handle infinite
traces.

\paragraph{Acknowledgement.} This work was supported by the Czech Science
Foundation project 14-11384S, the BUT FIT project FIT-S-14-2486, and the French
ANR-14-CE28-0018 project Vecolib.

\bibliographystyle{splncs03}
\bibliography{ref}



\end{document}
