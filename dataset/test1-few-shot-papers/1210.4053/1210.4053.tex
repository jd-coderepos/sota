\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{authblk}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amsmath}

\bibliographystyle{plain}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}

\begin{document}
\title{Joint Cache Partition and Job Assignment on Multi-Core Processors\footnote{This work was partially supported by the
Israel Science Foundation grant no. 822-10.
Israeli Centers of Research Excellence (I-CORE) program, (Center  No. 4/11).
Google Inter-university center for Electronic Markets and Auctions.}}

\author[1]{Avinatan Hassidim}
\author[2]{Haim Kaplan}
\author[2]{Omry Tuval}
\affil[1]{Dept. of Computer Science
Bar Ilan University
and Google Israel\\
  \texttt{avinatan@google.com}}
\affil[2]{Dept. of Computer Science, Tel Aviv University\\
  \texttt{\{haimk, omrytuva\}@post.tau.ac.il}}
\renewcommand\Authands{, }
\date{}


\maketitle
\begin{abstract}
Multicore shared cache processors  pose a challenge for designers of
embedded systems  who try to achieve minimal and predictable
execution time of workloads consisting of several jobs.
To address this challenge the cache is statically partitioned among
the cores and the jobs are assigned to the cores so as to minimize the
makespan.
Several heuristic algorithms have been proposed that jointly decide
how to partition the cache among the cores and assign the jobs. We
initiate a theoretical study of this problem which we call the joint
cache partition and job assignment problem.

By a careful analysis of the possible cache partitions we obtain a
constant approximation algorithm for this problem. For some
practical special cases we obtain a -approximation algorithm, and
show how to improve the approximation factor even further by
allowing the algorithm to use additional cache. We also study
possible improvements that can be obtained by allowing dynamic cache
partitions and dynamic job assignments.

We define a natural special case of the well known scheduling
problem on unrelated machines in which machines are ordered by
``strength''. Our joint cache partition and job assignment problem
generalizes this scheduling problem which we think is of independent
interest. We give a polynomial time algorithm for this scheduling
problem for instances obtained  by fixing the cache partition in a
practical case of the joint cache partition and job assignment problem where job loads are step functions.
\end{abstract}

\section{Introduction}

We study the problem of  assigning  jobs to  cores on a multi-core processor, and simultanously partitioning a shared cache of size  among the cores.
Each job  is given by a non-increasing function  indicating the running time of job  on a core with cache of size .
A solution is a cache partition , assigning  cache to each core ,  and a job assignment  assigning each job  to core .
The total cache allocated to the cores in the solution is , that is  .
The {\em makespan} of a cache partition  and a job assignment  is .
Our goal is to find a cache partition and a job assignment that minimize the makespan.

Multi-core processors are the prevalent  computational architecture
used today in PC's, mobile devices and high performance computing.
Having multiple cores running jobs concurrently, while sharing the
same level 2 and/or level 3 cache, results in complex interactions
between  the jobs, thereby posing a significant challenge in
determining the makespan of a set of jobs.
Cache partitioning has emerged as a technique  to increase run time
predictability and increase performance on multi-core processors
\cite{part_survey, part_throughput}. Theoretic research on online
multi-core caching  shows that  the cache partition (which may be
dynamic)  has more influence on the performance than the eviction
policy \cite{Hassidim,LO12}. To obtain effective cache partitions,
methods have been developed to estimate the running time of jobs as
a function of allocated cache, that is the functions  (see
for example the cache locking technique of \cite{liu_lock1}).

Recent empirical research \cite{LZLX,liu_lock2} suggests that
jointly solving for the cache partition among the cores and for the
job assignment to cores leads to significant improvements over combining separate algorithms for the two problems.
The papers \cite{LZLX,liu_lock2} suggest and test heuristic algorithms for the joint cache partition and job assignment problem.
Our work initiates the theoretic study of this problem.

We study this problem in the context of multi-core caching, but our
formulation and results  are applicable in a more general setting,
where  the running time of a job  depends on the availability of
some shared resource (cache, CPU, RAM, budget, etc.) that is allocated to the
machines. This setting is  applicable, for example, for users of a
public cloud infrastructure like Amazon's Elastic Cloud. When a user
decides on her public cloud setup, there is usually a limited
resource (e.g.\ budget), that can be spent on different machines in
the cloud. The more budget is spent on a  machine, it runs jobs
faster and the user is interested in minimizing the makespan of its
set of jobs, while staying within the given budget.

\smallskip

\noindent {\bf Related Work:} Theoretic study of multi-core caching
have shown that traditional online paging algorithms are not
competitive in the multi-core scenario \cite{Hassidim, LO12}. Both
papers \cite{Hassidim, LO12} show that the offline decision version of the caching problem
is NP-complete, in slightly different models.
Much of the difficulty in designing competitive online algorithms for multi-core caching stems from the fact that the way in which the request sequences of the different cores interleave is dependent on the algorithm. An algorithm with good competitive ratio is obtained in \cite{Barve}, when the interleaving of the request sequences is fixed.\\
For related work on scheduling see Section \ref{sec:scheduling}.

\smallskip

\noindent {\bf Our results:} We present a -approximation
algorithm for the joint cache partition and job assignment problem in Section \ref{sec_36}.
We obtain this algorithm by  showing that it suffices to consider a
subset of polynomial size of the cache partitions.

We obtain better approximation guarantees for special cases of the
joint cache partition and job assignment problem.

 When each job has a fixed running time and a minimal cache demand, we present
, in Section \ref{sec_slmc}, a -approximation algorithm, a -approximation
algorithm that uses  cache and a -approximation
algorithm that uses  cache. We call this problem the {\em single load
minimal cache demand} problem.  Our -approximation algorithm is based on an algorithm presented in Section \ref{threshold_dominant} that
finds  a dominant perfect matching in a threshold graph that has a perfect matching.
This algorithm and the existence of such a matching are of independent interest.

We present in Section \ref{correl_ptas} a polynomial time approximation scheme  for a special case of the single load minimal cache demand problem,
in which there is a correlation between the jobs' loads and cache demands. Such a model is inspired by practical cases where there is an underlying notion of a job's ``hardness'' that affects both its load and its cache demand.

We study, in Section \ref{sec_const},  the case where the
load functions of the jobs, , are step functions. That is, job
 takes  time to run if given at least   cache, and
otherwise it takes  time. For the case where there are a constant number of
different 's and 's we reduce the problem to the single
load minimal cache demand problem and thereby obtain
the same approximation results as for that problem (Section \ref{sec_const}).

We define the problem of scheduling on {\em ordered unrelated
machines}, a natural special case of the classical job scheduling
problem on unrelated machines.
In this problem there is a total order on the machines which captures their relative strength.
Each job has a different running time on each machine
and these running times are non-increasing with the strength of the
machine. We show a reduction from this problem to the joint
cache partition and job assignment problem. We also give a
polynomial time dynamic programming algorithm for a special case of
this problem that arises when we fix the cache partition in the
special case where the number of s and s is constant (Section \ref{sec_const}).

In section \ref{sec_variants} we generalize the joint cache
partition and job assignment problem and consider dynamic cache
partitions and dynamic job schedules. We show upper and lower bounds
on the makespan improvement that can be gained by using dynamic partitions and
dynamic assignments.


\section{The ordered unrelated machines problem}\label{sec:scheduling}
The ordered unrelated machines scheduling problem is defined as follows.
There are  machines and a set  of jobs.
The input is a matrix  giving the running time of job  on machine , such that for each two machines  and any job , . The goal is to assign the jobs to the machines such that  the makespan is minimized.

The ordered unrelated machines scheduling problem is a  special case of scheduling on unrelated machines in which
there is a total order on the machines that captures their relative strengths.
This special case is natural since
in many practical scenarios the machines have some underlying notion of strength and jobs run faster on a stronger machine.
For example a newer computer typically dominates an older one in all parameters, or a more experienced employee does any job faster than
a new recruit.

Lenstra et al \cite{LST90}
gave a  approximation algorithm for scheduling on unrelated machines based on
 rounding an optimal fractional
solution to a linear program, and proved that it is NP-hard to approximate the problem to within a factor better than
. Shchepin and  Vakhania \cite{SV05} improved Lenstra's rounding technique  and obtained a  approximation algorithm. It is currently an open question if there are better approximation algorithms for ordered unrelated machines than the more general algorithms that approximate unrelated machines.

Another well-studied scheduling problem is scheduling on uniformly related machines. In this problem, the time it takes for machine  to run job  is  where  is the  load of job  and  is the  speed of machine . A polynomial time approximation scheme for related machines is described in \cite{HS88}. It is easy to see that the problem of scheduling on related machines  is a special case of the problem of scheduling on ordered unrelated machines, and therefore the ordered unrelated machines problem is NP-hard.

The ordered unrelated machines problem is closely related to the joint cache partition and job assignment problem.
Consider an instance of the joint cache partition and job assignment problem with  cores,  cache and a set of jobs  such that  is the load function of job .
If we fix the cache partition to be some arbitrary partition , and we index the cores in non-decreasing order of their cache allocation,
then we get an instance of the ordered unrelated machines problem, where .
Our constant approximation algorithm for the joint cache partition and job assignment problem, described in Section \ref{sec_36}, uses this observation as well as Lenstra's -approximation for unrelated  machines.
In the rest of this section we prove that the joint cache partition and job assignment problem is at least as hard as the
ordered unrelated machines scheduling problem.

We reduce  the ordered unrelated machine problem to the joint cache partition and job assignment problem.
Consider the decision version of the ordered unrelated scheduling problem, with  machines and  jobs, where job  takes time  to run on machine .
We want to decide if it is possible to schedule the jobs on the machines with makespan at most .

Define the following instance of the joint cache partition and job assignment problem.
This instance has   cores, a total cache  and  jobs.
The first  jobs () correspond to the jobs in the original ordered unrelated machines problem, and  jobs are new jobs ().
The load function  of job , where ,  equals  if  and equals  if .
The load function  of job , where ,  equals  if  for some  and equals  if .
Our load functions  are non-increasing because the original 's are non-increasing in the machine index .

\begin{lemma} \label{reduce}
The makespan of the joint cache partition and job assignment instance defined above is at most  if and only if the makespan of the original unrelated scheduling problem is at most .
\end{lemma}
\begin{proof}
Assume there is an assignment  of the jobs in the original ordered  unrelated machines instance of makespan at most .
We show a cache partition  and job assignment  for the joint cache partition and job assignment instance with makespan at most .

The cache partition  is defined such that  for each core . The partition  uses exactly  cache.
The job  assignment  is defined such that for
 a job ,  and for a job , . The partition  assigns  cache to
core , which is exactly enough for job , which is assigned to core  by , to run in time .
It is easy to verify that  is a solution to the joint cache partition and job assignment instance with makespan at most .

Assume there is a solution   for the joint cache partition and job assignment instance, with makespan at most .
Job , such that , must run on a core with cache at least , or else the makespan would be infinite.
Moreover, no two jobs  and  are assigned by  the same core, as this would give a makespan of at least .
Combining these observations with the fact that the total available cache is , we get that the cache partition must be  for each core .
Furthermore, each job  is assigned by  to core  and all the other jobs assigned by  to core  are jobs
corresponding to original jobs in the ordered unrelated machines instance. Therefore, the total load of original jobs assigned by  to core  is at most .

We define , a job assignment for the original ordered unrelated machines instance, by setting  for each .
Since  assigns original jobs of total load at most  on each core, it follows that the makespaen of  is at most .
\end{proof}

The following theorem follows immediately from Lemma \ref{reduce}
\begin{theorem}
There is a polynomial-time reduction from the ordered unrelated machines scheduling problem to the joint cache partition and job assignment problem.
\end{theorem}

The reduction in the proof of Lemma \ref{reduce}  does not preserve approximation guarantees.
However by choosing  carefully we can get the following result.
\begin{theorem}\label{reduce_approx}
  Given an algorithm  for the joint cache partition and job assignment problem that approximates the optimal makespan up to a factor of , for , we can construct an algorithm for
  the ordered unrelated machines scheduling problem that approximates the optimal makespan up to a factor of  for any .
\end{theorem}
\begin{proof}
We first obtain a -approximation algorithm for the decision version of the ordered unrelated machines scheduling problem.
That is, an algorithm that given a value , either decides that there is no assignment of makespan  or finds an assignment with makespan .

Given an instance of the ordered unrelated machines scheduling problem, we construct an instance of the joint cache partition and job assignment as described before lemma \ref{reduce},
and set  , for an arbitrarily small .
We use algorithm  to solve the resulting instance of the joint cache partition and job assignment problem. Let  be the solution returned by .
We define  for each .
If the makespan of  is at most  we return  as the solution and otherwise decide that there is no solution with makespan at most .

If the makespan of the original instance is at most , then  by lemma \ref{reduce} there is a solution to the joint cache partition and job assignment instance resulting from the reduction, with makespan at most .
Therefore  , the solution returned by algorithm , is of makespan at most .

By our choice of  we have that  and therefore each core is assigned by  at most one job , such that .
In addition, any job  such that , must run on a core with cache at least , or else the makespan would be infinite.
Combining these observations with the fact that the total available cache is , we get that the cache partition must be  for each core .
Furthermore, each job  is assigned by  to core  and all the other jobs assigned by  to core  are jobs
corresponding to original jobs in the ordered unrelated machines instance. Therefore, the total load of original jobs assigned by  to core  is at most .
It follows that the makespan of  is
 at most .

We obtained a -approximation algorithm for the decision version of the ordered unrelated machines scheduling problem.
In order to approximately solve the optimization problem, we can perform a binary search for the optimal makespan using the approximation algorithm for the decision version of the problem and get a
-approximation algorithm for the optimization problem. We obtain an initial search range for the binary search by using  as an upper bound on the makespan of the optimal schedule and  as a lower bound.
(See section \ref{apn_approx_des_to_opt} for a detailed discussion of a similar case of using an approximate decision algorithm in a binary search framework to obtain an approximate optimization algorithm.)
\end{proof}

\section{A constant approximation algorithm}\label{sec_36}

We first obtain an 18-approximation algorithm that for the joint cache partition and job assignment problem that uses
 cache for some constant  .
We then show another algorithm that uses  cache and approximates the makespan up to a factor of 36.

Our first algorithm, denoted by , enumerates over a  subset of
cache partitions, denoted by . For each partition
in this set  approximates the makespan of  the corresponding
scheduling problem, using Lenstra's  algorithm, and returns the
partition and associated job assignment with the smallest makespan.

Let , the smallest integral power of  which is at least .
The set  contains cache partitions in which the cache allocated to each core is
an integral power of  and the number of different integral powers used by the partition is at most .
We denote by  the number of different cache sizes in a partition.
Each core is allocated  cache, where  and .
The smallest possible cache allocated to any core is the smallest integral power of  which is at least  and the largest possible cache allocated to a core is .
We denote by  the number of cores with cache at least .
It follows that there are  cores with   cache.
We require that  is an integral power of  and that the total cache used is at most .
Formally,

When the parameters are clear from the context, we use  to denote
. Let  denote the makespan of cache
partition  and job assignment . The following theorem
specifies the main property of , and is proven in the remainder of this section.
\begin{theorem}\label{P9thm}
Let  be any cache partition and job assignment. There are
a cache partition and a job assignment  such that
 and .
\end{theorem}

An immediate corollary of Theorem  \ref{P9thm} is that algorithm 
described above finds a cache partition and job assignment with
makespan  at most 18 times the optimal makespan.

Lemma \ref{lem_poly} shows that  is a polynomial time algorithm.

\begin{lemma}\label{lem_poly}
The size of  is polynomial in .
\end{lemma}
\begin{proof}
Let  .
The vector  is a strictly increasing vector of integral powers of , where each power is at most . Therefore the number of possible vectors for  is bounded by the number of subsets of  which is .
The vector  is a strictly increasing vector of integers, each integer is at most .
Therefore the number of vectors  is bounded by the number of subsets of integers that are at most  which is  since  is a constant.
Therefore .
\end{proof}

Let  be a cache partition and a job assignment that use  cores,  cache and have a makespan .
Define a cache partition  such that for each core , if  then  and if  then . For each core ,  and hence the total amount of cache allocated by  is bounded by . For each core ,  and therefore .

Let  be a cache partition such that for each core , , the smallest integral power of  that is at least .
For each ,  and thus .  We increased the total cache allocated by at most a multiplicative factor of  and therefore the total cache used by  is at most  since .

Let  be any  cache partition that allocates  to each core
an integral power of  cache. We define the notion of
. We say that core  is \textit{of cache
level } in  if . Let  denote the number
of cores in cache level  in .
The vector of 's, which we call the \textit{cache levels
vector} of , defines the partition  completely
since any two partitions that have the same cache level vector are
identical up to a renaming of the cores.

Let  be the vector of prefix sums of the cache
levels vector of . Formally, . Note that 
is the number of cores in cache partition  with at least
 cache and that for each ,
.

For each such cache partition  , we define
the \textit{significant cache levels}  recursively as
follows. The first significant cache level  is the
first cache level  such that . Assume we already
defined the  first significant cache levels and let
 then  is the smallest cache level
 such that .


\begin{lemma}\label{consec}
Let  and  be two consecutive significant cache levels
of , then the total number of cores in cache levels in
between  and   is at most . Let
 be the last significant cache level of  then the total
number of cores in cache levels larger than  is at most
 .
\end{lemma}
\begin{proof}
Assume to the contrary that  . This implies that for ,  which contradicts the assumption that there are no significant cache
levels in between  and  in . The proof of the
second part of the lemma is analogous.
\end{proof}

Let . For each core ,  , so we get that if  is a cache level in  such
that  then . Let
 and , where .
 Let , for , where  is the number of
significant cache levels in .


 We adjust  and  to create a new cache
partition  and a new job assignment . Cache partition
  has cores only in the significant cache levels 
of . We obtain  from  as follows. Let  be a
non-significant cache level in . If there is a  such that
 then we take the  cores  in cache level  in 
and reduce their cache so they are now in cache level  in . If  then we remove the  cores at level  from our solution.
It is easy to check that the significant cache levels of  are
the same as of , that is  . Since we only reduce the cache allocated to some cores, the new
cache partition  uses no more cache than  which is at most .

We construct  by changing the assignment of the jobs assigned
by  to cores in non-significant cache levels in . As before, let 
be a nonsignificant cache level and let  be the maximal
significant cache level such that . For each core  in
cache level  in  we move all the jobs assigned by  to
core , to a target core in cache level  in . Lemma
\ref{move_jobs_lem} specifies the key property of this
job-reassignment.

\begin{lemma}\label{move_jobs_lem}
We can construct   such that each core  in a significant level
of  is the target of the jobs from at most two cores in a
nonsignificant level of .
\end{lemma}
\begin{proof}
Let  denote the cache levels vector of  and let
 denote the vector of prefix sums of .
From the definition of   follows that for all ,
, and that for ,
.

By Lemma \ref{consec} the number of cores in nonsignificant levels
in  whose jobs are reassigned to one of the 
cores in level  in  is at most . So for  the ratio between the number of cores whose jobs are reassigned
to the number of target cores in level  in  is at most
. For
 the number of target cores in level  of  is
 which is at least as large as the
number of cores at nonsignificant levels between  and  in
 so we can reassign the jobs of a single core of a
nonsignificant level between  and  in  to each target
core.
\end{proof}

\begin{corollary}\label{crl_first_3}

\end{corollary}
\begin{proof}
In the new cache partition  and job assignment  we have
added to each core at a significant level in  the jobs from at
most  other cores at nonsignificant levels in . The target
core always has more cache than the original core, thus the added
load from each original core is at most . It follows that
.
\end{proof}


Let  denote the cache levels vector of  and let
 denote the vector of prefix sums of . We now define another
cache partition  based on . Let . The partition  has
 cores in cache level , and 
cores in cache level  for . The cache levels
 are the significant cache levels of  and
 has cores only in its significant cache levels. Let
 denote the number of cores   in the significant cache
level  in  .

\begin{lemma} \label{pppp}
 3
\end{lemma}
\begin{proof}
By the definition of , we have that . So for 

Since  and  are two consecutive significant cache
levels we have that . The ratio in
\ref{ratio_eq} is an increasing function of  and thus
 minimized by , yielding a lower bound of
. For ,
.
\end{proof}

Lemma \ref{pppp} shows that the cache partition   has in
each cache level  at least a third of the cores that  has at
level . Therefore, there exists a job assignment  that
assigns to each core of cache level  in   the jobs that
 assigns to at most  cores in cache level  in . We
only moved jobs within the same cache level and thus their load
remains the same, and the makespan .

\begin{lemma}\label{lem_hatinp}
Cache partition  is in the  set .
\end{lemma}
\begin{proof}
Let   be the vector of prefix sums of . The
vectors

clearly satisfy properties 1-3 in the definition of
. It remains to show that  uses at most
 cache (property 4).

Consider the core  with the th largest cache in . Let
 be the cache level of this core. Thus . Since   is the result of rounding down
 to the nearest integral power of , we have
that . It follows that
 and therefore the core with the th
largest cache in  is in cache level  or smaller and thus
is it has at least as much cache as the th largest core in
. So  uses at most the same amount of cache as
 which is at most .
\end{proof}

This concludes the proof of Theorem \ref{P9thm}, and establishes
that our algorithm  is an 18-approximation algorithm for the
problem, using  cache.

We provide a variation of algorithm  that uses at most  cache, and finds a -approximation for  the optimal makespan.
Algorithm  enumerates on , , the amount of cache allocated to the first core.
It then enumerates over the set of partitions .
For each partition in  it adds another core with  cache and applies Lenstra's approximation algorithm on the resulting instance of the unrelated machines scheduling problem, to assign all the jobs in  to the  cores. Algorithm  returns the partition and assignment with the minimal makespan it encounters.

\begin{theorem}\label{thm_36final}
If there is a solution of makespan  that uses at most  cache and at most  cores then algorithm  returns a solution of makespan  that uses at most  cache and at most  cores.
\end{theorem}
\begin{proof}
Let  be the a solution of makespan ,  cache and  cores. W.l.o.g. assume that the cores
are indexed according to the non-increasing order of their cache allocation in this solution, that is .

Let .
Consider the following job assignment  of the jobs in  to the cores of odd indices greater than  in /
The assignment  assigns to core , for , all the jobs that are assigned by  to cores
 and .
Note that all the jobs
assigned by  to some core are assigned by  to a core with at most the same amount of cache and thus
the makespan of  is at most .

Assume . Then  since  is non-increasing.
Therefore  we get that .
Therefore we can assign the jobs in  to  cores with a total cache of , such that the  makespan is at most .
By Theorem \ref{P9thm}, there is a partition  that allocates at most  cache to  cores, and a job assignment  of the jobs in  to these cores such that the makespan of  is at most .

Let  be a cache partition that adds to   another core (called ``core 1'') with  cache.
The total cache used by  is at most .
Let  be a job assignment such that  for  and
for a job  (a job that was assigned by  either to core  or to core ), .
Since the makespan of  is  we know that the load on core  in the solution  is at most . It follows that the makespan
of  is at most .


When algorithm  fixes the size of the cache of the first core to be , and
considers  then it obtains the cache partition
. We  know that  is a solution to the corresponding scheduling problem with makespan at most .
Therefore Lenstra's approximation algorithm finds an assignment with makespan at most .
\end{proof}

\section{Jobs with a single load and a minimal cache demand}\label{sec_slmc}

We consider a special case of the general joint cache partition and
job assignment  problem where each job has a minimal cache demand
 and single load value . Job  must run on a core with
at least  cache and it contributes a load of  to the core.
We want to decide if the jobs can be assigned to   cores, using  cache, such that the
makespan is at most ? W.l.o.g. we assume .

In Section \ref{slmc_2} we describe a -\textit{approximate decision} algorithm that if the given instance has a solution of makespan at most , returns a solution with makespan at most  and otherwise may fail. In Sections \ref{slmc_32} and \ref{slmc_43}  we improve the approximation guarantee to  and  at the expense of using  and  cache, respectively.
In Section \ref{apn_approx_des_to_opt} we show how to obtain an approximate optimization algorithm using an approximate decision algorithm and a standard binary search technique.

\subsection{2-approximation}\label{slmc_2}
We present a 2-approximate decision algorithm, denoted by .
Algorithm  sorts the jobs in a non-increasing order of their cache
demand. It then assigns the jobs to the cores in this order. It
keeps assigning jobs to a core until the load on the core exceeds
. Then,  starts assigning jobs to the next core.
Note that among the jobs assigned to a specific core the first one is the
most cache demanding and it determines the cache allocated to this core by .
Algorithm  fails if the generated solution uses more than  cores or more than  cache.
Otherwise,  returns the generated cache partition and job assignment.

\begin{theorem}\label{joint2}
If there is a cache partition and job assignemtn of makespan at most  that use  cores and  cache then algorithm  finds a cache partition
and job assignment of makespan at most  that use at most  cores and at most  cache.
\end{theorem}
\begin{proof}
Let  be  the cache partition and job assignment  with
makespan  whose existence is assumed by the lemma.  has makespan  so the sum of the loads of all jobs is at most
. Since  loads each core, except maybe the last one, with more
than  load it follows that  uses at most  cores.

Since  has makespan  the load of each of the jobs is at most
. Algorithm  only exceeds a load of  on a core by the load
of the last job assigned to this core and thus  yields a
solution with makespan at most .

Assume w.l.o.g that the cores in  are
indexed such that for any core , . Assume that
the cores in  are indexed in the order in which they were loaded
by . By the definition of  the cores are also sorted by
non-increasing order of their cache allocation. Denote by  the
amount of cache  allocates to core . We show that for
all , . This implies that
algorithm  uses at most  cache.

 allocates to the first core the cache required by the most
demanding job so . This job must be assigned in
 to some core and therefore . Assume to the
contrary that  for some . Each job  with cache demand  must be assigned in  to one of the first  cores,
because all the other cores don't have enough cache to run this
job. Since  has makespan  we know that . Consider all the jobs with cache demand at
least . Algorithm  failed to assign all these jobs to the first
 cores, and we know that  assigns more than  load to
each core. So . Since
 and there is a job with cache demand , we have  which leads to a contradiction.
Therefore  for all  and  algorithm  uses at
most  cache.
\end{proof}

\subsection{-approximation with  cache}\label{slmc_32}
We define a job to be {\em large} if  and {\em small} otherwise.
Our algorithm  assigns one large job to each core.
 Let
 be the load on core  after the large jobs are assigned. Let
. We process the small jobs by non-increasing order
of their cache demand , and assign them to the cores in
non-increasing order of the cores' 's.
We stop assigning  jobs to a core when its load exceeds 1 and start loading the next core.
Algorithm  allocates to each core the cache demand of its
most demanding job. Algorithm  fails if the resulting solution uses more than  cores or more than  cache.

\begin{theorem}\label{proof_32}
If there is a cache partition and job assignment of makespan at most  that use  cores and  cache then  finds a cache partition and job assignment that use at most  cache, at most  cores and have a makespan of at most .
\end{theorem}
\begin{proof}
Let  be  the cache partition and job assignment  with makespan  whose existence is assumed by the lemma. The existence of  implies that there are at most  large jobs in our input and that the total volume of all the jobs is at most . Therefore algorithm   uses at most  cores to assign the large jobs. Furthermore, when   assigns the small jobs it loads each core, except maybe the last one, with a load of at least  and thus uses at most  cores.
Algorithm   provides a solution with makespan at most  since it can only exceed a load of  on any core by the load of a single small job.

Let  be the cache partition generated by  . Let  be the set of cores whose most cache demanding job is a large job and  be the set of cores whose most cache demanding job is a small job.
For core , Let  be the most cache demanding job assigned to core , so we have . The solution  is a valid solution thus  so . If  are two large jobs then  and we get that .

In the rest of the proof we index the cores in the solution of   such that .This is the same order in which    assigns small jobs to the cores. In  we assume that the cores are indexed such that .
We now prove the  for any core . Assume, to the contrary, that for some , . Let  be the cache demand of the most cache demanding small job on core  in .
Let  and let . Since  and by our assumption  we get that  and therefore .

 does not assign all the jobs of  to its first  cores and therefore the total load of the jobs in  is greater than  .
On the other hand we know that in , assignment  assigns all the jobs in  on its first  cores while not exceeding a load of 1. Thus the total load of jobs in  is at most the space available for small jobs on the first  cores in solution .
Since ,  and since in any solution each core runs at most one large job, we get that  is at least as large as the space available for small jobs in any subset of  cores in any solution.
It follows that the total load of jobs in  is smaller than in . This contradicts the fact that .

We conclude that for every , . This implies that the total cache allocated to cores in  is at most . We previously showed that the total cache allocated to cores in  is at most  and thus the total cache used by algorithm  is at most .


\end{proof}


\subsection{-approximation with  cache, using dominant matching}\label{slmc_43}
We present a  approximate decision algorithm, , that uses at most  cache.
The main challenge is assigning the \textit{large jobs}, which here are defined as jobs of load greater than .

There are at most  large jobs in our instance, because we assume there is a solution of makespan at most  that uses  cores.
Algorithm  matches these large jobs into pairs, and assigns each pair to a different core.
In order to perform the matching, we construct a graph  where each vertex represents a large job  of weight . If needed, we add artificial vertices of weight zero to have a total of exactly  vertices in the graph.  Each two vertices have an edge between them if the sum of their weights is at most . The weight of an edge is the sum of the weights of its endpoints.

A perfect matching in a graph is a subset of edges such that every vertex in the graph is incident to exactly one edge in the subset. We note that there is a natural bijection between perfect matchings  in the graph  and assignments of makespan at most  of the large jobs to the cores.
The  edges in any perfect matching define the assignment of the large jobs to the  cores as follows: Let  be an edge in the perfect matching.
If both  and  correspond to large jobs, we assign both these jobs to the same core.
If  corresponds to a large job and  is an artificial vertex, we assign the job corresponding to  to its own core.
If both  and  are artificial vertices, we leave a core without any large jobs assigned to it. Similarly we can injectively map any assignment of the larges  jobs of makespan at most  to a perfect matching in : For each core that has 2 large jobs assigned to it, we select the edge in  corresponding to these jobs, for each core with a single large job assigned to it, we select an edge between the corresponding real vertex and an arbitrary artificial vertex, and for each core with no large jobs assigned to it we select an edge in  between two artificial vertices.

 A \textit{dominant perfect matching} in  is a perfect matching  such that for every , the  heaviest edges in  are a maximum weight matching in  of  edges.
The graph  is a threshold graph \cite{MP95}, and in Section \ref{threshold_dominant} we provide a polynomial time algorithm that finds a dominant perfect matching in any threshold graph that has a perfect matching. If there is a solution for the given instance of makespan at most  then the assignment of the large jobs in that solution correspond to a perfect matching in  and thus algorithm  can apply the algorithm from Section \ref{threshold_dominant} and find a dominant perfect matching, , in .

Algorithm  then assigns the small jobs (load ) similarly to algorithms  and  described in  Sections \ref{slmc_2} and \ref{slmc_32}, respectively.
It greedily assigns jobs to a core, until the core's load exceeds . Jobs are assigned in a non-increasing order of their cache demand and the algorithm goes through the cores in a non-decreasing order of the sum of loads of the large jobs on each core. Once all the jobs are assigned, the algorithm allocates cache to the cores according to the cache demand of the most demanding job on each core.
Algorithm  fails if it does not find a dominant perfect matching in  or if the resulting solution uses more than  cores or more than  cache.

\begin{theorem}\label{proof_43}
If there is a solution that assigns the jobs to  cores with makespan  and uses  cache then algorithm  assigns the jobs to  cores with makespan at most  and uses at most  cache.
\end{theorem}
\begin{proof}
Let  be a solution of makespan at most , that uses  cores and  cache.

Algorithm   provides a solution with makespan at most  since it may only exceed a load of  on any core by the load of a single small job.

Algorithm   uses at most  cores to assign the large jobs because the assignment is based on a perfect matching of size  in .
 The existence of  implies that the total load of all jobs is at most . When  assigns the small jobs it exceeds a load of  on all cores it processes, except maybe the last one, and therefore we get that  uses at most  cores.

Let  be the cache partition generated by  . Let  be the set of cores whose most demanding job is a large job and  be the set of cores whose most demanding job is a small job.

Consider any core . Let  be the most cache demanding large job assigned to core . Job  runs in solution  on some core . Therefore . Since each core in  runs at most two large jobs, we get that the total cache allocated by our algorithm to cores in  is at most .


Consider the large jobs assigned to cores according to the dominant perfect matching . Denote by  the load on core  after the large jobs are assigned (and before the small jobs are assigned) and let .
W.l.o.g. we assume the cores in  are indexed such that .
For every ,  is at least as large than this sum in any assignment of the large jobs of makespan at most  because any such assignment defines a perfect matching in graph  and if  is larger in some other assignment then  is not a dominant perfect matching in .
Since the total volume of all large jobs is fixed, we get that for every core  the amount of free volume on cores  till , , is maximal and can not be exceeded by any other assignment of the large jobs of makespan at most .

W.l.o.g we assume that the cores in solution  are indexed such that .
Let  be any core in . We show that . Assume, to the contrary, that .
Let  be the cache demand of the most demanding small job assigned to core  in solution .
Let  and . Since  , we get that .

Solution  assigns all the jobs in  to its first  cores, without exceeding a makespan of . Therefore the total volume of jobs in  is at most the total available space solution  has on its first  cores after assigning the large jobs. Since we know that for every ,  is maximal and can not be exceeded by any assignment of the large jobs of makespan at most , we get that the total volume of jobs in  is at most  . Algorithm  does not assign all the jobs in  to its first  cores, and since  loads each of the first  cores with at least , we get that the total volume of jobs in  is greater than . So we get that the total volume of jobs in  is less than the total volume of jobs in  but that is a contradiction to the fact that . Therefore we get that , for every .  It follows that the total cache allocated by our algorithm to cores in  is at most  and this concludes the proof that our algorithm allocates a total of at most  cache to all cores.
\end{proof}

\subsection{Approximate optimization algorithms for the single load, minimal cache model }\label{apn_approx_des_to_opt}
We presented approximation algorithms for the decision version of the joint cache partition and job assignment problem in the single load and minimal cache demand model.
If there is a solution with makespan , algorithms ,  and  find a solution of makespan ,  and , that uses ,  and  cache, respectively.
We now show how to transform these algorithms into approximate optimization algorithms using a standard binary search technique \cite{LST90}.

\begin{lemma}\label{bin_opt}
Given ,  and , assume there is a polynomial time approximate decision algorithm that if there is a solution of makespan ,  cache and  cores, returns a solution of makespan ,  cache and  cores,  where  and  are at least . Then, there is a polynomial time approximation algorithm that finds a solution of makespan ,  cache and  cores, where  is the makespan of the optimal solution with  cache and  cores.
\end{lemma}

\begin{proof}
Let's temporarily assume that the loads of all jobs are integers.
This implies that for any cache partition and job assignment the makespan is an integer.

Our approximate optimization algorithm performs a binary search for the optimal makespan and maintains a search range .
Initially,  and .
Clearly these initial values of  and  are a lower and an upper bound on the optimal makespan, respectively.
Let  be the approximate decision algorithm whose existence is assumed in the lemma's statement.
In each iteration, we run algorithm  with parameters ,  and .
If  succeeds and returns a solution with makespan at most  we update the upper bound .
If  fails, we know there is no solution of makespan at most , and we update the lower bound .
It is easy to see that the binary search maintains the invariant that after any iteration, if the search range is  then  and we have a solution of makespan at most . The binary search stops when .

The makespan of the solution when the binary search stops is at most . The binary search stops after  iterations, and since  runs in polynomial time, we get that our algorithm runs in polynomial time.
This shows that our binary search algorithm is a polynomial time -approximation algorithm.

If the loads in our instance are not integers, let  be the precision in which the loads are given.
By multiplying all loads by  we get an equivalent instance where all the loads of the jobs are integers.
Note that this only adds  iterations to the binary search and our algorithm still runs in polynomial time.
\end{proof}

The following theorem follows immediately from Lemma \ref{bin_opt}.

\begin{theorem}
Using the approximate decision algorithms presented in this section, we obtain polynomial time approximate optimization algorithms for the single load, minimal cache demand problem with approximation factors ,\, and  that use ,  and  cache,  respectively.
\end{theorem}

\subsection{Dominant perfect matching in threshold graphs}\label{threshold_dominant}

Let  be an undirected graph with  vertices where each vertex  has a weight . The edges in the graph are defined by a threshold  to be . Such a graph  is known as a threshold graph \cite{CH73,MP95}. We say that the \textit{weight} of an edge  is .

A perfect matching  in  is a subset of the edges such that every vertex in  in incident to exactly one edge in .
Let  denote the -th heaviest edge in . We assume, w.l.o.g, that there is some arbitrary predefined order of the edges in  that is used, as a secondary sort criteria, to break ties in case several edges have the same weight. In particular, this implies that  is uniquely defined.

\begin{definition}
A perfect matching  dominates a perfect matching  if for every  
\end{definition}

\begin{definition}
A perfect matching  is a dominant matching if  dominates any other perfect matching .
\end{definition}

Let  and  be two perfect matchings in .
We say that  and  \textit{share a prefix of length } if  for .
The following greedy algorithm finds a dominant perfect matching in a threshold graph  that has a perfect matching.
We start with .
At step , the algorithm selects the edge  with maximum weight in the graph . If there are several edges of maximum weight, then  is the first by the predefined order on .
The graph  is obtained from  by removing vertices ,  and all edges incident to  or .
The algorithm stops when it selected  edges and  is empty.

\begin{lemma}\label{not_stuck}
For every , If graph  has a perfect matching, then the graph  has a perfect matching.
\end{lemma}
\begin{proof}
Let  denote the perfect matching in graph .
Let  be the edge of maximum weight in  that we remove, with its vertices and their incident edges, to obtain .
If  then clearly  is a perfect matching in .
If , and since  is a perfect matching of , there are two vertices  and  such that  and  are in .
The edge  is the maximum weight edge in  and thus  and . Therefore  must be an edge in  because  the threshold defining the edges in our threshold graph.
Let .
It is easy to see that  is a perfect matching of graph .
\end{proof}

\begin{theorem}\label{dominant_matching}
If  is a threshold graph with  vertices that has a perfect matching, then the greedy algorithm described above finds a dominant perfect matching.
\end{theorem}
\begin{proof}
Lemma \ref{not_stuck} implies that our greedy algorithm is able to select a set of  edges that is a perfect matching in . Denote this matching by .

Assume, to the contrary, that  is not a dominant perfect matching in .
Let  be a perfect matching that is not dominated by  sharing the longest possible prefix with . Let  denote the length of the shared prefix of  and . Let  denote the graph obtained from  by removing the  edges that are the heaviest in both  and , their vertices and all edges incident to these vertices.

Let . Since  and  share a maximal prefix of length ,  .
Since  is of maximum weight in , it follows that  (otherwise, it would have been ).
The set of edges  form a perfect matching  of  so there must be two edges and two indices  and , such that . We assume w.l.o.g. that .
The edge  is of maximum weight in  therefore  and . It follows that , and therefore .
Let .
Clearly,  is a perfect matching in ,  and therefore  shares a prefix of length  with .
If  dominates , then since  does not dominate , it follows that  does not dominate . Thus  is a perfect matching that shares a prefix of length  with  and is not dominated by . This is a  contradiction to the choice of .  We finish the proof by showing that  dominates .

Let  be the index such that . Since , .
Let .
The matchings  and  share a prefix of length , so for every , . For ,  since  is the edge of maximum weight in .
For ,  also by the maximality .
For ,  which is non-negative because  and therefore .
For , .
This shows that  dominates  and concludes our proof that  is a dominant perfect matching in .
\end{proof}

\subsubsection{On dominant perfect matchings in -uniform hypergraphs}

The problem of finding a dominant perfect matching in a -uniform threshold hypergraph\footnote{ A \textit{-uniform threshold hypergraph} is defined on a set of vertices, , each with a non-negative weight . The set of edges, , contains all the subsets  of size  such that the sum of the weights of the vertices in  is at most some fixed threshold . } that has a perfect matching is interesting in the context of the single load, minimal cache version of the joint cache partition and job assignment problem. If we can find such a matching then an algorithm similar to Algorithm  in Section \ref{slmc_43} would give a solution that uses  cache and approximates the makespan up to a factor of .

However, the following example shows that in a -uniform threshold hypergraph that has a perfect matching,  a dominant perfect matching does not necessarily exist.
 Let  be an arbitrarily small constant. Consider a hypergraph with 12 vertices, 3 vertices of each weight in . Each triplet of vertices is an edge if the sum of its weights is at most . This hypergraph has a perfect matching. In fact, let's consider two perfect matchings in this hypergraph.
Matching  consists of the edges , ,  and .
Matching  consists of three edges of the form  and one edge of the form .
It is easy to check that  and  are valid perfect matchings in this hypergraph.
Any dominant perfect matching in this hypergraph must contain the edge  in order to dominate , since this is the only edge of weight  in this hypergraph.
The sum of the two heaviest edges in matching  is  and therefore any dominant perfect matching must have an edge of weight at least , as otherwise the matching will not dominate matching . But, if the edge  is in the dominant matching, then all edges disjoint from  have a weight smaller than . Thus no dominant perfect matching exists in this hypergraph.

Matching  in the example above is the perfect matching found by applying the greedy algorithm to this hypergraph.
It is interesting to note that in a -uniform threshold hypergraph, the greedy algorithm does not necessarily find a perfect matching at all.
This is because Lemma \ref{not_stuck} does not extend to -uniform threshold hypergraphs.
Let  be an arbitrarily small constant.
Consider a hypergraph with 9 vertices, 3 vertices of each weight in .
Each triplet of vertices is an edge if the sums of its weights is at most .
This hypergraph has a perfect matching since the 3 edges of the form  are a perfect matching in this hypergraph.
However the greedy algorithm first selects the edge  and then selects an edge of the form .
The remaining hypergraph now contains three vertices and no edges, so the greedy algorithm is stuck and fails to find a perfect matching.

\subsection{PTAS for jobs with correlative single load and minimal cache demand}\label{correl_ptas}

The main result in this section is a polynomial time approximation scheme for instances of the single load minimal cache demand problem, where there is a correlation between the load and the cache demand of jobs with non-zero cache demand. This special case is motivated by the observation that often there is some underlying notion of a job's ``hardness'' that affects both its load and its minimal cache demand.

Consider an instance of the single load minimal cache demand problem such that for any two jobs  such that  and  are non-zero, .
We call a job  such that  a \textit{demanding job} and a job  such that  a \textit{non-demanding job}.
We consider the following decision problem:
We want to decide if there is a cache partition of  cache to  cores and an assignment of jobs to the cores such that the job's minimal cache demand is satisfied and that the resulting makespan is at most ? By scaling down the loads of the jobs by , we assume w.l.o.g that .

Let . We present an algorithm that if there is a cache partition and a job assignment with makespan at most , returns a cache partition and a job assignment with makespan at most .
Otherwise, our algorithm either decides that there is no solution of makespan at most  or returns a solution of makespan at most .
Combining this algorithm with a binary search, we obtain a PTAS.

If there is a job  such that  then our algorithm decides that there is no solution of makespan at most .
Thus we assume that for any , .

Let , , .
In the first phase, we deal only with jobs in .
For each  let .
We say that  is the \textit{rounded-down load} of job .

Let  and .
An \textit{assignment pattern} of a core is a table that indicates for each  how many demanding jobs of rounded-down load  are assigned to the core and for each  how many non-demanding jobs of rounded-down load  are assigned to the core.
Note that an assignment pattern of a core does not identify the actual jobs assigned to the core.
We only consider assignment patterns whose rounded-down load is at most .

A \textit{configuration of cores} is a table indicating how many cores we have of each possible assignment pattern.
A configuration of cores  is \textit{valid} if for every , the number of demanding jobs in  whose  equals the sum of the numbers of demanding jobs with  in all assignment patterns in  and, similarly, for every , the number of non-demanding jobs in  whose  equals the sum of the numbers of non-demanding jobs with  in all assignment patterns in .

The outline of our algorithm is as follows.
The algorithm enumerates over all valid configurations of cores.
For each valid configuration , we find an actual assignment of the jobs in  that matches  and minimizes the total cache used.
We then proceed to assign the jobs in , in a way that guarantees that if there a solution of makespan  and  cache that matches this configuration of cores, then we obtain a solution of makespan at most  and at most  cache. If our algorithm does not generate a solution of makespan at most  and at most  cache, for all valid configurations of cores, then our algorithm decides that no solution of makespan at most  exists.

Let  be a valid configuration of cores.
For each core , let  be the maximal rounded-down load of a demanding job assigned to core  according to the assignment pattern of core  in .
Let  be the number of demanding jobs of rounded-down load  on core , according to .
We assume w.l.o.g that the cores are indexed such that .
Let .
For each , let  be the index of the first core  with  and let  be the index of the last core  with .
Assume that the cores  are indexed such that .
Let , the set of all demanding jobs in  whose rounded down load is .
Let  be the set of the  jobs of smallest cache demands in .

Our algorithm builds an assignment matching  of minimal cache usage among all assignments matching .
To do so, our algorithm goes over  in a decreasing order and distributes the jobs in  to the cores  in this order of the cores such that core , in turn, gets the  most cache demanding jobs in  that are not yet assigned.
After we assign the demanding jobs with the maximal rounded-down load on each core, our algorithm arbitrarily chooses the identity of all other jobs in the configuration .
These are non-demanding jobs and demanding jobs whose rounded-down load is not of the maximal rounded-down load on their core.
Each core is allocated cache according to the cache demand of the most cache demanding job that is assigned to it.


The algorithm continues with the jobs in . It first assigns the
demanding jobs in , in the following greedy manner. Order these
jobs from the most cache demanding to the least cache demanding. For
each core, we consider two load values: its \textit{actual load}
which is the sum of the actual loads of jobs in  assigned to
the core, and its \textit{rounded down load} which is the sum of
rounded down loads of jobs in  assigned to the core. We order
the cores such that first we have all the cores that already had
some cache allocated to them in the previous phase of the algorithm,
in an arbitrary order. Following these cores, we order the cores
with no cache allocated to them, from the least loaded core to the
most loaded core, according to their rounded down loads. These cores
are either empty or have only non demanding jobs, from ,
assigned to them. The algorithm assigns the jobs to the cores in
these orders (of the jobs and of the cores) and stops adding more
jobs to a core and moves to the next one when the core's actual load
exceeds . After all these jobs are assigned, the
algorithm adjusts the cache allocation of the cores whose most cache
demanding job is now a job of .

Finally, it assigns the non-demanding jobs in .
Each such job is assigned arbitrarily to a core whose actual load does not already exceed .

\begin{lemma}\label{ptas_poly}
The number of  valid configurations of cores is .
\end{lemma}
\begin{proof}
We first consider the number of assignment patterns with rounded-down load at most .
Since for each job , , the size of  and the size of  are at most .
In an assignment pattern of load at most , there are at most  jobs in  assigned to each core and thus we get that the number of possible assignment patterns is at most .
Since the number of assignment patterns we consider is , it follows that the number of possible configurations of cores is .
\end{proof}

Since our algorithm spends a polynomial time per configuration of cores then Lemma \ref{ptas_poly} implies that our algorithm runs in polynomial-time.

\begin{lemma}\label{take_smallest}
For any configuration of cores  there is an assignment matching  of minimal cache usage among all assignments matching , that for each  assigns the  least cache demanding jobs in  (i.e. the set of jobs Y(q)) to the cores .
\end{lemma}
\begin{proof}
Consider a job assignment  of minimal cache usage that matches .
Assume that for some  assignment  does not assign all the jobs in  to the cores .
So there is a core  that runs a job .

Since  assigns  jobs from  to cores  and since jobs in  cannot be assigned to cores , it follows that there is a core  and a job  such .
Suppose we switch the assignment of jobs  and  and run job  on core  and job  on core . Let  denote the resulting assignment.
The cache required by core  does not increase, as it runs demanding jobs of rounded down load greater than  and therefore of cache demand greater than the cache demand of job .
By the choice of the jobs  and  we know that  and therefore the cache required by core  in  can only decrease compared to the cache required by core  in .
It follows that the cache usage of  is at most that of  and since  is of the minimal cache usage of all assignments that match , we get that the cache usage of  must be the same as of .

By repeating this argument as long as there is a job that violates Lemma \ref{take_smallest}, we obtain an assignment as required.
\end{proof}

\begin{lemma}\label{by_order}
For any configuration of cores , Let  be an assignment matching  such that  for each  and for each core ,
if we index the jobs in  from the most cache demanding to the least cache demanding, assignment  assigns to core  the jobs in  of indices .
Assignment  is of minimal cache usage, among all assignments matching .
\end{lemma}
\begin{proof}
Assume to the contrary that assignment  is not of minimal cache usage, among all assignments matching .
Let  be an assignment whose existence is guaranteed by Lemma \ref{take_smallest}.
Since  and  have different cache usages, there exists  such that  and  differ on their assignment of the jobs in .
We index the jobs in  from the most cacn demanding to the least cache demanding.
Let  be the first job (most cache demanding) in  such that .
We select  such that it maximizes  among all assignments satisfying Lemma \ref{take_smallest} that disagree with  on the assignment of the jobs in .

Denote  and .
Since  and  both assign  jobs from  to core  and since  is the first job in  on which  and  disagree, then there is a job ,  such that .

We first assume that there is a job  such that .
Let  be the assignment such that ,  and for any job , .
The cache required by core  in  is at most the cache required by core  in , since .
Since  and , we know that  and also .
This implies that in , core  requires the same amount of cache as in .
It follows that  is also an assignment of minimal cache usage, and that it satisfies Lemma \ref{take_smallest}. Since , we get a contradiction to the way we selected .
Thus  is  of minimal cache usage, among all assignments matching .

We now assume that  is the first job in  such that .
Let  be the following assignment.
Any job that is assigned by  to a core different than  and  is assigned by  to the same core.
For any job  such that ,  .
All the  least cache demanding jobs assigned by  to core  are assigned by  to core .
Note that  and therefore assignment  is well defined.

Since  and  agrees on the assignment of jobs  in  and assign them to cores , then job  is the most cache demanding job assigned to cores  by  and .
Therefore in assignment , core  requires  cache and in assignment  core  requires  cache.
In assignment , core  is assigned a set of jobs that is a subset of the jobs assigned to core  by .
Thus the cache required by core  in assignment , is at most the cache required by core  in assignment .
It follows that  is also an assignment of minimal cache usage, and that it satisfies Lemma \ref{take_smallest}.
This contradicts the choice of  and concludes the proof that assignment  is of minimal cache usage, among all assignments matching .
\end{proof}

\begin{corollary}\label{actual_opt_ident}
For each configuration of cores  our algorithm builds an actual assignment of minimal cache usage of the jobs in  that matches .
\end{corollary}
\begin{proof}
The assignment returned by our algorithm is an assignment , as in the statement of Lemma \ref{by_order}.
\end{proof}

\begin{lemma}\label{ptas_aprx_dcsn}
Consider an instance of the correlative single load minimal cache demand problem.
If there is a cache partition and job assignment that schedules the jobs on  cores, uses at most  cache and has a makespan of at most  then our algorithm finds a cache partition and job assignment that schedules the jobs on  cores, uses at most  cache and has a makespan of at most .
\end{lemma}
\begin{proof}
Let  be a solution of makespan at most  with  cores and  cache, whose existence is assumed by the lemma.
Let  be the configuration of the cores corresponding to the assignment of the jobs in  by solution  and assume our algorithm currently considers  in its enumeration.

We show that our algorithm succeeds in assigning all the jobs to  cores. Let's assume to the contrary that it fails. It can only fail if all cores are assigned an actual load of more than  and there are still remaining jobs to assign. This indicates that the total volume to assign is larger than , which contradicts the fact that assignment  is able to assign the jobs to  cores with makespan at most .

Let  denote the assignment of all jobs on  cores that out algorithm returns when it considers . 
We know that  matches   for jobs in .
We now show that in  each core has an actual load of at most .
When we restrict  to  we know that the rounded down load on each core is at most  and that each core has at most  jobs from  assigned to it.
Since the actual load of any job in  is at most  larger than its rounded down load, we get that if we restrict assignment  to , the actual load on each core is at most .
The way our algorithm assigns the jobs in  implies that the actual load of a core in assignment  can only exceed  by the load of a single job from . Therefore the actual load on any core in assignment  is at most .

We show that assignment  uses at most  cache.
Cache is allocated by our algorithm in two steps: when it decides on the actual assignment of the jobs in  that matches  and when it assigns the demanding jobs in .
Lemma \ref{actual_opt_ident} shows that  restricted to  is of minimal cache usage of all assignments matching  and thus uses at most the same amount of cache as assignment  restricted to .

We show that when we also take into account the demanding jobs in ,  uses at most the same amount of cache as .
Assume the cores in  are indexed according to the order in which our algorithm assigns demanding jobs from  to them.
Assume the cores in  are indexed such that core  in  and core  in  have the same assignment pattern.
For any core in , we say that its \textit{free space} is   minus the sum of the actual loads of all jobs in  assigned to it by .
For any core in , we say that its free space is  minus the sum of the actual loads of all jobs in  assigned to it by .
For any , core  in  has the same rounded down load as core  in  and the actual load of core  in  is at most  larger than the actual load of core  in . 
Therefore, by the definition of free space, the free space of core  in solution  is at least the free space of core  in solution .

Let  be the number of cores in  that have a demanding job from  assigned to them.
When our algorithm assigns jobs in  to a core ,  it does not increase the cache required by core  since any job in  is at least as cache demanding as any job in .
It follows that the total cache required by cores  in  is at most the total cache required by cores  in A. 

Let  be a core in   whose cache demand is determined by a job from .
We now show that core  in  requires no more cache than core  in . This will conclude the proof that  uses at most  cache. 

The total load of demanding jobs in  that  assigns to cores  is at least the sum of the free space of these cores, since our algorithm exceeds an actual load of  on each core before moving the next. The sum of the free space of cores  in  is at least the sum of the free space of the cores  in , which in turn is an upper bound on the total load of demanding jobs from  that are assigned in  to cores .
Since our algorithm assigns the demanding jobs in  in a non-increasing order of their cache demand we get that the cache demand of the most cache demanding job from  on core  in  is at most the cache demand of the most cache demanding job in  on core  in . 
\end{proof}

Lemma \ref{ptas_aprx_dcsn} shows that for any , we have a polynomial time -approximate decision algorithm.
Given , by applying our algorithm with  we obtain a polynomial time -approximate decision algorithm.

By using a binary search similar to the one in Lemma \ref{bin_opt} we obtain an -approximation for the optimization problem, using our -approximate decision algorithm.
To conclude, we have proven the following theorem.

\begin{theorem}
There is a polynomial time approximation scheme for the joint cache partition and job assignment problem, when the jobs have a correlative single load and minimal cache demand.
\end{theorem}

\section{Step functions with a constant number of load types}\label{sec_const}

Empirical studies \cite{Drepper} suggest that the the load of a job, as a function of available cache, is often similar to a step-function.
The load of the job drops at a few places when the cache size exceeds the working-set required by some critical part.
In between these critical cache sizes the load of the job decreases negligibly with additional cache. The problems we consider in this section are motivated by this observation.

Formally, each job  is described by two load values  and a \textit{cache demand} . If job  is running on a core with at least  cache then it takes  time and otherwise it takes  time. If a job is assigned to a core that meets its cache demand, , we say that it is \textit{assigned as a small job}. If it is assigned to a core that doesn't meet its cache demand we say that it is \textit{assigned as a large job}.
At first we study the case where the number of different load types is constant and then we show a polynomial time scheduling algorithm for the corresponding special case of the ordered unrelated machines scheduling problem.

Let  and , the sets of small and large loads, respectively.  Here we assume that  and  are both bounded by a constant.

For each , , we say that job  is of \textit{small type } if  and we say that job  is of \textit{large type } if . If job  is of small type  and large type  we say that it is of \textit{load type }. Note that jobs  of the same load type may have different cache demands  and thus if we take cache demands into account the number of different job types is  and not  .

We reduce this problem to the single load minimal cache demand problem studied in Section \ref{sec_slmc}.
For each load type , we enumerate on the number, , of the jobs of load type  that are assigned as small jobs. For each setting of the values  for all load types, we create an instance of the single load minimal cache demand problem in which each job corresponds to a job in our original instance.
For each job  which is one of the  most cache demanding jobs of load type  we create a job of load  and cache demand . For each job  of load type  which is not one of the  most cache demanding job of this load type, we create a job of load  and cache demand .
We solve each of the resulting instances using any algorithm for the single load minimal cache demand problem presented in Section \ref{sec_slmc}, and choose the solution with the minimal makespan. We transform this solution back to a solution of the original instance, by replacing each job with its corresponding job in the original instance. Note that this does not affect the makespan or the cache usage.

\begin{lemma}
Given a polynomial time -approximation algorithm for the single load minimal cache demand problem that uses at most  cache, the reduction described above gives a polynomial time -approximation algorithm for the problem  where job loads are step functions with a constant number of load types, that uses at most  cache.
\end{lemma}
\begin{proof}
Consider an instance of the joint cache partition and job assignment problem with load functions that are step functions with a constant number of load types.
Assume there is a solution  for this instance of makespan  that uses at most  cache. Let  be the number of jobs of load type  that are assigned in  as large jobs. W.l.o.g we can assume that that for each , the  jobs that are assigned as large jobs are the  most cache demanding jobs of load type . The existence of  implies that when our algorithm considers the same values for , for each , it generates an instance of the single load cache demand problem that has a solution of makespan at most  and at most  cache.
Applying the -approximation algorithm for the single load minimal cache demand problem, whose existence in assumed by the lemma, on this instance yields a solution of makespan at most  that uses at most  cache. This solution is transformed to a solution of our original instance without affecting the makespan or the cache usage.

Our algorithm runs in polynomial time since the size of the enumeration is .
\end{proof}

\begin{corollary}
For instances in which the load functions are step functions with a constant number of load types there are polynomial time approximation algorithms that approximate the makespan up to a factor of ,  and  and use at most ,  and , respectively.
\end{corollary}

\subsection{The corresponding special case of ordered unrelated
machines}\label{apn_const} Recall that if we fix the cache partition
in an instance of the joint cache partition and job assignment
problem then we obtain an instance of the ordered unrelated machines
scheduling problem. For the case where the load functions are step
functions with a constant number of load types, the resulting
ordered unrelated machines instance can be solved in polynomial time
using the dynamic programming algorithm described below. The dynamic
program follows a structure similar to the one used in \cite{leah},
where polynomial time approximation schemes are obtained for several
variants of scheduling with restricted processing sets.

In this special case of the ordered unrelated scheduling problem job  runs in time  on some prefix of the machines, and in time  on the suffix (we assume that the machines are ordered in non-increasing order of their strength/cache allocation).  For simplicity, we assume  is given as the index of the first machine on which job  has load . If job  takes the same amount of time to run regardless of cache, we assume  and its load on any machine is . As before, we assume that  and  are of constant size.

We design a polynomial time algorithm that finds a job assignment that minimizes the makespan.
The algorithm does a binary search for the optimal makespan, as in Section \ref {apn_approx_des_to_opt}, using an algorithm for the following decision problem: Is there an assignment of the jobs  to the  machines with makespan at most ?
By scaling the loads, we assume that .

For every machine , we define , the set of all jobs that are large on machine  and small on any machine .
Let  and . It is convenient to think of  as a vector in .

Let ,  and  be any machine.
Let  be a set of jobs which contains all the jobs in  together with additional  jobs of load type  from , for each load type .
Let  be  if we can schedule all the jobs in , except for  jobs of each large load type , on the first  machines. Note that since the additional jobs specified by  are small on all machines ,  does not depend on the additional jobs' identity.
Our original decision problem has a solution if and only if .

Consider the decision problem  .
We want to decide if it is possible to schedule the jobs in , except for  jobs of each large load type , on machine . To decide this, our algorithm chooses the   jobs of each large job type  that have the largest small loads and removes them from .
If the sum of the small loads of the remaining jobs is at most ,  then , and otherwise .

To solve  we enumerate, for each load type , on , the number of jobs in  of this load type that are assigned as small jobs to machine .
Note that these jobs are either in  or in the additional set of  jobs of type .
For each , we enumerate on the number  of jobs in  of large load type  that are assigned as large jobs to machine .
The following lemma is the basis for our dynamic programming scheme. Its proof is straightforward.

\begin{lemma}\label{cond_lemma}
We can schedule all the jobs in  except for  jobs of large load type  (for each ) on machines  with makespan at most  such that  jobs of load type  are assigned to machine  as small jobs and  jobs of large load type  are assigned to machine  as large jobs if and only if the following conditions hold:

\begin{itemize}
\item For each : The number of jobs of each load type that we assign as small jobs to machine  is at most the number of jobs in  of this load type that are small on machine .
\item . The total load of the jobs assigned to  machine  is at most .
\item Let  and  then
.  The jobs in , except for  jobs of large load  for each ,  can be scheduled on machines  with makespan at most .
\end{itemize}

\end{lemma}

The algorithm for solving   sets  if it finds  and  such that the conditions in  Lemma \ref{cond_lemma} are met. If the conditions are not met for all  and  then .

Our dynamic program solves  in increasing order of  from  to  and returns the result of  .
The correctness of the dynamic program follows from Lemma \ref{cond_lemma} and from the fact that for , our algorithm chooses the jobs that it does not assign to machine  such that the remaining load on machine  is minimized. Therefore we set  if and only if there is a solution of makespan at most .

By adding backtracking links, our algorithm can also construct a schedule with makespan at most .
We maintain links between each  that is  to a corresponding  that is also , according to the last condition in Lemma \ref{cond_lemma}.
Tracing back the links from  gives us an assignment with makespan at most  as follows.
Consider a link between  and  . This defines  and .
For each  we assign to machine ,   arbitrary jobs of load type  from  that we have not assigned already, and we reserve  slots of load  on machine  to be populated with jobs later.
Our algorithm guarantees that the load on machine  is at most . When we reach , for some  and , in the backtracking phase, we have  slots of size  allocated on machines .
The  jobs of large load  with the largest small loads in  are assigned to these slots. Note that these jobs may be large on their machine and have a load of  or they may be small and have a load smaller than . In any case, the resulting assignment assigns all the jobs in  and has a makespan of at most .

The number of problems  that our dynamic program solves is .
To solve each problem, we check the conditions in Lemma \ref{cond_lemma} for  possible 's and 's. This takes  per  and  since we already computed  for every  and . Thus the total complexity of this algorithm is polynomial. This concludes the proof of the following theorem.

\begin{theorem}
Our dynamic programming algorithm is a polynomial-time exact optimization algorithm for the special case of the ordered unrelated machines scheduling problem, where each job  has load  on some prefix of the machines, and load  on the corresponding suffix.
\end{theorem}

\section{Joint dynamic cache partition and job scheduling}\label{sec_variants}

We consider a generalization of the joint cache partition and job assignment problem that allows for dynamic cache partitions and dynamic job assignments.
We define the generalized problem as follows.
As before,  denotes the set of jobs, there are  cores and a total cache of size .
Each job  is described by a non-increasing function .

A dynamic cache partition  indicates the amount of cache allocated to core  at time unit \footnote{To simplify the presentation we assume that time is discrete.}.
For each time unit , .
A dynamic assignment  indicates for each core  and time unit , the index of the job that runs on core  at time . If no job runs on core  at time  then . If  then for any other core , .
Each job has to perform 1 \textit{work unit}. If job  runs for  time units on a core with  cache, then it completes  work. A partition and schedule  are \textit{valid} if all jobs complete their work.
Formally,  are valid if for each job , .
The \textit{load} of core  is defined as the maximum  such that .
The makespan of  is defined as the maximum load on any core. The goal is to find a valid dynamic cache partition and dynamic job assignment with a minimal makespan.

It is easy to verify that dynamic cache partition and dynamic job assignment, as defined above, generalize  the static partition and static job assignment.
The partition is static if for every fixed core ,  is constant with respect to .
The schedule is a static assignment if for every job , there are times  and a core  such that .

We consider four variants of the joint cache partition and job assignment problem.
The static partition and static assignment variant studied so far, the variant in which the cache partition is dynamic and the job assignment is static, the variant in which the job assignment is dynamic and the cache partition is static and the variant in which both are dynamic.

Note that in the variant where the cache partition is dynamic but the job assignment is static we still have to specify for each core, in which time units it runs each job that is assigned to this core. That is, we have to specify a function  for each core . This is due to the fact that different schedules of the same set of jobs assigned to a particular core, when the cache partition is dynamic, may have  different loads, since jobs may run with different cache allocations. When the cache partition is also static, the different schedules of the same set of jobs on a particular core have the same load, and it suffices to specify which jobs are assigned to which core.

We study the makespan improvement that can be gained by allowing a dynamic solution.
We show that allowing a dynamic partition and a dynamic assignment can improve the makespan by a factor of at most , the number of cores.
We also show an instance where by using a dynamic partition and a static assignment we achieve an improvement factor arbitrarily close to .
We show that allowing a dynamic assignment of the jobs, while keeping the cache partition static, improves the makespan by at most a factor of , and that there is an instance where an  improvement of  is achieved, for .

Given an instance of the joint cache partition and job assignment problem, we denote by  the optimal static cache partition and static job assignment, by  the optimal dynamic cache partition and static job assignment, by  the optimal static cache partition and dynamic job schedule and by  the optimal dynamic cache partition and dynamic job schedule. For any solution  we denote its makespan by .


\begin{lemma}\label{dsub}
For any instance of the joint cache partition and job assignment problem,
.
\end{lemma}
\begin{proof}
Let  be the trivial static partition and schedule, that assigns all jobs to the first core and allocates all the cache to this core.
Let's consider any job  that takes a total of  time to run in the solution .
Whenever a fraction of job  runs on some core with some cache partition, it has at most  cache available to it.
Therefore, in solution , when we run job  continuously on one core with  cache,  it take at most  time.
Since the total running time of all the jobs in solution  is at most , we get .
\end{proof}

\begin{corollary}
For any instance of the joint cache partition and job assignment problem,
 .
\end{corollary}
\begin{proof}
Clearly,  for any instance. Combine this with Lemma \ref{dsub} and we get that 
\end{proof}


\begin{lemma}\label{dslb}
For any  there is an instance of the joint cache partition and job assignment problem, such that .
\end{lemma}
\begin{proof}
Let  be an arbitrary constant.
Let's consider the following instance with two types of jobs.
There are  jobs of type , such that for each such job , , for  and .
There are  jobs of type , such that for each such job ,  if  and  if .

Consider the following solution. The static job assignment runs  jobs of type  on each core. After  time units, it runs the  jobs of type  on core .
The dynamic cache partition starts with each core getting  cache. The cache partition changes after  time units and core  gets all the cache.
This solution has a makespan of  and therefore .

There is an optimal static cache partition and static job assignment that allocates to each core  or  cache, because otherwise we can reduce the amount of cache allocated to a core without changing the makespan of the solution.
This implies that there are only two static cache partitions that may be used by this solution optimal static solution: the partition in which  for each core , and the partition that gives all the cache to a single core.
It is easy to see that if we use the cache partition where  we get a solution with an infinite makespan because of the jobs of type .
Therefore this optimal static solution uses a cache partition that gives all the cache to a single core.
Given this partition, the optimal job assignment is to run all the  jobs of type  on the core with all the cache, and assign to that core additional   jobs type .
So the load on that core is .
Each of the  cores with no cache is assigned exactly one job of type , and each such core has a load of .
Therefore the ratio  . The lower  bound on this ratio approaches  as  approaches infinity.
Since  is an arbitrarily chosen constant, we can choose it large enough such that we get a lower bound that is greater than , for any .
\end{proof}

\begin{corollary}
For any  there is an instance of the joint cache partition and job assignment problem, such that .
\end{corollary}
\begin{proof}
Consider the same instance as in the proof of Lemma \ref{dslb}.
For that instance, .
It follows that   for the instance in  Lemma \ref{dslb} , since .
\end{proof}

\begin{lemma}\label{sdub}
For any instance of the joint cache partition and job assignment problem, .
\end{lemma}
\begin{proof}
Consider any instance of the joint cache partition and job assignment problem and let .
Let  be the fraction of job 's work unit that is carried out by core . Formally, .
Let's consider the instance of scheduling on unrelated machines where job  runs on core  in time .
Since for every job ,  then  is a fractional assignment for that instance of the unrelated machines scheduling problem.
The makespan of this fractional solution is .
Let  be the optimal fractional assignment of the defined instance of unrelated machines. We know that if we apply Lenstra's rounding theorem \cite{LST90} to , we get an integral assignment for the unrelated machines scheduling instance, denoted by , such that the makespan of  is at most twice the makespan of  and therefore at most twice the makespan of .
Assignment  is a static job assignment and therefore  is a solution to the joint static cache partition and static job assignment problem of our original instance, with makespan at most twice . It follows that .
\end{proof}

\begin{lemma}\label{sdlb}
For , there is an instance of the joint partition and scheduling problem such that .
\end{lemma}
\begin{proof}
Consider the following instance. There are  jobs, where each takes   time regardless of the cache allocation, and one job that takes  time unit, regardless of cache.
The optimal static schedule for this instance assigns two jobs of size  to the first core, assigns one job of size  to each of the cores , and assigns the unit sized job to the last core. This yields a makespan of .
The optimal dynamic assignment assigns one job of size  fully to each core, and then splits the unit job equally among the cores, to yield a makespan of . Notice that this can be scheduled in a way the the unit job will never run simultaneously on more than one core. This is achieved by running the th fraction of size  of the unit job on core  at time . The other jobs, that are fully assigned to a single core, are paused and resumed later, if necessary, to accommodate the fractions of the unit sized job.
Therefore in this instance the ratio     is exactly .
\end{proof}

\bibliography{references}

\end{document}
