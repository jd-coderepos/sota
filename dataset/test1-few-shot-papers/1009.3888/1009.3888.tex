\documentclass{article}

\usepackage{spconf}
\usepackage{amsmath,amsfonts,bm,amssymb,epsfig,psfrag,graphicx}
\usepackage{algorithm,algpseudocode}


\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{example}{Example}
\newtheorem{defn}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{assumption}{Assumption}
\newtheorem{property}{Property}
\newtheorem{conjecture}{Conjecture}
\newtheorem{algm}{Algorithm}
\newtheorem{problem}{Problem}

\newcommand{\note}{{\bf Note: }}
\newcommand{\beq}{}
\newcommand{\beqa}{}
\newcommand{\mb}{\mathbf}
\newcommand{\mt}{\textrm}
\newcommand{\bnum}{\begin{enumerate}}
\newcommand{\enum}{\end{enumerate}}
\newcommand{\bu}{ {\bf u}} 


\newcommand{\tH}{\widetilde{{ \rm H}\phi}}
\newcommand{\tn}{\widetilde{n}}
\renewcommand{\th}{\widetilde{h}}
\newcommand{\tA}{\widetilde{{A}}}
\newcommand{\tY}{\widetilde{{Y}}}
\newcommand{\tW}{\widetilde{{W}}}
\newcommand{\tmH}{\widetilde{ \mb{H}}}
\newcommand{\tmW}{\widetilde{\mb{W}}}
\newcommand{\tmY}{\widetilde{\mb{Y}}}

\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\HH}{\mathbb{H}}
\renewcommand{\S}{\mathbb{S}}
\newcommand{\bQ} { {\bf Q} }

\newcommand{\sfh}{ {\sf{H}}}
\newcommand{\bmfm}{ {\sf{bf}}}
\newcommand{\bo} { {\mathbf{0}} }
\newcommand{\trace}{ {\mathrm{Tr}} }
\newcommand{\diag}{ \mathrm{diag} }

\newcommand{\Y}{\tilde{\mb{Y}}}
\newcommand{\bA} { {\mathbf{A}} }
\renewcommand{\H}{\tilde{\mb{H}}}
\renewcommand{\N}{\tilde{\mb{N}}}
\newcommand{\A}{\widetilde{A}}
\newcommand{\Ad}{\widetilde{A}\widetilde{A}^H}
\renewcommand{\b}{\mb{b}}

\newcommand{\pf}{{\bf Proof: }}


\newcommand{\bLambda}  {{\mathrm{\Lambda}} } 
\newcommand{\bfLambda}  {{\mathbf{\Lambda}} } 
\newcommand{\bU}  {{\mathbf{U}} }
\newcommand{\bH}  {{\mathbf{H}} }
\newcommand{\bEe}{{\mathbf{E}}}    \newcommand{\iid} {  {\sf{iid}} }
\newcommand{\ind} { {\sf{ind}} }


\newcommand{\mse}{ {\sf mse} }
\newcommand{\mmse}{ {\sf{mmse}} }
\newcommand{\bflambda}{ {\mathbf{\Lambda}} }
\newcommand{\bAt} { {\widetilde{\bA }} }
\newcommand{\stat} { {\sf stat} }
\newcommand{\bI}{{\bf I}}
\newcommand{\dg}{\dagger}


\newcommand{\vsp}{\vspace{0.1in} }
\newcommand{\hsp}{\hspace{0.1in} }
\newcommand{\vspp}{\vspace{0.05in} }
\newcommand{\hspp}{\hspace{0.05in} }
\newcommand{\hsppp}{\hspace{0.02in} }
\newcommand{\vsppp}{\vspace{0.02in} }

\newcommand{\vspn}{\vspace{-0.1in} }
\newcommand{\vspnn}{\vspace{-0.05in} }
\newcommand{\hspn}{\hspace{-0.1in} }
\newcommand{\hspnn}{\hspace{-0.05in} }

\newcommand{\perf}{ {\sf{perf}}  } 
\newcommand{\bef} { {\sf{bf}} } 
\newcommand{\st} {{\sf{st}}} 

\newcommand{\bX} { {\bf X} }
\newcommand{\ord}{{\mathcal{O}}}
\newcommand{\cb}{{\mathcal{C}}}
\newcommand{\cbt}{{\mathcal{ \widetilde{C} }}}
\newcommand{\littleo}{{\mathnormal{o}}}
\newcommand{\opt}{ {\sf opt} }
\newcommand{\bY}{ {\bf Y} } 

\newcommand{\gammarone} { \mu_{r,\hsppp 1}  } 
\newcommand{\gammartwo} {  \mu_{r, \hsppp 2} }
\newcommand{\gammatone} { {\mathrm{Gap}}_{t,\hsppp 12} }
\newcommand{\gammattwo} { {\mathrm{Gap}}_t }
\newcommand{\gammatc} { {\mathrm{Gap}}_t^c }
\newcommand{\gammarc} { \mu_{r, \hsppp 2}^{ c} }
\newcommand{\gammarcone}  {  \mu_{ r,\hsppp 2 }^{c, \hsppp ub}  }

\newcommand{\spatpow}{{\bf P}_{\sf spat}} 
\newcommand{\temppow}{ {\bf P}_{\sf temp} } 
\newcommand{\symbpow}{ {\bf P}_{\sf symb} } 

\newcommand{\bfx}{ \mathbf{x} } 
\newcommand{\bfw}{ \mathbf{w} } 
\newcommand{\bfa}{ \mathbf{a} } 
\newcommand{\bfb}{ \mathbf{b} } 
\newcommand{\bfc}{ \mathbf{c} } 
\newcommand{\thetah}{ \hat{\theta} } 
\newcommand{\thetab}{ \bar{\theta} } 
\newcommand{\etab}{ \bar{\eta} } 
\newcommand{\Reps}{ R_{\epsilon} } 
\newcommand{\pr}{ \textrm{Pr} } 
\newcommand{\supp}{ {\mathrm{supp}} }
\newcommand{\magn}{ {\mathrm{Mag}} }
\newcommand{\magnf}{ {\mathrm{Mag}(\cdot)} }
\newcommand{\thetabm}{ {\boldsymbol{\theta}} }
\newcommand{\psibm}{ {\boldsymbol{\psi}} }
\newcommand{\thetahbm}{ \hat{\boldsymbol{\theta}} }
\newcommand{\deltabm}{ {\boldsymbol{\delta}} }
\newcommand{\lambdabm}{ {\boldsymbol{\lambda}} }
\newcommand{\omegabm}{ {\boldsymbol{\omega}} }
\newcommand{\xibm}{ {\boldsymbol{\xi}} }
\newcommand{\Uth}{U_{\boldsymbol{\theta}}}
\newcommand{\snr}{ {\mathrm{SNR}} }
\newcommand{\snrf}{ {\mathrm{SNR}(\cdot)} }
\newcommand{\sinr}{ {\mathrm{SINR}} }
\newcommand{\ADB}{adaptive distributed beamforming }


\hyphenation{op-tical net-works semi-conduc-tor}

\title{A General Proof of Convergence for Adaptive Distributed Beamforming Schemes}

\name{Chang-Ching Chen, Chia-Shiang Tseng, and Che Lin
\thanks{This work is supported by National Science Council, R.O.C.,
under Grant NSC 99-2221-E-007-089-MY3.}}
\address{Institute of Communication Engineering \& Department of Electrical Engineering\\
National Tsing Hua University, \\ Hsinchu, Taiwan 30013 \\
\small E-mail: s9864511@m98.nthu.edu.tw,~s9964518@m99.nthu.edu.tw,~clin@ee.nthu.edu.tw}

\begin{document}
\ninept
\maketitle

\begin{abstract}
\vspace{-0.10cm}
This work focuses on the convergence analysis of adaptive distributed beamforming schemes that can be reformulated as local random search algorithms via a random search framework. Once reformulated as local random search algorithms, it is proved that under two sufficient conditions: a) the objective function of the algorithm is continuous and all its local maxima are global maxima, and b) the origin is an interior point within the range of the considered transformation of the random perturbation, the corresponding adaptive distributed beamforming schemes converge both in probability and in mean. This proof of convergence is general since it can be applied to analyze randomized adaptive distributed beamforming schemes with any type of objective functions and probability measures as long as both the sufficient conditions are satisfied. Further, this framework can be generalized to analyze an asynchronous scheme where distributed transmitters can only update their beamforming coefficients asynchronously. Simulation results are also provided to validate our analyses.
\end{abstract}

\begin{keywords}
Beamforming, convergence analysis, distributed algorithms, feedback communications.
\end{keywords}

\vspace{-0.10cm}
\section{Introduction}\label{sec:intro}
\vspace{-0.20cm}
In a distributed network, distributed beamforming is considered as a promising scheme that allows distributed transmitters to convey common information efficiently in energy due to its potential array gain and low-complexity. However, to achieve distributed beamforming, or phase alignment, channel state information (CSI) at the transmitters is required and the cost of obtaining perfect CSI is too expensive in practice. Therefore, instead of obtaining perfect CSI, an adaptive scheme that uses a one-bit feedback link to acquire partial CSI at the transmitter ends was proposed in \cite{Mudumbai2006}, and the analyses of this one-bit feedback adaptive scheme have been extensively studied in \cite{RM07}\nocite{Johnson08, Thukral07, Bucklew08}-\cite{Lin10}.
In \cite{Johnson08}, \cite{Thukral07}, a discrete version of the one-bit adaptive scheme with binary signaling is considered. 
To analyze the behavior of the one-bit adaptive scheme, the authors in \cite{Bucklew08} applied stochastic approximations to show the convergence of the scheme. It has been shown that the sample path of the one-bit adaptive scheme approximately follows an ordinary differential equation under suitable conditions, and the convergence of the scheme is established accordingly. 
Alternatively, the one-bit adaptive scheme was reformulated as a local random search algorithm via a random search framework and analyzed in our previous work \cite{Lin10}. This reformulation allows us to use the techniques studied in the mature field of random search for systematically analyzing the characteristics of the one-bit adaptive scheme. With the help of this framework, it has been shown, without any approximation, that the one-bit adaptive scheme converges both in probability and in mean, and its convergence time scales linearly with the number of distributed transmitters. 

In this paper, we further generalize the framework in \cite{Lin10} and provide a more general proof of convergence and linear scalability for \ADB schemes. We show that any \ADB scheme that can be reformulated as a local random search algorithm converges both in probability and in mean if the algorithm satisfies two sufficient conditions for the objective function and the random perturbation. 
This framework is more general since once the sufficient conditions are satisfied, there is no need to specify the objective functions and probability measures. 
Instead of focusing on a particular objective function and symmetric probability measures as in \cite{Mudumbai2006}, \cite{Bucklew08}, \cite{Lin10}, our framework can be applied to analyze a much broader set of \ADB schemes and hence provide more potential to unify theoretical analysis in this field.
Furthermore, since the transmitters are deployed in a distributed fashion, it is possible that they experience different environments that cause their local clocks to be asynchronous. Our framework can be further extended to analyze \ADB schemes in such asynchronous setting by a straightforward application of Bayes' rule.

\vspace{-0.10cm}
\section{System Setup}\label{sec:syssetup}
\vspace{-0.20cm}
We consider a network with  distributed transmitters that attempt to convey a common message to the receiver. We assume that all transmitters and the receiver are equipped with one antenna and the channels between each transmitter and the receiver are slow faded and frequency flat. Furthermore, we assume a noncoherent communication model where both the transmitters and the receiver do not have CSI. However, there is an error-free, zero-delay, and low-rate feedback link from the receiver to each transmitter so that the receiver can help aligning the beamforming phases through this reverse feedback link. The discrete-time, complex baseband received signal can be expressed as 
\beq \label{eq:model}
y[n] = \sum_{i=1}^{N}h_ig_i[n]s[n]+w[n] = \sum_{i=1}^{N}a_ib_i[n]e^{j(\phi_i+\psi_i[n])}s[n]+w[n]
\eeq
where  is the received signal,  is the common message with the average power constraint  for all , and  is the additive white Gaussian noise. For transmitter , we denote the time-invariant channel fading gain by , and the beamforming coefficient by . 
For simplicity, we set  and  and focus on the phase alignment during the training stage.

The SNR function at the receiver is given by 
\beq \label{eq:snr}
\snr(\thetabm[n])=\frac{P_s\left | \sum_{i=1}^{N} a_i e^{j\theta_i[n]} \right |^2}{\sigma^2}
\eeq
where  and  is the total phase received at the receiver from transmitter . 
The goal is to maximize the  so that the receiver can recover the signal with minimum error. However, since the receiver has neither the knowledge of CSI nor the objective function, \textit{i.e.}, the SNR function, it can only estimate a sample of the SNR function at each iteration. Therefore, this adaptive distributed beamforming problem can be reformulated as the problem stated as follows \cite{Lin10}:

\textit{Problem 1}: Given an unknown objective function , where , and only samples of  are available for any , find the global maxima of .

This problem cannot be solved by gradient search method since there is no knowledge on the objective function and its gradient at the transmitter end in our case. However, from our previous work \cite{Lin10}, it can be solved by global random search algorithms in general. Further, if all the local maxima of the objective function are global maxima, local random search algorithms, which are more efficient, can also be applied.



\vspace{-0.10cm}
\section{General Proof of Convergence and Linear Scalability}\label{sec:pf}
\vspace{-0.20cm}
In this section, we provide a more general proof for the convergence and linear scalability of a set of adaptive distributed beamforming problems that can be reformulated as local random search algorithms. 
To this end, we briefly describe the local random search algorithm in \cite{Lin10} as follows:
\begin{itemize}

\item \emph{Step zero}: Initialize the algorithm by choosing .

\item \emph{Step one}: Generate a random perturbation  from the probability measure  that could be time-varying and has the support . 

\item \emph{Step two}: Update the search point by , where the mapping  satisfies the condition that
\beq\nonumber
f(D(\thetabm[n-1],\deltabm[n])) \geq f(\thetabm[n-1]) 
\eeq

\end{itemize}
In most cases, the mapping  can be expressed as

where  is the indicator function and  can be a general transformation. Note that  and  are in the same space, .

Now, referring to the local random search algorithm described above, we further provide two sufficient conditions for our proof.

\begin{enumerate}

\item[(S1)] The objective function  is continuous and all its local maxima are global maxima. 
\item[(S2)] The origin is an interior point of the range of the transformation , for all .

\end{enumerate}
In the following analyses, we consider local random search algorithms that satisfy both the sufficient conditions. 
Note that we do not need to specify the exact expressions of the objective function and the probability measure once the sufficient conditions are satisfied. This makes our proofs much more general than those in \cite{Lin10}.

\subsection{Convergence}
We first define the convergence in probability as follows.
\vspace{-0.10cm}
\begin{defn}
A sequence  generated by a random search algorithm is said to converge in probability if given ,
\beq\nonumber
\lim_{n \rightarrow \infty} \pr\left[ \thetabm[n] \in \Reps \right] = 1
\eeq
where
\beq\nonumber\label{eq:def_Reps}
\Reps := \left\{ \thetabm \in \Theta : f(\thetabm) > f\left(\thetabm^{*}\right) -\epsilon \right\}
\eeq
is the -convergence region. In other words,  converges to  in probability, where  is a global maximum point.
\end{defn}


Now, we further derive two propositions for the proof of convergence. For notational simplicity, we omit the time indices and write ,  instead of ,  in the following propositions and the corresponding proofs.

\vspace{-0.10cm}
\begin{prop} \label{prop:1}
Given an objective function  and a transformation  with domain  that satisfy the sufficient conditions (S1) and (S2). Let  be the mapping as defined in \eqref{eq:mapping}, then for any , there exists a set  with nonempty interior points, such that  for all , where  is the range of the mapping  at .
\end{prop}

\vspace{-0.10cm}
\pf We begin the proof by defining a -superlevel set
\beq \nonumber
U_\thetabm := \left \{ \psibm \in \Theta : f(\psibm) \geq f(\thetabm) \right \}
\eeq
which is the subset of  with all the elements in  mapping to function values no less than . Note that the assumption  implies that  and since  is nonempty,  is nonempty. Furthermore, since  is continuous, the boundary points are those points that satisfy .

We claim that for any , there exists a set  with nonempty interior points, such that  for all , where  is an open ball centered at  with radius . 
To this end, we first rule out the case where there are flat regions outside , that is, for some , there exists a  such that  for all . This case cannot happen since if it does, then  for all  and this implies that  is a local maxima point and thus a global maxima point by the sufficient condition (S1), and this contradicts to the assumption that . Therefore, there are no flat regions outside .

Excluding the existence of flat regions outside , we now consider two cases where  is either a local minimum point or not. Note that the arguments leading to the absence of flat regions outside  implies that  cannot be a local maxima point.

Case I:
If  is a local minimum point, we can show that it is an interior point of  since the fact that  is a local minimum point but not a local maxima point implies that there exists a  such that  for all . This means that  and thus  is an interior point of . Note that in this case, the entire  are in the interior of  and we choose , which obviously has nonempty interior points.

Case II:
If  is not a local minimum point, it can be shown that it is a boundary point of  but not an isolated point. First, we show that  is not an isolated point. If  is an isolated point, it means that there exists a  such that for all , , or equivalently, . This means that  is a local maximum point and thus a global maximum point by the sufficient condition (S1). Again, we obtain a contradiction to the assumption that . Now, since  is neither a local maximum point nor a local minimum point, then for any , we can always find a point  such that , i.e.,  and a point  such that , i.e., . Thus, for any ,  contains both points inside and outside . This means that  is a boundary point. Note that  is an interior point in  since if it is not, then it is a boundary point of  and it means , which contradicts to the statement that .
In this case, we choose , where  and there are nonempty interior points in . Therefore, our claim is indeed true.

Now we define 
\beq\nonumber
\Omega := \left\{ \omegabm \in \Theta : \omegabm = \thetabm+G_n(\deltabm), \hspp \deltabm \in \supp(\mu_n) \right\}
\eeq
as the set by shifting  with respect to . Then the range of  for any  is given by
\beq\nonumber
Range\{ D\left ( \thetabm, \cdot \right ) \} = \Omega \cap U_\thetabm
\eeq
Note that the sufficient condition (S2) implies that  is an interior point of . Since  is also a boundary or interior point of , there always exist  such that . Therefore, we can conclude that .


The following proposition states that for any  outside , there is a non-zero probability to improve  by applying a local perturbation to . 

\begin{prop}\label{prop:pos_improve}
For any given , there correspond  and  such that
\beq\nonumber
\pr \left[ f(\thetabm+G_n(\deltabm)) - f(\thetabm) \geq \gamma \right] \geq \eta
\eeq
where  is a random vector generated with the probability measure .
\end{prop}

\pf \textit{Proposition \ref{prop:1}} implies that for any , there exists an interior point  and  such that , . Then, 
\beq\nonumber
\pr \left[ f(\thetabm+G_n(\deltabm)) - f(\thetabm) \geq \gamma(\thetabm) \right] \geq \mu_n (T) =: \eta(\thetabm) >0
\eeq
Note that  is a function of  since  depends on . We complete the proof by letting 



Since there is always a non-zero probability to improve  for each time step before the sequence reaches , the convergence is expected. We describe this more precisely in the following theorem.

\begin{thm}\label{thm:converge}
For an objective function  and a transformation  with domain  that satisfy the sufficient conditions (S1) and (S2), let  be a sequence generated from the local random search algorithm. Then the resulting sequence converges in probability, i.e., given ,
\beq\nonumber
\lim_{n \rightarrow \infty} \pr\left[ \thetabm[n] \in \Reps \right] = 1
\eeq
\end{thm}

With \textit{Proposition \ref{prop:pos_improve}}, the proof directly follows the one provided in our previous work \cite{Lin10} by replacing the  in \cite{Lin10} by a general objective function . We hence omit the details. Note that since  is non-negative and monotonically non-decreasing, this sequence also converges in mean by the Monotone Convergence Theorem \cite{Durrett95}.

\subsection{Linear Scalability}
For the analysis of the scaling law, we use an alternative definition of convergence. 
\begin{defn}
A sequence  generated by a random search algorithm is said to converge in mean if there exists an  such that 
\beq
E_{\{\deltabm[m]\}_{m=0}^{n} | \thetabm[0]}\left[f\left( \thetabm[n] \right)\right]>f\left( \thetabm^* \right) - \epsilon \label{eq:cvg_in_mean}
\eeq
for all .
That is,  converges to  in mean. 
Furthermore, the iterations required to converge in mean is defined as the hitting time.
\end{defn}


With the above definition, we introduce the following theorem for linear scalability.

\begin{thm}
Given , the \textbf{hitting time} of the random search algorithm scales linearly with . That is, there exists , such that Eqn. \eqref{eq:cvg_in_mean} holds for .
\end{thm} 


By substituting the  in \cite{Lin10} by a more general objective function  which satisfies the stated sufficient conditions, the proof directly follows the one provided in \cite{Lin10}.

Even though the derivation of the proofs for the above two theorems directly follow those in \cite{Lin10} with only little modification, we emphasize again that we do not need to specify the objective function and the probability measure used as in \cite{Lin10} once the sufficient conditions are satisfied. Therefore, our proofs are more general.

\vspace{-0.20cm}
\section{Asynchronous Scheme}\label{sec:asyn}
\vspace{-0.20cm}
In this section, we model an asynchronous \ADB scheme and analyze its convergence by extending our random search framework. 
We consider the case where at each time instance based on the global clock, only  of the distributed transmitters update their phases and the rest of them keep their phases unchanged. 
This scenario can be equivalently modeled by assuming that each transmitter perturbs its phase independently with probability  at each time slot. This is similar to but different from the  algorithm proposed in \cite{Bucklew08} since in our case, we assume that all the transmitters transmit at all times but only on average  of them change their phases at each time slot. 


Now, we show that this \ADB scheme still converges even when the phases are updated asynchronously. Similar to the analysis in Sec.~\ref{sec:pf}, we first derive a proposition stating that for each perturbation, there is a non-zero probability to improve the objective function .


\vspace{-0.10cm}
\begin{prop}\label{prop:rho_improve}
Consider the asynchronous scheme described above, then for any given , there corresponds  and  such that
\beq\nonumber
\pr \left[ f(\thetabm+G_n(\deltabm)) - f(\thetabm) \geq \gamma \right] \ge \lambda
\eeq
where  is a random vector generated with the probability measure .
\end{prop}

\pf We prove the proposition by Bayes' rule. Let  be the event that all transmitters update their phases. Then
\beqa
&\ &\pr \left[ f(\thetabm+G_n(\deltabm)) - f(\thetabm) \geq \gamma \right]  \nonumber\\ 
&\ge& \pr \left[ f(\thetabm+G_n(\deltabm)) - f(\thetabm) \geq \gamma \mid Z \right] \pr \left[ Z \right] \nonumber \\
&\ge& \eta p^{N} =:\lambda \nonumber
\eeqa
The last inequality follows from \textit{Proposition \ref{prop:pos_improve}}. 


With \textit{Proposition \ref{prop:rho_improve}}, we can apply \textit{Theorem \ref{thm:converge}} to show that this asynchronous scheme converges both in probability and in mean. Note that by applying the simple Bayes' rule, we are able to prove the convergence for a much broader set of \ADB schemes. This demonstrates again the generality and flexibility of our framework.



\vspace{-0.20cm}
\section{Simulation Results and Conclusion}\label{sec:sim}
\vspace{-0.20cm}
In this section, numerical results are provided to validate our analyses. We consider a network with  distributed transmitters and assume the channel coefficients are i.i.d. . Unless otherwise specified, we use the SNR function described by \eqref{eq:snr} as our objective function, set  to be an identity function, and use a random perturbation with the time-invariant probability measure , where  denotes the uniform distribution and  in the simulation. Besides, for simplicity, we say that the algorithm converges once , where . It has been shown in~\cite{Lin10} that the SNR function, the probability measure , and the transformation  considered above satisfy both the sufficient conditions. We hence use this setting to verify our analyses.




\begin{figure}[tb]
\psfrag{No. of Iterations}[ct][lc][0.8]{No. of Iterations}
\psfrag{Proportion to Max}[lb][lc][0.8]{Proportion to Max}
\psfrag{(a)}[cb][lc][0.8]{(a)}
\psfrag{(b)}[cb][lc][0.8]{(b)}
\psfrag{title}{}
\centering{
\includegraphics[width = 3.6 in, height= 2.1 in ]{simres_func_asym_1012.eps} 
\caption{The convergence of (a) the objective function  defined in Sec. \ref{sec:sim} satisfying the sufficient condition (S1) and (b) the asymmetric probability measure satisfying the sufficient condition (S2)}
\label{fig:cvg}
}
\end{figure}

\begin{figure}[tb]
\psfrag{No. of Iterations}[lc][lc][0.8]{Average No. of Iterations}
\psfrag{rho}[lc][lc][0.7]{}
\psfrag{(a)}[cb][lc][0.8]{(a)}
\psfrag{(b)}[cb][lc][0.8]{(b)}
\psfrag{Number of Distributed Transmitters}[lc][lc][0.7]{No. of Distributed Transmitters}
\centering{
\includegraphics[width= 3.6 in, height=2.1 in]{Asynchronous_1020.eps} 
\caption{(a) The average iterations necessary for the convergence of the asynchronous scheme at different . (b) The average convergence time of the asynchronous scheme with different }
\label{fig:asyn}
}
\end{figure}
Fig.~\ref{fig:cvg} shows the convergence of (a) an arbitrary objective function satisfying the sufficient condition (S1) and (b) a random perturbation with probability measure which is not symmetric but satisfies the sufficient condition (S2). For Fig.~\ref{fig:cvg}(a), we choose the objective function to be , where mod is the modulo function.  
It can be shown that this function satisfies the sufficient condition (S1) and we omit the details due to space constraint. 
For Fig.~\ref{fig:cvg}(b), we generate the asymmetric distribution by randomly shifting  around zero. For both settings, we demonstrate that the modified algorithm either with new objective function or asymmetric probability measure converges from different initial points. Note that more simulations with different random shifts of  have been done and show similar behaviors but are not included here due to space constraint. The asynchronous scheme described in Sec.~\ref{sec:asyn} is considered in Fig.~\ref{fig:asyn}. In Fig.~\ref{fig:asyn}(a), we show the difference between the asynchronous scheme with different  and the synchronous scheme in terms of the convergence time. This figure also shows the average iterations necessary for the asynchronous scheme to converge for different . It is obvious that the performance of the asynchronous scheme is worse than that of the synchronous scheme. However, we emphasize that even when only  of the distributed transmitters update their phases at a given time instance, the algorithm still converges. Since the convergence behavior from different initial points of the asynchronous scheme for any  is also similar to those in Fig.~\ref{fig:cvg}, we omit it due to space limitation. In Fig.~\ref{fig:asyn}(b), we demonstrate the linear scalability of the asynchronous scheme with . We observe that the convergence time increases with , and that for any , the average number of iterations necessary for the convergence scales linearly with the number of distributed transmitters. These simulation results verify our theoretical analyses.




In this paper, we generalized the proof of convergence for adaptive distributed beamforming schemes that can be reformulated as local random search algorithms and 
satisfy two sufficient conditions. Specifically, we have shown that such adaptive distributed beamforming schemes converge both in probability and in mean and their convergence time scales linearly with the number of distributed transmitters. We further extended our framework and analyzed the case where distributed transmitters can only update their beamforming coefficients asynchronously. Simulations were provided to validate our analyses.



\bibliographystyle{IEEEtran}
\footnotesize
\bibliography{ICASSP2011_Ref.bib}


\end{document}