\subsection{Soundness}
\label{sec:soundness}

We now state our soundness theorem.

 denotes that 
is provable using instances of the axiom and
proof rule schemas for protocol  (that is, all rules of
the form  or ).


\begin{theorem} (Soundness)
If 
then .
\end{theorem}

We first present definitions and lemmas required
to prove the soundness of QPCL's proofsystem,
and then prove the soundness of the axioms about
cryptographic primitives as illustrative cases. Appendix~\ref{sec:soundness-app} contains proofs of other axioms.


Each property that is provable using QPCL's proof system is
a safety property in the following sense.


\begin{definition}
  A basic formula  is called a \emph{safety property} if
   implies that for all traces
   such that ,  and .
\end{definition}

Safety ensures that properties which are false on a trace continue to be false.
This allows us the bound the probability of a formula being false in the
middle of an execution, by the probability at the end of the execution.

Since safety applies only to trace properties and not to formulas with belief
operators, we convert probabilistic assertions to basic formulas using an
erasure operation .

\begin{definition}[Erasure]
  The erasure operation  is defined by induction on  as follows:
      \begin{itemize}
        \item .
        \item .
        \item .
        \item .
        \item .
      \end{itemize}
\end{definition}


\begin{lemma}[Safety]
\label{lemma:safety}
If , then  is a safety property.
\end{lemma}

\begin{proof}
By induction on the derivation of . We consider three
cases here, and leave the remaining cases to the reader:
\begin{description}
  \item[\axname{B1}.] Assume by the induction hypothesis that  is a safety property.
    Then it is immediate that  is
a safety property.

  \item[\axname{PC}.] Assuming, by the induction hypothesis,
    that  is a safety property, we must
    show that  is a safety property. Assume
    that for some , , it is the case that
    . By the
    semantics of the modal formula,
    we know that there exists , ,  such that ,
    , and . For
    all traces  such that , we must have
    that . Therefore,
    .

  \item[\axname{FS2}.] We need to show that  is a safety
    property. Assume that for some trace , ,
    it is the case that .
    Therefore, it must be the case that  and that  does not appear in  before . Therefore, the same must be true for all
     such that .
\end{description}
\end{proof}


\paragraph*{Soundness of the axioms about cryptographic primitives}
We prove axioms about cryptographic primitives sound by reducing the validity
of the axiom to the security of the primitive. Such proofs require augmenting
the implementations of primitives with a program that monitors the validity of
the axiom on the trace. When a violation of the axiom is detected, it can be
transformed into a violation of the primitive's security.  As every attack on
the axiom can be transformed in to an attack on the primitive, the probability
of the primitive being broken is a bound on the probability that the axiom is
false. However, we need to account for the additional time required to monitor
the validity of the axiom while computing the probability of attack on the
primitive.

In order to prove the soundness of \axname{VER}, we need to provide a
formal definition of execution tree, so that we can do an induction on
the structure of the execution tree.

We define a prefix relation on trees. Intuitively, a tree 
is a prefix of  if every trace in  is a prefix of .

\begin{definition}[Tree Prefix]
A tree  is a \emph{prefix} of , denoted , if
one of the following conditions hold:
\begin{enumerate}
  \item ,
  \item  is a configuration  and \footnote{
   Cost and probability labels are elided here for brevity. },
  \item ,
,
    and .
\end{enumerate}
\end{definition}

We now present an equivalent definition of the probability of a
formula interpreted on a tree. The function 
denotes the probability of a formula  in the subtree
 that follows after trace , with \valuations . Figure
 shows a trace  followed by a subtree 
of . Since QPCL formulas depend on an entire trace, it is not enough to
define the probability of a formula with respect to a subtree, but to include
the history of events that ocurred before the subtree as illustrated in
Figure~\ref{fig:prob}. In the definitions below, 
denotes the the trace obtained by extending  with the transition
, where  is the last configuration in .
The empty trace is denoted by , and  is the
trace , containing only a single configuration and no transitions.

\begin{figure}
  \centering
		\includegraphics[width=0.4\textwidth]{Diagrams/CTrees-trimmed.pdf}
        \caption{An Execution Tree with a trace  and subtree }
   \label{fig:prob}
 \end{figure}


\begin{definition}[Probability]
 is defined inductively on 
as follows:
\begin{enumerate}
\item  if ,
\item  if ,
\item 
   if .
\end{enumerate}
\end{definition}

The probability of a formula  interpreted on a tree 
preceded by
 the empty trace, and using
\valuation  is .
The following lemma states
 that the two definitions of probability are equivalent.
\begin{lemma}
\label{lemma:ind-equiv}
For all \valuations ,
.
\end{lemma}

We also state a lemma that relates the probability of a safety
property on a tree  to its probability on a prefix of .
\begin{lemma}
\label{lemma:safety-prefix}
If  is a safety property and ,  then
for all ,
.
\end{lemma}

In our proofs of the soundness of the axioms about cryptographic
primitives, we replace the implementations of some actions with
different implementations that preserve input-output behavior, in a
sense made precise by the following definition.


\begin{definition}[Simulation]
An implementation  \emph{simulates} an implementation 
with the relation  on 
(where  denotes the set of states of implementation ), if
(a) , where  and 
are the initial states of  and  respectively and
(b) if , then for all
transitions  of , there exists a
transition  of  such that .
If there exists a  such that, for all transitions of , if
 is the cost of the transition
and  is the cost of the
corresponding transitions of , we have
,
 then  simulates  \emph{with time bound }.
\end{definition}
\noindent Intuitively, if  simulates  with the relation , then starting from
-related states, the implementations  and  exhibit the same
input-output behavior, but have possibly different costs.

We wish to lift simulations over action implementations to simulations over
setups, which are collections of action implementations.  However, for a setup
 to simulate , it is not sufficient for
the corresponding implementations in  and  to be
simulations.  Recall that different implementations may share state, and that
state sharing is governed by the label  of an action  in the thread
with identifier
 in the global state. Therefore, we require implementations that share state
to respect each other's simulation relations.

\begin{definition}[Setup Simulation] A setup  simulates a setup
 if there exists a set  of relations, indexed by global state labels  ,  and each
 in  simulates the corresponding implementation in
 with relation , where .
\end{definition}

We now show that if two setups  and  differ only in
their action implementations, and the action implementations in 
simulate the corresponding implementations in , then for any safety property ,
and assignment , the probability of  in the tree
generated by  is bounded by the probability of  in the
tree generated by .

\begin{lemma}\label{lemma:simulation-bound}
If setup  simulates
  setup , each implementation  in
   simulates the corresponding implementation in
   with time bound , and
   is a safety property,
  then for all , , where  is the
  number of times
implementation  is called.
\end{lemma}

\begin{proof}
  We first show by induction on   that . Essentially, we can show
that
each trace using the implementations in  makes
transitions identical to the
  trace using the implementations in , and
takes no more time than the extra time allotted ().
We then apply Lemma~\ref{lemma:safety-prefix}.
\end{proof}

In the theorem above, we call the extra time allocated for
the simulation to execute
() the \emph{reduction overhead}.



\begin{lemma} The inference rule \axname{VER} is sound. \end{lemma}


\begin{proof}
Let  abbreviate the formula .
We must show that  \mbox{}, where 
  is defined as
follows:

where,  is the concrete security bound of the signature
scheme  specified by the protocol ,  is a bound on the total number of signing actions on a trace,  is
the number of instances of  in ,  is the number of signing
actions in role , and  is the reduction overhead
for the simulation where the implementations of actions  and
 are replaced respectively by the implementations  and 
described in Algorithm ~\ref{fig:ver-instr}.

  \begin{algorithm2e}
    \SetKwFunction{isign}{sign'}\SetKwFunction{iverify}{verify'}
    \SetKwFunction{sign}{sign}\SetKwFunction{verify}{verify}
    \SetKwProg{myalg}{Implementation}{}{}
    \myalg{\isign{}}{
      \nl  \sign{}\;
      \nl \KwRet{}\;}{}
    \setcounter{AlgoLine}{0}
    \SetKwProg{myproc}{Procedure}{}{}
    \myalg{\iverify{}}{
      \nl  \verify{}\;
      \nl\;
      \nl \KwRet{}\;}{}
  \caption{Implementations  and  augment  and  to monitor \axname{VER}}
  \label{fig:ver-instr}
  \end{algorithm2e}


Given , , and , we want to show that

As a first step, we replace the implementations of  and
 in  with
the implementations shown in Algorithm~\ref{fig:ver-instr}.
The implementation  keeps track of the messages signed;
 checks whether a verified message has been signed before. The
variable  in  is set to true when a message is verified
that has not been signed before. Therefore,  is set to true precisely when
 is true on a trace.  Note that the
implementations  and  simulate  and
. The simulation relation is  for all
 and , and the initial state for  and 
is , where  is the initial state for the
implementation of  and . Therefore, by
Lemma~\ref{lemma:simulation-bound}, we have that

Let  be the protocol that results by replacing the implementations
 and  in  with  and .
Let  be the additional runtime required
for the reduction in Algorithm~\ref{fig:ver-instr};  can be bounded by a
polynomial that is , where  and  are the number of signature and verification
actions in a role, assuming some quadratic implementation for the set operations
in Algorithm~\ref{fig:ver-instr}.
Recall from Section~\ref{sec:primer} that the  security condition
is violated when the adversary is able to create a signature of
a message that has not been signed before. Therefore, when  is set
to true, the  security of the scheme  has been violated. Consequently, the
probability that  is set to true can be bounded by ,
where  is the number of signing actions and is bounded by the number of signing
operations possible in running the protocol, that is,  and  is the number of signing actions in role  of
protocol . Since  is set to true when 
is true on a trace, we can show that

\end{proof}




\newcommand{\nonces}[1]{\mathtt{nonces}(#1)}
\begin{lemma} The axiom \axname{FS2}
  is sound. \end{lemma}



\begin{proof}
Let  abbreviate

We must show that , where  is defined as follows:

where  is the total number of  actions on a trace,  is an upper bound on the number of nonces that the adversary can
send to a protocol thread on a ,  is the length of the
longest message that can be received,  is the number of new, send, and receive actions in
a trace, and  is the reduction overhead for the simulation where the
implementations of actions ,  and  are
replaced respectively by the implementations ,   and
 described in Algorithm~\ref{fig:fs-instr}.

\begin{algorithm2e}
    \SetKwFunction{isend}{send'}\SetKwFunction{irecv}{recv'}
    \SetKwFunction{send}{send}\SetKwFunction{recv}{recv}
    \SetKwFunction{new}{new}\SetKwFunction{inew}{new'}
    \SetKwProg{myalg}{Implementation}{}{}
    \myalg{\inew{}}{
      \nl  \new{}\;
      \nl \KwRet{}\;}{}
    \setcounter{AlgoLine}{0}
    \myalg{\isend{}}{
      \nl  \send{}\;
      \nl \KwRet{}\;}{}
    \setcounter{AlgoLine}{0}
    \SetKwProg{myproc}{Procedure}{}{}
    \myalg{\irecv{}}{
      \nl  \recv{}\;
      \nl \lIf{}{}
      \nl \KwRet{}\;}{}
      \caption{Implementations , , and  augment ,  and  repectively to monitor \axname{FS2}}
  \label{fig:fs-instr}
  \end{algorithm2e}

Given , and , we must show that

Let  be the protocol that results from replacing
the implementations of , , and

with the implementations shown in Algorithm~\ref{fig:fs-instr}.
The
set  records the
nonces that have been generated but not been sent out. The implementation
 records the nonces that have been generated. When
a message is sent with a nonce using , it is
removed from .
The variable  is set to true when there is a nonce in  that has been received.
Essentially,  is set to true on a trace exactly when  is false.

Consider the
following two experiments:
\begin{itemize}
\item : Run protocol , with  implemented
by a random-number generator with uniformly random distibution. If
 is set to true output  else .
\item : Run protocol , with  implemented
by the pseudorandom-number generator  specified by the
protocol. If  is set to true output  else
.
\end{itemize}

Recall from Section~\ref{sec:primer} that the probability of an adversary being
able to distinguish a uniform random number generator from the output of a
pseudorandom-number generator  after seeing  samples and in
time  is bounded by
.
Therefore, we have the following:

where , where  is the number of  actions in
role  and  is the number of instances of role  in protocol roles . The additional runtime 
can be bounded by a polynomial that is , where  is
the total number of
new, send, and receive actions in the protocol, assuming some quadratic implementation
of the set operations in Algorithm~\ref{fig:fs-instr}.
The total runtime for  is  to account for the additional
runtime for the reduction.

As  is set to true exactly when  is
true, as with the proof for , we can use Lemma~\ref{lemma:simulation-bound}
to get the following bound for :


We now only need to derive a bound for
, since
.
When we use a true random number generator, at each guess, the adversary can
guess the random number generated with probability only . Therefore,
if the adversary has  guesses, by the union bound, we can show that the total
probability of  being true is .  The adversary can attempt to
guess the nonce at each  action. However, each message received
can contain multiple nonces. If the longest message in the protocol is of
length , then each message received can contain at most  nonces of
length , and so a bound on , the total number of guesses available to
the adversary, is . Finally, we have that

Therefore, we have that

\end{proof}

