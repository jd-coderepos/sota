\documentclass{LMCS}

\def\doi{9(1:13)2013}
\lmcsheading {\doi}
{1--26}
{}
{}
{Feb.~29, 2012}
{Mar.~26, 2013}
{}
\usepackage{vaucanson-g}
\usepackage{fancyvrb}
\usepackage{todonotes}
\usepackage{url}
\usepackage{float}
\usepackage{eucal}
\usepackage{subfig}
\usepackage{changebar}
\usepackage{paralist}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{latexsym}
\usepackage{xspace}
\usepackage[norelsize]{algorithm2e}
\usepackage[on]{auto-pst-pdf}
\usepackage{hyperref,enumerate}
\newcommand{\forappendix}[2]{#2}
\renewcommand{\forappendix}[2]{#1}

\renewcommand{\phi}{\varphi}

\newcommand\hide[1]{}
\setlength{\marginparwidth}{2.4cm}

\newcounter{lemmasave}

\newcommand{\zug}[1]{{\langle #1  \rangle}}
\newcommand{\set}[1]{\text{}} 
\newcommand{\rzug}[1]{{\scriptstyle\langle} #1  {\scriptstyle\rangle}}


\newcommand\kahler{K\"ahler\xspace}
\newcommand\konig{Ko\"nig\xspace}
\newcommand\buchi{B\"uchi\xspace}
\newcommand{\N}{\mbox{IN}}
\newcommand{\bft}{\mbox{\em \bf true}}
\newcommand{\bff}{\mbox{\em \bf false}}
\newcommand{\U}{{\mathcal U}}
\newcommand\A{{\mathcal A}}
\newcommand{\B}{{\mathcal B}}
\newcommand{\R}{{\mathcal R}}
\newcommand{\Tau}{{\mathcal T}}
\newcommand{\Y}[2]{\ensuremath{Y_{#1#2}}}
\newcommand{\Z}[2]{\ensuremath{Z_{#1#2}}}
\newcommand\splus{\ensuremath{+\!}}
\newcommand\stimes{\ensuremath{\!\times\!}}
\newcommand\mcS{\mathcal{S}}
\newcommand{\La}{{\mathcal L}}
\renewcommand{\theenumi}{(\arabic{enumi})}
\renewcommand{\labelenumi}{\theenumi}
\newcommand{\DAG}{\textsc{dag}\xspace}
\newcommand{\DAGs}{\textsc{dag}s\xspace}

\def\squarebox#1{\hbox to #1{\hfill\vbox to #1{\vfill}}}
\renewcommand{\qed}{\hspace*{\fill}
          \vbox{\hrule\hbox{\vrule\squarebox{.667em}\vrule}\hrule}\smallskip}
\newcommand{\abs}[1]{\lvert#1\rvert}

\nochangebars


\newcommand{\standout}[1]{\medskip \noindent {\bf #1:}}




\newcounter{examplectr}
\setcounter{examplectr}{0}
\newenvironment{example}{
\refstepcounter{examplectr}
{
\vspace{\bigskipamount}

\it\noindent Example \theexamplectr.}
}{ \vspace{\bigskipamount}}


\newcommand{\G}{\ensuremath{G}\xspace}
\newcommand{\Gprime}{\ensuremath{G'}\xspace}
\newcommand{\Gdubprime}{\ensuremath{G''}\xspace}
\newcommand{\TGP}{\ensuremath{T^{\Gprime}}\xspace}
\newcommand{\TGPP}{\ensuremath{T^{\Gdubprime}}\xspace}
\newcommand{\LR}{\ensuremath{\mathcal{R}}}
\newcommand{\TLRL}{\ensuremath{\mathcal{R}^l_T}}
\newcommand{\TLRM}{\ensuremath{\mathcal{R}^m_T}}
\newcommand{\PSQ}{\ensuremath{{\bf Q}}}

\SetKwFunction{torank}{torank}
\SetKwFunction{pred}{pred}
\SetKwFunction{maxrank}{mr}
\SetKwFunction{tighten}{tighten}
\SetKwFunction{min}{min}
\SetKwFunction{prerank}{\ensuremath{\alpha}}
\SetKwFunction{prerankstate}{\ensuremath{\beta}}



\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{lem} \newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}


\pagenumbering{arabic}

\begin{document}
\title[Unifying B\"uchi Complementation Constructions]{Unifying B\"uchi Complementation Constructions}

\author[S.~Fogarty]{Seth Fogarty\rsuper a}
\address{{\lsuper a}Computer Science Department, Trinity University, San Antonio, TX}
\email{sfogarty@trinity.com}
\thanks{{\lsuper a}The authors are grateful to Yoad Lustig for his extensive help in analyzing the original
slice-based construction.  Work supported in part by NSF grants CNS-1049862 and CCF-1139011, by NSF
Expeditions in Computing project "ExCAPE: Expeditions in Computer Augmented Program Engineering," by
BSF grant 9800096, and by gift from Intel. Work by Seth Fogarty done while at Rice University.}
\author[O.~Kupferman]{Orna Kupferman\rsuper b}
\address{{\lsuper b}School of Computer Science and Engineering, Hebrew University of Jerusalem, Israel}
\email{orna@cs.huji.ac.il}
\author[T.~Wilke]{Thomas Wilke\rsuper c}
\address{{\lsuper c}Institut f\"ur Informatik, Christian-Albrechts-Universit\"at zu Kiel, Kiel, Germany}
\email{wilke@ti.informatik.uni-kiel.de}
\author[M.~Y.~Vardi]{Moshe Y.~Vardi\rsuper d}
\address{{\lsuper d}Department of Computer Science, Rice University, Houston, TX}
\email{vardi@cs.rice.edu}

\keywords{Automata Theory, Omega Automata, B\"uchi Automata, B\"uchi Complementation, Model Checking}
\ACMCCS{[{\bf Theory of computation}]:  Formal languages and automata
  theory---Automata over infinite objects; [{\bf Software and its
      engineering}]: Software organization and properties---Software functional properties---Formal methods---Model checking} 
\subjclass{F.1.3, F.4.1}

\begin{abstract}
Complementation of \buchi automata, required for checking automata containment, is of major
theoretical and practical interest in formal verification. We consider two recent approaches to
complementation. The first is the {\em rank-based approach} of Kupferman and Vardi, which operates
over a \DAG that embodies all runs of the automaton. This approach is based on the observation that
the vertices of this \DAG can be ranked in a certain way, termed an {\em odd ranking}, iff all 
runs are rejecting. The second is the {\em slice-based approach} of \kahler and Wilke. This approach
tracks levels of ``split trees'' -- run trees in which only essential information
about the history of each run is maintained. While the slice-based construction is conceptually
simple, the complementing automata it generates are exponentially larger than those of the recent
rank-based construction of Schewe, and it suffers from the difficulty of symbolically encoding
levels of split trees.

In this work we reformulate the slice-based approach in terms of run \DAGs and preorders over
states. In doing so, we begin to draw parallels between the rank-based and slice-based approaches.
Through deeper analysis of the slice-based approach, we strongly restrict the nondeterminism it
generates. We are then able to employ the slice-based approach to provide a new odd ranking, called
a {\em retrospective ranking}, that is different from the one provided by Kupferman and Vardi.  This
new ranking allows us to construct a deterministic-in-the-limit rank-based automaton with a highly
restricted transition function.  Further, by phrasing the slice-based approach in terms of ranks,
our approach affords a simple symbolic encoding and achieves the tight bound of Schewe's
construction.
\end{abstract}

\maketitle

\section{Introduction}
The complementation problem for nondeterministic automata is central to the automata-theoretic
approach to formal verification \cite{Var07a}.  To test that the language of an automaton  is
contained in the language of a second automaton , check that the intersection of  with an
automaton that complements  is empty.  In model checking, the automaton  corresponds to
the system, and the automaton  corresponds to a property \cite{VW86b}.  While it is easy to
complement properties given as temporal logic formulas, complementation of properties given as
automata is not simple. Indeed, a word  is rejected by a nondeterministic automaton  if
\emph{all} runs of  on  reject the word. Thus, the complementary automaton has to consider
all possible runs, and complementation has the flavor of determinization.  Representing liveness,
fairness, or termination properties requires automata that recognize languages of infinite words.
Most commonly considered are nondeterministic \buchi automata, in which some of the states are
designated as accepting, and a run is accepting if it visits accepting states infinitely often
\cite{Buc62}.  For automata on finite words, determinization, and hence also complementation, is
done via the subset construction \cite{RS59}.  For B\"uchi automata the subset construction is not
sufficient, and optimal complementation constructions are more complicated \cite{Var07b}.

Efforts to develop simple complementation constructions for \buchi automata started early
in the 60s, motivated by decision problems of second-order logics.  \buchi suggested a
complementation construction for nondeterministic \buchi automata that involved a 
Ramsey-based combinatorial argument and a doubly-exponential blow-up in the state space
\cite{Buc62}.  Thus, complementing an automaton with  states resulted in an automaton with
 states.  In \cite{SVW87}, Sistla et al. suggested an improved implementation of
B\"uchi's construction, with only  states, which is still not optimal.  Only
in \cite{Saf88} Safra introduced a determinization construction, based on {\em Safra trees}, which also
enabled a  complementation construction, matching a lower bound described by Michel
\cite{Mic88}.  A careful analysis of the exact blow-up in Safra's and Michel's bounds, however,
reveals an exponential gap in the constants hiding in the  notations: while the upper bound on
the number of states in the complementary automaton constructed by Safra is , Michel's lower
bound involves only an  blow up, which is roughly . In addition, Safra's construction
has been resistant to optimal implementations \cite{ATW06,THB95}, which has to do with the complicated
combinatorial structure of its states and transitions, which can not be encoded symbolically.

The use of complementation in practice has led to a resurgent interest in the exact blow-up that
complementation involves and the feasibility of a symbolic complementation construction.  In 2001,
Kupferman and Vardi suggested a new analysis of runs of \buchi automata that led to a simpler
complementation construction \cite{KV01c}. In this analysis, one considers a \DAG that
embodies all the runs of an automaton  on a given word . It is shown in \cite{KV01c} that the
nodes of this \DAG can be mapped to ranks, where the rank of a node essentially indicates the
progress made towards a suffix of the run with no accepting states.
Further, all the runs of  on  are rejecting iff there is a {\em bounded odd ranking\/} of the
\DAG: one in which the maximal rank is bounded, ranks along paths do not increase, paths become
trapped in odd ranks, and nodes associated with accepting states are not assigned an odd rank.
Consequently, complementation can circumvent Safra's determinization construction along with the
complicated data structure of Safra trees, and can instead be based on an automaton that guesses an
odd ranking. The state space of such an automaton is based on annotating states in subsets with 
the guessed ranks. Beyond the fact that the {\em rank-based construction\/} can be implemented
symbolically \cite{TV07}, it gave rise to a sequence of works improving both the blow-up it involves
and its implementation in practice.  The most notable improvements are the introduction of tight
rankings \cite{FKV06} and Schewe's improved cut-point construction \cite{Sch09}. These improvements tightened
the  upper bound of \cite{KV01c} to .
Together with recent work on a tighter lower bound \cite{Yan06}, the gap between the upper and lower
bound is now a quadratic term.  Addressing practical concerns, Doyen and Raskin have introduced a
useful subsumption technique for the rank-based approach \cite{DR09}.

In an effort to unify \buchi complementation with other operations on automata,  \kahler and Wilke
introduced yet another analysis of runs of nondeterministic B\"uchi automata \cite{KW08}. The
analysis is based on {\em reduced split trees}, which are related to the M\"uller-Schupp trees used
for determinization \cite{MS95}.  A reduced split tree is a binary tree whose nodes are sets of
states as follows: the root is the set of initial states; and given a node associated with a set of
states, its left child is the set of successors that are accepting, while the right child is the set
of successors that are not accepting. In addition, each state of the automaton appears at most once
in each level of the binary tree: if it would appear in more than one set, it occurs only in the
leftmost one.  The construction that follows from the analysis, termed the {\em slice-based
construction\/},  is simpler than Safra's determinization, but its implementation suffers from
similar  difficulties: the need to refer to leftmost children requires encoding of a preorder, and
working with reduced split trees makes the transition relation between states awkward.  Thus,
as has been the case with Safra's construction, it is not clear how the slice-based approach can be
implemented symbolically.  This is unfortunate, as the slice-based approach does offer a very clean
and intuitive analysis, suggesting that a better construction is hidden in it.

In this paper we reveal such a hidden, elegant, construction, and we do so by unifying the
rank-based and the slice-based approaches. Before we turn to describe our construction, let us point
to a key conceptual difference between the two approaches. This difference has made their relation
of special interest and challenge.  In the rank-based approach, the ranks assigned to a node bound
the visits to accepting states yet to come. Thus, the ranks refer to the {\em future\/} of the run,
making the rank-based approach inherently nondeterministic. In contrast, in the slice-based
approach, the partition of the states of the automaton to the different sets in the tree is based on
previous visits to accepting states. Thus, the partition refers to the {\em past\/} of the run, and
does not depend on its future.

In order to draw parallels between the two approaches, we present a formulation of the slice-based
approach \hide{of \kahler and Wilke} in terms of run \DAGs. A careful analysis of the slice-based
approach then enables us to reduce the nondeterminism in the construction.  We can then employ this
improved slice-based approach in order to define a particular odd ranking of rejecting run \DAGs,
called a {\em retrospective ranking}.  In addition to revealing the theoretical connections between
the two seemingly different approaches, the new ranks lead to a complementation construction with a
transition function that is smaller and deterministic in the limit: every accepting run of the
automaton is eventually deterministic. This presents the first 
deterministic-in-the-limit complementation construction that does not use determinization.  Determinism in the limit
is central to verification in probabilistic settings \cite{CY95} and has proven useful in
experimental results \cite{ST03}.  Phrasing slice-based complementation as an odd ranking also
immediately affords us the improved cut-point of Schewe, the subsumption operation of Doyen and
Raskin, and provides an easy symbolic encoding.


\section{Preliminaries}\label{Sect:Ranks}\label{Sect:Tight}



A \emph{nondeterministic \buchi automaton on infinite words} (NBW for short) is a tuple , where  is a finite alphabet,  a finite set of states,  a set of initial states,  a set of accepting states, and  a nondeterministic transition relation. A state  is {\em
deterministic} if for every  it holds that . We lift
the function  to sets  of states in the usual fashion: . Further, we lift  to words word  by defining
 = . For
completeness, let .

\cbstart An infinite {\em run} of an NBW  on a word 
is an infinite sequence of states  such that  and, for
every , we have . Correspondingly, a \emph{finite run} is a
finite sequence of states  such that  and, for every , we have . When unspecified, a run refers to an infinite run. 
\cbend  A run is \emph{accepting} iff  for infinitely many .  A word  is accepted by  if there is an accepting run of  on .  The words accepted
by  form the {\em language} of , denoted by . The complement of , denoted
, is .  We say an automaton is \emph{deterministic
in the limit} if every state reachable from an accepting state is deterministic. Converting  to
an equivalent deterministic in the limit automaton involves an exponential blowup \cite{CY95,Saf88}.
One can simultaneously complement and determinize in the limit, via co-determinization into a parity
automaton \cite{Pit06}, and then converting that parity automaton to a deterministic-in-the-limit
\buchi automaton, with a cost of . 

\standout{Run \DAGs} 
Consider an NBW  and an infinite word . The runs of  on  can
be arranged in an infinite \DAG (directed acyclic graph) , where 
\begin{iteMize}{}
\cbstart
\item  is such that  iff some finite or infinite run  of  on  has
.
\cbend
\item  is
s.t.   iff  and .
\end{iteMize}
The \DAG , called the \emph{run \textsc{dag} of  on }, embodies all possible runs
of  on . We are primarily concerned with \emph{initial paths} in : paths that start in
.  Define a node  to be an -node when , and a path in
 to be \emph{accepting} when it is both initial and contains infinitely many -nodes.  An
accepting path in  corresponds to an accepting run of  on . When  contains an accepting path, 
call  an accepting run \DAG, otherwise call it a rejecting run \DAG.  We often consider
\DAGs  that are subgraphs of . A node  is a \emph{descendant} of  in  when  is
reachable from  in . A node  is \emph{finite} in  if it has only finitely many
descendants in .  A node  is \emph{-free} in  if it is not an -node, and has no
descendants in  that are -nodes. We say a node \emph{splits} when it has at least two
children, and conversely that two nodes \emph{join} when they share a common child.

\begin{exa}\label{ExampleOne}
In Figure~\ref{Fig:Automaton} we describe an NBW  that accepts
words with finitely many letters
. On the right is a prefix of the rejecting run \DAG of  on \hide{,
the word with an increasing number of 's between successive 's}. 
\end{exa}

{
\begin{figure}
\begin{centering}
\subfloat{
\ChgEdgeLabelScale{0.8}
{
\begin{postscript}
\SmallPicture\VCDraw{\begin{VCPicture}{(0,-3)(10,5)}
\State[p]{(0,0)}{p} \FinalState[q]{(2.5,0)}{q} \State[r]{(5,0)}{r}
\State[s]{(5,-2)}{s} \FinalState[t]{(7.5,0)}{t}
\EdgeL{p}{q}{b}
\EdgeL{q}{r}{b}
\EdgeL{r}{t}{b}
\EdgeR{r}{s}{a}
\EdgeL{s}{t}{b}

\CLoopN{p}{\tiny{a,\!b}}
\CLoopN{q}{a}
\CLoopN{r}{a,\!b}
\CLoopW{s}{a}
\CLoopN{t}{a}

\end{VCPicture}}
\end{postscript}
}


\quad}\quad\quad
\subfloat{
{
\begin{postscript}
\SmallPicture\VCDraw{\begin{VCPicture}{(0,-12)(8,2)}
\def\level{0}\def\offset{0}
\State[p]{(0,\offset)}{p\level} \FinalState[q]{(2,\offset)}{q\level} \State[r]{(4,\offset)}{r\level}
\State[s]{(6,\offset)}{s\level} \FinalState[t]{(8,\offset)}{t\level}
\def\level{1} \def\prevlevel{0} \def\offset{-2}
\State[p]{(0,\offset)}{p\level} \FinalState[q]{(2,\offset)}{q\level} \State[r]{(4,\offset)}{r\level}
\FinalState[t]{(8,\offset)}{t\level}
\EdgeR{p\prevlevel}{p\level}{b~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{p\prevlevel}{q\level}{}
\EdgeL{q\prevlevel}{r\level}{} \EdgeL{r\prevlevel}{t\level}{} \EdgeL{s\prevlevel}{t\level}{}
\def\prevlevel{1} \def\level{2}\def\offset{-4}
\State[p]{(0,\offset)}{p\level} \FinalState[q]{(2,\offset)}{q\level} \State[r]{(4,\offset)}{r\level}
\State[s]{(6,\offset)}{s\level} \FinalState[t]{(8,\offset)}{t\level}
\EdgeR{p\prevlevel}{p\level}{a~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{q\prevlevel}{q\level}{}
\EdgeL{t\prevlevel}{t\level}{} \EdgeL{r\prevlevel}{s\level}{} 
\def\prevlevel{2} \def\level{3}\def\offset{-6}
\State[p]{(0,\offset)}{p\level} \FinalState[q]{(2,\offset)}{q\level} \State[r]{(4,\offset)}{r\level}
\FinalState[t]{(8,\offset)}{t\level}
\EdgeR{p\prevlevel}{p\level}{b~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{p\prevlevel}{q\level}{}
\EdgeL{q\prevlevel}{r\level}{} \EdgeL{r\prevlevel}{t\level}{} \EdgeL{s\prevlevel}{t\level}{}
\def\prevlevel{3} \def\level{4}\def\offset{-8}
\State[p]{(0,\offset)}{p\level} \FinalState[q]{(2,\offset)}{q\level} \State[r]{(4,\offset)}{r\level}
\State[s]{(6,\offset)}{s\level} \FinalState[t]{(8,\offset)}{t\level}
\EdgeR{p\prevlevel}{p\level}{a~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{q\prevlevel}{q\level}{}
\EdgeL{t\prevlevel}{t\level}{} \EdgeL{r\prevlevel}{s\level}{} 
\hide{
\def\prevlevel{4} \def\level{5}\def\offset{-10}
\State[p]{(0,\offset)}{p\level} \FinalState[q]{(2,\offset)}{q\level} \State[r]{(4,\offset)}{r\level}
\State[s]{(6,\offset)}{s\level} \FinalState[t]{(8,\offset)}{t\level}
\EdgeR{p\prevlevel}{p\level}{a~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{q\prevlevel}{q\level}{}
\EdgeL{s\prevlevel}{s\level}{} \EdgeL{t\prevlevel}{t\level}{} \EdgeL{r\prevlevel}{s\level}{} 
\def\prevlevel{5} \def\level{6}\def\offset{-12}
\State[p]{(0,\offset)}{p\level} \FinalState[q]{(2,\offset)}{q\level} \State[r]{(4,\offset)}{r\level}
\FinalState[t]{(8,\offset)}{t\level}
\EdgeR{p\prevlevel}{p\level}{b~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{p\prevlevel}{q\level}{}
\EdgeL{q\prevlevel}{r\level}{} \EdgeL{r\prevlevel}{t\level}{} \EdgeL{s\prevlevel}{t\level}{}
}
\begin{boldmath}
\multirput(0.65,0.25)(0.0,-2.0){5}{\large}
\multirput(2.65,0.25)(0.0,-2.0){5}{\large}
\multirput(4.65,0.25)(0.0,-2.0){5}{\large}
\multirput(6.65,0.25)(0.0,-4.0){2}{\large}
\multirput(6.65,-7.75)(0.0,-2.0){1}{\large}
\multirput(8.65,0.25)(0.0,-2.0){5}{\large}


\end{boldmath}

\end{VCPicture}}
\end{postscript}
}
}\quad
\vspace{-0.5in}
\caption{Left, the NBW , in which all states are initial.
Right, the rejecting run \DAG  of  on .
Nodes are superscripted with the prospective ranks of Section~\ref{Sect:Ranks}.
}\label{Fig:Automaton}
\end{centering}
\end{figure}
}



\standout{Rank-Based Complementation} 
If an NBW  does not accept a word , then every run of  on  must eventually cease
visiting accepting states. The notion of \emph{ranking}s, foreshadowed in \cite{Kla90} and
introduced in \cite{KV01c}, uses natural numbers to track the progress of each run in the \DAG
towards this point. A ranking for a \DAG  is a mapping from  to ,
in which no -node is given an odd rank, and in which the ranks along all paths do not increase.
Formally, a ranking is a function  such that if  is an -node
then  is even; and for every , if  then . Since each path starts at a finite rank and ranks cannot increase, every path eventually
becomes trapped in a rank.  A ranking is called an \emph{odd ranking} if every path becomes trapped
in an odd rank.  Since -nodes cannot have odd ranks, if there exists an odd ranking , then
every path in  must stop visiting accepting nodes when it becomes trapped in its final, odd,
rank, and  must be a rejecting \DAG.

\begin{lem}\label{Odd_Ranking_Rejecting}{\rm\cite{KV01c}}
If a run \DAG  has an odd ranking, then  is rejecting.
\end{lem}

A ranking is \emph{bounded by } when its range is , and an NBW  is of rank 
when for every , the rejecting \DAG  has an odd ranking bounded by . If we
can prove that an NBW  is of rank , we can use the notion of odd rankings to construct a
complementary automaton. This complementary NBW, denoted , tracks the levels of the run \DAG
and attempts to guess an odd ranking bounded by .  An \emph{-bounded level ranking} for an NBW
 is a function , such that if  then  is
even or .  Let  be the set of all -bounded level rankings.  The state space of
 is based on the set of -bounded level rankings for .  To define transitions of
, we need the following notion: for  and , say that
\emph{ follows  under } when for every  and , if  then  and : i.e. no transition between  and  on
 increases in rank.  Finally, to ensure that the guessed ranking is an odd ranking, we
employ the cut-point construction of Miyano and Hayashi, which maintains an obligation set of nodes
along paths obliged to visit an odd rank \cite{MH84}. For a level ranking , let
 and .

\begin{defi}\label{KVDef}
For an NBW   and , define
 to be the NBW , where
\smallskip
\begin{iteMize}{}
\item  for each ,\  otherwise.
\smallskip
\item 
f\sigmaf\sigma
\end{iteMize}
\end{defi}



By \cite{KV01c}, for every , the NBW  accepts only words rejected by  ---
exactly all words for which there exists an odd ranking with maximal rank . In addition,
\cite{KV01c} proves that for every rejecting run \DAG there exists a bounded odd ranking.  Below we
sketch the derivation of this ranking. Given a rejecting run \DAG , we inductively define a
sequence of subgraphs by eliminating nodes that cannot be part of accepting runs.  At odd steps we
remove finite nodes, while in even steps we remove nodes that are -free.  Formally, define a
sequence of subgraphs as follows:

\smallskip
\begin{iteMize}{}
\item .
\smallskip
\item .
\smallskip
\item F.
\end{iteMize}
\medskip

It is shown in \cite{GKSV03,KV01c} that only  steps are necessary to remove all
nodes from a rejecting run \DAG:  is empty. Nodes can be ranked by the last graph in which
they appear: for every node , the \emph{prospective rank} of  is the index  such
that  but .  The \emph{prospective ranking} of  assigns every
node its prospective rank.  Paths through  cannot increase in prospective rank, and no -node
can be given an odd rank: thus the prospective ranking abides by the requirements for rankings. We
call these rankings prospective because the rank of a node depends solely on its descendants.  By
\cite{KV01c}, if  is a rejecting run \DAG, then the prospective ranking of  is an odd
ranking bounded by . By the above, we thus have the following. 

\begin{theorem}\label{KV_Complement}{\rm \cite{KV01c}}
For every NBW , it holds that .
\end{theorem}

\begin{exa}\label{Example2}
In Figure~\ref{Fig:Automaton}, nodes for states  and  are finite in .
With these nodes removed, -nodes are -free in .  Without -nodes, -nodes 
are finite in .  Finally, -nodes are -free in .
\end{exa}


Karmarkar and Chakraborty have derived both theoretical and practical benefits from exploiting properties
of this prospective ranking: they demonstrated an unambiguous complementary automaton that, for
certain classes of problems, is exponentially smaller than  \cite{KC09}.



\standout{Tight Rankings} 
For an odd ranking  and , let  be the maximum rank that  assigns a vertex on level  of the run \DAG.  We say that  is
{\em tight}\footnote{This definition of tightness for an odd ranking is weaker that of
\cite{FKV06}, but does not affect the resulting bounds.} if there exists an  such that, for
every level , all odd ranks below  appear on level .  It is
shown in \cite{FKV06} that the retrospective ranking is tight.  This observation suggests two
improvements to .  First, we can postpone, in an unbounded manner, the level in which it
starts to guess the level ranking. Until this point,  may use sets of states to
deterministically track only the levels of the run \DAG, with no attempt to guess the ranks.
Second, after this point,  can restrict attention to {\em tight level rankings} -- ones in
which all the odd ranks below the maximal rank appear.  Formally, say a level ranking  with a
maximum rank  is tight when, for every odd , there exists a  such that . Let  be the subset of  that
contains only tight level rankings. The size of  is at most  \cite{FKV06}.
Including the cost of the cut-point construction, this reduces the state space of  to
.


\section{Analyzing \DAGs With Profiles}\label{Sect:Comp_Profiles}

In this section we present an alternate formulation of the slice-based complementation construction
of \kahler and Wilke \cite{KW08}. Whereas \kahler and Wilke approached the problem through
reduced split trees, we derive the slice-based construction directly from an analysis of
the run \DAG. This analysis proceeds by pruning  in two steps: the first removes edges, and the
second removes vertices.

\subsection{Profiles}
Consider a run \DAG . Let the labeling function  be
such that  if  and  otherwise. Thus,
 labels -nodes by  and all other nodes by . The \emph{profile} of a path in 
is the sequence of labels of nodes in the path. The profile of a node is then the lexicographically
maximal profile of all initial paths to that node.  Formally, let  be the lexicographic
ordering on .  The profile of a finite path
 in , written , is , and
the profile of an infinite path  is . Finally,
the profile of a node , written , is the lexicographically maximal element of . The lexicographic order of profiles induces a preorder over
nodes.

We define the sequence of preorders  over the nodes on each level of the run \DAG as
follows.  For every two nodes  and  on a level , we have that  if
, and  if . For convenience, we conflate nodes on the th level of
the run \DAG with their states when employing this preorder, and say  when . Note that  is an equivalence relation. Since the final element of a
node's profile is  iff the node is an -node, all nodes in an equivalence class must agree
on membership in . We call an equivalence class an -class when all its members are -nodes,
and a non--class when none of its members is an -node.  We now use profiles in order to remove
from  edges that are not on lexicographically maximal paths.  Let  be the subgraph of
 obtained by removing all edges  for which there is another edge  such
that .  Formally,  where .

\begin{lem}\label{Gprime_Captures_Profiles}
For every two nodes  and , if , then .
\end{lem}
\begin{proof}
Assume by way of contradiction that .  Recall that  is the
lexicographically maximal element of . Thus our
assumption entails an initial path  to  so that . Let  be
: the node on the same level of  as . Since  is a path to , it holds that
. Further, , it must be that .  By definition of
, the presence of  where  precludes the edge  from being in 
--- a contradiction.
\end{proof}

Note that while it is possible for two nodes with different profiles to share a child in ,
Lemma \ref{Gprime_Captures_Profiles} precludes this possibility in . If two nodes join in
, they must have the same profile and be in the same equivalence class.  We can thus
conflate nodes and equivalence classes, and for every edge , consider  to be the
child of .  Lemma~\ref{Gprime_Captures_Profiles} then entails that the class  can have at
most two children: the class of -nodes with profile , and the class of non--nodes with
profile . We call the first class the -child of , and the second class the
non--child of .

By using lexicographic ordering we can derive the preorder for each level  of the run \DAG
solely from the preorder for the previous level .  To determine the relation between two nodes,
we need only know the relation between the parents of those nodes, and whether the nodes are
-nodes. Formally, we have the following.

\begin{lem}\label{Lexicographic_Ordering}
For all nodes  on level , and nodes  where 
and \emph{:}
\begin{iteMize}{}
\item If , then .
\item If  and either both  and  are -nodes, or neither are -nodes,
then .
\item If  and  is an -node while  is not, then .
\end{iteMize}
\end{lem}
\begin{proof}
If , then  and, by Lemma~\ref{Gprime_Captures_Profiles}, we know that  must be smaller than , implying that .  If , we have three sub-cases. If  is an -node and
 is not, then  and . If 
both  and  are -nodes, then  and .  Finally, if neither  nor  are -nodes, then  and .
\end{proof}

We now demonstrate that by keeping only edges associated with lexicographically maximal profiles,
 
captures an accepting path from .  

\begin{lem}\label{Lexicographic_Edge_Pruning}
 has an accepting path iff  has an accepting path.
\end{lem}
\begin{proof}
In one direction, if  has an accepting path, then its superset  has the same path.

In the other direction, assume  has an accepting path. Consider the set  of accepting paths
in . We prove that there is a lexicographically maximal element .  To begin,
we construct an infinite sequence, , of subsets of  such that the elements of
 are lexicographically maximal in the first  positions.  If  contains paths starting in
an -node, then F is all elements beginning
in -nodes . Otherwise . Inductively, if  contains an element  such that 
is an -node, then F.  Otherwise
. For convenience, define the predecessor of  to be  if , and 
otherwise.  Note that since  has an accepting path,  is non-empty. Further, every set 
is not equal to its predecessor  only when there is a path in  with an -node in the th
position. In this case, that path is in . Thus every  is non-empty. 

First, we prove that there is a path .  Consider the sequence
 where  is the set of nodes that occur at position  in runs in
.  Formally, . Each node in  has a parent in
, although it may not have a child in . We can thus connect the nodes in
 to their parents, forming a sub-\DAG of . As every  is non-empty, every
 is non-empty, and this \DAG has infinitely many nodes. Since each node has at most 
children, by \konig's Lemma there is an initial path  through this \DAG, and thus through .
We now show by induction that  for every . As a base case, . Inductively,
assume  is in the predecessor  of . The set  is either , in which case , or the set F.  In this latter case, as
 consists only of -nodes, the node  must be an -node.  and . 

Second, having established that there must be an element , we prove
 is lexicographically maximal in .  Assume by way of contradiction that there exists an
accepting path  so that . Let  be the first point where 
differs from .  At this point, it must be that  is not an  node, while  is
an  node.  However,  is an accepting path that shares a profile with  up until this
point. As  is in the predecessor  of , it must also be that  is in .  By
definition,  then would be F. This would
imply , a contradiction.

Finally, we demonstrate that every edge in  occurs in . Assume by way of contradiction
that some edge  is in  but not in . This implies there is a node  on
level  such that  is in  and . Since , there is an
initial path  to .  Thus, the path  is an accepting path in
.  This path would be lexicographically larger than , contradicting the second claim above.
Hence, we conclude  is an accepting path in .
\end{proof}

In the next stage, we remove from  finite nodes. Let 
.  Note there may be
nodes that are not finite in , but are finite in .  It is not
hard to see that  may have infinitely many -nodes and still not contain a path with
infinitely many -nodes.  Indeed,  may have infinitely many paths each with finitely many
-nodes. We now show that the transition from  via  to  removes this
possibility, and the presence of infinitely many -nodes in  does imply the existence
of a path with infinitely many -nodes.

\begin{lem}\label{Lexicographic_Node_Pruning}
 has an accepting path iff  has infinitely many -nodes.
\end{lem}
\begin{proof}
If  has an accepting path, then by Lemma~\ref{Lexicographic_Edge_Pruning} the \DAG 
contains an accepting path. Every node in this path is infinite in , and thus this path is
preserved in . This path contains infinitely many -nodes, and thus 
contains infinitely many -nodes.

In the other direction, we consider the \DAG over equivalence classes induced by .
Given a node  in , recall that its equivalence class in  contains all
states  such that  and . Given two equivalence classes  and ,
recall that  is a child of  when there are ,  , and  . As
mentioned above, once we have pruned edges not in , two nodes of different 
classes cannot join. Thus this \DAG is a tree.  Further, as every node  in  is
infinite and has a child, its equivalence class must also have a child.  Thus the \DAG of
classes in  is a leafless tree. The width of this tree must monotonically
increase and is bounded by . It follows that at some level  the tree reaches a stable width. We call this
level  the \emph{stabilization level} of .

After the stabilization level, each class  has exactly one child: as noted above, 
cannot have zero children, and if  had two children the width of the tree would increase.
Therefore, we identify each equivalence class on level  of  with its unique branch of
children in , which we term its \emph{pipe}. These pipes form a
partition of nodes in  after . Every node in these pipes has an ancestor, or it would not
be in the \DAG, and has a child, or it would not be infinite and in . Therefore each
node is part of an infinite path in this pipe.  Thus, the pipe with infinitely many
-classes contains only accepting paths. These paths are accepting in , which
subsumes .
\end{proof}

In the proof above we demonstrated there is a \emph{stabilization level}  at which the number of
equivalence classes in  stabilized, and discussed the {\em pipes} of : the single
chain of descendants from each equivalence class on the stabilization level  of .

\begin{exa}
Figure~\ref{Fig:GDubPrime} displays  for the example of Figure~\ref{Fig:Automaton}.
Edges removed from  are dotted: at levels 1 and 3 where both  and  transition
to .  When both  and  transition to , they have the same profile and both edges remain.
The removed edges render all but the first -node finite in . The stabilization level is
.
\end{exa}
\vspace{-0.0in}

\begin{figure}
\centering
{
\begin{postscript}
\SmallPicture\VCDraw{\begin{VCPicture}{(-4,-12)(15,2)}
\def\level{0}\def\offset{0}
\State[p]{(0,\offset)}{p\level} \FinalState[q]{(2,\offset)}{q\level}
\ChgStateLineStyle{dotted}
\State[r]{(4,\offset)}{r\level} \State[s]{(6,\offset)}{s\level} \FinalState[t]{(8,\offset)}{t\level}
\RstStateLineStyle
\def\level{1} \def\prevlevel{0} \def\offset{-2}
\State[p]{(0,\offset)}{p\level}\State[r]{(4,\offset)}{r\level}
\ChgStateLineStyle{dotted}
\FinalState[q]{(2,\offset)}{q\level} \FinalState[t]{(8,\offset)}{t\level}
\RstStateLineStyle
\EdgeR{p\prevlevel}{p\level}{b~~~~~~~} \EdgeL{p\prevlevel}{q\level}{} 
\ChgEdgeLineStyle{dotted}\EdgeL{r\prevlevel}{r\level}{}\RstEdgeLineStyle
\EdgeL{q\prevlevel}{r\level}{} \EdgeL{r\prevlevel}{t\level}{} \EdgeL{s\prevlevel}{t\level}{}
\def\prevlevel{1} \def\level{2}\def\offset{-4}
\State[r]{(4,\offset)}{r\level} \State[p]{(0,\offset)}{p\level}
\ChgStateLineStyle{dotted}
\FinalState[q]{(2,\offset)}{q\level} \State[s]{(6,\offset)}{s\level} \FinalState[t]{(8,\offset)}{t\level}
\RstStateLineStyle
\EdgeR{p\prevlevel}{p\level}{a~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{q\prevlevel}{q\level}{}
\EdgeL{t\prevlevel}{t\level}{} \EdgeL{r\prevlevel}{s\level}{} 
\def\prevlevel{2} \def\level{3}\def\offset{-6}
\State[p]{(0,\offset)}{p\level} \State[r]{(4,\offset)}{r\level}
\ChgStateLineStyle{dotted}
\FinalState[t]{(8,\offset)}{t\level} \FinalState[q]{(2,\offset)}{q\level} 
\RstStateLineStyle
\EdgeR{p\prevlevel}{p\level}{b~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{p\prevlevel}{q\level}{}
\ChgEdgeLineStyle{dotted}\EdgeL{q\prevlevel}{r\level}{}\RstEdgeLineStyle
\EdgeL{r\prevlevel}{t\level}{} \EdgeL{s\prevlevel}{t\level}{}
\def\prevlevel{3} \def\level{4}\def\offset{-8}
\State[r]{(4,\offset)}{r\level} \State[p]{(0,\offset)}{p\level}
\ChgStateLineStyle{dotted}
\FinalState[q]{(2,\offset)}{q\level} \State[s]{(6,\offset)}{s\level} \FinalState[t]{(8,\offset)}{t\level}
\RstStateLineStyle
\EdgeR{p\prevlevel}{p\level}{a~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{q\prevlevel}{q\level}{}
\EdgeL{t\prevlevel}{t\level}{} \EdgeL{r\prevlevel}{s\level}{} 
\hide{
\def\prevlevel{4} \def\level{5}\def\offset{-10}
\State[r]{(4,\offset)}{r\level} \State[p]{(0,\offset)}{p\level}
\ChgStateLineStyle{dotted}
\FinalState[q]{(2,\offset)}{q\level} \State[s]{(6,\offset)}{s\level} \FinalState[t]{(8,\offset)}{t\level}
\RstStateLineStyle
\EdgeR{p\prevlevel}{p\level}{a~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{q\prevlevel}{q\level}{}
\EdgeL{s\prevlevel}{s\level}{} \EdgeL{t\prevlevel}{t\level}{} \EdgeL{r\prevlevel}{s\level}{} 
\def\prevlevel{5} \def\level{6}\def\offset{-12}
\State[p]{(0,\offset)}{p\level} \State[r]{(4,\offset)}{r\level}
\ChgStateLineStyle{dotted}
\FinalState[t]{(8,\offset)}{t\level} \FinalState[q]{(2,\offset)}{q\level} 
\RstStateLineStyle
\EdgeR{p\prevlevel}{p\level}{b~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{p\prevlevel}{q\level}{}
 \EdgeL{r\prevlevel}{t\level}{} \EdgeL{s\prevlevel}{t\level}{}
\ChgEdgeLineStyle{dotted}\EdgeL{q\prevlevel}{r\level}{}\RstEdgeLineStyle
}

\psline[linewidth=2pt] (-0.7,0.5)(-0.7,-9)
\psline[linewidth=2pt] (0.8,0.5)(0.8,-9)
\psline[linewidth=2pt] (1.25,0.5)(1.25,-0.3)(3.25,-1.7)(3.25,-9)
\psline[linewidth=2pt] (2.85,0.5)(2.85,-0.3)(4.85,-1.7)(4.85,-9)
\begin{boldmath}

\multirput(0.58,0.25)(0.0,-2.0){5}{\large}
\multirput(2.65,0.25)(0.0,-2.0){5}{\large}
\multirput(4.60,0.22)(0.0,-2.0){5}{\large}
\multirput(6.65,0.25)(0.0,-4.0){2}{\large}
\multirput(6.65,-7.75)(0.0,-2.0){1}{\large}
\multirput(8.65,0.25)(0.0,-2.0){5}{\large}

\rput[u](15,0){\Large }
\rput[u](15,-2){\Large }
\rput[u](15,-4){\Large }
\rput[u](15,-6){\Large }
\rput[u](15,-8){\Large }
\end{boldmath}

\end{VCPicture}}
\end{postscript}\qquad\qquad\qquad\qquad
}
\vspace{-0.5in}
\caption{The run \DAG \Gdubprime, where dotted edges were removed from \G and dotted states were removed from
\Gprime. Nodes are superscripted with their -labels. Bold lines denote the pipes of \Gdubprime. The
lexicographic order of equivalence classes for each level of \Gprime is to the right.
}\label{Fig:GDubPrime}
\end{figure}


\subsection{Complementing With Profiles}
We now complement  by constructing an NBW, , that employs
Lemma~\ref{Lexicographic_Node_Pruning} to determine if a word is in . This construction is a
reformulation of the slice-based approach of \cite{KW08} in the framework of run \DAGs\forappendix{:
see Appendix~\ref{App:Slices}}{}.  The NBW  tracks the levels of  and guesses which
nodes are finite in  and therefore do not occur in . To track , the
automaton  stores at each point in time a set  of states that occurs on each level. The
sets  are labeled with a guess of which nodes are finite and which are infinite.  States that are
guessed to be infinite, and thus correspond to nodes in , are labeled , and states
that are guessed to be finite, and thus omitted from , are labeled .  In order to
track the edges of , and thus maintain this labeling,  needs to know the
lexicographic order of nodes.  Thus  also maintains the preorder  over states on
the corresponding level of the run \DAG.  To enforce that states labeled  are indeed finite,
 employs the cut-point construction of Miyano and Hayashi \cite{MH84}, keeping an ``obligation
set'' of states currently being verified as finite.  Finally, to ensure the word is rejected, 
must enforce that there are finitely many -nodes in .  To do so,  uses a bit 
to guess the level from which no more -nodes appear in . After this point, 
-nodes must be labeled .

Before we define , we formalize {\em preordered subsets} and 
operations over them.  For a set  of states, define S to be the set of preordered subsets of .
Let  be an element in .  When considering the successors of
a state, we want to consider edges that remain in .
For every state  and , define q' \in Sr \in \rho(q',\sigma).  
Now define the {\em -successor of } as the tuple
, where for every ,  , and
:
\begin{iteMize}{}
\item If , then 
\item If  and either both  and , or both  and , then .
\item If  and one of  and , say , is in  while the other, , is not, then . 
\end{iteMize}

We now define . 
The states of  are tuples
 where:  is preordered subset of ;~
 is a labeling 
indicating which states are guessed to be finite () or
infinite ();~  is the
obligation set;~ and  is a bit indicating whether we have seen the last -node in
. 
To transition between states of , say that 
\emph{ follows
 under } when: 
\begin{enumerate}[(1)]
\item  is the -successor of . 
\item  is such that for every : 
\begin{iteMize}{}
\item If , then there exists  such that ,
\item If , then for every , it holds that .
\end{iteMize}
\item 
\item .
\end{enumerate}
We want to ensure that runs of  reach a suffix where all -nodes are finite. To this
end, given a state of  , we say that  is \emph{-free} if
for every  we have .

\begin{defi}\label{Slice_Def}
For an NBW , let  be the NBW 
, where:
\begin{iteMize}{}
\item b=1\lambdaF,
\item q,r \in Q^{in},
\item \textbf{t}\sigma, and
\item .
\end{iteMize}
\end{defi}

\cbstart
We divide runs of  into two parts. The {\em prefix} of a run is the initial sequence of
states in which  is , and the {\em suffix} is the remaining sequence states, in
which  is . A run without a suffix, where  stays  for the entire run, has no accepting
states.
\cbend

\begin{theorem}\label{Slice_Complement}
For every NBW , it holds that .
\end{theorem}
\begin{proof}
\cbstart
Consider a word  and the run \DAG . We first make the following claims
about every infinite run , where
.  For convenience, define
. 
\begin{enumerate}[(1)]

\item\label{Step:S} \textit{The states in  are precisely .}\\
We exploit this claim to conflate a state  in the th state with the node ,
and speak of states in  being in, being finite in, and being infinite in a graph . 

\item\label{Step:Preorder} \textit{The preorder  is the projection of 
onto states occurring at level .} \\This follows from Lemma~\ref{Lexicographic_Ordering}
and the definition of one state in  following another.

\item\label{Step:Transitions} \textit{For every , , it holds that  iff }\\
This follows from the definitions of  and . 

\item\label{Step:O} \textit{ is empty for infinitely many indices
   iff every state labeled  is not in }.\\ This
  follows from the cut-point construction of Miyano and
  Hayashi. \cite{MH84}.

\item\label{Step:Inf} \textit{Every state labeled  is in }.\\
This follows from the definition of transitions between states: every -labeled state must
have a -labeled child, and thus is infinite in  and in .
\end{enumerate}

\noindent We can now prove the theorem. In one direction, assume there is an accepting run . As this run is accepting, infinitely often . By \ref{Step:O} and
\ref{Step:Inf}, this implies the states in  are correctly labeled  when and only when they occur
in .  Further, for this run to be accepting we must be able to divide the run into a prefix,
and suffix as specified above. In the suffix no state in  can be
labeled , and thus no -nodes occur in  past this point. As only finitely many
-nodes can occur before this point, by Lemma~\ref{Lexicographic_Edge_Pruning}  does not have
an accepting path and .

In the other direction, assume . This implies there are finitely many -nodes in
, and thus a level  where the last -node occurs.  We construct an accepting run
, demonstrating along the way that we satisfy the requirements for
 to be in . Given , the sequence
 of preordered subsets  is uniquely defined by
.  There are many possible labelings . For every , select  so that a
state  is labeled with  when , and  when it is
not. Since every node in  has a child, by \ref{Step:Transitions}, for every 
where , there exist a  so that
.  Further, every node labeled  has only finitely many descendants, and
so for every  where  and , it holds
that .  Therefore the transition from  to  satisfies
the requirements of . The set , and given the sets  and labelings
, the sets ,  are again uniquely defined by .  Finally, we
choose  when , and  for .  Since there are no -nodes in 
past , no -node will be labeled  and all states past  will be -free. We have
satisfied the last requirement for the transitions from every  to  to be
valid, rendering this sequence a run. By \ref{Step:O}, infinitely often , including
infinitely often after , thus there are infinitely many states  where  and
, and this run is accepting.
\cbend
\end{proof} 

If , the number of preordered subsets is roughly  \cite{Var80}. As there
are  labelings, and a further  obligation sets, the state space of  is at most
.  The slice-based automaton obtained in \cite{KW08} coincides with , modulo the
details of labeling states and the cut-point construction (see
Appendix~\ref{App:Slices}). Whereas the correctness proof in \cite{KW08} is given by means of
reduced split trees, here we proceed directly on the run \DAG.

\section{Retrospection}\label{Slices_To_Ranks}

Consider an NBW . So far, we presented two complementation constructions for , generating
the NBWs  and . In this section we present a third
construction, generating an NBW that combines the benefits of the two constructions above.  Both
constructions refer to the run \DAG of .  In the rank-based approach applied in , the
ranks assigned to a node bound the visits in accepting states yet to come. Thus, the ranks refer to
the future, making  inherently nondeterministic.  On the other hand, the NBW   refers
to both the past, using profiles to prune edges from , as well as to the future, by keeping in
 only nodes that are infinite in . Guessing which nodes are infinite and
labeling them  inherently introduces nondeterminism into the automaton.

Our first goal in the combined construction is to reduce this latter nondeterminism.  Recall that a
labeling is -free if all the states in  are labeled .  Observe that the fewer labels of
 (finite nodes) we have, the more difficult it is for a labeling to be -free and,
consequently, the more difficult it is for a run of  to proceed to the -free suffix in
which .  It is therefore safe for  to underestimate which nodes to label , as long
as the requirement to reach an -free suffix is maintained.  We use this observation in order to
introduce a purely retrospective construction.

For a run \DAG , say that a level  is an \emph{-finite level} of  when all -nodes
{\em after} level  (i.e. on a level  where ) are finite in .  
By Lemma~\ref{Lexicographic_Node_Pruning},  is rejecting iff there is a level after which
 has no -nodes. As finite nodes in  are removed from , we
have:

\begin{corollary}\label{Rejecting_iff_k}
A run \DAG  is rejecting iff it has an -finite level.
\end{corollary}

\subsection{Retrospective Labeling}
The labeling function  used in the construction of  labels nodes by ,
with  standing for ``finite'' and  standing for ``infinite''. In this section we
introduce a variant of  that again maps nodes to  except that now 
stands for ``unrestricted'', allowing us to underestimate which nodes to label
. To capture the relaxed requirements on labelings, say that a labeling  is
\emph{legal} when every -labeled node is finite in .  This enables the automaton to
track the labeling and its effect on -nodes only after it guesses that an -finite level 
has been reached: all nodes {\em at or before} level  (i.e. on a level  where ) are
unrestricted, whereas -nodes after level  and their descendants are required to be finite. The only nondeterminism
in the automaton lies in guessing when the -finite level has been reached.  This reduces the
branching degree of the automaton to 2, and renders it deterministic in the limit. 

The suggested new labeling is parametrized by the -finite level .  The labeling 
is defined inductively over the levels of .  Let  be the set of nodes on level  of .
For , the function  is defined as follows:
\begin{iteMize}{}
\item If , then for every  we define .
\item If , then for every :
\begin{iteMize}{}
\item If  is an -node, then .
\item Otherwise, , for a node  where . 
\end{iteMize}
\end{iteMize}
For  to be well defined when  and  is not an -node, we need to show that
 does not depend on the choice of the node  where  holds. By
Lemma~\ref{Gprime_Captures_Profiles}, all parents of a node in  belong to the same
equivalence class. Therefore, it suffices to prove that all nodes in the same class share a label:
for all nodes  and , if  then .  The
proof proceeds by an induction on . 
Consider two nodes  and  on level  where . As a base case, if , then  and
 are labeled .  For , if  is an -node, then  is also an -node and
.  Finally, if  and  are both non--nodes, recall that all
parents of  are in the same equivalence class . As ,
Lemma~\ref{Gprime_Captures_Profiles} implies that all parents of  are also in . By the
induction hypothesis, all nodes in  share a label, and thus .

\begin{lem}\label{Slices_Make_Sense}
For a run \DAG  and , the labeling  is legal iff  is an -finite
level for .
\end{lem}
\begin{proof}
If  is legal, then every -labeled node is finite in .  Every -node
after level  (i.e. on a level  where ) is labeled , and thus  is an -finite level for .  If  is
not legal, then there is a -labeled node  that is infinite in . Every
ancestor of  is also infinite.  Let  be the earliest ancestor of  
(possibly  itself) so
that . Observe that only nodes after level  can be -labeled, and so
 is on a level . It must be that  is an -node: otherwise it would inherit its
parents' label, and by assumption the parents of  are -labeled. Thus,  is an
-node after level  that is infinite in , and  is not an -finite level for
.
\end{proof}

\begin{corollary}\label{Slices_Complement}
A run \DAG  is rejecting iff, for some , the labeling  is legal.
\end{corollary}

\subsection{From Labelings to Rankings}
In this section we derive an odd ranking for  from the function , thus unifying the
retrospective analysis behind  with the rank-based analysis of \cite{KV01c}.  Consider
again the \DAG  and 
the
function .  Recall that every equivalence class  has at
most two child equivalence classes, one -class and one non--class.  After the -finite level
, only non--classes can be labeled . Hence, after level , every -labeled
equivalence class  can only have a one child that is -labeled.  For every 
class  on level , we consider this possibly infinite sequence of -labeled
non--children. The odd ranking we are going to define, termed the {\em retrospective ranking},
gives these sequences of -labeled children odd ranks. The -labeled classes, which
lie between these sequences of -labeled classes, are assigned even ranks. The ranks increase
in inverse lexicographic order, i.e. the maximal -labeled class in a level is given rank 1. As
with , the retrospective ranking is parametrized by . The primary insight that allows
this ranking is that there is no need to distinguish between two adjacent -labeled classes.
Formally, we have the following.

\begin{defi}[-retrospective ranking]\label{kret_ranks}
Consider a run \DAG , , and the labeling .  Let
. For a node  on level  of , let  be the number of
-labeled classes lexicographically larger than ; .  The \emph{-retrospective ranking\/} of  is the function  defined for every node  on level  as follows.

\end{defi}

Note that  is tight. As defined in Section \ref{Sect:Tight}, a ranking is
tight if there exists an  such that, for every level , all odd ranks below  appear on level . For  this level is , after which each
-labeled class is given the odd rank greater by two than the rank of the next lexicographically larger
-labeled class. 


\begin{lem}\label{Ranking_Respects_Preorder} For every , the following hold:
\begin{enumerate}[\em(1)]
\item If  then .
\item If , then .
\end{enumerate}
\end{lem}
\begin{proof}
As both claims are trivial when  is at or before level , assume  is on level . To prove
the first claim, note that : every class, -labeled
or not, that is larger than  must also be larger than . If , then
(1) follows immediately.  Otherwise , which implies that
: otherwise  would be a -labeled equivalence class larger than ,
but not larger than itself. Thus , and  is at least .

As a step towards proving the second claim, we show that . Consider
every -labeled class  where . The class  must have a
-labeled parent .  Since , the contrapositive of
Lemma \ref{Lexicographic_Ordering}, part 1, entails that .  By the definition of ,
the class
 can only have one -labeled child class: .  We have thus established
that for every -labeled class larger than , there is a unique -labeled class larger
than , and can conclude that .  We now show by contradiction that
. For , it must be that
, that  = , and that . In this case,  and .  Since a
-labeled node cannot have a -labeled child in , this is impossible.
\end{proof}

When  is an -finite level of , the -retrospective ranking is an -bounded odd ranking.

\begin{lem}\label{Slices_Provide_Ranking}
For a run \DAG  and , the function  is a ranking bounded by .
Further, if the labeling  is legal then  is an odd ranking.
\end{lem}
\begin{proof}
There are three requirements for  to be a ranking bounded by :
\begin{enumerate}[(1)]
\item \textit{Every -node must have an even rank.} At or before 
level ,
every node has rank ,
which is even.  After  only -labeled nodes are given odd ranks, and every -node is
labeled .

\item \textit{For every , it must hold that .} 
If  is at or before level , then it has the maximal rank of . If  is after level , we
consider two cases: edges in , and edges in .  For edges in , this follows
from Lemma \ref{Ranking_Respects_Preorder} (2). For edges , we know there
exists a  where  and . By Lemma
\ref{Ranking_Respects_Preorder}, .

\item \textit{The rank is bounded by .} No -node can be -labeled. Thus the maximum
number of -labeled classes on every level is .  The largest possible
rank is given to a node smaller than all -labeled classes, which must be
be a -node and -labeled.  Thus, this node is given a rank of at most .\smallskip
\end{enumerate}

\noindent It remains to show that if  is legal, then  is an odd ranking.  Consider an
infinite path  in .  We demonstrate that for every  
such that  is an even rank , there exists  such that . 
Since
a path cannot increase in rank, this implies . To do so, define the
sequence , of sets of nodes inductively as follows.  Let .  For every , let .  As  is even only when , if  is
legal then every node given an even rank (such as ) must be finite in . Therefore every
element of  is finite in , and thus at some , the set  is empty. Since
 is empty, to establish that , it is sufficient to prove  that for
every , if , then .

To show that  entails , we prove a stronger claim: for every  and  on level , if  and , then .  We
proceed by induction over .  For the base case of , this follows from the definition
of . For the inductive step, take a 
node
 on level  where  and .  We consider two cases. If  then the path 
from  to  entails that , and this case of the subclaim
follows from Lemma \ref{Ranking_Respects_Preorder} (1).  Otherwise, it holds that , and thus . Let  and  be nodes on level  so that
 and .  As , the contrapositive of Lemma
\ref{Lexicographic_Ordering}, part 1, entails that . Further, since  and , we know .  By transitivity we can thus
conclude that , which along with Lemma \ref{Ranking_Respects_Preorder} (1) entails
. As , Lemma \ref{Ranking_Respects_Preorder} (2)
entails that . Thus , and by the inductive
hypothesis . As  holds, by definition , and our subclaim is proven.
\end{proof}




The ranking of Definition~\ref{kret_ranks} is termed {\em retrospective} as it relies on the relative
lexicographic order of equivalence classes; this order is determined purely by the history of
nodes in the run \DAG, not by looking forward to see which descendants are infinite or -free in
some subgraph of .

\begin{exa}
Figure~\ref{Fig:GPrime} displays  and the 0-retrospective ranking of our running example.
In the prospective ranking (Figure~\ref{Fig:GDubPrime}), the nodes for state  on levels 
and  are given rank , like other -nodes. In the absence of a path forcing this rank, their
retrospective rank is . 
\end{exa}

\begin{figure}
\centering
{
\begin{postscript}
\SmallPicture\VCDraw{\begin{VCPicture}{(-1,-12)(8,2)}
\def\level{0}\def\offset{0}
\State[p]{(0,\offset)}{p\level} \FinalState[q]{(2,\offset)}{q\level}
\State[r]{(4,\offset)}{r\level}
\State[s]{(6,\offset)}{s\level} \FinalState[t]{(8,\offset)}{t\level}
\def\level{1} \def\prevlevel{0} \def\offset{-2}
\State[p]{(0,\offset)}{p\level}\State[r]{(4,\offset)}{r\level}
\FinalState[q]{(2,\offset)}{q\level} \FinalState[t]{(8,\offset)}{t\level}
\EdgeR{p\prevlevel}{p\level}{b~~~~~~~}
\ChgEdgeLineStyle{dotted}\EdgeL{r\prevlevel}{r\level}{}\RstEdgeLineStyle
 \EdgeL{p\prevlevel}{q\level}{}
\EdgeL{q\prevlevel}{r\level}{} \EdgeL{r\prevlevel}{t\level}{} \EdgeL{s\prevlevel}{t\level}{}
\def\prevlevel{1} \def\level{2}\def\offset{-4}
\State[r]{(4,\offset)}{r\level} \State[p]{(0,\offset)}{p\level}
\FinalState[q]{(2,\offset)}{q\level} \State[s]{(6,\offset)}{s\level} \FinalState[t]{(8,\offset)}{t\level}
\EdgeR{p\prevlevel}{p\level}{a~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{q\prevlevel}{q\level}{}
\EdgeL{t\prevlevel}{t\level}{} \EdgeL{r\prevlevel}{s\level}{} 
\def\prevlevel{2} \def\level{3}\def\offset{-6}
\State[p]{(0,\offset)}{p\level} \State[r]{(4,\offset)}{r\level}
\FinalState[t]{(8,\offset)}{t\level} \FinalState[q]{(2,\offset)}{q\level} 
\EdgeR{p\prevlevel}{p\level}{b~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{p\prevlevel}{q\level}{}
\ChgEdgeLineStyle{dotted}\EdgeL{q\prevlevel}{r\level}{}\RstEdgeLineStyle
\EdgeL{r\prevlevel}{t\level}{} \EdgeL{s\prevlevel}{t\level}{}
\def\prevlevel{3} \def\level{4}\def\offset{-8}
\State[r]{(4,\offset)}{r\level} \State[p]{(0,\offset)}{p\level}
\FinalState[q]{(2,\offset)}{q\level} \State[s]{(6,\offset)}{s\level} \FinalState[t]{(8,\offset)}{t\level}
\EdgeR{p\prevlevel}{p\level}{a~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{q\prevlevel}{q\level}{}
\EdgeL{t\prevlevel}{t\level}{} \EdgeL{r\prevlevel}{s\level}{} 
\hide{
\def\prevlevel{4} \def\level{5}\def\offset{-10}
\State[r]{(4,\offset)}{r\level} \State[p]{(0,\offset)}{p\level}
\FinalState[q]{(2,\offset)}{q\level} \State[s]{(6,\offset)}{s\level} \FinalState[t]{(8,\offset)}{t\level}
\EdgeR{p\prevlevel}{p\level}{a~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{q\prevlevel}{q\level}{}
\EdgeL{s\prevlevel}{s\level}{} \EdgeL{t\prevlevel}{t\level}{} \EdgeL{r\prevlevel}{s\level}{} 
\def\prevlevel{5} \def\level{6}\def\offset{-12}
\State[p]{(0,\offset)}{p\level} \State[r]{(4,\offset)}{r\level}
\FinalState[t]{(8,\offset)}{t\level} \FinalState[q]{(2,\offset)}{q\level} 
\EdgeR{p\prevlevel}{p\level}{b~~~~~~~} \EdgeL{r\prevlevel}{r\level}{} \EdgeL{p\prevlevel}{q\level}{}
 \EdgeL{r\prevlevel}{t\level}{} \EdgeL{s\prevlevel}{t\level}{}
\ChgEdgeLineStyle{dotted}\EdgeL{q\prevlevel}{r\level}{}\RstEdgeLineStyle
}

\psline[linewidth=2pt] (-0.60,-1.7)(-0.60,-9)
\psline[linewidth=2pt] (0.85,-1.7)(0.85,-9)
\psline[linewidth=2pt] (3.35,-1.7)(3.35,-9)
\psline[linewidth=2pt] (6.84,-1.7)(6.82,-9)
\begin{boldmath}
\multirput(0.60,0.25)(2.00,0.0){5}{\large}
\multirput(0.60,-1.75)(0.0,-2.0){4}{\large}
\multirput(2.65,-1.60)(0.0,-2.0){4}{\large}
\multirput(4.60,-1.75)(0.0,-2.0){4}{\large}
\multirput(6.60,-3.75)(0.0,-4.0){2}{\large}
\multirput(8.65,-1.60)(0.0,-2.0){4}{\large}

\multirput(0.63,-0.25)(2.03,0.0){2}{\large} \multirput(6.63,-0.25)(2.03,0.0){2}{\large}
\multirput(4.66,-0.13)(2.03,0.0){1}{\large}
\multirput(0.60,-2.25)(0.0,-2.0){4}{\large}
\multirput(2.65,-2.25)(0.0,-2.0){4}{\large}
\multirput(4.60,-2.25)(0.0,-4.0){2}{\large} \multirput(4.60,-8.25)(0.0,-4.0){1}{\large}
\multirput(4.65,-4.12)(0.0,-6.0){1}{\large}
\multirput(6.60,-4.25)(0.0,-2.0){1}{\large} \multirput(6.60,-8.25)(0.0,-2.0){1}{\large}\multirput(8.65,-2.25)(0.0,-2.0){2}{\large} \multirput(8.65,-6.25)(0.0,-2.0){2}{\large}

\rput[u](15,0){\Large }
\rput[u](15,-2){\Large }
\rput[u](15,-4){\Large }
\rput[u](15,-6){\Large }
\rput[u](15,-8){\Large }


\end{boldmath}

\end{VCPicture}}
\end{postscript}\qquad\qquad\qquad\qquad\qquad\qquad\qquad
}
\vspace{-0.5in}
\caption{The run \DAG \Gprime, where  is an -finite level.  The labels of  and
ranks in  are displayed as superscripts and subscripts, respectively.  The bold lines
display the sequences of -labeled classes in .  The lexicographic order of states is
repeated on the right.  }\label{Fig:GPrime}
\end{figure}


We are now ready to define a new construction, generating an NBW , which combines the benefits
of the previous two constructions.  The automaton  guesses the -finite level , and uses
level rankings to check if the -retrospective ranking is an odd ranking.  We partition the
operation of  into two stages. Until the level , the NBW  is in the first stage,
where it deterministically tracks preordered subsets.  After level , the NBW  moves to the
second stage, where it tracks ranks. This stage is also deterministic.  Consequently, the only
nondeterminism in  is indeed the guess of . Before defining , we need some
definitions and notations. 

\hide{
Lemma~\ref{Slices_Provide_Ranking} gives us an alternative odd ranking to the one of \cite{KV01c}.
We now provide an NBW that uses level rankings to guess this retrospective ranking.  In comparison
to the slice-based construction in Definition \ref{Slice_Def}, employing level rankings gives us a
tighter bound and affords further improvements, discussed later. In comparison to the rank-based
construction in Definition \ref{KVDef}, this automaton needs make only a single guess on each
accepting run: what is the -finite level .  Before and after this guess we proceed
deterministically. Before , our automaton tracks preordered subsets.  At level  our automaton
moves to ranks, and these ranks proceed stably. We thus obtain an automaton with a linear-sized
transition relation. We now introduce the machinery to define the automaton.
}

Recall that  denotes the set of preordered subsets of , and  the set of tight level
rankings bounded by .  We distinguish between three types of transitions of : transitions
within the first stage, transitions from the first stage to the second, and transitions within the
second stage.  The first type of transition is similar to the one taken in , by means of the
-successor relation between preordered subsets. Below we explain in detail the other two
types of transitions.
Recall that in the retrospective ranking , each class in 
labeled  by  is given a unique odd rank. Thus the rank of a node  depends on the
number of -labeled classes larger than it, denoted .

We begin with transitions where  moves between the stages: from a preordered subset
 to a level ranking.  On level , a node is labeled  iff it is a
non--node.  Thus for every , let
\mid be the number of non--classes
larger than . We now define . Let
 be the tight level ranking  where for every : 


We now turn to transitions within the second stage, between level rankings.  The rank of a node 
is inherited from its predecessor  in . However,  may label a finite class . If a
-labeled class larger than  has no children, then . In this
case the rank of  decreases.  Given a level ranking , for every  where , let  be the
number of odd ranks in the range of  lower than . We define the function . Let  be  the tight level ranking  where for every : 
\hide{if , then ; if , then ; and if ,
then .}
{

}
Note that if  is tight, then , and that while  may merge
two even ranks, it cannot merge two odd ranks.

For a level ranking , a letter , and , let
 be the predecessors of 
given a non- rank by . The lowest ranked element in this set corresponds to the
predecessor in  with the maximal profile. With two exceptions,  will inherit this lowest rank. 
First, \tighten might shift the rank down. Second, if  is in , it cannot be given
an odd rank. For , let  be:  when  is even; and  when
 is odd.  Define the \emph{-successor of } to be  where for every :



\begin{defi}\label{Slice_Rank}
For an NBW , let  be the NBW\\
, where
\begin{iteMize}{}
\item  where  is such that for all , .
\item ,
where  is the -successor of .
\item \begin{tabbing}
 
           w\=here  is the -successor of \\
           \>and 
\end{tabbing}\vspace{6 pt}
\end{iteMize}
\end{defi}

\noindent The proof of Theorem~\ref{SR_Complement} is based on Lemmas~\ref{Odd_Ranking_Rejecting} and
\ref{Slices_Provide_Ranking} and Corollary~\ref{Slices_Complement}.

\begin{theorem}\label{SR_Complement}
For every NBW , it holds that .
\end{theorem}
\begin{proof}
\cbstart
Consider a word  and the run \DAG . We first make the following claims
about every infinite run
.
For , define .

\begin{enumerate}[(1)]

\item\label{Step:psS} \textit{The states in  are precisely .}\\
This follows by the definitions of -successors of preordered subsets and 
-successors of level rankings.

\item\label{Step:pPreorder} \textit{The preorder  is the projection of 
onto states occurring at level .} \\
This follows from Lemma~\ref{Lexicographic_Ordering} and the definition of -successors. 

\item\label{Step:pTransitions} \textit{For every , state , and , it
holds that  iff }\\
This follows from the definitions of  and . 

\item\label{Step:sTransitions} \textit{For every  and , if , then .}

\item\label{Step:sOddTight} \textit{For every  and , if  is
odd and , then .}\\
This and \ref{Step:sTransitions} are proven below.

\item\label{Step:OddBottom} \textit{For every  and , it holds that  is
even iff . }\\
This follows from the definition of , which assigns  to -nodes and their
descendants in , and , which assigns even ranks to states in .  By
\ref{Step:sTransitions}, the parent of a node in  will be the parent with the lowest rank.
Thus the descendants of -nodes in  will inherit the even
rank of their parent.\vspace{6 pt}
\end{enumerate}

\noindent We simultaneously prove \ref{Step:sTransitions} and \ref{Step:sOddTight} by induction.  As a base
case, both hold from the definition of . As the inductive step, assume both hold for level
.
To prove step~\ref{Step:sTransitions}, take two states  where .  Each state has a parent in , i.e. a  and  so that  and
. By the inductive hypothesis, this implies 
 and .  We analyze two cases. When , by the inductive hypothesis
we have .  Since  and , by
Lemma~\ref{Gprime_Captures_Profiles} this implies .  Alternately,
when , then for  to hold, it must be that  is
odd, , and . Since  is odd, by the inductive hypothesis we
have that .  By Lemma~\ref{Gprime_Captures_Profiles} we then have
.

To prove step~\ref{Step:sOddTight}, consider when  is odd and . This implies that . Thus in order for 
 to hold,  must hold. By the inductive hypothesis, this
implies . Before the  function reduces ranks, since 
, and  is odd, it must be that .
The \tighten function can shift  down more than  only when an odd rank
between  and  becomes empty. Since this odd rank must be two greater than
, reducing  by 2 cannot change that .  We now proceed with the proof of Theorem~\ref{SR_Complement}. 

In one direction, assume the run
  is accepting.  We construct
a ranking  of  as follows. For all nodes  on level , . For all nodes
 where , .  We note that each state is given at most the
minimum rank of all its parents, and that no state in  is given an odd rank, thus  is in fact
a ranking. That  is an odd ranking follows from the cut-point construction.

In the other direction, assume  is a rejecting run \DAG. By Lemma~\ref{Slices_Provide_Ranking}
there exists a  so that  is an odd ranking. We construct a run
, which is uniquely defined
by the transition relation of Definition~\ref{Slice_Rank}. Further, the transition relation of
Definition~\ref{Slice_Rank} is total, so this run is infinite. To demonstrate that this run is
accepting, we will prove below that for every  and , it holds that .  Since  is an odd ranking and the cut-point construction is identical
to that of Definition~\ref{KVDef}, this is sufficient to show the run is accepting.

Recall that if , then , and otherwise
. We can thus use \ref{Step:OddBottom} to simplify our claim. 
It suffices to show that for every  and , we have 
.  We proceed by induction over .  As the
base case, consider a node . Recall that . By
the definition of , a node on level  is labeled  only when it is an -node.
All other nodes inherit the label of their parents, and every node on level  is -labeled.
From \ref{Step:pPreorder}, we then have that 
,
which is the definition of .

Inductively, assume the claim holds for every . We show for every , it
holds that .
Let  be the parent of  in
, i.e. .  Take the set .  of
-labeled equivalence classes greater than , By the inductive hypothesis, 
.  By the definition of , each 
 has a unique odd rank assigned to each of its elements.  By \ref{Step:sOddTight}, for each 
this odd rank is smaller than . Consider the subset of 
given by
\top.  Define
 to be the complementary set: pipes that die on level . By
\ref{Step:sOddTight}, before the  operation is applied, every element of  has a
corresponding odd rank that is unoccupied on level .  Since  is clearly not in an element of
, this odd rank must be less than .  Thus the final rank
assigned to , after , is either
 or .  In both cases 
.  By the inductive hypothesis this is
equivalent to .  By the definition of  and
, .  By Lemma~\ref{Gprime_Captures_Profiles}, every
-labeled child of a class in  is lexicographically larger than . As every
-labeled child must have a unique parent in , we conclude that
.
\cbend
\end{proof}

\noindent {\bf Analysis:} Like the tight-ranking construction in Section \ref{Sect:Tight}, the
automaton  operates in two stages. In both, the second stage is the set of tight level
rankings and obligation sets. The tight-ranking construction uses
sets of states in the first stage, and is bounded by the size of the second stage: 
\cite{FKV06}.  The automaton  replaces the first stage with preordered subsets.
As the number of preordered subsets is  \cite{Var80}, the
size of  remains bounded by . This can be improved to : see
Section~\ref{App:Variants} and \cite{Sch09}. 
Further,  has a very restricted transition relation: states in the first stage only
guess whether to remain in the first stage or move to the second, and have nondeterminism of
degree 2. States in the second stage are deterministic.  Thus the transition relation is linear in
the number of states and size of the alphabet, and  is deterministic in the limit.

\section{Variations on }\label{App:Variants}
\cbstart

In this section we present two variations of : one based on Schewe's variant of the
rank-based construction that achieves a tighter bound; and one that is amenable to Tabakov and
Vardi's symbolic implementation of the rank-based construction.
Schewe's construction alters the cut-point of the rank-based construction to check only one even
rank at a time. Doing so drastically reduces the size of the cut-point: intuitively, we can avoid
carrying the obligation set explicitly. Instead we could carry the current rank  we are checking,
and add to the domain of our ranking function a single extra symbol  that indicates the state is
currently being checked, and thus is of rank .  For an analysis of the resulting state space,
please see \cite{Sch09}. For clarity , we do not remove the obligation set from the construction.
Instead, states in this variant of the automaton carry with them the index , and in a state
, it holds that . For a level ranking , let
 be the largest rank in . Note that , for a tight ranking, is always
odd.

\begin{defi}\label{Stable_Rank_Schewe}
For an NBW , let  be the NBW\\
, where
\begin{iteMize}{}
\item ,
where  is the -successor of .
\item \begin{tabbing}
 \=where\\
           \> is the -successor of \\
           \>\\
           \>and 
\end{tabbing}
\item 
\end{iteMize}
\end{defi}

\begin{theorem}\label{Schewe_Complement}
For every NBW , it holds that .
\end{theorem}
\begin{proof}
Given a word , we relate the runs of  and . As both
automata are comprised of two internally deterministic stages, with a
nondeterministic transition, each index  defines a unique run for each
automaton.  As the first stage of both automata are identical, and the second
stage is deterministic, given a fixed  let 

be the run of  on  that moves to the second stage on the th transition, and let
the corresponding run of  be

We show that  is accepting iff  is accepting, or more precisely that
 is rejecting iff  is rejecting.  First, we note that
the level rankings  and  in both automata are
defined by  and the -successor relation, and thus for every , it holds . 

In one direction, assume that  is rejecting.  This implies there
is some  so that for every ,  is non-empty. In turn,
this implies that there is a sequence  of states so that,
for every , we have that , that
, and that . If there is
no  where , then we have that  is rejecting.
Alternately, if there is such a , then , and for
every  we have . Again, this implies  is
rejecting.

In the other direction, assume that  is rejecting. This implies there is some  so that for
every  the set  is non-empty. In turn, this implies that there is an
even rank  and sequence  of states so that, for every
, we have that , that , and
that . We now consider the indexes 
in . If there is some  where , then for every , it will hold that , and  will be rejecting.
Alternately, if there is no  where , then it must be that the
indexes  stops cycling through the even ranks. This implies the
obligation set stops emptying, and therefore that  must be rejecting.
\end{proof}

To symbolically encode a deterministic-in-the-limit automaton, we avoid storing the preorders.  To
encode the preorder in a BDD as a relation would require a quadratic number of variables, increasing
the size unacceptably. Alternately, we could associate each state with its index in the preorder.
Unfortunately, calculating the index of each state in the succeeding preorder would require a global
compacting step, to remove indices that had become empty. To handle this difficulty, we simply store
only the subset in the first stage, and transition to an arbitrary level ranking when we move to the
second stage. This maintains determinism in the limit, and cannot result in false accepting run: we
can always construct an odd ranking from the sequence of level rankings. The construction and a
small example encoding are provided below.

\begin{defi}\label{Symbolic_DetLim}
For an NBW , let  be the NBW\\
, where
\begin{iteMize}{}
\item .
\item 
\end{iteMize}
\end{defi}

\begin{theorem}\label{Symb_Complement}
For every NBW , it holds that .
\end{theorem}
\begin{proof}
In one direction, assume . This implies , and thus there exists an
accepting run

of  on . We show that 
is an accepting run of  on . We note that in the second stage transitions and
accepting states in  are identical to . Thus to show that this is an accepting run
, we only need show that the run is valid from  to ,

By definition,  is the initial state of . For every , it holds that . Finally, consider the transition
from  to . Let  be
the -successor of .  By definition, . 
By the transition relation of ,  we have
 and .  By the definition of
, for every  it holds that  iff .
Thus 
, and
 is an accepting run of
 on . 

In the other direction,  if , there is an accepting run
  of  on .
From this run we construct an odd ranking of , which implies .  Define
the ranking function  so that for every : if  then
; and if  then
.  As demonstrated in the proof of Theorem \ref{SR_Complement}, the
definition of -successors and  implies that when , it holds that . Similarly, by the definition of -successors no path in  can increase in rank under
. We conclude that  is a valid ranking function.

To demonstrate that  is an odd ranking, assume by way of
contradiction that there is a path  in 
that gets trapped in an even rank.  Let  be the point at which this path
gets trapped, or , whichever is later. If there is no  such that
, then there is no accepting state after , and the run
would not be accepting. If there is such a , then  would contain
, as  is even. At every point , the
obligation set will contain , and thus there will be no accepting
state after , and the run would not be accepting.  However, we have that
the run is accepting as a premise. Therefore no path in  gets trapped in
an even rank,  is an odd ranking, and by Lemma \ref{Odd_Ranking_Rejecting} .
\end{proof}


As an example, Figure \ref{Fig:SMV_Encoding} is the SMV encoding of the complement of a two-state automaton.


\fvset{formatcom=\scriptsize}
{
\begin{SaveVerbatim}{SMVExample}
typedef STATE 0..1;  /* Size for complemented automaton: 2, maximum allowed rank = 2*/
module main() { 
 letter: {a,b};                   /* The transition letter */
 rank: array STATE of 0..3;       /* The value 3 represents bottom */
 phase : 0..1;                    /* The phase of the automaton, ranks 2 or 3 in phase 0*/
 subset: array STATE of boolean;  /* The obligation set vector */
 init(rank) := [2,2,2,2];         /* 2 to initial states, 3 to others */
 init(subset) := [1,1,1,1];       /* initially rejecting */
 init(phase) := 0;
 next(phase) := {i : i=0..1, i >= phase}; 

 /* Define the rank of states in the next time step. Cases fall through. */
 /* state 0 has transition from 0 on a and b */
 next(rank[0]) := case {
     rank[0]=3 : 3;
     next(phase)=0 : 2; 
     phase=0 & next(phase)=1 : {i : i=0..2, i <= rank[0]};
     phase=1 : rank[0];
 };

 /* 1 has transition from 1 on a and from 0 on b. 1 is accepting */
 next(rank[1]) := case {
    letter=a & rank[1]=3 : 3;
    letter=a & next(phase)=0 : 2;
    letter=a & phase=0 & next(phase)=1 : {i : i=0..2, i <= rank[1] & i in {0,2}};
    letter=a & phase=1 : {i : i=0..2, i in {rank[1], rank[1]-1} & i in {0,2}};
    letter=b & rank[0]=3 : 3;
    letter=b & next(phase)=0 : 2;
    letter=b & phase=0 & next(phase)=1 : {i : i=0..2, i <= rank[0] & i in {0,2}};
    letter=b & phase=1 : {i : i=0..2, i in {rank[0], rank[0]-1} & i in {0,2}};
 };

 
 /* Defining the transitions of the P-set */
 if (next(phase)=0)  {
     forall (i in STATE) next(subset[i]) := 1;
 } else {
   if (subset=[0,0,0,0]) { /* The P-set is empty */
     forall (i in STATE) next(subset[i]) := next(rank[i]) in {0,2};
   } else { /* The P-set is non-empty */
     if (letter=a) {
       next(subset[0]) := (subset[0]) & next(rank[0]) in {0,2};
       next(subset[1]) := (subset[1]) & next(rank[1]) in {0,2};
     } else { /* letter=b */
       next(subset[0]) := (subset[0]) & next(rank[0]) in {0,2};
       next(subset[1]) := (subset[0]) & next(rank[1]) in {0,2};
 }}} 
SPEC 0;
 FAIRNESS subset=[0,0,0,0];
}
\end{SaveVerbatim}
}


\begin{figure}[htbp]
	\fbox{
		\begin{minipage}{\textwidth}
			\BUseVerbatim{SMVExample}
		\end{minipage}
	}
			\caption{The SMV encoding of the , for the two-state
automaton consisting of states  and  of Figure \ref{Fig:Automaton}.}
			\label{Fig:SMV_Encoding}
\end{figure}

\cbend

\section{Discussion}

We have unified the slice-based and rank-based approaches by phrasing the former in the language of
run \DAGs. This enables us to define and exploit a retrospective ranking, providing a
deterministic-in-the-limit complementation construction that does not employ determinization.
Experiments show that the more deterministic automata are, the better they perform in practice
\cite{ST03}. By avoiding determinization, we reduce the cost of such a construction from 
to  \cite{Pit06}.

In addition, our transition generates a transition relation that is linear in the number of states
and size of the alphabet. Schewe demonstrated how to achieve a similar linear bound on the
transition relation, but the resulting relation is larger and is not deterministic in the limit
\cite{Sch09}.

As shown in Section~\ref{App:Variants}, the use of level rankings affords several improvements from
existing research on the rank-based approach. First, the cut-point construction of Miyano and
Hayashi \cite{MH84} can be improved. Schewe's construction only checks one even rank at a time,
reducing the size of the state space to , only an  factor from the lower bound
\cite{Sch09}. As Schewe's approach does not alter the progression of the level rankings, it can be
applied directly to the second stage of Definition~\ref{Slice_Rank}.  The resulting construction
inherits the asymptotic state-space complexity of \cite{Sch09}. Second, symbolically encoding a
preorder is complicated.  In contrast, ranks are easily encoded, and the transition between ranks is
nearly trivial to implement in SMV \cite{TV07}.  By changing the states in first stage of 
from preordered subsets to simple subsets, and guessing the appropriate transition to the second
stage, we obtain a symbolic representation while maintaining determinism in the limit.  This
approach sacrifices the linear-sized transition relation, but this is less important in a symbolic
encoding.  Finally, although not addressed in Section~\ref{App:Variants}, the subsumption relations
of Doyen and Raskin \cite{DR09} could be applied to the second stage of 
Definition~\ref{Slice_Rank}, while it is unclear if it could be applied at all to the slice-based
construction. 

From a broader perspective, we find it very interesting that the prospective and retrospective
approaches are so strongly related. Odd rankings seem to be inherently ``prospective,'' depending on
the descendants of nodes in the run \DAG. By investigating the slice-based approach, we are able to
pinpoint the dependency on the future to a single component: the -free level. This suggests it
may be possible to use odd rankings for determinization, automata with other accepting conditions,
and automata on infinite trees.

\bibliographystyle{alpha}
\bibliography{ok,cav,sfogarty}

\newpage
\appendix

\section{Slices}\label{App:Slices}

The paper of \kahler et al. introduces the notion of the split tree, reduced
split tree, and skeleton of an automaton  and word 
 Trees are represented as
prefix-closed non-empty subsets of .  In a tree , a node 
is called the left child of , and  the right child of . The root is
. A node  is said to be on level  when . For a set
, an -labeled tree is a pair  where  is a tree and  is a label function. By abuse of notation, for an -labeled tree
 and vertex , say  when , and let
. For two nodes  and , say that  when
 and  is to the right of, i.e. lexicographically larger
than, .

The \emph{split tree}, written , is the -labeled tree defined
inductively as follows\footnote{Compared to \cite{KW08}, these definitions 
reverse the left and right children.  This was done to match 
the paper.}.  As a base case,  and
.  Inductively, given a node  on level , let
.  If  then  and .  Similarly, if , then  and .  As argued in \cite{KW08}, branches in  correspond to runs of 
on .  We gloss over this discussion and simply state that  iff
 has a branch that goes right infinitely often. 
The split tree is analogous to . Each path  to node  corresponds to a node  on level  of  that contains  in
its label. Edges in  correspond to edges in , and thus paths in
 correspond to paths in .

\begin{lem}\label{Split_Nodes_Correspond}
For every state  and level ,  iff there is at least one node  where  and .
\end{lem}
\begin{proof}
We prove this by simple induction over . As the base case we have that 
and , while by definition  iff . Thus our
lemma holds for .

Inductively, assume that the lemma holds for , and let . In one direction, if
, then there is a run  so that . By the inductive hypothesis,
there is a node  where  and .  If , then
, , and .  Similarly, if , then , , and .

In the other direction, if there is a node  so that  and , then  has a parent  so that . As  , there
is a state  so that . By the inductive hypothesis, , and by definition . By the definition of a run,
this implies , and thus .
\end{proof}

\begin{lem}\label{Split_Paths_Correspond}
For every , and , it holds that  iff there are nodes  and  in  so that ,  is
a child of , , and . 
\end{lem}
\begin{proof}
In one direction, let , and  be such that . By the
definition of , we have .  By Lemma \ref{Split_Nodes_Correspond}, there is a
node  so that  and .  If , then let , otherwise   and let . In either case that  implies that
 and . 

In the other direction, let , and  be such that there are nodes  and  in 
where ,  is a child of , , and . By Lemma
\ref{Split_Nodes_Correspond}, we have that  and . By
the definition of , we have , and thus .
\end{proof}

The \emph{reduced split tree}, written , keeps only the rightmost 
instance of each state at each level of the tree. This bounds the width of
 to . Formally, we define  inductively as follows. As a base
case, the root , and .
Inductively, given a node  on level , let  and
let .
If  then 
and .  Similarly, if
, then  and
.
The reduced split tree is analogous to the profiles of nodes in  and the edges in \Gprime.
Since paths in  correspond to paths in , the lexicographically
maximal path through  to a node  corresponds to the rightmost
path through  to an instance of  on level .  This is the only
instance that remains in .

\begin{lem}\label{Reduced_Split_Nodes}
For every node , there is a node  where
 and . Further, .
\end{lem}
\begin{proof}
By Lemma \ref{Split_Nodes_Correspond}, for every . there is at least one node  where  and . Let  be the rightmost such node. We must show
that , and we do so by induction over . As a base case, we have that , , and . Since, by assumption, , we have
. Inductively, assume that this lemma holds for a fixed , and let  be such
that . Let  be  if , and  if . Since
there are no orphan nodes in , we know that there is a  on level  such that
.  By Lemma \ref{Gprime_Captures_Profiles}, we know that
, and that  has the lexicographically
maximal profile of all predecessors of .   By the inductive hypothesis, there is a node  so that
, , and . Since lexicographic maximality in profiles
corresponds to being rightmost in the tree, this means  is the rightmost node containing  in
. Thus  is the rightmost node containing  in , and the only node containing
 in .
\end{proof}

\begin{lem}\label{Reduced_Split_Edges}
For every , and , it holds that  iff there are nodes  and  in  so that ,  is
a child of , , and . 
\end{lem}
\begin{proof}
This follows from Lemma \ref{Reduced_Split_Nodes} and Lemma \ref{Gprime_Captures_Profiles}.
\end{proof}

Finally, the \emph{skeleton}  is obtained by removing from the reduced
split tree all nodes that are finite. As a corollary of Lemma
\ref{Reduced_Split_Edges}, the skeleton is a representation of .
The slice automaton of \kahler and Wilke proceeds by tracking the levels of
 and guessing which nodes occur in .  Each level  of
 is encoded as a \emph{slice}, a sequence  of
pairwise disjoint subsets of . This slice is precisely the sequence of
equivalence classes in level  of \Gprime, indexed by their relative
lexicographic ordering (see Figure~\ref{Fig:GDubPrime}).  The automaton of
\kahler and Wilke differs from Definition~\ref{Slice_Def} only in the details
of labeling states and the cut-point construction.



\end{document}
