\documentclass[submission,copyright,creativecommons]{eptcs}
\providecommand{\event}{TYPES 2009 Post-Proceedings} \usepackage{breakurl}             

\include{amssymb}


\newcommand{\carrow}[1]{\stackrel{#1}{\longrightarrow}}
\newcommand{\cto}[1]{\carrow{#1}}


\newcommand{\selfcomment}[1]{\ifodd 0 {\sf #1 }\fi}
\newcommand{\selfc}{\selfcomment}
\newcommand{\selfcc}[1]{\ifodd 1 {\sf #1 }\fi}
\newcommand{\selffootnote}[1]{\ifodd 0 \footnote{{\sf #1}} \fi}
\newcommand{\selff}{\selffootnote}

\newcommand{\sect}{\section}
\newcommand{\subsect}{\subsection}
\newcommand{\ssubsect}{\subsubsection}
\newcommand{\para}{\paragraph}
\newcommand{\subpara}{\subparagraph}
\newtheorem{definition}{Definition}[section]
\newtheorem{defn}[definition]{Definition}
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{thm}[definition]{Theorem}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{cor}[definition]{Corollary}
\newtheorem{corollary}[definition]{Corollary}
\newtheorem{prop}[definition]{Proposition}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{fact}[definition]{Fact}
\newtheorem{property}[definition]{Property}
\newtheorem{properties}[definition]{Properties}
\newtheorem{conj}[definition]{Conjecture}
\newtheorem{conjecture}[definition]{Conjecture}
\newtheorem{example}[definition]{Example}
\newcommand{\proofsketch}{{\bf Proof\ sketch}\ }
\newcommand{\convention}{\ \\{\bf Convention}\ }
\newcommand{\conventions}{\ \\{\bf Conventions}\ }
\newcommand{\notation}{\ \\{\bf Notation}\ }
\newcommand{\notations}{\ \\{\bf Notations}\ }
\newcommand{\remark}{\ \\{\bf Remark}\ }
\newcommand{\remarks}{\ \\{\bf Remarks}\ }
\newcommand{\exercise}{\ \\{\bf Exercise}\ }
\newcommand{\blob}{\mbox{\rule[-1.5pt]{5pt}{10.5pt}}}
\newcommand{\qed}{}

\newcommand{\them}[1]{{\mbox{\em #1}}}

\newcommand{\casestwo}[2]{\cases {#1 \cr #2}}

\newcommand{\set}[2]{\{\,#1\,\mid\,#2\,\}}      \newcommand{\emptyseq}{\langle\rangle}          \newcommand{\seq}[2]{#1_{1} \ldots #1_{#2}}
\newcommand{\cseq}[2]{#1_{1},\ldots,#1_{#2}}
\newcommand{\pair}[3]{\langle#1,#2\rangle_{#3}} 

\mathcode`:="003A               \mathchardef\colon="303A        

\newcommand{\cross}{\times}                     \newcommand{\del}{\delta}
\newcommand{\e}{\epsilon}
\newcommand{\g}{\gamma}
\newcommand{\G}{\Gamma}
\newcommand{\defd}{\mathord{\downarrow}}        \newcommand{\undefd}{\mathord{\uparrow}}        \newcommand{\ts}{\vdash}        \newcommand{\tseq}{\vdash^=}    \newcommand{\dts}{\models}      \newcommand{\rts}{{\ \|\!\!-}}  \newcommand{\bottom}{\perp}     \newcommand{\lam}{\lambda}
\newcommand{\fa}{\forall}                       \newcommand{\To}{\Rightarrow}                   \newcommand{\fppto}{\to_{FPP}}                  \newcommand{\isoto}{\buildrel \cong \over \to}  \newcommand{\Iff}{\mathrel{\Leftrightarrow}}    \renewcommand{\iff}{\Iff}                       \newcommand{\infinity}{\infty}          \newcommand{\intersect}{\cap}           \newcommand{\nt}{\buildrel . \over \to} \newcommand{\pto}{\rightharpoonup}      \newcommand{\sig}{\sigma}
\newcommand{\union}{\cup}               \newcommand{\w}{\omega}
\newcommand{\iso}{\cong}          \newcommand{\conv}{\simeq}        \newcommand{\red}{\rhd}           \newcommand{\bconv}{\conv_\beta}  \newcommand{\bred}{\rhd_\beta}    \newcommand{\contract}{\leadsto}  \newcommand{\subs}{\subseteq}
\newcommand{\lekind}{\preceq}
\newcommand{\lesskind}{\prec}
\newcommand{\gekind}{\succeq}
\newcommand{\grkind}{\succ}
\newcommand{\eqkind}{\approx}
\newcommand{\dlb}{\lbrack\!\lbrack}
\newcommand{\ldb}{\dlb}
\newcommand{\drb}{\rbrack\!\rbrack}
\newcommand{\rdb}{\drb}
\newcommand{\sem}[1]{\mathop{\ldb #1\rdb}\nolimits}     \newcommand{\df}{{\ =_{\mbox{\scriptsize df }}}}                 \newcommand{\iffdf}{{\ \iff_{\mbox{\scriptsize df }}}}           \newcommand{\redk}{{\mbox{\rm red}}} \newcommand{\rednf}{{ \mbox{ }}}   \newcommand{\CR}{Church-Rosser theorem} \newcommand{\IH}{induction hypothesis}  \newcommand{\ML}{Martin-L\"{o}f}        \newcommand{\qn}{quasi-normal}          \newcommand{\SN}{strongly normalisable} \newcommand{\ECC}{\mbox{{\rm ECC}}}                     \newcommand{\ECCn}{{\ECC}}                          \newcommand{\ECCbn}{{\ECC}} \newcommand{\SCC}{{{\mbox{CC}}}}    \newcommand{\SCCinf}{{{\mbox{CC}}}}  \newcommand{\CCinf}{{{\mbox{CC}}}\ }           \newcommand{\CCinfcoq}{{{\mbox{CC}}}}                  \newcommand{\SCCn}{{{\mbox{CC}}}\ }         \newcommand{\Obj}{{\mbox{\rm Obj}}}             


\newcommand{\cf}{{cf.}}
\newcommand{\eg}{{e.g.}}
\newcommand{\etal}{{\it et~al.}}
\newcommand{\etc}{{etc.}}
\newcommand{\ie}{{i.e.}}
\newcommand{\vs}{{\it vs.}}
\newcommand{\wrt}{{w.r.t.}}
\newcommand{\ala}{\`{a} la}
\newcommand{\D}{{\cal D}}               \newcommand{\E}{{\cal E}}               \newcommand{\U}{{\cal U}}               \newcommand{\level}{{\cal L}}           \newcommand{\lev}{\level}               \newcommand{\Check}[2]{{\cal C}(#1;\ #2)}       \newcommand{\Terms}{{\cal T}}           \newcommand{\1}{{\mbox{\bf 1}}}         \newcommand{\back}{{\mbox{\bf back}}}   \newcommand{\false}{{\mbox{\bf false}}} \newcommand{\inc}{{\mbox{\bf inc}}}     \newcommand{\jbf}{{\mbox{\bf j}}}       \newcommand{\key}{{\mbox{\bf key}}}     \newcommand{\M}{{\mbox{\bf M}}}         \newcommand{\n}{{\mbox{\bf n}}}         \newcommand{\pairbf}{{\mbox{\bf pair}}} \newcommand{\PER}{{\mbox{\bf PER}}}     \newcommand{\PROP}{{\mbox{\bf PROP}}}   \newcommand{\Set}{{\mbox{\bf Set}}}     \newcommand{\true}{{\mbox{\bf true}}}   \newcommand{\valid}{{\mbox{\bf valid}}} \newcommand{\wS}{{\mbox{{-}{\bf Set}}}}     \newcommand{\Prf}{{\mbox{\bf Prf}}}     

\newcommand{\Frule}[4]
{}
\newcommand{\Tworules}[6]
{}
\newcommand{\tworule}[4]                {}
\newcommand{\Threerules}[9]
{}
\newcommand{\threerule}[6]              {}
\newcommand{\Fourrules}[8]
{}
\newcommand{\onerule}[2]
{}
\newcommand{\Onerule}[3]
{}
\newcommand{\tablerule}[2]
{\begin{tabular}{c}\vspace{.05in}
  \end{tabular}
}

\newcommand{\tuple}[1]{\langle #1 \rangle}              \newcommand{\CirSigmaText}{\sum\!\!\!\!\!\!\circ\ }
\newcommand{\CirSigmaMath}{\sum\!\!\!\!\!\!\!\circ\ }
\newcommand{\Dot}{\bullet}

\newcommand{\List}{List}
\newcommand{\nil}{nil}
\newcommand{\cons}{cons}
\newcommand{\N}{N}
\newcommand{\suc}{succ}                         \newcommand{\rec}{Rec}
\newcommand{\ff}{\mbox{ff}}
\newcommand{\ifN}{\mbox{if}_N}

\newcommand{\refn}{\rho}
\newcommand{\refnto}{\Longrightarrow}
\newcommand{\refncon}[1]{\buildrel c\over\Longrightarrow_{#1}}
\newcommand{\refnc}{\refncon}
\newcommand{\refnsel}[1]{\buildrel s\over\Longrightarrow_{#1}}
\newcommand{\refnabs}[2]{\buildrel a\over\Longrightarrow^{#1}_{#2}}

\newcommand{\SPEC}{{\mbox{\bf SPEC}}}
\newcommand{\Spec}{{\mbox{\bf Spec}}}
\newcommand{\Str}{{\mbox{\bf Str}}}
\newcommand{\Ax}{{\mbox{\bf Ax}}}
\newcommand{\Mod}{{\mbox{\bf Mod}}}
\newcommand{\Sat}{{\mbox{\bf Sat}}}
\newcommand{\Setoid}{{\mbox{\bf Setoid}}}
\newcommand{\Stack}{{\mbox{\bf Stack}}}
\newcommand{\STACK}{{\mbox{\bf STACK}}}
\newcommand{\Array}{{\mbox{\bf Array}}}
\newcommand{\ARRAY}{{\mbox{\bf ARRAY}}}
\newcommand{\Elem}{{\mbox{\bf Elem}}}
\newcommand{\Cong}{{\mbox{\bf Cong}}}
\renewcommand{\Join}{{\mbox{\bf Join}}}
\newcommand{\Meet}{{\mbox{\bf Meet}}}
\newcommand{\Extend}{{\mbox{\bf Extend}}}
\newcommand{\Con}{{\mbox{\bf Con}}}
\newcommand{\Sel}{{\mbox{\bf Sel}}}
\newcommand{\Abs}{{\mbox{\bf Abs}}}
\newcommand{\derive}{{\mbox{\bf derive}}}
\newcommand{\Thm}{{\mbox{\bf Thm}}}     \newcommand{\Prfs}{{\mbox{\bf Prfs}}}   \newcommand{\THEORY}{{\mbox{\bf THEORY}}}

\newcommand{\LF}{{\sc LF}}
\newcommand{\kind}{{\mbox{\bf kind}}}
\newcommand{\Type}{{\mbox{\bf Type}}}
\newcommand{\Ebf}{{\mbox{\bf E}}}
\newcommand{\emptytype}{\emptyset}
\newcommand{\App}{{\mbox{\bf App}}}
\newcommand{\app}{{\mbox{\bf app}}}
\newcommand{\T}{{\mbox{\bf T}}}
\renewcommand{\t}{{\mbox{\bf t}}}

\newcommand{\SOL}{{SOL}}
\newcommand{\plt}{plt}
\newcommand{\lts}{\models}
\newcommand{\TSCH}{{\sc Tsch}}
\newcommand{\pltRule}[1]{(\them{{\sc #1}})}

\newcommand{\Types}{{\sc Types}}
\newcommand{\Sch}{{\sc Isch}}
\newcommand{\Pos}{{\sc Pos}}
\newcommand{\Ari}{{\sc Ari}}

\newcommand{\Mu}{{\cal M}}
\newcommand{\leschema}{<}



\newcommand{\p}{\ \ \ }         \newcommand{\mathover}[2]{\buildrel \rm #1 \over #2}    %
 
\renewcommand{\SN}{strongly normalisable}

\newcommand{\RType}[1]{RType[#1]}
\newcommand{\lCat}{\textsf{L}}
\newcommand{\labels}{\textsc{Labels}}
\newcommand{\record}[1]{\langle #1 \rangle}
\newcommand{\nrecord}[1]{\bar{\langle} #1 \bar{\rangle}}
\newcommand{\ctostar}[1]{\carrowstar{#1}}
\newcommand{\R}{{\cal R}}
\newcommand{\singleton}[2]{{\{ #2 \}}_#1}
\newcommand{\uniteq}{\sim}

\newcommand{\where}[2]{{#1}|_{#2}}
\newcommand{\withR}[2]{\ \underline{\texttt{with}}\ #1\ \underline{\texttt{as}}\ #2}
\newcommand{\withS}[2]
 {\ \underline{\texttt{with}}\ \underline{\texttt{field}}\ #1\ \underline{\texttt{as}}\ #2}
\newcommand{\SIGMA}[1]{\sum [ #1 ]}

\newcommand{\with}{\emph{\underline{\texttt{with}}}}
\newcommand{\field}{\emph{\underline{\texttt{field}}}}
\newcommand{\as}{\emph{\underline{\texttt{as}}}}

\newcommand{\Unit}{\textbf{1}}
\newcommand{\unit}{\ast}

\newcommand{\RECORD}[1]{\left\{ #1 \right\}}
\newcommand{\RECORDobj}[1]{\left[ #1 \right]}
\newcommand{\subst}[2]{#1\{#2\}}


\title{Typed Operational Semantics for Dependent Record Types\thanks{The authors acknowledge the support from the Leverhulme Trust (grant ref. F/07-537/AA) and the first author also acknowledges the support from the College Research Studentship and an award from Computer Science Department in Royal Holloway, University of London.}}
\author{Yangyue Feng and Zhaohui Luo
\institute{Department of Computer Science\\ Royal Holloway, University of London \\
Egham, Surrey TW20 0EX, UK\\}
\email{\{yangyue,zhaohui\}@cs.rhul.ac.uk}
}
\def\titlerunning{Typed Operational Semantics for Dependent Record Types}
\def\authorrunning{Yangyue Feng and Zhaohui Luo}

\begin{document}


\maketitle

\begin{abstract}
Typed operational semantics is a method developed by H. Goguen to prove meta-theoretic properties of type systems. This paper studies the metatheory of a type system with dependent record types, using the approach of typed operational semantics. In particular, the metatheoretical properties we have proved include strong normalisation, Church-Rosser and subject reduction.
\end{abstract}


\section{Introduction}

\par{H. Goguen \cite{healf:thesis,healf:TLCA99YY} has developed a method called \emph{typed operational semantics} (TOS for short) to prove meta-theoretic properties of type theories, including strong normalisation, Church-Rosser and subject reduction. In this paper, using the TOS approach, we study the meta-theoretic properties of a type system with dependent record types. }

\par{A record type is a type of labelled tuples called records.  A dependent record type (DRT) is a type of records whose fields may have types that depend on the values of earlier fields.  Dependent records have been studied previously for various different type systems \cite{Harper-Lillibridge93, bet-tar:subtyping98, Pollack:records02, ctp:semantic-records05}, with applications to the study of module mechanisms for both programming and proof languages. Recently, in the context of studying manifest fields of module types, the second author has proposed a formulation of dependent record types \cite{luo:TYPES08}, for type theories with canonical objects such as \ML's type theory, and shown in \cite{luo:MLPA09} that, in some applications, dependent record types are more useful than -types (dependent types of tuples without labels). }

Studying the meta-theory of dependent record types, the contributions of the current paper are two-fold.  First of all, the meta-theory of dependent record types has not been well-studied.  This work makes a positive contribution, showing that our formulation of dependent record types has the good meta-theoretic properties such as strong normalisation.  Secondly, the type theory we study has record \emph{types} as studied in \cite{Pollack:records02,luo:TYPES08}, rather than record \emph{kinds} as in \cite{bet-tar:subtyping98,ctp:semantic-records05}.  Since types have a much more sophisticated structure than kinds, the meta-theory for dependent record types is expected to be much more difficult than that for dependent record kinds as found in, \eg, \cite{ctp:semantic-records05}.  We shall study the meta-theory by taking the TOS approach, which is shown to be robust enough to deal with dependent record types.  In particular, we study the \emph{intensional} DRTs, that is, the dependent record types without the so-called weakly extensional rules (these rules are considered in \cite{luo:TYPES08}).  The typed operational semantics for intensional DRTs is developed and shown to be sound and complete and, based on this, it is proved that the intensional DRTs have good meta-theoretic properties, including strong normalisation, Church-Rosser and subject reduction.

The paper is arranged as follows. The type system IDRT for intensional DRTs is described in Section~\ref{sec:LFwithDRT}.  In Section~\ref{sec:TOS}, after introducing the basic idea of TOS, we define the TOS for dependent record types.  The properties of the TOS are studied in Section~\ref{sec:metaTOS} and the meta-theoretic properties of IDRT in Section~\ref{sec:metaDRT}.  Discussions of related work and future work are given in the conclusion.


\section{Dependent Record Types}
\label{sec:LFwithDRT}

A dependent record type is a type of labelled tuples whose fields may have types that depend on the values of earlier fields. For instance, if  and  are the types of natural numbers and vectors of length , respectively,  is the dependent record type with objects (called {\sl records}) such as , where dependency is respected: the vector  must be of type .

Formally, in our study, dependent record types are formulated as an extension of the logical framework that we describe briefly first.

\paragraph{Logical Framework.}  LF \cite{luo:book94} is the typed version of Martin-L\"{o}f's logical framework \cite{NPS:book}.  It is itself a type system that serves as a meta-language to specify type theories such as \ML's intensional type theory \cite{NPS:book} and the Unifying Theory of dependent Types (UTT) \cite{luo:book94}.  Here, we give only a brief introduction, fixing the notations to be used in the paper.  (For details of, for example, how inductive types like , -types and -types can be specified in the logical framework, see Part III of \cite{NPS:book} or Chapter 9 of \cite{luo:book94}.)

In LF, the syntactical entities \emph{contexts}, \emph{kinds} and \emph{terms} are of the following forms:

The types in LF are called \emph{kinds}, including:
\begin{itemize}
\item  -- the kind representing the collection of all types ( is a type if );
\item  -- the kind of objects of type  (we often omit ); and
\item  (or simply  when ) -- the kind of dependent functional operations.
\end{itemize}
The judgement forms in LF include, for example,
\begin{itemize}
  \item , which asserts that  is an object of kind ; and
  \item , which asserts that  and  are (computationally) equal objects of kind .
\end{itemize}
The inference rules of LF to define the typing relation and the computational equality are given in Appendix~\ref{app:LF-rules}.  In particular, -equal objects are computationally equal.  For instance, an abstraction  can be applied to form  that is computationally equal to .

\begin{notation}
We shall use  to denote the syntactical identity (up to -conversion).
\end{notation}

\paragraph{Dependent Record Types.}
We now give a formal presentation of the system IDRT of intensional dependent record types, which is an extension of LF.  The syntax of this type system is given as follows, where  is an (infinite) set of labels,  and  is finite:

The inference rules of IDRT consist of the rules for LF (Appendix~\ref{app:LF-rules}) and the additional rules in Figure~\ref{DRT-rules}. Here are some informal explanations.
\begin{figure}[top]
\framebox[5.8in][l]{
\begin{minipage}{\linewidth}
\ \\

\ \ \ \emph{Kinds of record types}



\ \ \ \emph{Formation rules}


\ \ \ \emph{Introduction rules}


\ \ \ \emph{Elimination rules}



\ \ \ \emph{Computation rules}




\ \ \ \emph{Congruence rules for record types}



\ \ \ \emph{Congruence rules for records}


\\
\end{minipage}
} \caption{Inference Rules of IDRT} \label{DRT-rules}
\end{figure}

\begin{itemize}
  \item We add new kinds  and  of record types.  Intuitively,  is the kind of the record types whose (top-level) labels are all in , a finite set of labels.  Naturally, if , every record type in  is also in .  The kind  is the kind of all record types and could  conceptually be understood as `'.  Finally, every record type is also a type.  These are formally reflected in the rules for the kinds of record types in Figure~\ref{DRT-rules}.
  \item Record types are types of the form  or .  Intuitively, a record type is of the form ,\footnote{We overload the  notation for records and their types.  It is always possible to distinguish between the two.} where each  is a \emph{field} labelled by .  An object of this record type is a labelled tuple , where  is of the type of the corresponding field.  \selfc{The kind of the field types are dependent kinds from \emph{previous} record types to .}  Note that, formally, each  in the record type is not a type, but a family of types; this is how dependency is incorporated -- we have dependent record types.
      
      Notation-wise, we shall adopt the following notational conventions: for record types, we write  for  and often use label occurrences/non-occurrences to show dependency/non-dependency respectively.
For instance, we write  for  where , and  for .
  \item There are two operations on records: \emph{restriction} (or first projection)  that removes the last component of record  and \emph{field selection}  that selects the value of the field labelled by .  For instance, intuitively, for the record  of type , we have  and .  These are formally reflected in the introduction, elimination and computation rules in Figure~\ref{DRT-rules}.
  \item The congruence rules for record types and records in Figure~\ref{DRT-rules} propagate the computational equality through the term structure.  Also, we do not include the weakly extensional equality rules as considered in \cite{luo:TYPES08}.  Therefore, we call the system the type system for intensional DRTs.
\end{itemize}
We shall adopt the following terminology: the terms of the form  will be called \emph{pair-records}.  (For example, we shall use this terminology in specifying the TOS-rules for record types in Figure~\ref{TOS-DRT-rules} in Section~\ref{sec:TOS-IDRT}.)




\paragraph{Record types v.s. record kinds.}  It is worth pointing out that our type system contains dependent record \emph{types} (as studied by Pollack \cite{Pollack:records02}, Luo \cite{luo:TYPES08,luo:MLPA09} and the current paper), rather than dependent record \emph{kinds} (as studied by Betarte and Tasistro \cite{bet-tar:subtyping98} and Coquand, Pollack and Takeyama \cite{ctp:semantic-records05}\footnote{\emph{Types} in the terminology of \ML's type theory are what we call \emph{kinds} in this paper.  Therefore, the so-called record types in \cite{bet-tar:subtyping98} and \cite{ctp:semantic-records05} are really record kinds.}).  We would like to distinguish these two notions clearly: in a type theory with inductive types, types include those such as  of natural numbers and -types of dependent pairs, while the examples of kinds include, for example, the kind  of all types.  They exist at two completely different levels and have rather different structures and properties.

In general, types have a much more sophisticated and richer structure than kinds.  For instance, it is easy to show that a kind is of the form either  or , but types are not (\eg, a type may be of the form ).  To appreciate the difference, let us consider the issue of ensuring label distinctness.  If one considers only record kinds, it is easy to guarantee that the labels in the same record kind are distinct because of the limited syntactic forms of kinds (see, for example, \cite{ctp:semantic-records05}).  However, this is not easy at all for record types (think, for example, how one ensures that a label does not occur in a type of the form ).  In our case, we have to introduce the kinds  to ensure that it is the case that the (top-level) labels in the same record type are distinct.  In other words, intuitively,  for any record type .  This is guaranteed by means of the side condition  of the second formation rule in Figure~\ref{DRT-rules}.

That a type system with record types is more powerful than one with only record kinds can be understood from another angle when one wants to introduce universes of record types.  It is possible to introduce type universes for dependent record types, as shown in \cite{luo:MLPA09}; this, however, cannot be done for record kinds.  Therefore, record types are more useful than record kinds (for example, in representing module types in data refinement \cite{luo:MLPA09}).

Since types have a more sophisticated structure than kinds, it is more difficult to study the meta-theoretic properties of a system with record types, as compared with a meta-theoretic study of record kinds.  As we show in this paper, the approach of using typed operational semantics can be used in this endeavour.



\section{Typed Operational Semantics for Dependent Record Types}
\label{sec:TOS}

The typed operational semantics (TOS for short) is a proof-theoretic method to prove the meta-theoretic properties of type theories.  It was developed by H. Goguen in his PhD thesis \cite{healf:thesis}, where he studied the meta-theory of UTT and proved that UTT has the nice properties such as Church-Rosser, Subject Reduction and Strong Normalisation.

In this paper, the TOS approach is applied to study the meta-theory of dependent record types.  After a brief informal introduction of the approach, we develop the typed operational semantics for the system IDRT of intensional DRTs and show that it has the soundness and completeness properties.  The meta-theoretic properties of dependent record types are studied in the next section.

\subsection{The TOS Approach}
\label{sec:introTOS}

For a type theory, its typed operational semantics captures its computational behaviour, usually given by its (untyped) reduction relation.  For example, in TOS, the following judgement

informally asserts that, among other things,  and  are the weak-head normal form and the normal form of the term , respectively.\footnote{Formally, the reduction relation and the TOS are related to each other by means of the `adequacy theorems' such as Lemmas~\ref{AUR} and~\ref{ANF} for IDRT in Section~\ref{subsec: adeq}.}  For the logical framework LF, for example, its corresponding TOS has been studied \cite{healf:TLCA99YY} and its inference rules are given in Appendix~\ref{app:LF-TOSrules}.  Since many meta-theoretic properties of a type theory are concerned with its computational behaviour, it is not a surprise that TOS provides an effective approach to the meta-theory of type theories.\footnote{It is worth noting that, although it is useful to study the meta-theory for many type theories, the TOS approach would not be suitable for non-normalising type theories.  See \cite{healf:thesis} for discussions.}

The TOS and its corresponding type theory are related to each other by means of the soundness and completeness theorems.  Using the judgement  to abbreviate ` for some  and ', we can state the soundness and completeness properties as follows:
\begin{itemize}
  \item Soundness:  implies  (for  that is the `normal form' of ).
  \item Completeness:  implies .
\end{itemize}
Based on soundness and completeness, we can prove many meta-theoretic properties of the type theory.  For example, it can be shown that, if , then  is strongly normalisable.  Therefore, strong normalisation, the property that every well-typed term is strongly normalisable, can be proved by means of such a fact together with the soundness property, as pictured as follows:

\begin{picture}(100, 80)(-60, -50)
\put(30, 10){\makebox(0,0){}}
\put(120, -30){\makebox(0,0){}}
\put(210, 10){\makebox(0,0){ is SN}}
\put(40, -30){\line(0, 1){35}}
\put(40, -30){\vector(1, 0){50}}
\put(150, -30){\line(1, 0){60}}
\put(210, -30){\vector(0, 1){35}}
\put(60, 10){\dashbox{.5}(120, 0)[t]{}}\put(180, 10){\vector(1, 0){3}}
\put(120, 14){\makebox(0,0){\emph{\begin{small}Strong Normalisation\end{small}}}}
\put(15, -15){\makebox(0,0){\emph{\begin{small}Soundness\end{small}}}}
\put(245, -15){\makebox(0,0){\emph{\begin{small}SN for TOS\end{small}}}}
\end{picture}

\noindent As shown in this paper, for dependent record types, the SN property for the corresponding TOS is proven in Theorem~\ref{SN-TOS}.  Then, by the Soundness Theorem (Theorem~\ref{Soundness-TOS-LF}), we can show that strong normalisation for IDRT (Corollary~\ref{SN-LFDRT}).

Note that, to implement such ideas is not a simple matter: it requires one to prove:
\begin{itemize}
  \item that the TOS is `adequate' \wrt\ the (untyped) reduction relation,
  \item that the TOS is sound and complete \wrt\ the original type theory, and
  \item that the TOS satisfies some specific meta-theoretic properties (\eg, strong normalisation).
\end{itemize}
Then, one can transfer the results to the original type theory to show that it has nice meta-theoretic properties.  This is what we shall do for IDRT, the type theory with dependent record types.


\subsection{TOS for Dependent Record Types}
\label{sec:TOS-IDRT}

The typed operational semantics for dependent record types is described in this section.  The judgement forms in a TOS are given in Figure~\ref{TOS-judgements},
\begin{figure}[top]
\begin{minipage}{\linewidth}

\end{minipage}
\caption{Judgement Forms in Typed Operational Semantics} \label{TOS-judgements}
\end{figure}
three of which are the basic forms of judgements whose informal meanings are:
\begin{itemize}
  \item : the context  has context  as its normal form;
  \item : the kind  is well-formed in context  and has normal form ; and
  \item : the terms , ,  are well-formed in context  of kind  and  has weak-head normal form  and normal form .
\end{itemize}
From these basic judgements, one can define other forms of judgements, including the following:
\begin{itemize}
  \item  stands for ` for some ';
  \item  stands for ` for some ';
  \item  stands for ` for some '; and
  \item  stands for ` for some   and '.
\end{itemize}

The typed operational semantics for the type system IDRT of intensional DRTs is the extension of that for LF (Appendix~\ref{app:LF-TOSrules}) with the inference rules given in Figure~\ref{TOS-DRT-rules}.
\begin{figure}[top]
\framebox[6.2in][l]{
\begin{minipage}{\linewidth}
\ \\

\ \ \ \emph{Record Kinds}

\ \ \ \emph{Record Types}


\ \ \ \emph{Pair-records}


\ \ \ \emph{Restrictions}


\ \ \ \emph{Selections}

  

\\
\end{minipage}
}\caption{Inference Rules of Typed Operational Semantics for IDRT} \label{TOS-DRT-rules}
\end{figure}
Most of the rules are self-explanatory. We only mention that, besides using the abbreviated forms of judgement (see above) in the rules, we also use the terminology of `pair-record' as introduced in Section~\ref{sec:LFwithDRT}.  For example, in , we require that  or  be not a pair-record, for otherwise, for instance,  could be a redex and would not be in normal form.

\section{Properties of TOS for Dependent Record Types}
\label{sec:metaTOS}

We shall study the properties of the TOS for IDRT, as presented above in Section~\ref{sec:TOS-IDRT}.  These include those properties \wrt\ the relationship with IDRT (soundness and completeness) and those \wrt\ the reduction relation.
\subsection{Basic Structural Properties}
\label{subsec:struc}

The typed operational semantics satisfy some basic properties as stated in the following lemma, which can all be proved by induction on the TOS-derivations.\footnote{Some of the lemmas (\eg, the strengthening lemma) can only be proved by proving a stronger statement by induction on derivations.  We omit the details here.}

\begin{lemma} \label{Stru-prop}\
\begin{enumerate}
  \item (Context Validity) Any derivation of  has a sub-derivation of .
  \item (Variables) Let  be the set of variables declared in context  and  the set of free variables occurring in term .
  \begin{enumerate}
    \item If , then .
    \item If , then .
    \item If , then .
  \end{enumerate}
\selfc{\item (Renaming) Suppose  is a renaming from  to . If , then  (where  is the -renaming from , i.e.\  or  when  appears as the form  or  respectively).
}\item (Weakening) If  and , then .
  \item (Strengthening) If  and , then .
  \item (Determinacy) \label{UNF}
  \begin{itemize}
    \item If  and , then .
    \item If  and , then .
    \item If  and , then ,  and .
  \end{itemize}
\end{enumerate}
\end{lemma}

\remark\ The above Lemma~\ref{Stru-prop}(\ref{UNF}) of `Determinacy' says that the TOS-normal forms are unique.  Of course, in order to show that the normal form of a well-typed term (under the usual reduction relation) is unique, one has to prove that the TOS-reductions are adequate.  This is what we do in the following subsection.

\subsection{Adequacy \wrt\ the Untyped Reduction}
\label{subsec: adeq}

We shall show in this section that the notions of computation captured in TOS are adequate \wrt\ the usual (untyped) reduction relation, which is defined in the following definition.

\begin{defn}[Untyped Reduction for IDRT] \label{untyped-red}
The (untyped) one-step reduction over terms, notation , is the compatible closure\footnote{The compatible closure of a relation  over terms propagates R to all of the terms.  We omit its formal definition here; see \cite{healf:thesis,Fen10} for formal details.} of the relation given by the following rules:

We write  and  for the corresponding transitive closure and reflexive and transitive closure, respectively.

A term of the form on the left of an arrow is called a \emph{redex}.  For example, a -redex is a term of the form .
\end{defn}

\selfc{
\begin{definition}[Compatible Closure] \label{comp-clos}
Let  be a relation on terms.   The \emph{compatible closure} of , notation , is the least relation satisfying the following rules:





\\
\end{definition}




\begin{definition}[Untyped Reduction ] \label{un-red}
We introduce the one-step reduction rules over untyped terms in IDRT:
the untyped reduction (or just reduction)  is the compatible closure of all the following rules in Figure \ref{Untyped-reduction}; we write  for the transitive closure of reduction and  for the reflexive, transitive closure of reduction. We also write  for the compatible closure of the last three rules that operate only on the record terms, and  and  accordingly. Similarly  is the compatible closure of  and , and  and  accordingly. \\
\begin{figure}[here]
\framebox[5.8in][c]{
\begin{minipage}{\linewidth}

\end{minipage}
} \caption{One-step Reduction of Untyped Terms in IDRT} \label{Untyped-reduction}
\end{figure}
(\textbf{Redex}) Let  be a relation, a term  is an -redex if there is some  such that . A term  in IDRT is a redex if  is a -redex. \\
\end{definition}

}

\begin{defn}[Weak-Head Normal Forms and Normal Forms] \label{WHN-N}\
\begin{itemize}
  \item A term  is \emph{weak-head normal} if
  \begin{itemize}
    \item  is a variable;
    \item ;
    \item , where  is weak-head normal and not an abstraction;
    \item ;
    \item ; or
    \item  or , where  is weak-head normal and not a pair-record.
  \end{itemize}

  \item A term  is \emph{normal} if
  \begin{itemize}
    \item  is a variable;
    \item , which is not an -redex, and  and  are normal;
    \item  and  and  are normal and  not an abstraction;
    \item ;
    \item  and ,  and  are normal.
    \item  or , where  is normal and not a pair-record.
  \end{itemize}
\end{itemize}
The notions of weak-head normal forms and normal forms are lifted to record types, kinds and contexts in the usual way.
\end{defn}


This case was in our original proof of a DRT system with the WER rules, it was of interest because the weakly extensional rules are -like rules that cause problems, such as strong normalization fails for untyped raw terms. For reason of discussion we keep this case still here.
The following lemmas show that the notion of computation captured in TOS is adequate \wrt\ the untyped reduction and the associated notions of normal forms.

\begin{lemma}[Adequacy of TOS \wrt\ Untyped Reduction] \label{AUR}\
\begin{itemize}
  \item If  then there exists  such that .
  \item If , then there exists  such that .
\end{itemize}
\end{lemma}
\textbf{Proof.} By induction on derivations.

\begin{lemma}[Adequacy of TOS \wrt\ Normal Forms and WHNFs] \label{ANF}\
\begin{itemize}
  \item If , then  is normal.
  \item If , then  is normal.
  \item If , then  is weak-head normal and  and  are normal.
\end{itemize}
\end{lemma}
\textbf{Proof.} By induction on derivations.

\selfc{\begin{lemma}[Determinacy (Unique Normal Form)] \label{UNF}
\ \\
(1) If , , then ; \\
(2) If , , then ; \\
(3) If , , then , , .
\end{lemma}
\textbf{Proof.} By simultaneous induction on derivations.
}

\subsubsection{Soundness and Completeness}
\label{subsec:comp-sound}

The TOS we have studied is sound and complete \wrt\ the type system IDRT of dependent record types.  In the informal introduction to TOS in Section~\ref{sec:introTOS}, we have over-simplified the situation.  In fact, what we shall do is to show that completeness holds for a simpler system  (with judgements of the form ), which is obtained from IDRT by removing the seven substitution rules in Appendix~\ref{app:LF-rules}.  Therefore, the soundness and completeness may be pictured as follows:

\begin{picture}(100, 65)(-115, 0)
\put(50, 50){\makebox(0,0){}}
\put(120, 50){\makebox(0,0){}}
\put(82, 10){\makebox(0,0){}}
\put(60, 40){\oval(20, 60)[bl]}
\put(105, 40){\oval(20, 60)[br]}
\put(82, 50){\oval(48, 10)[t]}
\put(24, 30){\makebox(0,0){\emph{\begin{small}Soundness\end{small}}}}
\put(150, 30){\makebox(0,0){\emph{\begin{small}Completeness\end{small}}}}
\put(82, 48){\makebox(0,0){\emph{\begin{small}\end{small}}}}
\put(60, 10){\vector(1, 0){2}}
\put(115, 40){\vector(0, 1){2}}
\put(58, 50){\vector(-1, -2){2}}
\end{picture}

\begin{theorem}[Completeness of TOS \wrt\ ] \label{compl}\
\begin{itemize}
  \item If  then .
  \item If  then  and .
  \item If  then , ,  and .
\end{itemize}
\end{theorem}
\textbf{Proof.} By simultaneous induction on derivations and examining each case of the  inference rules.


\begin{cor}[Completeness of TOS \wrt\ IDRT] \label{completeness}\
\begin{itemize}
  \item If  then .
  \item If  then  and .
  \item If  then , ,  and .
\end{itemize}
\end{cor}
\textbf{Proof.} By Theorem~\ref{compl} and the inclusion of  in IDRT.

\ \\

The Soundness Theorem is harder to prove.  We have to consider all the inference rules of IDRT including the structural rules.   In the following, we only consider some selected cases.  The detailed proof can be found in \cite{Fen10}.

\begin{theorem}[Soundness of TOS \wrt\ IDRT] \label{Soundness-TOS-LF}\
\begin{itemize}
  \item If , then there exists  such that .
  \item If , then there exists  such that .
  \item If  then there exists  such that  and .
  \item If  then there exist ,  such that  and .
  \item If , then there exist ,  such that , and , .
\end{itemize}
\end{theorem}
\textbf{Proof.} By induction on derivations. For the cases of LF-rules, see \cite{healf:TLCA99YY}.  We consider the following two cases about record types.
\begin{itemize}
  \item The second introduction rule in Figure~\ref{DRT-rules}:
  
  By induction hypothesis, the following hold:
  \begin{enumerate}
    \item \label{(*)}
       for some  and ,
    \item  and  for some ,  and , and
    \item \label{(**)}
       and   for some  and .
  \end{enumerate}
  By Lemma~\ref{Stru-prop}(\ref{UNF}) (Determinacy) and inversion of the rule  in Figure~\ref{TOS-DRT-rules}, .  Therefore, by rule  in Figure~\ref{TOS-DRT-rules}, .

  \item The third elimination rule in Figure~\ref{DRT-rules}:
  
  By induction hypothesis, the following hold:
  \begin{enumerate}
    \item  and  for some ,  and , and
    \item  and  for some  and .
  \end{enumerate}
  Since , by  in Figure~\ref{TOS-DRT-rules}, we have .
\end{itemize}

\selfc{
We shall examine each case of  and  inference rules
and consider all the structural rules (selected proof segment): \\
-- Kinding rules. We show for : By induction hypothesis , using  we have . \\
-- Formation rules for . We show for the second one: By induction hypothesis there exist  such that  (so by inversion ), and . Also by induction hypothesis there exist  such that . Together with the condition , using  we have . \\
-- Introduction rules. We show for the second one: By induction hypothesis there exist  such that  ; also that there exist  such that  and  for some . By inversion of  and by Determinacy we know . Also by induction hypothesis there exist  such that  and  . Here, consider two subcases when we construct the new normal form for the small record : \\
\indent
First subcase,  is not an -redex. By inversion on , we have  and . Use the  rule for application, we have . Use the  rule for , we have  . Compare  and , by Determinacy we have . By inversion on 's  rule we have . Apply induction hypothesis again and by the fact that  is normal (Adequacy for normal forms, Lemma \ref{ANF}), we have . Finally, with all these consitions got, we apply  rule and get . \\
\indent
Second subcase,  is an -redex. This means there exists  such that  and . Similarly to the above subcase, by inversion on  and  rules of , we have  for some . \\
-- Elimination rules. We show for the third one (the first two could be easily deduced from inverting the  rules): By induction hypothesis there exist  such that  and ; also that there exist  such that  and . There are two subcases here, apply an inversion either on the rule  or on the rule , we will have . Together with the condition , using  we have . \\
-- Computation rules. We show for the third one: From the induction hypothesis and by inversion on the rule  and using the rule  it will be easily derived that  and  and  for some . 


-- Congruence rules. We show for the one for : Using induction hypothesis and the rule , also by Determinacy, we will derive that ,  for some  and .
\qed \\


}



\subsection{Strong Normalisation in TOS}
\label{sec:PSR-SN}

The strong normalisation property of the TOS says that, if a term  is well-typed in the TOS (\ie, ), then  is strongly normalisable.  This result, together with the soundness theorem, will then be enough to show that the original type theory has the property of strong normalisation.

The strong normalisation property of the TOS by introducing a notion of \emph{parallel reduction} and showing that it has the so-called \emph{Parallel Subject Reduction} property.

\begin{definition}[Parallel Reduction] \label{Pal-Red}
Parallel reduction  is defined as the least relation closed under the rules in Figure~\ref{Parallel-reduction}, and is extended in an obvious way to kinds and contexts.

\begin{figure}[here]
\framebox[5.8in][c]{
\begin{minipage}{\linewidth}
\ \\







\\
\end{minipage}
}\caption{Parallel Reduction for IDRT} \label{Parallel-reduction}
\end{figure}
\end{definition}

\remark\ Parallel reduction has some simple properties. First,  for all M. Furthermore, if  then , and if  then . Finally, if  and  then .

\selfc{
\begin{lemma}[Parallel Reduction   Untyped Reduction ] \label{rel-reductions}
If  then . \end{lemma}
\textbf{Proof.} By structural induction on the terms. From Definition \ref{Parallel-reduction} we know that no -redex was created by parallel reduction . \footnote{As consequence of Lemma \ref{rel-reductions}, we have , Church-Rosser holds for both  and . } \qed \\
}

\begin{lemma}[Parallel Subject Reduction] \label{PSR}\
\begin{enumerate}
  \item If  and , then .
  \item If ,  and , then .
  \item If ,  and , then there exist  and  such that ,  and .
\end{enumerate}
\end{lemma}
\textbf{Proof.} By simultaneous induction on derivations. The detailed proof can be found in \cite{Fen10}.

\begin{lemma}[Subject Reduction] \label{SR}
If ,  and , then there exists  such that  and .
\end{lemma}
\textbf{Proof.} By simultaneous induction on derivations, using Lemma \ref{PSR}.
\ \\

The proof of strong normalisation of the TOS (Theorem~\ref{SN-TOS}) uses the following lemma.

\begin{lemma}\label{NOT-ABS-PAIR}\
\begin{itemize}
  \item If  is weak-head normal and not an abstraction and , then  is weak-head normal and not an abstraction.
  \item If  is weak-head normal and not a pair record and , then  is weak-head normal and not a pair record.
\end{itemize}
\end{lemma}
\textbf{Proof.} By induction on length of reduction for untyped terms.

\begin{theorem}[Strong Normalisation of TOS] \label{SN-TOS}\
\begin{enumerate}
  \item If  then  is strongly normalisable.
  \item If  then  is strongly normalisable.
\end{enumerate}
\end{theorem}
\textbf{Proof.} By simultaneous induction on derivations.   The full proof can be found in \cite{Fen10}.  We shall consider one of the most difficult cases -- when the last rule used is  in Figure~\ref{TOS-DRT-rules}:
  
By \IH,  is \SN.  It suffices for us to show that  is \SN\ if  such that  is not a pair-record.  We do this by induction on the maximal length of reductions starting from .

Assume that .  \selfc{As  is not a pair-record and  is arbitrary, it is enough to show that  is \SN. Since ,}  We then have , which implies by Lemma~\ref{PSR} (Parallel Subject Reduction) that there exist  and  such that

We therefore have that  is weak-head normal (by Lemma~\ref{ANF}) and that  (see the remark above).  From these and Lemma~\ref{NOT-ABS-PAIR}, we have
\begin{itemize}
  \item[(*)]  is weak-head normal and not a pair-record.
\end{itemize}
Furthermore, by Lemma~\ref{AUR}, we have
\begin{itemize}
  \item[(**)] .
\end{itemize}
From  and ,  is not a pair-record by Lemma~\ref{NOT-ABS-PAIR}.  Therefore, since , we conclude by \IH\ that  is \SN.

\selfc{
\par{And eventually, we arrive at the following main Corollary, which is strong normalisation of our original system of dependent record types IDRT: }

\begin{corollary}[Strong Normalisation of IDRT] \label{SN-LFDRT}
\ \\
(1) If  then  is strongly normalisable; \\
(2) If  then  is strongly normalisable; \\
(3) If  then both  and  are strongly normalisable to some ; \\
(4) If , then  is strongly normalisable to some ,  is strongly normalisable to some  such that  in ; \\
(5) If , then both  and  are strongly normalisable to some ,  is strongly normalisable to some  such that  in .
\end{corollary}
\textbf{Proof.} Derived from Theorem \ref{Soundness-TOS-LF}
and Theorem \ref{SN-TOS}.  \\


\par{\noindent Other metatheory such as the Church-Rosser property, uniqueness of normal form, etc. could be derived in a similar way as strong normalisation and subject reduction are done. }

\begin{corollary}[Church-Rosser Property of IDRT] \label{CR-LFDRT}
\ \\
If , then  such that  and .
\end{corollary}
\textbf{Proof.} By Soundness (Theorem \ref{Soundness-TOS-LF}), there exist  such that  and . By Adequacy (Lemma \ref{AUR}) we prove that  and . \\
}

\section{Meta-theoretic Properties of IDRT}
\label{sec:metaDRT}

From the properties of the TOS that have been proved in the last section, the meta-theoretic properties of IDRT, the type theory for dependent record types, can be proved.  Here, we give the theorems for Subject Reduction, Church-Rosser and Strong Normalisation.  (For further details and other properties, see \cite{Fen10}.)

\begin{thm}[Subject Reduction for IDRT] \label{SR-LFDRT}
If  and , then .
\end{thm}
\textbf{Proof.} First of all, we have  (by the Soundness Theorem \ref{Soundness-TOS-LF}) and  (since ).  Therefore, by Lemma~\ref{SR}, we have .  Now, by Completeness (Theorem~\ref{completeness}), .

\begin{thm}[Strong Normalisation for IDRT] \label{SN-LFDRT}\
\begin{enumerate}
  \item If , then  is strongly normalisable.
  \item If , then  is strongly normalisable.
  \item If , then both  and  are strongly normalisable to some .
  \item If , then  and  are strongly normalisable and , where  and  are the normal forms of  and , respectively.
  \item If , then both  and  are strongly normalisable to some ,  is strongly normalisable to some  such that .
\end{enumerate}
\end{thm}
\textbf{Proof.} By the Soundness Theorem~\ref{Soundness-TOS-LF}
and Theorem \ref{SN-TOS}.


\begin{thm}[Church-Rosser for IDRT] \label{CR-LFDRT}
If , then  and  for some .
\end{thm}
\textbf{Proof.} By Soundness (Theorem \ref{Soundness-TOS-LF}), there exist  and  such that  and .  Then, by Adequacy (Lemma \ref{AUR}), we have  and .

\section{Conclusions}
\label{sec:conclusion}

We have studied the meta-theory of a type theory with dependent record types, by studying its typed operational semantics.  As we have mentioned in Section~\ref{sec:LFwithDRT}, dependent record \emph{types} are rather different from dependent record \emph{kinds}, with the former having a much richer structure and being more difficult to study.  The meta-theory of dependent record kinds has been studied by Coquand \emph{et. al} \cite{ctp:semantic-records05}, where they have given a proof of termination of type-checking.  As far as we know, ours is the first attempt to study the meta-theory of dependent record types formulated in a logical framework \cite{Pollack:records02,luo:TYPES08,luo:MLPA09}.  In the light that the TOS-approach has been successfully applied to the meta-theoretic study of type theories with -equality \cite{healf:TLCA99YY} and with inductive types \cite{healf:thesis}, the current work can be used to justify the incorporation of dependent record types in a full-scale type theory as implemented in the proof assistants such as Agda and Coq.

The dependent record types studied in this paper are \emph{intensional} in the sense that we do not have the following extensional equality rules \cite{bet-tar:subtyping98,luo:TYPES08}:

They basically say that two records are computationally equal if their components are.  For instance, from the second rule above, we would have  for any  of type .  It is unclear whether the TOS-approach as adopted in this paper can be applied to such (weakly) extensional record types.  It would be obviously problematic if one considered the reduction relation for the records as follows:

for, together with the -reduction for -terms, the Church-Rosser property would fail to hold.  A natural question arises here: would it possible if one takes the TOS-approach by considering a reduction relation that treats -long normal forms (\eg, by taking the above reduction in the other direction)?  This involves the development of the TOS-approach to incorporate -long normal forms and research is needed to see whether it is possible.

\selfc{

\par{
This is generally problematic with systems with -equality, an example for why Church-Rosser fails could be as: In a system with both -type, -type and unit type , suppose we allow -rules for ,  and for unit types, }


then, a term  with  could have two reductions by  and by  that do not commute:  and . Note that  is already a canonical form.
\par{Similarly for a term , it reduces to both  and to } under  and  respectively, which do not commute.

This situation happens because there are two types of -reductions: one is the structural s such as  or , the other one is the non-structural or ``terminating'' s such as  (they are called ``terminating'' because the calculations are towards a canonical form). The mixture of these two different types of -rules has caused the failure of the Church-Rosser property. But if a system simply has only the structural s, Church-Rosser still holds, for example,



\par{In our system, the weakly extensional equality rules are similar to the -rules, and in particular, if one allows -reduction for the DRTs in the definition of untyped reduction (Definition \ref{Untyped-reduction}), our proofs will not work, because the first weakly extensional equality rule is one in the category of non-structural s, while the second still belongs to the category of structural s. So if this system is extended with non-structural s, i.e., the first WER, Church-Rosser fails. However, in our proof, the part related to the weakly extensionality rules in TOS and in other related definitions are supposed to be \emph{disconnected} with other part, which means, if we add a case in the proof for Strong Normalisation that deals with the weakly extensional equality rules given above, it will only use rules provided by the TOS rule  in Figure \ref{TOS-DRT-rules} and the -parallel reduction definition in Figure \ref{Parallel-reduction}. }
\par{In another word, if one takes the weakly extensional equality rules out of the system, and remove also the  rule in TOS and the other related definitions, such as the ETA for parallel reduction, the proof still go through. If one adds back these rules concerning structural -calculation, as a corollary, Church-Rosser works for the typeable terms in TOS. This typeable semantic control ensures that s do not cause problem, and it is one of the main features of applying the TOS approach. This approach could be useful for other systems without -definitions or non-structural -definitions for similar metatheoretical proof. }







\par{In this paper we have introduced a new formulation of dependent record types as an extension of the logical framework LF, and we give a typed operational semantics for this formulation. We have proved some metatheoretical results on this typed semantics, and by its soundness theorem, we have derived the strong normalisation of the dependent record types. Other metatheoretical results such as the Church-Rosser property, subject reduction, etc., could be similarly derived. }

\par{Coquand \emph{et. al} have presented also a metatheoretical study in \cite{ctp:semantic-records05}, on a system of record kinds. They have given a proof of termination of type-checking for the record types; different with their method, we have shown that the typed semantical method to prove strong normalisation that Goguen suggested could also apply on our dependent record types. }

\par{As Goguen's work has established a full metatheory for the UTT and the LF, we here also similarly set up a full metatheory for the DRTs with a same way. Our work has led to an understanding on the following two points: First, the DRTs with intensional manifest fields developed in previous work \cite{luo:TYPES08,luo:MLPA09} own good metatheoretical properties, which would support themselves further as a modelling foundation to module mechanism; Second, this technique used here of the typed operational semantics could be applied to other type systems with structural -rules. In conclusion, the methodology of applying TOS has set up a relation between well-formedness in the TOS and well-behaveness in original systems, which is ensured by the typing control of the TOS. }

\par{In the future, we have a few attempts concerning the approach discussed in this paper. Firstly, we would like to extend this technique to wider range of type systems, such as to the Logical Framework with inductive schemata and the dependent record types together with other types such as the unit types.
Also, we are interested to find out if this technique could be applied
to ill-behaving (e.g. non-SN) calculi, or, for not only proving strong normalisation, we would like to also prove weak-head normalisation in related type systems. }





\paragraph{Comparason with other Systems of Dependent Records}
\par{Dependent record types have been previously studied in \cite{MacQ:module86, Harper-Lillibridge93, bet-tar:subtyping98, Pollack:records02, ctp:semantic-records05}, with applications to the study of module mechanisms for both programming and proof languages.
MacQueen has firstly suggested in \cite{MacQ:module86} a module system using dependent -types as module signatures, which combines the first ideas coming from ML on data abstraction, and from Pebble on dependent Sigma types.
Later, Harper and Lillibridge have put more emphasis on the \emph{control of information flow} between program units, i.e. the idea of sharing, and have proposed in \cite{Harper-Lillibridge93} the weak sum type to implement the ML-style ``sharing by equation'', or called ``sharing by coherence conditions''; but in their formulation, the bounded quantification used is proven to be undecidable, the reason is by the FORGET-rule which loses type information. This has been proved similarly as in Pierce's proof for undecidability of  \cite{Pie94}.  }

\par{Betarte and Tasistro have suggested in \cite{bet-tar:subtyping98} a different record system, i.e. of \emph{record kinds},
with type inclusion to represent subtyping, this system is proved to be decidable (the proof is called unicity of right identity); however the record kinds are simpler than record types as a structure.
Pollack presented in \cite{Pollack:records02} a system with dependent record types which is similar to ours however allows repetition of field labels. }





}

\vspace{0.6cm}

\noindent\textbf{Acknowledgement} The authors would like to thank Robin Adams for discussions on dependent record types and the first author thanks Cody Roux for discussions.

\bibliographystyle{alpha}
\bibliography{bib}

\selfc{
\begin{thebibliography}{BCGS91}


\bibitem[BT98]{BT98}
G. Betarte and A. Tasistro.
\newblock \emph{Extension of Martin-L\"{o}f's Type Theory with Record Types and Subtyping}.
\newblock Twenty-five Years of Constructive Type Theory, 1998.
\bibitem[CPT05]{CPT05}
T. Coquand, R. Pollack and M. Takeyama.
\newblock \emph{A Logical Framework with Dependently Typed Records}.
\newblock Fundamenta Informaticae, 65(1-2), 2005.
\bibitem[Fen10]{Fen10}
Y. Feng.
\newblock \emph{A Theory of Dependent Record Types with Structural Subtyping}.
\newblock Ph.D. thesis, RHUL, 2010.
\bibitem[Gog94]{Gog94}
H. Goguen.
\newblock \emph{A typed operational semantics for type theory}.
\newblock Ph.D. thesis, University of Edinburgh, August 1994.
\bibitem[Gog99]{Gog99}
H. Goguen.
\newblock \emph{Soundness of Typed Operational Semantics for the Logical Framework}.
\newblock Lecture Notes in Computer Science, vol. 1581, pp. 177-197, Springer-Verlag, 1999.
\selfc{
\bibitem[HHP93]{HHP93}
R. Harper, F. Honsell and G. Plotkin.
\newblock \emph{A framework For defining logics}.
\newblock Journal of the Association for Computing Machinery, 40(1):143-184, 1993.
}\bibitem[HL94]{HL94}
R. Harper and M. Lillibridge.
\newblock \emph{A Type-theoretic Approach to Higher-order Modules with Sharing}.
\newblock POPL'94, 1994.
\bibitem[Luo94]{Luo94}
Z. Luo.
\newblock \emph{Computation and Reasoning: a type theory for computer science}.
\newblock Oxford University Press, 1994.
\selfc{
\bibitem[Luo07]{Luo07}
Z. Luo.
\newblock \emph{A type-theoretic framework for formal reasoning with different logical foundations}.
\newblock Advances in Computer Science. Proc. of the 11th Annual Asian Computing Science Conference. LNCS 4435. 2007.
}\bibitem[Luo09a]{Luo08}
Z. Luo.
\newblock \emph{Manifest fields and module mechanisms in intensional type theory}.
\newblock Types for Proofs and Programs. Proc. of Inter. Conf. of TYPES'08. LNCS 5497. 2009.
\bibitem[Luo09b]{Luo09}
Z. Luo.
\newblock \emph{Dependent Record Types Revisited}.
\newblock Proc. of the 1st Inter. Workshop on Modules and Libraries for Proof Assistants (MLPA'09), Montreal. ACM Inter. Conf. Proceeding Series; Vol. 429. 2009.
\bibitem[Mac86]{Mac86}
D. MacQueen.
\newblock \emph{Using dependent types to express modular structure}.
\newblock POPL'86, 1986.
\bibitem[NPS90]{NPS90}
B. Nordstr\"{o}m, K. Petersson, J. M. Smith.
\newblock \emph{Programming in Marin-L\"{o}f type theory}.
\newblock Oxford University Press, 1990.
\bibitem[Pie94]{Pie94}
B. Pierce.
\newblock \emph{Bounded quantification is undecidable}.
\newblock Information and Computation, 112(1):131-165, 1994.
\bibitem[Pol02]{Pol02}
R. Pollack.
\newblock \emph{Dependently typed records in type theory}.
\newblock Formal Aspects of Computing, 13:386-402, 2002.

\end{thebibliography}
}

\appendix

\section{Inference Rules of LF}
\label{app:LF-rules}

The inference rules of the logical framework LF are given below.  (See Chapter 9 of \cite{luo:book94} for further details.)

\ \\
\noindent
\ \ \ \emph{Contexts and assumptions}

\emph{General equality rules}


\emph{Equality typing rules}

\emph{Substitution rules}




\emph{The kind Type}

\emph{Dependent product kinds}





\selfc{
\begin{figure}[top]
\framebox[5.8in][l]{
\begin{minipage}{\linewidth}
\ \ \ \emph{Contexts and assumptions}

\ \ \ \emph{General equality rules}


\ \ \ \emph{Equality typing rules}

\ \ \ \emph{Substitution rules}




\ \ \ \emph{The kind Type}

\ \ \ \emph{Dependent product kinds}




\end{minipage}
}\caption{Inference Rules of Logical Framework} \label{LF-rules}
\end{figure}
}

\section{Inference Rules of Typed Operational Semantics for LF}
\label{app:LF-TOSrules}

The inference rules of the TOS for LF are given below.  (See \cite{healf:TLCA99YY,healf:thesis} for further details.)

\ \\

\ \ \ \emph{Contexts}


\ \ \ \emph{Kinds}

\\


\ \ \ \emph{Terms}

\\

\\

\\

\\



\selfc{
\begin{figure}[here] \framebox[6.2in][l]{
\begin{minipage}{\linewidth}
\ \\

\ \ \ \emph{Contexts}


\ \ \ \emph{Kinds}

\\


\ \ \ \emph{Terms}

\\

\\

\\

\\

\\
\end{minipage}
}\caption{Inference Rules of Typed Operational Semantics for LF} \label{TOS-LF-rules}
\end{figure}

}

\end{document} 