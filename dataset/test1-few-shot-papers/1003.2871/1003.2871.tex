\label{sec:task-translation}

This section details how the compilation process translates the input
program into a set of real-time tasks. We first extract a task graph
from the program, where tasks are related by precedence constraints. We
then encode task precedences in task real-time attributes to obtain a
set of independent tasks.

\subsection{Task Graph Extraction}
\label{sec:extraction}
\subsubsection{Tasks}

A synchronous program consists of a hierarchy of nodes, the leaves of
which are predefined or imported nodes. The task graph generation
process first inlines intermediate nodes appearing in the main node
recursively, replacing each intermediate node call by its set of
equations. For instance, the program of the Flight Control System of
Sect. \ref{sec:CDV-prog} is translated into a single node (the main node
\lstinline!FCS!) containing one node call to each imported node,
\lstinline!PA!, \lstinline!AA!, \lstinline!FL!,
\lstinline!PF!, \lstinline!PL!, \lstinline!NF!, \lstinline!NL!, one node
call to operator , one node call to operator \lstinline!fby!
and three node calls to operator .

This ``flattened'' main node is then translated into a task graph. Each
imported node call is translated into a task. Each variable of the node
and predefined operator call is also translated into a vertex but will
later be reduced to simplify the graph (see
Sect. \ref{sec:reduced-graph}). The clustering of several nodes into the
same task to reduce the number of generated tasks is
beyond the scope of this paper. We could probably reuse existing
strategies, for instance those suggested in \cite{curic05}.

\subsubsection{Task Precedences}
In order to respect the synchronous semantics, for each data-dependency there
must be a precedence from the task producing the data to the task
consuming it. Task precedences are deduced from data dependencies
between expressions of the program. Similarly to \cite{halbwachs91b}, we
say that an expression  precedes an expression  when 
syntactically depends on . This occurs either when  appears in
 or when  appears in  and we have an equation . Let
 denote a task graph, where  is the set of tasks of the
graph and  is the set of task precedences of the graph (a subset of
). For instance, the flattened Flight Control program
contains the two equations \lstinline!pos_o=NF(pos_i/^12);!
\lstinline!pos_i=PA(pos);!. These equations produce the following graph:
\lstinline!NF,PA,/^12,pos,pos_i,pos_o!,
\lstinline!pos! \lstinline!PA!, \lstinline!PA!
\lstinline!pos_i!, \lstinline!pos_i! \lstinline!/^12!,
\lstinline!/^12! \lstinline!NF!, \lstinline!NF!  
\lstinline!pos_o!.

\subsubsection{Task Graph Reduction}
\label{sec:reduced-graph}
We then simplify the intermediate graph structure. First, each input of
the main node is translated into a (sensor) task and each output of the
main node is translated into a (actuator) task. Second, we remove
variables from the graph, replacing recursively each pair of precedence
, where  is a local variable, by a single
precedence .

We finally translate predefined nodes into \textit{precedence
  annotations}. A precedence  represents an
\textit{extended precedence}, where  is a list of precedence
annotations , with .  denotes the list whose head is  and
whose tail is  and  denotes the empty list. For instance,
the precedences \lstinline!PA! \lstinline!pos_i!,
\lstinline!pos_i! \lstinline!/^12!, \lstinline!/^12!
\lstinline!NF! are simplified into a single extended precedence
\lstinline!PA!\lstinline!NF!. When the rewriting terminates,
every task of the graph corresponds to either an imported node or a
sensor or an actuator. The reduced task graph of the Flight Control
System is given in Fig. \ref{fig:prec-graph}.


\begin{figure}[hbt]
  \centering
  \centering \includegraphics[width=.5\linewidth]{CDV-reduced}
  \caption{Reduced task graph for the Flight Control System program}
  \label{fig:prec-graph}
\end{figure}



\subsection{Real-Time Characteristics Extraction}
Each task  of the graph is characterized by its
real-time attributes .  is instantiated
periodically with period . It cannot start its execution before all
its predecessors, defined by the precedence constraints, complete their
execution.  is the (worst case) execution time of the task. 
is the release date of the first instance of the task. The subsequent
release dates are , , etc.  is the relative
deadline of the task. The absolute deadline  of the instance 
of a task  is the release date  of this instance plus
the relative deadline of the task: .  Task real-time
characteristics are extracted as follows:
\begin{itemize}
\item \emph{Periods}: The period of a task is obtained from its clock . We have .
\item \emph{Deadlines}: By default, the deadline of a task is its period (). Deadline
constraints can also be specified on the production of a node output
(\lstinline!o: due n!).
\item \emph{Release Dates}: The initial release date of a task is the phase of its clock:
.
\item \emph{Execution Times}: The execution time  of a task is
  directly specified by the \lstinline!wcet! of the imported node
  declaration. For simplification, we consider that the run-time
  overhead due to task preemptions is negligible.
\end{itemize}





\subsection{Precedence Encoding}
\label{sec:prec-encoding}
\subsubsection{Simple Precedences Encoding}
\cite{chetto90} showed that a set of dependent tasks (task related by
precedence constraints) can be reduced to a set of independent ones
(without precedences) obtaining an equivalent problem under the EDF
policy, by adjusting task release dates and deadlines such that
precedences are encoded in the adjusted real-time characteristics. The
adjusted absolute deadline  of a task is:

If we want to perform a schedulability test, the adjusted release date of a task
is: 

 If we
only want to schedule the program correctly, the adjusted release date
of a task  is:

For simplification, we only
consider the second encoding in the following.

\subsubsection{Extended Precedences Encoding}
Fig. \ref{fig:multi-prec}, shows that we can unfold extended precedences
between tasks into simple precedences between task instances. The
precedence encoding technique can then be applied to
the ``unfolded'' graph.

\begin{figure}[hbt]
  \centering
  \subfigure[]
  {\label{fig:fast-to-slow-prec}
    \includegraphics[width=.2\linewidth]{fast-to-slow-enc}}
  \hfill
  \subfigure[]
  {\label{fig:slow-to-fast-prec}
    \includegraphics[width=.2\linewidth]{slow-to-fast-enc}}
  \hfill
  \subfigure[]
  {\label{fig:delayed-prec}
    \includegraphics[width=.2\linewidth]{delayed-prec-enc}}
  \hfill
  \subfigure[]
  {\label{fig:offset-prec}
    \includegraphics[width=.2\linewidth]{offset-prec}}
  \caption{Encoding extended precedences}
  \label{fig:multi-prec}
\end{figure}

More formally, let  denote a precedence
from task instance  to task instance . From the
semantics of predefined operators, we have
, with  defined as follows:

The precedence relation is an over-approximation of the data-dependency
relation. Indeed, there is a data dependency between  and
, meaning that  consumes the data produced by
, if and only if .

We can then adapt the encoding to our context. For each precedence
, we must adjust the release dates and deadlines
of each instance  such that 
and . Concerning release dates, we
can easily prove that thanks to the synchronous semantics we already
have , so release dates do not need to be
adjusted. Concerning deadlines, we need to transpose the formulae to
relative deadlines to fit our task model. From the definition of
relative deadlines: .

\subsubsection{Deadline Calculus}
\label{sec:deadline-calculus}
In practice we do not need to unfold extended precedences to perform
their encoding. Instead, we represent the sequence of deadlines of the
instances of a task as a finite repetitive pattern called
\textit{\dword}. A \emph{unitary deadline} specifies the relative
deadline for the computation of a single instance of a task. It is
simply an integer value . A \emph{\dword} defines the sequence of
unitary deadlines for each instance of a task. The set of \dwords\ is
defined by the following grammar: . Term  denotes the infinite repetition of word . In the
following,  denotes the  unitary deadline of \dword\ 
().

Let  denote the \dword\ of task . A precedence
 is encoded by a constraint relating  to
 of the form:
 where, for
all ,  and
.

Let
.
\begin{property}
   is periodic and can be represented as a
  \dword. The set of \dwords\ is closed under operation 
  and under \dwords\ addition. As a consequence, 
  is a \dword.
\end{property}
\begin{proof}
  By induction.
\end{proof}

\begin{property}
  The \dwords\ of a task graph  can be computed with complexity
  , where  denotes the \dword\
  which has the longest size in the task graph.
\end{property}
\begin{proof}
  A reduced task graph is a DAG (when we do not consider delayed
  precedences), so we can compute the \dwords\ of the graph by
  performing a topological sort working backwards
  (starting from the end of the graph). As the complexity of a
  topological sort is , the complexity of the
  algorithm is  where  denotes
  the longest \dword\ in the task graph.
\end{proof}

For instance, for the Flight Control System program, we take ,
, , , , , .
To simplify, we take null durations for sensors and actuators. The
result of the deadline calculus is:
, ,
, ,
, ,
. The \dwords\ of tasks \lstinline!AA! and
\lstinline!PA! state that, each first repetition out of four successive
repetitions the two tasks have a shorter deadline as \lstinline!PF! and
\lstinline!PL! execute. Notice that if we set deadline  for all the
instances of \lstinline!AA! (instead of a \dword), this example is not
schedulable.

