
\subsection{Heuristics of the geometric averaging with respect to the reference
values\label{sub:Heuristics-of-the}}

Most often the pairwise comparisons method is used to transform the
\emph{PC} matrix into the ranking list of mutually compared concepts.
During the transformation to each concept a priority is assigned.
Therefore, this transformation is often called a priority deriving
method. There are many priority deriving methods. Besides the eigenvalue
based method (\ref{eq:eq:artihmetic_mean_meth}), where the ranking
values  are approximated as the arithmetic means of ,
also the geometric mean of rows is used (\ref{eq:geometric_mean_meth}).
This may suggest that also for the ranking problem with the reference
set \citep{Kulakowski2013hrea}, the arithmetic mean (\ref{eq:append3_eq1})
might be replaced by the geometric mean. This observation prompted
the author to formulate and investigate \emph{the geometric averaging
with respect to the reference values heuristics}. According to this
proposition to determine the unknown values  for 
the following non-linear equation is used: 



After rising both sides to the  power the geometric averaging
heuristics equation (\ref{eq:geometric_mean_proposal}) leads to the
non-linear equation system in the form: 



Of course, since the ranking values for 
make the reference set where the values  are known and
fixed, some products in the form  are initially
known constants. Let us denote:



for  as the constant part of each equation (\ref{eq:non_linear_eq_system}).
Thus, the non-linear equation system can be written as: 



Hence , let us denote
,
 and 
for some . It is easy to see that the above
non-linear equation system is equivalent to the following one: 



By grouping all the constant terms on the right side of each above
equation we obtain the linear equation system 




where 
for , which can be easily written down in the matrix
form 

where: 







Therefore, the solution  of the linear equation system
(\ref{eq:linear_equation_system_2a}) automatically provides the solution
to the original non-linear problem as formulated in (\ref{eq:non_linear_eq_system}).
Indeed the ranking vector  can be computed following the formula:



Importantly, as it is shown below a feasible solution of (\ref{eq:linear_equation_system_2a})
always exists. Hence, the heuristics of the averaging with respect
to the geometric mean always provides the user an appropriate ranking
function. 




\subsection{Existence of solution\label{sub:Existence-of-solution}}

The form of  is specific. The positive diagonal and
the negative off-diagonal real entries cause that 
(see Sec. \ref{sub:M-matrices}). Let us put:

and . Of course  is positively
dominant matrix. Thus, the product .
The sum of each row in  equals 

Since  is nonempty, thus its cardinality 
is greater than . This means that the sum of each row of 
is positive. Hence, due to the Theorem \ref{PlemmonsTheo}, 
is a nonsingular M-matrix (Def. \ref{def:M-matrix-def}). Thus, 
exists (i.e. ) and always the equation
(\ref{eq:linear_equation_system_2a}) has a solution in .
Due to the form of the solution of the main problem (\ref{eq:geometric_mean_solution})
 is a vector in , i.e. every its entry
is strictly positive. In other words unlike the original proposition
\citep{Kulakowski2013hrea} the heuristics of the geometric averaging
with respect to the reference values always provides a feasible ranking
result to the user.


\subsection{Optimality condition\label{sub:Optimality-condition}}

One of the reasons for introducing the geometric mean method (\ref{eq:geometric_mean_meth})
is minimizing the multiplicative error  \citep{Ishizaka2011rotm}
defined as:

In the case of the geometric averaging heuristics the multiplicative
error equation takes the form: 


The multiplicative error is commonly accepted to be log normal distributed
(in the same way the additive error would be assumed to be normally
distributed). Let  be
the sum of multiplicative errors (see \citep{Ishizaka2011rotm}) defined
as follow: 


As it is shown in the Theorem below very often the heuristics (\ref{eq:geometric_mean_proposal})
is optimal with respect to the value of multiplicative error function
. 
\begin{theorem}
The geometric averaging with respect to the reference values heuristics
minimizes the sum of multiplicative errors 
if 



for . \end{theorem}
\begin{proof}
To determine the minimum of (\ref{eq:error_funct}) let us forget
for a moment that  are constants
(the reference values), and let us treat them as any other arguments
of . In order to determine the minimum of (\ref{eq:error_funct})
the first derivative need to be calculated. Thus, 
\end{proof}

for . Due to the reciprocity of , i.e. ,
the equation (\ref{eq:first_derivative_1}) can be written as:




The function  reaches the minimum if .
This leads to the postulate that 

for . Thus, 

which is directly equivalent to (\ref{eq:geometric_mean_proposal}).
In other words any solution to the equation system (\ref{eq:non_linear_eq_system})
is a good candidate to be a minimum of (\ref{eq:error_funct}). It
remains to settle the matrix  of second derivative of . When
 is positive definite then the solution of (\ref{eq:non_linear_eq_system})
actually minimizes the function . As a result of further differentiation
is determined that the diagonal elements of  are 


\begin{proof}
where , and the other elements for which 
and  take the form:

Since the matrix  is considered for  in the point 
 such that (\ref{eq:geometric_mean_proposal})
holds, thus the first derivative of  is . Therefore, the Hessian
matrix  takes the form:

According to \citep[p. 29]{Quarteroni2000nm} if  is strictly
diagonally dominant by rows, symmetric, and with positive diagonal
entries then it is also positive definite. To meet the first strict
diagonal dominance criterion (other are satisfied) it is required
that:



for . Thus, 



Since every , then it is easy to verify that the above
equation is equivalent to the desired condition (\ref{eq:optimality_condition_theorem}). \end{proof}

