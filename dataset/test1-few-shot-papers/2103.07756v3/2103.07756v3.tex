
\documentclass{article} \usepackage{iclr2021_conference,times}




\usepackage{url}
\usepackage{float}
\usepackage{microtype}

\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} \usepackage{wrapfig}
\usepackage{amsmath}
\usepackage{url}
\usepackage{bbm}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{color}       \usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algorithmic}


\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}


\usepackage{amsmath,amsfonts,bm,amsthm}






\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}


\def\eps{{\epsilon}}


\def\reta{{\textnormal{}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbf{1}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\def\ynoise{{\widetilde{y}}}

























%
 \usepackage{enumitem}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary} 
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}

\title{Learning with feature-dependent label noise: a progressive approach}

\usepackage{hyperref}





\author{Yikai Zhang\thanks{Equal contributions.}~~,~Songzhu Zheng\footnotemark[1]~~,~Pengxiang Wu\footnotemark[1]~~,~Mayank Goswami, Chao Chen \\
Rutgers University, \texttt{\{yz422,pw241\}@cs.rutgers.edu} \\ 
Stony Brook University, ~\texttt{\{zheng.songzhu,chao.chen.1\}@stonybrook.edu}\\
City University of New York, ~\texttt{mayank.isi@gmail.com}\\
}




\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\newcommand{\myparagraph}[1]{\textbf{#1}}

\setlength{\marginparwidth}{2cm}
\usepackage[colorinlistoftodos]{todonotes}

\iclrfinalcopy \begin{document}


\maketitle

\begin{abstract}
Label noise is frequently observed in real-world large-scale datasets. The noise is introduced due to a variety of reasons; it is heterogeneous and feature-dependent. Most existing approaches to handling noisy labels fall into two categories: they either assume an ideal feature-independent noise, or remain heuristic without theoretical guarantees. 
In this paper, we propose to target a new family of feature-dependent label noise, which is much more general than commonly used i.i.d.~label noise and encompasses a broad spectrum of noise patterns.
Focusing on this general noise family, we propose a progressive label correction algorithm that iteratively corrects labels and refines the model. We provide theoretical guarantees showing that for a wide variety of (unknown) noise patterns, a classifier trained with this strategy converges to be consistent with the Bayes classifier. 
In experiments, our method outperforms SOTA baselines and is robust to various noise types and levels.

\end{abstract}

\section{Introduction}

Addressing noise in training set labels is an important problem in supervised learning. Incorrect annotation of data is inevitable in large-scale data collection, due to intrinsic ambiguity of data/class and mistakes of human/automatic annotators \citep{yan_2014learning,Veit_LearnNoise_CVPR2017}. Developing methods that are resilient to label noise is therefore crucial in real-life applications.

Classical approaches take a rather simplistic \emph{i.i.d.~assumption} on the label noise, i.e., the label corruption is independent and identically distributed and thus is feature-independent. 
Methods based on this assumption either explicitly estimate the noise pattern \citep{reed_bootstrapping_ICLRW2014, patrini_CVPR2017_FCorrection, Hendrycks_selfsuper_2019_ICML, xu_dmi_2019l_NIPS} or introduce extra regularizer/loss terms \citep{natarajan_learning_NIPS2013, Rooyen_unhinge_2015_NIPS, cloth1m, gce_nips2018, Ma_dim_driven_ICML18, dynamic_bootstrap_2019_icml, shen2019learning}. Some results prove that the commonly used losses are naturally robust against such i.i.d. label noise \citep{manwani_noisetolerance_2013, Ghosh_riskmini_2015_NIPS,gao_2016_arXiv, ghosh2017robust,  charoenphakdee2019symmetric, simple_reg_iclr2020}. 

Although these methods come with theoretical guarantees, they usually do not perform as well as expected in practice due to the unrealistic i.i.d.~assumption on noise. This is likely because \emph{label noise is heterogeneous and feature-dependent.} A cat with an intrinsically ambiguous appearance is more likely to be mislabeled as a dog. An image with poor lighting or severe occlusion can be mislabeled, as important visual clues are imperceptible. 
Methods that can combat label noise of a much more general form are very much needed to address real-world challenges.

To adapt to the heterogeneous label noise, state-of-the-arts (SOTAs) often resort to a \emph{data-recalibrating} strategy.
They
progressively identify trustworthy data or correct data labels, and then train using these data~\citep{tanaka2018joint, Wang_open_set_CVPR2018, Jiang_MentorNet_ICML18, learning_to_learn_cvpr2019}. 
The models gradually improve as more clean data are collected or more labels are corrected, eventually converging to models of high accuracy.
These data-recalibrating methods best leverage the learning power of deep neural nets and achieve superior performance in practice. However, their underlying mechanism  remains a mystery. No methods in this category can provide theoretical insights as to why the model can converge to an ideal one. Thus, these methods require careful hyperparameter tuning and are hard to generalize.

\begin{figure}[b!]
\centering
\begin{tabular}{cccc}
\includegraphics[scale=0.22]{figs/demon/Demon_a.png} &
\includegraphics[scale=0.22]{figs/demon/Demon_b.png} &
\includegraphics[scale=0.22]{figs/demon/Demon_c.png} &
\includegraphics[scale=0.22]{figs/demon/Demon_d.png}
\\
(a) Clean Data & (b) Corrupted Data & (c) Corrected Data & (d) Corrected Labels \\
\includegraphics[scale=0.22]{figs/demon/Demon_e.png} &
\includegraphics[scale=0.22]{figs/demon/Demon_f.png} &
\includegraphics[scale=0.22]{figs/demon/Demon_g.png} & 
\includegraphics[scale=0.22]{figs/demon/Demon_h.png} 
\\
(e) Epoch 10 & (f) Epoch 20 & (g) Epoch 30 & (h) Final Epoch
\end{tabular}
\caption{Illustration of the algorithm using synthetic data. (a) Gaussian blob with clean label (). (b) Data with corrupted labels. (c) Final corrected data. Black dots are the data that have their clean labels. Red dots are the noisy data. Points that remain un-corrected are closer to the decision boundary. Our algorithm corrects most of the noise only using noisy classifier's confidence. (d) Data after label correction. (e)-(h) We show the intermediate results at different iterations. Gray region is the area where the classifier has high confidence. Labels within this region are corrected. }
\label{fig:demo}
\end{figure}

In this paper, we propose a novel and principled method that specifically targets the heterogeneous, feature-dependent label noise. Unlike previous methods, we target a much more general family of noise, called \emph{Polynomial Margin Diminishing} (PMD) label noise. 
In this noise family, we allow arbitrary noise level except for data far away from the true decision boundary.
This is consistent with the real-world scenario; data near the decision boundary are harder to distinguish and more likely to be mislabeled. Meanwhile, a datum far away from the decision boundary is a typical example of its true class and should have a reasonably bounded noise level.

Assuming this new PMD noise family, we propose a theoretically-guaranteed data-recalibrating algorithm that gradually corrects labels based on the noisy classifier's confidence. We start from data points with high confidence, and correct the labels of these data using the predictions of the noisy classifier. Next, the model is improved using cleaned labels. We continue alternating the label correction and model improvement until it converges.
See Figure \ref{fig:demo} for an illustration. 
Our main theorem shows that with a theory-informed criterion for label correction at each iteration, the improvement of the label purity is guaranteed. Thus the model is guaranteed to improve with sufficient rate through iterations and eventually becomes consistent with the Bayes optimal classifier. 

Beside the theoretical strength, we also demonstrate the power of our method in practice. Our method outperforms others on CIFAR-10/100 with various synthetic noise patterns. We also evaluate our method against SOTAs on three real-world datasets with unknown noise patterns.

To the best of our knowledge, our method is the first data-recalibrating method that is theoretically guaranteed to converge to an ideal model. The PMD noise family encompasses a broad spectrum of heterogeneous and feature-dependent noise, and better approximates the real-world scenario. It also provides a novel theoretical setting for the study of label noise.

\myparagraph{Related works.}
We review works that do not assume an i.i.d.~label noise. 
\cite{Aditya_Binary_Instance_2018_MachLearn} generalized the work of \citep{Ghosh_riskmini_2015_NIPS} and provided an elegant theoretical framework, showing that loss functions fulfilling certain conditions naturally resist instance-dependent noise. The method can achieve even better theoretical properties (i.e., Bayes-consistency) with stronger assumption on the clean posterior probability .
In practice, this method has not been extended to deep neural networks.
\cite{jiacheng_BoundedInstance_2020_ICML} proposed an active learning method for instance-dependent label noise. The algorithm iteratively queries clean labels from an oracle on carefully selected data. However, this approach is not applicable to settings where kosher annotations are unavailable.
Another contemporary work \citep{chen2020beyond} showed that the noise in real-world dataset is unlikely to be i.i.d., and proposed to fix the noisy labels by averaging the network predictions on each instance over the whole training process. While being effective, their method lacks theoretical guarantees.
\cite{chen2019topological} showed by regulating the topology of a classifier's decision boundary, one can improve the model's robustness against label noise. 

Data-recalibrating methods use noisy networks' predictions to iteratively select/correct data and improve the models.
\cite{tanaka2018joint} introduced a joint training framework which simultaneously enforces the network to be consistent with its own predictions and corrects the noisy labels during training. \cite{Wang_open_set_CVPR2018} identified noisy labels as outliers based on their label consistencies with surrounding data. \cite{Jiang_MentorNet_ICML18} used a curriculum learning strategy where the teacher net is trained on a small kosher dataset to determine if a datum is clean; then the learnt curriculum that gives the weight to each datum is fed into the student net for the training and inference. \citep{yu_coteachingplus_2019_ICML,Han_Co-Teaching_NIPS2018} trained two synchronized networks; the confidence and consistency of the two networks are utilized to identify clean data. \cite{wu2020topological} selected the clean data by investigating the topological structures of the training data in the learned feature space.
For completeness, we also refer to other methods of similar design~\citep{li_distillation_ICCV2017, vahdat2017toward, Veit_LearnNoise_CVPR2017, Ma_dim_driven_ICML18, abstention, dynamic_bootstrap_2019_icml,  Meta-Weight-Net_nips2019,  pencil_cvpr2019}. 

As for theoretical guarantees,
\cite{Ren_Reweight_ICML2018} proposed an algorithm that iteratively re-weights each data point by solving an optimization problem. They proved the convergence of the training, but provided no guarantees that the model converges to an ideal one. \cite{BregmanDiv_2019_NIPS} generalized the work of \citep{TsallisDiv_2019_PMLR} and proposed a tempered matching loss. They showed that when the final softmax layer is replaced by the bi-tempered loss, the resulting classifier will be Bayes consistent. 
\cite{songzhu_2020_ICML} proved a one-shot guarantee for their data-recalibrating method; but the convergence of the model is not guaranteed. 
\emph{Our method is the first data-recalibrating method which is guaranteed to converge to a well-behaved classifier.}

\section{Method}

We start by introducing the family of Poly-Margin Diminishing (PMD) label noise. In Section \ref{sec:alg}, we present our main algorithm. Finally, we prove the correctness of our algorithm in Section \ref{sec:theory}.

\newcommand{\calX}{\mathcal{X}}

\textbf{Notations and preliminaries.} 
Although the noise setting and algorithm naturally generalize to multi-class, for simplicity we focus on binary classification.
Let the feature space be .
We assume the data  is sampled from an underlying distribution  on . Define the posterior probability . Let  and  be the noise functions, where  denotes the corrupted label. For example, if a datum  has true label , it has  chance to be corrupted to 1. Similarly, it has  chance to be corrupted from 1 to 0. Let  be the noisy posterior probability of  given feature .  Let  be the (clean) Bayes optimal classifier, where  equals 1 if  is true, and 0 otherwise. Finally, let  be the classifier scoring function (the softmax output of a neural network in this paper). 

\subsection{Poly-Margin Diminishing Noise}
\label{sec:noise}

We first introduce the family of noise functions  this paper will address. We introduce the concept of \emph{polynomial margin diminishing noise} (PMD noise), which only upper bounds the noise  in a certain level set of , thus allowing  to be arbitrarily high outside the restricted domain. This formulation not only covers the feature-independent scenario but also generalizes scenarios proposed by \citep{du_BCN_2015_AAAI,  Aditya_Binary_Instance_2018_MachLearn,jiacheng_BoundedInstance_2020_ICML}.

\begin{definition}[PMD noise] \label{poly_diminish}
A pair of noise functions  and  are polynomial-margin diminishing (PMD), if there exist constants , and  such that:

\end{definition}

We abuse notation by referring to  as the ``margin'' of . Note that the PMD condition only requires the \emph{upper bound} on  to be polynomial and monotonically decreasing in the region where the Bayes classifier is fairly confident. For the region , we allow both  and  to be arbitrary. Figure \ref{fig:noise}(d) illustrates the upper bound (orange curve) and a sample noise function (blue curve). We also show the corrupted data according to this noise function (black points are the clean data whereas red points are the data with corrupted labels). 

The PMD noise family is much more general than existing noise assumptions. 
For example, the boundary consistent noise (BCN) \citep{du_BCN_2015_AAAI,Aditya_Binary_Instance_2018_MachLearn} assumes a noise function that monotonically decreases as the data are moving away from the decision boundary. See Figure \ref{fig:noise}(c) for an illustration.
This noise is much more restrictive compared to our PMD noise which (1) only requires a monotonic upper bound, and (2) allows arbitrary noise strength in a wide buffer near the decision boundary. 
Figure \ref{fig:noise}(b) shows a traditional feature-independent noise pattern \citep{reed_bootstrapping_ICLRW2014,patrini_CVPR2017_FCorrection}, which assumes  (resp.~) to be a constant independent of . 

\begin{figure*}[htb!]
\centering
\begin{tabular}{cccc}
\includegraphics[width=0.22\textwidth]{figs/noise/clean_label.png} &
\includegraphics[width=0.22\textwidth]{figs/noise/uniform_label.png} &
\includegraphics[width=0.22\textwidth]{figs/noise/BCN_label.png} &
\includegraphics[width=0.22\textwidth]{figs/noise/ours_label.png}\\
\includegraphics[width=0.22\textwidth]{figs/noise/clean_eta.png} &
\includegraphics[width=0.22\textwidth]{figs/noise/uniform_noise.png} &
\includegraphics[width=0.22\textwidth]{figs/noise/BCN_noise.png} &
\includegraphics[width=0.22\textwidth]{figs/noise/ours_noise.png}\\
(a) Clean labels & (b) Uniform noise & (c) BCN noise & (d) PMD noise
\end{tabular}
\caption{Illustration of different noise functions. (a) The original data: Gaussian blob with clean labels (by clean label, we refer to the prediction of the Bayes optimal classifier , not ). Confident region of  (and thus ) in this case is the place where  is close to 0 or 1. Blue and green dots correspond to different classes. (b) Uniform label noise: each point has an equal probability to be flipped. Red dots are data with corrupted labels; black dots correspond to data that are not corrupted. (c) BCN noise: the level of noise is decreasing as  becomes confident. (d) PMD noise: noise level (blue) is only upper bounded by diminishing polynomial function when  is higher or lower than certain threshold. The upper bound is shown in solid orange curve. The dashed orange curve means the noise level near the decision boundary is unbounded.}
\label{fig:noise}
\end{figure*}

\subsection{The Progressive Correction Algorithm}
\label{sec:alg}
Our algorithm iteratively trains a neural network and corrects labels. 
We start with a warm-up period, in which we train the neural network (NN) with the original noisy data. This allows us to attain a reasonable network before it starts fitting noise \citep{Zhang_noise_ICLR2017}.
After the warm-up period, the classifier can be used for label correction. 
We only correct a label on which the classifier  has a very high confidence. 
The intuition is that under the noise assumption, there exists a ``pure region'' in which the prediction of the noisy classifier  is highly confident and is consistent with the clean Bayes optimal classifier .
Thus the label correction gives clean labels within this pure region.
In particular, we select a high threshold . If  predicts a different label than  and its confidence is above the threshold, , we flip the label  to the prediction of .
We repeatedly correct labels and improve the network until no label is corrected.
Next, we slightly decrease the threshold , use the decreased threshold for label correction, and improve the model accordingly. We continue the process until convergence.
For convenience in theoretical analysis, in the algorithm, we define a continuous increasing threshold  and let .
Our algorithm is summarized in Algorithm~\ref{alg:PLC}. We term our algorithm as PLC (Progressive Label Correction).
In Section \ref{sec:theory}, we will show that this iterative algorithm will converge to be consistent with clean Bayes optimal classifier  for most of the input instances.

\begin{table}[h]
\centering
\begin{minipage}[t]{1\textwidth}
\begin{algorithm}[H] 
\caption{\texttt{Progressive Label Correction}}
\label{alg:PLC}
\begin{algorithmic}[1]
\REQUIRE Dataset , initial NN , step size ,\\
initial and end thresholds , warm-up , total round 
\ENSURE 
\STATE 
\STATE 
\FOR {}
    \STATE Train  on 
\FORALL{ \AND }
    \STATE   {}    
    \ENDFOR
    \IF {}
    \STATE 
\IF {}
    \STATE {}
    \ENDIF
    \ENDIF
    \STATE {}
\ENDFOR
\end{algorithmic}
\end{algorithm}
\end{minipage}
\end{table}

\myparagraph{Generalizing to the multi-class scenario.} In multi-class scenario, denote by  the classifier's prediction probability of label . Let  be the classifier's class prediction, i.e., . 
We change the  term to the gap between the highest confidence  and the confidence on , . If the absolute difference between these two confidences is larger than certain threshold , then we correct  to . In practice, we find using the difference of logarithms will be more robust.

\section{Analysis}
\label{sec:theory}
\vspace{-0.5em}

Our analysis focuses on the asymptotic case and answers the following question: Given infinitely many data with corrupted labels, is it possible to learn a reasonably good classifier? We show that if the noise satisfies the arguably-general PMD condition, the answer is yes. Assuming mild conditions on the hypothesis class of the machine learning model and the distribution , we prove that Algorithm~\ref{alg:PLC} obtains a nearly clean classifier. This reduces the challenge of noisy label learning from a realizable problem into a sample complexity problem. In this work we only focus on the asymptotic case, and leave the sample complexity for future work.

\subsection{Assumptions}
\vspace{-0.5em}

Our first assumption restricts the model to be able to at least approximate the true Bayes classifier . This condition assumes that given a hypothesis class  with sufficient complexity, the approximation gap between a classifier  in this class and  is determined by the inconsistency between the noisy labels and the Bayes optimal classifier. 

\begin{definition} [Level set -consistency] \label{levelset_consist}
Suppose data are sampled as   and . Given , we call  is -consistent if:

\end{definition}

For two input instances  and  such that  (and hence the clean Bayes optimal classifier  has higher confidence at  than it does at ), the indicator function  equals to 1 if the label of the more confident point  is inconsistent with . This condition says that the approximation error of the classifier at  should be controlled by the risk of  at points  where  is more confident than it is at . 

We next define a regularity condition of data distribution which describes the continuity of the level set density function.

 \begin{definition} [Level set bounded distribution] \label{leverlset_lip}
 Define the margin  and   be the cdf of : . Let  be the density function of . We say the distribution  is -bounded if for all , . If  is -bounded, we define the worst-case density-imbalance ratio of  by := .
 \end{definition}
 
The above condition enforces the continuity of level set density function. This is crucial in the analysis since such a continuity allows one to borrow information from its neighborhood region so that a clean neighbor can help correct the corrupted label. To simplify the notation, we will omit  in the subscript when we mention . From now on, we will assume:

\noindent\textbf{Assumption 1.} There exist constants  such that the hypothesis class  is  -consistent and the unknown distribution  is -bounded.

\subsection{Main Result and Proof Sketch}

In this section we first state our main result, and then present the supporting claims. Complete proofs can be found in the appendix. Our main result below states that if our starting function is trained correctly, i.e., , then Algorithm~\ref{alg:PLC} terminates with most of the final labels matching the Bayes optimal classifier labels. In practice, minimizing true risk is not achievable. Instead, the empirical risk is used to estimate true risk, approaching true risk asymptotically. For a scoring function , we will denote by  the label predicted by . 

\begin{theorem} \label{main}
Under Assumption 1, for any noise  which is PMD with margin , define . Then for the output of Algorithm \ref{alg:PLC}
 with  as above and with the following initializations: (1) , (2) , (3) , (4)  and (5)  , we have: 
\end{theorem}

In the remainder of this section we shall assume that the noise  is PMD with margin . To prove our result we first define a ``pure'' level set. 
 \begin{definition} [Pure -level set]
 A set  is pure for  if  for all . 
 \end{definition}

We now state a lemma that forms the foundation of our progressive correction algorithm. We show that given a tiny region where the model is reliable, we can move one step forward by trusting the model. Although the improvement is slight in a single round, it empowers a conservatively  recursive step in the Algorithm \ref{alg:PLC}.

\begin{lemma}[One round purity improvement] \label{one_round}
Suppose Assumption 1 is satisfied, and assume an  such that there exists a pure -level set with . Let  if  and  if  , and assume .
Let . Then .


\end{lemma}

The above lemma states that the cleansed region will be enlarged by at least a constant factor. In the following lemma, we justify the functionality of the first  warm-up rounds. Since the initial neural network can behave badly, the region where we can trust the classifier can be very limited. Before starting the flipping procedure in a relatively larger level set, one first needs to expand the initial tiny region  to a constant .  
\begin{lemma}[Warm-up rounds] \label{First stage}
Suppose for a given function  there exists a level set  which is pure for . Given , after running Algorithm \ref{alg:PLC} for  rounds, there exists a level set  that is pure for .  
\end{lemma}

Next we present our final lemma that combines the previous two lemmata. 

\begin{lemma} \label{main2}
Suppose Assumption 1 is satisfied, and for a given function  there exists a level set  which is pure for . If one runs Algorithm \ref{alg:PLC} starting with  and the initializations: (1) , (2) , (3) , (4)  and (5) , then we have .
\end{lemma}

This lemma states that given an initial model that has a reasonably pure super level set, one can manage to progressively correct a large fraction of corrupted labels by running Algorithm \ref{alg:PLC} for a sufficient long time with carefully chosen parameters. The limit of Algorithm \ref{alg:PLC} will depend on the approximation ability of the neural network, which is characterized by parameter  in Definition \ref{levelset_consist}. 
To prove  Theorem \ref{main} using Lemma~\ref{main2}, it suffices to get a model which has a reliable region. This is provably achievable by training with a family of good scoring functions on PMD noisy data.

\section{Experiments}

We evaluate our method on both synthetic and real-world datasets.
We first conduct synthetic experiments on two public datasets CIFAR-10 and CIFAR-100 \citep{cifar10_100}. To synthesize the label noise, we first approximate the true posterior probability  using the confidence prediction of a clean neural network (trained with the original clean labels). We call these original labels \textit{raw labels}. Then we sample  for each instance . Instead of using raw labels, we use these sampled labels  as the clean labels, whose posterior probabilities are exactly ; and therefore the neural network is the Bayes optimal classifier , where  is the number of classes. Note that in multi-class setting,  has a vector output and  is the -th element of this vector.  

\textbf{Noise generation.} We consider a generic family of noise. We consider not only feature-dependent noise, but also hybrid noise that consists of both feature-dependent noise and i.i.d.~noise. 

For feature-dependent noise, we use three types of noise functions within the PMD noise family. To make the noise challenging enough, for input  we always corrupt label from the most confident category  to the second confident category , according to . Because  is the class that confuses  the most, this noise will hurt the network's performance the most. Note that  is sampled from , which has quite an extreme confidence. Thus we generally assume  is . For each datum , we only flip it to  or keep it as . The three noise functions are as follows:

Notice that the noise level is determined by the  naturally and we cannot control it directly. To change the noise level, we multiply  by a certain constant factor such that the final proportion of noise matches our requirement. For PMD noise only, we test noise levels 35\% and 70\%, meaning that 35\% and 70\% of the data are corrupted due to the noise, respectively.

For i.i.d. noise we follow the convention and adopt the commonly used uniform noise and asymmetric noise \citep{patrini_CVPR2017_FCorrection}. We artificially corrupt the labels by constructing the noise transition matrix , where  defines the probability that a true label  is flipped to . Then for each sample with label , we replace its label with the one sampled from the probability distribution given by the -th row of matrix . We consider two kinds of i.i.d. noise in this work. (1) Uniform noise: the true label  is corrupted uniformly to other classes, i.e.,  for , and , where  is the constant noise level; (2) Asymmetric noise: the true label  is flipped to  or stays unchanged with probabilities  and , respectively.

\textbf{Baselines.} We compare our method with several recently proposed approaches. (1) GCE \citep{gce_nips2018}; (2) Co-teaching+ \citep{yu_coteachingplus_2019_ICML}; (3) SL \citep{sce_cvpr2019}; (4) LRT \citep{songzhu_2020_ICML}. All these methods are generic and handle the label noise without assuming the noise structures. Finally, we also provide the results by standard method, which simply trains the deep network on noisy datasets in a standard manner.

During training, we use a batch size of 128 and train the network for 180 epochs to ensure the convergence of all methods. We train the network with SGD optimizer, with initial learning rate 0.01. We randomly repeat the experiments 3 times, and report the mean and standard deviation values. Our code is available at \url{https://github.com/pxiangwu/PLC}.

\textbf{Results.} Table~\ref{tab:cifar} lists the performance of different methods under three types of feature-dependent noise at noise levels 35\% and 70\%. We observe that our method achieves the best performance across different noise settings. Moreover, notice that some of the baseline methods' performances are inferior to the standard approach. Possible reasons are that these methods behave too conservatively in dealing with noise. Thus they only make use of a small subset of the original training set, which is not representative enough to grant the model good discriminative ability.

In Table~\ref{tab:hybrid} we show the results on datasets corrupted with a combination of feature-dependent noise and i.i.d.~noise, which ends up to real noise levels ranging from 50\% to 70\% (in terms of the proportion of corrupted labels). I.i.d.~noise is overlayed on the feature-dependent noise. Our method outperforms baselines under these more complicated noise patterns. In contrast, when the noise level is high like the cases where we further apply additional 30\% and 60\% uniform noise,  performances of a few baselines deteriorate and become worse than the standard approach. 

We carry out the ablation studies on hyper-parameters  (determining the initial confidence threshold for label correction, see Algorithm~1) and  (the step size). In Tables~\ref{tab:delta} and \ref{tab:beta}, we show that our method is robust against the choice of  and  up to a wide range. Notice that to compare against the threshold , here we are calculating the absolute difference of  and . As mentioned in Section \ref{sec:alg}, this operation gives a good performance in practice.

\begin{table*}[!hbt]
	\caption{Test accuracy (\%) on CIFAR-10 and CIFAR-100 under different feature-dependent noise types and levels. The average accuracy and standard deviation over 3 trials are reported.}
	\begin{center}
	\resizebox{1.0\columnwidth}{!}{
			\begin{tabular}{c|l|ccccc|c}
\hline
Dataset & Noise & Standard & Co-teaching+ & GCE & SL & LRT & \textbf{PLC (ours)} \\
\hline
\multirow{6}{*}{CIFAR-10~~}  
  & Type-I ( 35\% ) & &  &   &  &   &  \\ 
  & Type-I ( 70\% )& & &  & & &  \\ 
  \cline{2-8} 
  & Type-II ( 35\% ) &  &  &   &  &  &  \\
  & Type-II ( 70\% ) &  &  &  &  &  &  \\
  \cline{2-8} 
  & Type-III ( 35\% ) & & &  &  &  &  \\
  & Type-III ( 70\% ) & &&&& & \\
    \hline \hline
\multirow{6}{*}{CIFAR-100} 
  & Type-I ( 35\% ) &  & 
                    &  & 
                    &  & \\
  & Type-I ( 70\% ) &  & 
                    &  &  
                    & & \\
  \cline{2-8} 
  & Type-II ( 35\% ) &  &  & 
                     &  &  & \\
  & Type-II ( 70\% ) &  &  & 
                     &  &  & \\
  \cline{2-8} 
  & Type-III ( 35\% ) &  &  & 
                      &  &  & \\
  & Type-III ( 70\% ) &  &  &  
                      &  &  & \\
\hline
			
			\end{tabular}
		}
	\end{center}
\label{tab:cifar}
\end{table*}


\begin{table*}[!hbt]
\vspace{-1.5em}
	\caption{Test accuracy (\%) on CIFAR-10 and CIFAR-100 under different hybrid noise types and levels. The average accuracy and standard deviation over 3 trials are reported.}
	\begin{center}
	\resizebox{1.0\columnwidth}{!}{
			\begin{tabular}{c|l|ccccc|c}
\hline
Dataset & Noise & Standard & Co-teaching+ & GCE & SL & LRT & \textbf{PLC (ours)} \\
\hline
\multirow{9}{*}{CIFAR-10~~}  
  & Type-I + 30\% Uniform &  &  &  &  &  &   \\
  & Type-I + 60\% Uniform &  &  &  &  &  &
   \\
  & Type-I + 30\% Asymmetric &  &  &  &  &  &
  \\
  \cline{2-8} 
  & Type-II + 30\% Uniform &  &  &  &  &  &
  \\
  & Type-II + 60\% Uniform &  &  &  &  &  &
  \\
  & Type-II + 30\% Asymmetric &  &  &  &  &  &
  \\
  \cline{2-8} 
  & Type-III + 30\% Uniform &  &  &  &  &  & 
  \\
  & Type-III + 60\% Uniform &  &  &  &  &  &  
  \\
  & Type-III + 30\% Asymmetric &  &  &  &  &  &
  
  \\
    \hline \hline
\multirow{9}{*}{CIFAR-100} 
  & Type-I + 30\% Uniform &  &  &  &  &  &
   \\
  & Type-I + 60\% Uniform &  &  &  &  &  &
  \\
  & Type-I + 30\% Asymmetric &  &  &  &  &  &
  \\
  \cline{2-8} 
  & Type-II + 30\% Uniform &  &  &  &  &  &
  \\
  & Type-II + 60\% Uniform &  &  &  &  &  &
  \\
  & Type-II + 30\% Asymmetric &  &  &  &  &  &
   \\
  \cline{2-8} 
  & Type-III + 30\% Uniform &  &  &  &  &  & 
  \\
  & Type-III + 60\% Uniform &  &  &  &  &  &
  \\
  & Type-III + 30\% Asymmetric &  &   &  &  &  & \\
	\hline
			\end{tabular}
		}
	\end{center}
	\label{tab:hybrid}
\end{table*}

\begin{table}[!htb]
\vspace{-1.5em}
    \centering
    \begin{minipage}{.48\linewidth}
        \caption{The effect of  on the performance. We use CIFAR-10 with 35\% feature-dependent noise, and set .}
        \resizebox{0.99\columnwidth}{!}{
            \begin{tabular}{c|cccc}
            \hline
                  & 0.2 & 0.3 & 0.4 & 0.5 \\
                 \hline
                 Type-I Noise & 83.33 & 83.04 & 82.66 &82.94\\
                 Type-II Noise & 81.84 & 81.18 & 81.09 & 81.24\\
                 Type-III Noise &  81.79 & 81.75 & 81.98 & 82.06\\
                 \hline
            \end{tabular}
        }
        \label{tab:delta}
    \end{minipage}~~~~
    \begin{minipage}{.48\linewidth}
        \caption{The effect of  on the performance. We use CIFAR-10 with 35\% feature-dependent noise, and set .}
        \resizebox{0.99\columnwidth}{!}{
            \begin{tabular}{c|cccc}
            \hline
                  & 0.05 & 0.1 & 0.2 & 0.3 \\
                 \hline
                 Type-I Noise & 83.58 & 83.04 & 83.28 & 83.31\\
                 Type-II Noise & 80.94 & 81.18 & 80.98 & 80.86\\
                 Type-III Noise & 81.91 & 81.75 & 82.13 & 82.39\\
                 \hline
            \end{tabular}
        }
        \label{tab:beta}
    \end{minipage}
\end{table}


\textbf{Results on real-world noisy datasets.} To test the effectiveness of the proposed method under real-world label noise, we conduct experiments on the Clothing1M dataset \citep{cloth1m}. This dataset contains 1 million clothing images obtained from online shopping websites with 14 categories. The labels in this dataset are quite noisy with an unknown underlying structure. This dataset provides 50\textit{k}, 14\textit{k} and 10\textit{k} manually verified clean data for training, validation and testing, respectively. Following \citep{tanaka2018joint,pencil_cvpr2019}, in our experiment we discard the 50\textit{k} clean training data and evaluate the classification accuracy on the 10\textit{k} clean data. Also, following \citep{pencil_cvpr2019}, we use a randomly sampled pseudo-balanced subset as the training set, which includes about 260\textit{k} images. We set the batch size 32, learning rate 0.001, and adopt SGD optimizer and use ResNet-50 with weights pre-trained on ImageNet, as in \citep{tanaka2018joint,pencil_cvpr2019}.

We compare our method with the following baselines. (1) Standard; (2) Forward Correction \citep{patrini_CVPR2017_FCorrection}; (3) D2L \citep{Ma_dim_driven_ICML18}; (4) JO \citep{tanaka2018joint}; (5) PENCIL \citep{pencil_cvpr2019}; (6) DY \citep{dynamic_bootstrap_2019_icml}; (7) GCE \citep{gce_nips2018}; (8) SL \citep{sce_cvpr2019}; (9) MLNT \citep{learning_to_learn_cvpr2019}; (10) LRT \citep{songzhu_2020_ICML}. In Table~\ref{tab:cloth1m} we observe that our method achieves the best performance, suggesting the applicability of our label correction strategy in real-world scenarios.

Apart from Clothing1M, we also test our method on another smaller dataset, Food-101N \citep{food101n}. Food-101N is a dataset for food classification, and consists of 310k training images collected from the web. The estimated label purity is 80\%. Following \citep{food101n}, the classification accuracy is evaluated on the Food-101 \citep{food101} testing set, which contains 25k images with curated annotations. We use ResNet-50 pre-trained on ImageNet. We train the network for 30 epochs with SGD optimizer. The batch size is 32 and the initial learning rate is 0.005, which is divided by 10 every 10 epochs. We also adopt simple data augmentation procedures, including random horizontal flip, and resizing the image with a short edge of 256 and then randomly cropping a 224x224 patch from the resized image. We repeat the experiments with 3 random trials and report the mean value and standard deviation. The results are shown in Table~\ref{tab:food101}. Our method much improves upon the previous approaches.

Finally, we test our method on a recently proposed real-world dataset, ANIMAL-10N \citep{song2019selfie}. This dataset contains human-labeled online images for 10 animals with confusing appearance. The estimated label noise rate is 8\%. There are 50,000 training and 5,000 testing images. Following \citep{song2019selfie}, we use VGG-19 with batch normalization. The SGD optimizer is employed. Also following \citep{song2019selfie}, we train the network for 100 epochs and use an initial learning rate of 0.1, which is divided by 5 at 50\% and 75\% of the total number of epochs. We repeat the experiments with 3 random trials and report the mean value and standard deviation. As is shown in Table~\ref{tab:animal}, our method outperforms the existing baselines.

\begin{table}[!htb]
\vspace{-0.5em}
    \centering
    \caption{Test accuracy (\%) on Clothing1M.}
    \resizebox{1.0\columnwidth}{!}{
        \begin{tabular}{c|cccccccccc|c}
        \hline
             Method &  Standard & Forward & D2L & JO & PENCIL & DY & GCE & SL & MLNT & LRT & \textbf{PLC (ours)} \\
             \hline
             Accuracy & 68.94 & 69.84 & 69.47 & 72.23 & 73.49 & 71.00 & 69.75 & 71.02 & 73.47 & 71.74 & \textbf{74.02}\\
             \hline
        \end{tabular}
    }
    \label{tab:cloth1m}
\end{table}
\vspace{-0.5em}
\begin{table}[!htb]
\vspace{-0.5em}
    \centering
    \begin{minipage}{.48\linewidth}
        \caption{Test accuracy (\%) on Food-101N.}
        \resizebox{0.99\columnwidth}{!}{
            \begin{tabular}{l|c}
            \hline
                 Method & Accuracy \\
            \hline
                 Standard & 81.67 \\
                 CleanNet \citep{food101n} & 83.95 \\
                 \textbf{PLC (ours)} & \textbf{85.28  0.04} \\
            \hline
            \end{tabular}
        }
        \label{tab:food101}
    \end{minipage}~~~~
    \begin{minipage}{.48\linewidth}
        \caption{Test accuracy (\%) on ANIMAL-10N.}
        \resizebox{0.99\columnwidth}{!}{
            \begin{tabular}{l|c}
            \hline
                 Method & Accuracy \\
                 \hline
                 Standard & 79.4  0.14\\
                 SELFIE \citep{song2019selfie} & 81.8  0.09\\
                 \textbf{PLC (ours)} & \textbf{83.4  0.43} \\
            \hline
            \end{tabular}
        }
        \label{tab:animal}
    \end{minipage}
\end{table}

\section{Conclusion}
We propose a novel family of feature-dependent label noise that is much more general than the traditional i.i.d.~noise pattern. Building upon this noise assumption, we propose the first data-recalibrating method that is theoretically guaranteed to converge to a well-behaved classifier. On the synthetic datasets, we show that our method outperforms various baselines under different feature-dependent noise patterns subject to our assumption. Also, we test our method on different real-world noisy datasets and observe superior performances over existing approaches. The proposed noise family offers a new theoretical setting for the study of label noise.

\myparagraph{Acknowledgement.}
The authors acknowledge support from US National Science Foundation (NSF) awards CRII-1755791, CCF-1910873, CCF-1855760. 
This effort was partially supported by the Intelligence Advanced Research Projects Agency (IARPA) under the contract W911NF20C0038. 
The content of this paper does not necessarily reflect the position or the policy of the Government, and no official endorsement should be inferred.

\bibliography{iclr2021_conference}
\bibliographystyle{iclr2021_conference}

\appendix
\section{Appendix}
\setcounter{theorem}{0}
\setcounter{lemma}{0}
\setcounter{corollary}{0}

\begin{lemma}[One round purity improvement]
Suppose Assumption 1 is satisfied, and assume an  such that there exists a pure -level set with . Let  if  and  if  , and assume .
Let . Then . 


\end{lemma}

\textbf{Proof}: We analyze the case where . The analysis on the other side can be derived similarly.
Due to the fact that there exists a level set  pure to , we have 
, :

Now consider  where . Since the distribution  is -bounded, we have:  


If , the impurity in super level set   is at most . 
The level set -consistency condition implies  for  s.t. . If ,  will give the same label as  and thus -level set becomes pure for . Meanwhile, the choice of  ensures that .
\qed

\begin{lemma}[Warm-up rounds]
Suppose for a given function  there exists a level set  which is pure for . Given , after running Algorithm \ref{alg:PLC} for  rounds, there exists a level set  that is pure for . 
\end{lemma}
\textbf{Proof}:
The proof follows from the fact that each round of label flipping improves the purity by a factor of . To obtain an at least  pure region, it suffices to repeat the flipping step for  rounds. \qed

\begin{lemma} 
Suppose Assumption 1 is satisfied, and for a given function  there exists a level set  which is pure for . If one runs Algorithm \ref{alg:PLC} starting with  and the initializations: (1) , (2) , (3) , (4)  and (5) , then we have .
\end{lemma}

\textbf{Proof}:
The proof can be done by combining Lemma \ref{one_round} and Lemma \ref{First stage}. In the first  iterations, by Lemma \ref{First stage}, we can guarantee a level set   pure to .  In the rest of the iterations we ensure the level set  is pure. We increase  by a reasonable factor of  to avoid incurring too many corrupted labels while ensuring enough progress in label purification, i.e., , such that in the level set  we have . This condition ensures the correctness of flipping  when . 
The purity cannot be improved once  since there is no guarantee that  has consistent label with  when  and . By -bounded assumption on , its mass of impure  level set region is at most .
\qed

\begin{theorem} 
Under assumption 1, for any noise  which is PMD with margin , define . Then for the output of Algorithm \ref{alg:PLC}
 with  as above and with the following initializations: (1) , (2) , (3) , (4)  and (5)  , we have: 
\end{theorem}


\textbf{Proof}:
The proof is based on Lemma \ref{main2} plus a verification of the existence of  for which there exists a pure -level set. Let:

In the level set , . By level set -consistency, it suffices to satisfy   to ensure that   has the same prediction with  when . By polynomial level set diminishing noise, we have  if , and thus by choosing  one can ensure that initial  has a pure -level set. The rest of the proof follows from Lemma \ref{main2}.
\qed


\end{document}
