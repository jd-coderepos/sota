\documentclass{LMCS}

\def\dOi{11(1:7)2015}
\lmcsheading {\dOi}
{1--50}
{}
{}
{Oct.~26, 2011}
{Mar.~13, 2015}
{}

\ACMCCS{[{\bf Theory of computation}]: Semantics and
  reasoning---Program constructs / Program semantics; Logic; [{\bf
      Software and its engineering}]: Software notations and
  tools---Formal language definitions---Semantics}
\subjclass{F.3.2 Semantics of Programming Languages, 
           F.3.3 Studies of Program Constructs, 
           F.4.1 Mathematical Logic.}

\usepackage{hyperref}
\usepackage[all]{xy}
\usepackage{amsfonts,amssymb}
\usepackage{oldlfont}
\usepackage{tikz}
\usetikzlibrary{shapes}
\theoremstyle{plain}
\newtheorem{maintheorem}[thm]{Main Theorem}
\newtheorem{convention}[thm]{Convention}
\newtheorem{theorem}[thm]{Theorem}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{proposition}[thm]{Proposition}
\newtheorem{corollary}[thm]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[thm]{Definition}
\newtheorem{example}[thm]{Example}
\newtheorem{remark}[thm]{Remark}
\newenvironment{proof*}{\proof}{}
\newcommand{\eg}{{\em e.g.}}
\newcommand{\Eg}{{\em E.g.}}
\newcommand{\cf}{{\em cf.}}
\newcommand{\ie}{{\em i.e.}}
\newcommand{\Ie}{{\em I.e.}}
\newcommand{\wrt}{{\em w.r.t.}}
\newcommand{\st}{{\em s.t.}}
\newcommand{\FIGURE}{Fig.}
\newcommand{\lam}{\lambda}
\newcommand{\lr}{\ensuremath{\mbox{\tt letrec}}\;}
\newcommand{\inn}{\ensuremath{\; \mbox{\tt in}}\;}
\newcommand{\annRed}[1]{\xrightarrow{#1}}
\newcommand{\annRedM}[1]{\xrightarrow{#1,*}}
\newcommand{\ITT}{\mathit{IT}}
\newcommand{\ANSWERS}{{\mathbb{A}}}
\newcommand{\EXPRESSIONS}{{\mathbb{E}}}
\newcommand{\CONTEXTS}{{\mathbb{C}}}
\newcommand{\LLAZYCC}{L_{\LCC}}
\newcommand{\LLCC}{L_{\LCC}}
\newcommand{\LCC}{{\mathit{lcc}}}
\newcommand{\tBot}{{\texttt{Bot}}}
\newcommand{\Ctxt}{C}
\newcommand{\italt}{\mathit{alt}}
\newcommand{\LABELCOMP}{\|}
\mathchardef\mhyphen="2D
\newcommand{\impl}{\Rightarrow}
\newcommand{\vect}[1]{{\overrightarrow{#1}}}
\newcommand{\tbot}{{\tt Bot}}
\newcommand{\leb}{\preccurlyeq}
\newcommand{\geb}{\succcurlyeq}
\newcommand{\simb}{\simeq}
\newcommand{\lec}{\le}
\newcommand{\gec}{\geq}
\newcommand{\simc}{\sim}
\newcommand{\UptoSim}{F_{\LCC,\sim}}
\newcommand{\UptoSimLR}{F_{\LR,\sim}}
\newcommand{\cBot}{\mathit{cBot}}
\newcommand{\redrule}[1]{{\ensuremath{\mathrm{{#1}}}}}
\newcommand{\rlapp}{\redrule{lapp}}
\newcommand{\rlcase}{\redrule{lcase}}
\newcommand{\rlseq}{\redrule{lseq}}
\newcommand{\rcp}{\redrule{cp}}
\newcommand{\rcpin}{\redrule{cp\mhyphen{}in}}
\newcommand{\rcpe}{\redrule{cp\mhyphen{}e}}
\newcommand{\rcpcv}{\redrule{cpcv}}
\newcommand{\rcpcvin}{\redrule{cpcv\mhyphen{}in}}
\newcommand{\rcpcve}{\redrule{cpcv\mhyphen{}e}}
\newcommand{\rbeta}{\redrule{beta}}
\newcommand{\rlbeta}{\redrule{lbeta}}
\newcommand{\rnbeta}{\redrule{nbeta}}
\newcommand{\rnbet}{\redrule{nbeta}}
\newcommand{\rlletin}{\redrule{llet\mhyphen{}in}}
\newcommand{\rllet}{\redrule{llet}}
\newcommand{\rllete}{\redrule{llet\mhyphen{}e}}
\newcommand{\rlll}{\redrule{lll}}
\newcommand{\rcase}{\redrule{case}}
\newcommand{\rgcp}{\redrule{gcp}}
\newcommand{\rabs}{\redrule{abs}}
\newcommand{\rcasec}{\redrule{case\mhyphen{}c}}
\newcommand{\rcasein}{\redrule{case\mhyphen{}in}}
\newcommand{\rcasee}{\redrule{case\mhyphen{}e}}
\newcommand{\rncase}{\redrule{ncase}}
\newcommand{\rseq}{\redrule{seq}}
\newcommand{\rnseq}{\redrule{nseq}}
\newcommand{\rseqc}{\redrule{seq\mhyphen{}c}}
\newcommand{\rseqin}{\redrule{seq\mhyphen{}in}}
\newcommand{\bbbn}{\mathbb{n}}
\newcommand{\rseqe}{\redrule{seq\mhyphen{}e}}
\newcommand{\rbetaTr}{\redrule{betaTr}}
\newcommand{\rseqTr}{\redrule{seqTr}}
\newcommand{\rcaseTr}{\redrule{caseTr}}
\newcommand{\DIV}{{\Uparrow}}
\newcommand{\IEXPR}{\ensuremath{\mathcal{E}_I}}
\newcommand{\IECtxts}{\ensuremath{{\mathcal{R}}_{\TREE}}}
\newcommand{\ECtxt}{R}
\newcommand{\OR}{\syxor}
\newcommand{\NL}{\mathit{NL}}
\newcommand{\cand}{\leb_{\mathit{cand}}}
\newcommand{\candc}{(\leb_{\mathit{cand}})^c}
\newcommand{\Fcand}{F_{\mathit{cand}}}
\newcommand{\tauop}{\tau} 
\newcommand{\closed}[1]{(#1)^c}
\newcommand{\open}[1]{(#1)^o}
\newcommand{\Y}{{\boldsymbol{Y}}}
\newcommand{\RRAP}[1]{\xrightarrow{#1}}
\newcommand{\tnil}{{\tt Nil}}
\newcommand{\tif}{{\tt if}}
\newcommand{\tthen}{{\tt then}}
\newcommand{\telse}{{\tt else}}
\newcommand{\ttlc}{{\tt lcase}}
\newcommand{\ttrue}{{\tt True}}
\newcommand{\tfalse}{{\tt False}}
\newcommand{\tlet}{{\tt let}}
\newcommand{\tletrec}{{\tt letrec}}
\newcommand{\tin}{{\tt in}}
\newcommand{\tcase}{{\tt case}}
\newcommand{\tof}{{\tt of}}
\newcommand{\tletrx}[2]{(\tletrec~#1 ~{\tt in}~#2)}
\newcommand{\tletrxx}[2]{\tletrec~#1 ~{\tt in}~#2}
\newcommand{\ari}{{\mathrm{ar}}}
\newcommand{\tseq}{{\tt seq}}
\newcommand{\LAM}[2]{{(\lambda~#1~.~#2)}}
\newcommand{\iEnv}{{\mathit{Env}}}
\newcommand{\ialts}{{\mathit{alts}}}
\newcommand{\FV}{{\mathit{FV}}}
\newcommand{\dotcup}{\ensuremath{\mathaccent\cdot\cup}}
\newcommand{\disjcup}{\dotcup}
\newcommand{\syxor}{\mathrel{|}}
\newcommand{\bchainGen}[6]{\{{#1_{#2}=#3_{#4}}\}_{i=#5}^{#6}}
\newcommand{\bchainGenA}[6]{\{{#1_{#2}=#3_{#4}}\}_{#5}^{#6}}
\newcommand{\bchainX}{\bchainGen{x}{i}{x}{i-1}{2}{n}}
\newcommand{\bchainXInd}[2]{\bchainGen{x}{i}{x}{i-1}{#1}{#2}}
\newcommand{\bchainN}[3]{\bchainGen{#1}{i}{#2}{i}{1}{#3}}
\newcommand{\tCons}{{\tt Cons}}
\newcommand{\maycon}{{\downarrow}}
\newcommand{\mustcon}{{\Downarrow}}
\newcommand{\chole}{[\cdot]}
\newcommand{\LAMBDAEXPR}{\ensuremath{{\EXPRESSIONS}_{\lambda}}}
\newcommand{\LAMBDACTXT}{\ensuremath{{\CONTEXTS}_{\lambda}}}
\newcommand{\LETRECEXPR}{\ensuremath{{\EXPRESSIONS}_{\cal L}}}
\newcommand{\LETRECCTXT}{\ensuremath{{\CONTEXTS}_{\cal L}}}
\newcommand{\INFCTXT}{\ensuremath{{\CONTEXTS}_{\cal I}}}
\newcommand{\LLR}{L_{\mathit{LR}}} 
\newcommand{\LNAME}{L_{\mathit{name}}}
\newcommand{\LNEED}{L_{\mathit{need}}}
\newcommand{\LTREE}{\ensuremath{L_{\mathit{tree}}}}
\newcommand{\CBN}{\ensuremath{\LLAZY}}
\newcommand{\FNAME}{\ensuremath{\LNAME}}
\newcommand{\LR}{{\mathit{LR}}}
\newcommand{\NAME}{\mathit{name}}
\newcommand{\NEED}{{\mathit{need}}}
\newcommand{\TREE}{\ensuremath{{\mathit{tree}}}}
\newcommand{\NTREE}{\ensuremath{\neg{\mathit{tree}}}}
\newcommand{\transComp}{N}
\newcommand{\transN}{N'}
\setcounter{secnumdepth}{5}
\begin{document}
\title[Simulation in the Call-by-Need Lambda Calculus]{Simulation in the Call-by-Need Lambda-Calculus with Letrec, Case, Constructors, and Seq\rsuper*}
\author[M.~Schmidt-Schau{\ss}]{Manfred Schmidt-Schau{\ss}\rsuper a}
\address{{\lsuper{a,b}}Dept. Informatik und Mathematik, Inst. Informatik, J.W. Goethe-University, PoBox 11 19 32, D-60054 Frankfurt, Germany}
\email{\{schauss,sabel\}@ki.informatik.uni-frankfurt.de}
\thanks{{\lsuper a}The first author is supported by the DFG under grant SCHM 986/9-1.}
\author[D.~Sabel]{David Sabel\rsuper b}
\address{\vspace{-18 pt}}
\author[E.~Machkasova]{Elena Machkasova\rsuper c} 
\address{{\lsuper c}Division of Science and Mathematics, University of Minnesota, Morris, MN 56267-2134, U.S.A} \email{elenam@morris.umn.edu} 


\keywords{semantics, contextual equivalence, bisimulation, lambda calculus, call-by-need, Haskell}
\titlecomment{{\lsuper*}This paper is an extended version of \cite{schmidt-schauss-sabel-machkasova-rta:10} for more expressive calculi, and also of \cite{schmidt-schauss-copy-rta:07} \wrt~infinite trees, with fully worked out proofs.}
\begin{abstract}
This paper shows equivalence of several versions of applicative similarity and
contextual approximation, and hence also of applicative bisimilarity and 
contextual equivalence, in LR, the deterministic call-by-need lambda calculus
with letrec extended by data constructors, case-expressions and Haskell's 
seq-operator. LR models an untyped version of the core language of Haskell. 
The use of bisimilarities simplifies equivalence proofs in calculi and opens a
way for more convenient correctness proofs for program transformations.
 
The proof is by a fully abstract and surjective transfer into a 
call-by-name calculus, which is an extension of Abramsky's lazy lambda calculus.    
In the latter calculus equivalence of our similarities and contextual 
approximation can be shown by Howe's method. Similarity is transferred back to
LR on the basis of an inductively defined similarity.
 
The translation from the call-by-need letrec calculus into the extended 
call-by-name lambda calculus is the composition of two translations. The first
translation replaces the call-by-need strategy by a call-by-name strategy and
its correctness is shown by exploiting infinite trees which emerge by unfolding
the letrec expressions. The second translation encodes letrec-expressions by 
using multi-fixpoint combinators and its correctness is shown syntactically 
by comparing reductions of both calculi.

A further result of this paper is an isomorphism  between the mentioned calculi, 
which is also an identity on letrec-free expressions.
\end{abstract}
\maketitle\vfill
\section{Introduction}
\subsection*{Motivation}
Non-strict functional programming languages, such as the core-language of 
Haskell \cite{peyton-jones-haskell-98:03}, can be modeled using extended 
call-by-need lambda calculi. 

The operational semantics of such a programming language defines how programs
are evaluated and how the value of a program is obtained. 
Based on the operational semantics, the notion of {\em contextual equivalence} 
(see \eg\ \cite{morris:68,plotkin:75}) is a natural notion of program 
equivalence which follows Leibniz's law to identify the indiscernibles, that is
two programs are equal iff their observable (termination) behavior is 
indistinguishable even if the programs are used as a subprogram of any other 
program (\ie\ if the programs are plugged into any arbitrary {\em context}). 
For pure functional programs it suffices to observe whether or not the 
evaluation of a program terminates with a value (\ie\ whether the program
{\em converges}). 
Contextual equivalence has several advantages: 
Any reasonable notion of program equivalence should be a congruence which
distinguishes obvious different values, \eg\ different constants are 
distinguished, and functions (abstractions) are distinguished from constants. 
Contextual equivalence satisfies these requirements and is usually the 
coarsest of such congruences. 
Another (general) advantage is that once expressions, contexts, an evaluation,
and a set of values are defined in a calculus, its definition of contextual 
equivalence can be derived, and thus this approach can be used for a broad 
class of program calculi.
 
On the other hand, due to the quantification over all program contexts, 
verifying equivalence of two programs \wrt\ contextual equivalence is often a
difficult task.
Nevertheless such proofs are required to ensure the 
{\em correctness of program transformations} where the correctness notion 
means that contextual equivalence is preserved by the transformation.
Correctness of program transformations is indispensable for the correctness of 
compilers, but program transformations also play an important role in several 
other fields, \eg\ in code refactoring to improve the design of programs, or in
software verification to simplify expressions and thus to provide proofs 
or tests.

Bisimulation is another notion of program equivalence which was first invented
in the field of process calculi 
(\eg\ \cite{Milner:80,milner-pi-calc:99,sangiorgi-walker:01}), but has also 
been applied to functional programming and several extended lambda calculi 
(\eg\ \cite{howe:89,abramsky-lazy:90,howe:96}).
Finding adequate notions of bisimilarity is still an active research topic 
(see~\eg\ \cite{koutavas-wand:2006,Sangiorgi-Kobayashi-Sumii:2011}).
Briefly explained, bisimilarity equates two programs  if all 
experiments passed for  are also passed by  and vice versa. For 
applicative similarity (and also bisimilarity) the experiments are evaluation
and then recursively testing the obtained values: 
Abstractions are applied to all possible arguments, data objects are decomposed
and the components are tested recursively.
Applicative similarity is usually defined co-inductively, \ie\ as a greatest
fixpoint of an operator. 
Applicative similarity allows convenient and automatable proofs of correctness
of program transformations, \eg\ in mechanizing 
proofs~\cite{Dennis-Bundy-Green:1997}.

Abramsky and Ong showed that applicative bisimilarity is the same as contextual
equivalence in a specific simple lazy lambda calculus  
\cite{abramsky-lazy:90,abramsky-ong:93}, and Howe \cite{howe:89,howe:96} proved
that in classes of lambda-calculi applicative bisimulation is the same as 
contextual equivalence. 
This leads to the expectation that some form of applicative bisimilarity may be
used for calculi with  Haskell's cyclic letrec. 
However, Howe's proof technique appears to be not adaptable to lambda calculi
with cyclic let, since there are several deviations from the requirements for
the applicability of Howe's framework.
(i) Howe's technique is for call-by-name calculi and it is not obvious how to
adapt it to call-by-need evaluation. 
(ii) Howe's technique requires that the values (results of reduction) are 
recognizable by their top operator. 
This does not apply to calculi with , since -expressions
may be values as well as non-values. 
(iii) Call-by-need calculi with letrec usually require reduction rules to shift
and join \tletrec-bindings. These modifications of the syntactic structure of
expressions do not fit well into the proof structure of Howe's method.

Nevertheless, Howe's method is also applicable to calculi with non-recursive 
let even in the presence of nondeterminism \cite{mannmss:10}, where for the
nondeterministic case applicative bisimilarity is only sound (but not complete)
\wrt\ contextual equivalence.
However, in the case of (cyclic) letrec and {\em nondeterminism} applicative
bisimilarity is unsound \wrt\ contextual equivalence
\cite{schmidt-schauss-sabel-machkasova-IPL:11}.
This raises a question: 
which call-by-need calculi with letrec permit applicative bisimilarity as a 
tool for proving contextual equality?
 
\subsection*{Our Contribution}
In \cite{schmidt-schauss-sabel-machkasova-rta:10} we have already shown that
for the minimal extension of Abramsky's lazy lambda calculus with letrec which
implements sharing and explicit recursion, the equivalence of contextual
equivalence and applicative bisimilarity indeed holds. 
However, the full (untyped) core language of Haskell has data constructors, 
case-expressions and the seq-operator for strict evaluation. 
Moreover, in ~\cite{schmidt-schauss-machkasova-sabel:rta:2013} it is shown that
the extension of Abramsky's lazy lambda calculus with \tcase{}, constructors, 
and \tseq{} is not conservative, \ie\ it does not preserve contextual 
equivalence of expressions. 
Thus our results obtained in \cite{schmidt-schauss-sabel-machkasova-rta:10} for
the lazy lambda calculus extended by letrec only are not transferable to the
language extended by \tcase{}, constructors, and \tseq.
For this reason we provide a new proof for the untyped core language of Haskell.

As a model of  Haskell's core language we use the call-by-need lambda calculus
 which was introduced and motivated in 
\cite{schmidt-schauss-schuetz-sabel:08}. 
The calculus  extends the lazy lambda calculus with letrec-expressions, 
data constructors, \tcase-expressions for deconstructing the data, and 
Haskell's \tseq-operator for strict evaluation.

We define the operational semantics of  in terms of a small-step 
reduction, which we call normal order reduction.
As it is usual for lazy functional programming languages, evaluation of 
-expressions successfully halts if a {\em weak head normal form} is 
obtained, \ie\ normal order reduction does not reduce inside the body of
abstractions nor inside the arguments of constructor applications.
The  calculus has been studied in detail in 
\cite{schmidt-schauss-schuetz-sabel:08} and correctness of several important
program transformations has been established for it.

Our main result in this paper is that several variants of applicative 
bisimilarities are sound and complete for contextual equivalence in ,
\ie\ coincide with contextual equivalence. 
Like context lemmas, an applicative bisimilarity can be used as a proof tool
for showing contextual equivalence of expressions and for proving correctness
of program transformations in the calculus . 
Since we have completeness of our applicative bisimilarities in addition to
soundness, our results can also be used to disprove contextual equivalence of
expressions in .
Additionally, our result shows that the untyped applicative bisimilarity is
sound for a polymorphic variant of , and hence for the typed core 
language of Haskell. 

Having the  proof tool of applicative bisimilarity in  is also very 
helpful for more complex calculi if their pure core can be conservatively
embedded in the full calculus.
An example is our work on Concurrent Haskell 
\cite{sabel-schmidt-schauss-PPDP:2011,sabel-schmidt-schauss:12:LICS},
where our calculus CHF that models Concurrent Haskell has top-level processes
with embedded lazy functional evaluation.
We have shown in the calculus CHF that Haskell's deterministic core language
can be conservatively embedded in the calculus CHF.

\begin{figure}
\begin{tikzpicture}
\node (LR)    at (-3,0)   [] [line width=1pt,shape=ellipse,draw,fill=blue!5!white] {\rule{0mm}{6mm}\rule{6mm}{0mm}};
\node (txt)   at (-3,0)   [] {};
\node (IT)    at (0,-1.5) [] [line width=1pt,dotted,shape=ellipse,draw,fill=blue!5!white] {\rule{0mm}{6mm}\rule{6mm}{0mm}};
\node (txt)   at (0,-1.5) [] {};
\node (LName) at (3,0)    [] [line width=1pt,shape=ellipse,draw,fill=blue!5!white] {\rule{0mm}{6mm}\rule{6mm}{0mm}};
\node (txt)   at (3,0)    [] {};
\node (Lcc)   at (6,0)    [] [line width=1pt,shape=ellipse,draw,fill=blue!5!white] {\rule{0mm}{6mm}\rule{6mm}{0mm}};
\node (txt)   at (6,0)    [] {};
\draw[->,line width=1pt]               (LR)    to node [above] {W} (LName);
\draw[->,line width=1pt]               (LName) to node [above] {N} (Lcc);
\draw[<->,line width=1pt,dotted]       (LR)    to node [] {}       (IT);
\draw[<->,line width=1pt,dotted]       (LName) to node [] {}       (IT);
\draw[->,line width=1pt,bend left =20] (LR)    to node [above] {} node [] {} (Lcc);
\end{tikzpicture}

\caption{Overall structure. Solid lines are fully-abstract translations, which
are also isomorphisms and identities on letrec-free expressions; dotted lines
are convergence preservation to/from the system  of infinite trees.
\label{figure:results}}
\end{figure}

We prove the equivalence between the applicative similarities and contextual 
equivalence in , by lifting the equivalence from a \tletrec-free call-by-name calculus . 
The calculus  minimally extends Abramsky's lazy calculus by Haskell's
primitives. 
As shown in~\cite{schmidt-schauss-machkasova-sabel:rta:2013}, data constructors
and  are explicitly needed in .
The structure of the proof, with its intermediate steps, is shown in Figure~\ref{figure:results}.
We prove the equivalence between the applicative similarities and contextual
equivalence in , by extending Howe's method. 
We bridge  and  in two steps, using intermediate calculi 
 and .  is the call-by-name variant of , and
 is obtained from  by encoding letrec using multi-fixpoint
combinators. 
The calculi  and  are related to each other via their infinite 
unfoldings, thus we introduce a calculus  of infinite trees 
(similar infinitary rewriting, see \cite{kennaway-klop:97,schmidt-schauss-copy-rta:07}).
Convergence of expressions in  and  is shown to be equivalent to
their translation as an infinite tree in the calculus  (dotted lines in
the picture).
We establish full abstractness of translation  and  between calculi 
, , and  with respect to contextual equivalence. 
Correctness of similarity is transferred back from  to  on the
basis of an inductively defined similarity (for more details see 
\FIGURE~\ref{subsec:sim-lr-def}).
 
A consequence of our result is that the three calculi , , and
 are isomorphic, modulo the equivalence 
(see Corollaries~\ref{cor:N-iso} and~\ref{cor:W-iso}), and also that the 
embedding of the calculus  into the call-by-need calculus  is
an isomorphism of the respective term models. 

\subsection*{Related Work}
In \cite {Gordon:99} Gordon shows that bisimilarity and contextual equivalence
coincide in an extended call-by-name PCF language.
Gordon provides a bisimilarity in terms of a labeled transition system.  
A similar result is obtained in \cite{pitts:97} for PCF extended by product 
types and lazy lists where the proof uses Howe's method 
(\cite{howe:89,howe:96}; see also \cite{mannmss:10,Pitts:2011}), and where the
operational semantics is a big-step one for an extended PCF-language.
The observation of convergence in the definition of contextual equivalence is 
restricted to programs (and contexts) of ground type (\ie\ of type integer or
{\tt Bool}). 
Therefore  and  are equal in the calculi considered
by Gordon and Pitts. 
This does not hold in our setting for two reasons: 
first, we observe termination for functions and thus the empty context already
distinguishes  and , and second, our languages employ 
Haskell's seq-operator which permits to test convergence of any expression and
thus the context  distinguishes  and 
.

\cite{jeffrey-short:94} presents an investigation into the semantics of a 
lambda-calculus that permits cyclic graphs, where a fully abstract denotational
semantics is described.
However, the calculus is different from our calculi in its expressiveness since
it permits a parallel convergence test, which is required for the full 
abstraction property of the denotational model. 
Expressiveness of programming languages was investigated 
\eg\ in \cite{Felleisen:91} and the usage of syntactic methods was formulated as
a research program there, with non-recursive \tlet{} as the paradigmatic example. 
Our isomorphism-theorem \ref{thm:isomorphism} shows that this approach is 
extensible to a cyclic \tlet{}.

Related work on calculi with recursive bindings includes the following 
foundational papers.
An early paper that proposes cyclic let-bindings (as graphs) 
is \cite{ariola-klop-short:94}, where reduction and confluence properties are
discussed.
\cite{ariola:95,ariola:97} study equational theory for call-by-need lambda
calculus extended with non-recursive \tlet{}, 
which is finer than contextual equivalence, and in \cite{maraistoderskywadler:98}
it is shown that call-by-name and call-by-need
evaluation induce the same observational equivalences for a call-by-need lambda
calculus with non-recursive \tlet{}.
Additionally, the extension of the corresponding calculi by recursive \tlet{} is
discussed in \cite{ariola:95,ariola:97}, and further call-by-need lambda calculi
with a recursive \tlet{} are presented 
in \cite{ariola-blom:97,ariola-blom:02,Nakata-hasegawa:2009:jfp} where 
\cite{Nakata-hasegawa:2009:jfp} study the equivalence between a natural 
semantics and a reductions semantics.
In \cite{ariola-blom:02} it is shown that there exist infinite normal forms and
that the calculus satisfies a form of confluence.
All these calculi correspond to our calculus .
A difference is that the let-shifting in the standard reduction in the mentioned works is different from .
However, this difference is not substantial, since it does not influence the contextual semantics.
A more substantial difference is that  combines 
recursive  with data constructors, case-expressions and \tseq, which none of the related works do.

In \cite{moran-sands:99} a call-by-need calculus is analyzed which is closer to
our calculus , since \tletrec, \tcase, and constructors are present (but not
\tseq).
Another difference is that \cite{moran-sands:99} uses an abstract machine semantics
as operational semantics, while their approach to program equivalence is based on
contextual equivalence, as is ours.

The operational semantics of call-by-need lambda calculi with \tletrec{} are 
investigated in \cite{launch:93} and \cite{sestoft:97}, where the former proposed
a natural semantics, and proved it correct and adequate with respect to a 
denotational semantics, and the latter derived an efficient abstract machine 
from the natural semantics.

Investigations of the semantics of lazy functional programming languages including
the -operator can be found in 
\cite{johann-voigtlaender:06,voigtlaender-johann:07}.

\subsection*{Outline}
In Sect.~\ref{sec:common} we introduce some common notions of program calculi,
contextual equivalence, similarity and also of translations between those 
calculi.
In Sect.~\ref{sec:calculi} we introduce the extension  of Abramsky's
lazy lambda calculus with \tcase, constructors, and \tseq, and two 
letrec-calculi ,  as further syntactic extensions.
In Sect.~\ref{sec:simulation-lazy} we show that for so-called 
``convergence admissible'' calculi an alternative inductive characterization of
similarity is possible. 
We then use Howe's method in  to show that contextual approximation and
a standard version of applicative similarity coincide. 
Proving that  is convergence admissible then implies that the 
alternative inductive characterization of similarity can be used for .
In Sect.~\ref{sec-translation-NEED-NAME} and~\ref{sec:NAME-to-LAZY} the 
translations  and  are introduced and the full-abstraction results are
obtained.
In Sect.~\ref{sec-simulations} we show soundness and completeness of our 
variants of applicative similarity w.r.t. contextual equivalence in .
We conclude in Sect.~\ref{sec:conclusion}.

\section{Common Notions and Notations for Calculi}\label{sec:common}
Before we explain the specific calculi, some common notions are introduced.
A calculus definition consists of its syntax  together with its operational 
semantics which defines the evaluation of programs and the implied equivalence
of expressions: 

\begin{definition}\label{def:calculus}
An untyped deterministic {\em calculus}  is a four-tuple 
\mbox{}, where  
are expressions (up to -equivalence), 
 is  a set of functions 
(which usually represents contexts),  is a small-step reduction relation
(usually the normal-order reduction), which is a partial function on expressions
(\ie, deterministic), and  is a set of 
{\em answers} of the calculus.

For  and an expression , the functional application is
denoted as  . 
For contexts, this is the replacement of the hole of  by . 
We also assume that the identity function  is contained in 
 with  for all expressions , and that 
 is closed under composition, 
\ie\ . 

The {\em transitive  closure} of  is denoted as  and the
{\em transitive and reflexive closure} of  is denoted as . 
The notation  means equality or one reduction, 
and  means  reductions.
Given an expression , a sequence  is called a
{\em reduction sequence}; it is called an {\em evaluation} if  is an answer,
\ie\ ; in this case we say   {\em converges} and denote 
this as  or as  if  is not important.  
If there is no  \st\  then  {\em diverges},
denoted as . 
When dealing with multiple calculi, we often use the calculus name to mark its
expressions and relations, \eg\  denotes a reduction 
relation in . 
\end{definition}
We will have to deal with several calculi and preorders. Throughout this paper
we will use the symbol  for co-inductively defined preorders 
(\ie\ similarities), and  for (inductively defined or otherwise defined)
contextual preorders. 
For the corresponding symmetrizations we use  for  and
 for . 
All the symbols are always indexed by the corresponding calculus and sometimes
more restrictions like specific sets of contexts are attached to the indices
of the symbols. 

Contextual approximation and equivalence can be defined in a general way:
\begin{definition}[Contextual Approximation and Equivalence,  and ]
Let  be a calculus and 
 be -expressions.
{\em Contextual approximation} (or {\em contextual preorder})   and 
{\em contextual equivalence}  are defined as: 


A {\em program transformation} is a binary relation 
). 
A program transformation  is called {\em correct} iff 
.
\end{definition}
Note that  is a precongruence, \ie,  is reflexive, 
transitive, and  implies  for all 
, and that  is a congruence, \ie\ a 
precongruence and an equivalence relation.

We also define a general notion of similarity coinductively for untyped
deterministic calculi.
We first define the operator  on binary relations of 
expressions:
\begin{definition}
Let  be an untyped deterministic
calculus and let   be a set of functions on 
expressions (\ie\ ).
Then the {\em -experiment operator} 
  
is defined as follows for :

\end{definition}

\begin{lemma}
The operator  is monotonous \wrt\ set inclusion, \ie\ for all
binary relations  on expressions 
.
\end{lemma}
\begin{proof}
Let  and . 
From the assumption  the implication 
 
follows.
From  the implication

follows.
Thus, .
\end{proof}
\noindent Since  is monotonous, its greatest fixpoint exists:
\begin{definition}[-Similarity, ]\label{def:Q-gfp-preorder}
The behavioral preorder , called {\em -similarity},
is defined as the greatest fixed point of .
\end{definition}

We also provide an inductive definition of behavioral equivalence, which is
defined as a contextual preorder where the contexts are restricted to the set
 (and the empty context).

\begin{definition}\label{def:Q-simpl-preorder}
Let  be an untyped 
deterministic calculus, and .
Then the relation  is defined as follows:

\end{definition}
Note that contextual approximation is a special case of this definition,
\ie\ .

Later in Section~\ref{sec:conv-admissible} we will provide a sufficient
criterion on untyped deterministic calculi that ensures that 
 and  coincide.

We are interested in translations between calculi that are faithful 
\wrt\ the corresponding contextual preorders. 
\begin{definition}[\cite{schmidt-schauss-niehren-schwinghammer-sabel-ifip-tcs:08,schmidt-schauss-niehren-schwinghammer-sabel-frank-33:09}]\label{def:translation-compo-etal}
For  let  be
untyped deterministic calculi.
A {\em translation} 

is a mapping 
 
and a mapping  such that
. 
The following properties of translations are defined:
\begin{itemize}
\item  is {\em compositional}\ iff  for all . 
\item  is {\em convergence equivalent}\ iff  for all . 
\item  is {\em adequate}\ iff for all : .
\item  is {\em fully abstract}\ iff for all : . 
\item  is an {\em isomorphism}\ iff it is fully abstract and a bijection on the quotients \\
\mbox{\hspace*{5mm} }. 
\end{itemize}
\end{definition}
Note that isomorphism means an order-isomorphism between the term-models, where
the orders are  and  (which are the relations
in the quotient).  

\begin{proposition}[\cite{schmidt-schauss-niehren-schwinghammer-sabel-ifip-tcs:08,schmidt-schauss-niehren-schwinghammer-sabel-frank-33:09}]\label{prop:adequate}
Let  for  be untyped deterministic calculi.
If a translation 

is compositional and convergence equivalent, then it is also adequate.
\end{proposition}
\begin{proof}
Let  with  and let 
 for some . 
It is sufficient to show that this implies : 
Convergence equivalence shows that . 
Compositionality implies , and then
 implies . 
Compositionality applied once more implies , and then
convergence equivalence finally implies . 
\end{proof}


\section{Three Calculi}\label{sec:calculi}
In this section we introduce the calculi , , and .
 is a call-by-need calculus with recursive , data constructors,
\tcase-expressions, and the -operator. 
The calculus  has the same syntactic constructs as , but uses a
call-by-name, rather than a call-by-need, evaluation. The calculus 
does not have , and also uses a call-by-name evaluation.
 
For all three calculi we assume that there is a (common) set of 
{\em data constructors}  which is partitioned into {\em types}, such that 
every constructor  belongs to exactly one type. 
We assume that for every type  the set of its corresponding data constructors
can be enumerated as  where  is the number of
data constructors of type .
We also assume that every constructor has a fixed arity denoted as  
which is a non-negative integer.
We assume that there is a type  among the types, with the data
constructors  and  both of arity 0.
We require that data constructors occur only fully saturated, \ie\ a constructor
 is only allowed to occur together with  arguments, written as 
 where  are expressions of the corresponding 
calculus\footnote{Partial applications of constructors  of the form  
(as \eg\ available in Haskell) thus have to be represented by 
.
}. 
We also write  as an abbreviation for the constructor application
. 
All three calculi allow deconstruction via \tcase-expressions:

where  are expressions and  are variables of the corresponding calculus.
Thus there is a -construct for every type  and we require that 
there is exactly one case-alternative 
 for every constructor
 of type .
In a case-alternative  we 
call  a {\em pattern} and  the
right hand side of the alternative. 
All variables in a -pattern must be pairwise distinct.
We will sometimes abbreviate the case-alternatives by  if the exact 
terms of the alternatives are not of interest.
As a further abbreviation we sometimes write 
for the case-expression 
.

We now define the syntax of expressions with , \ie\ the set
 of expressions which are used in both of the calculi
 and .

\begin{definition}[Expressions ]
The set  of expressions is defined by the following grammar,
where  are variables:

We assign the names {\em application}, {\em abstraction}, -expression,
or {\em \tletrec-expression} to the expressions , ,
, or , respectively. 
A {\em value}  is defined as an abstraction or a constructor application.
A group of  bindings is sometimes abbreviated as . 
We use the notation  for the chain 

of bindings where  are injective, 
\eg,  means the bindings 
. 
We assume that variables  in \tletrec-bindings are all distinct, that 
\tletrec-expressions are identified up to reordering of binding-components,
and that, for convenience, there is at least one binding. 
-bindings are recursive, \ie, the scope of  in 
 are all expressions 
 with . 

 denotes the set of all contexts for the expressions .
\end{definition}

Free and bound variables in expressions and -renamings are defined as usual.
The set of free variables in  is denoted as .

\begin{convention}[Distinct Variable Convention]
We use the {\em distinct variable convention}, \ie, all bound variables in expressions
are assumed to be distinct, and free variables are distinct from bound variables.
All reduction rules are assumed to implicitly -rename bound variables 
in the result if necessary. 
\end{convention}

In all three calculi we will use the symbol  for the specific 
(\tletrec-free) expression . 
In all of our calculi  is divergent and the least element of the 
corresponding contextual preorder.
This is proven in \cite{schmidt-schauss-schuetz-sabel:08} for  and
can easily be proven for the other two calculi using standard methods, 
such as context lemmas. 
Note that this property also follows from the Main Theorem~\ref{thm:maintheorem}
for all three calculi.


\subsection{\texorpdfstring{The Call-by-Need Calculus }{The Call-by-Need-Calculus LR}}\label{sec:LR-calc}
We begin with the call-by-need lambda calculus  which is exactly the 
call-by-need calculus of \cite{schmidt-schauss-schuetz-sabel:08}.
It has a rather complex form of reduction rules using variable chains. 
The justification is that this formulation permits direct syntactic proofs
of correctness \wrt\ contextual equivalence for a large class of transformations. 
Several modifications of the reduction strategy, \ removing indirections, do 
not change the semantics of the calculus, however, they appear to be not 
treatable by syntactic proof methods using diagrams 
(see \cite{schmidt-schauss-schuetz-sabel:08}). 
-expressions are exactly the expressions .

\begin{definition}\label{def-red-rules} 
The {\em reduction rules} for the calculus and language  are defined in 
\FIGURE~\ref{figure-reductions-LLR}, where the labels  are used for the 
exact definition of the normal-order reduction below. 
Several reduction rules are denoted by their name prefix: 
the union of (\rlletin) and (\rllete) is called (\rllet).  
The union of (\rllet), (\rlapp), (\rlcase), and (\rlseq) is called (\rlll).
\end{definition}

\begin{figure*}[htpb] 
-1.8ex]
(\rlbeta)&C[((\lambda x. s)^S~t)]   \to    C[\tletrxx{x = t}{s}]
\1.1ex]
(\rcpe) & \tletrxx{x_1 = (\lambda x.s)^S, \bchainXInd{2}{m},  \iEnv, y = C[x_m^V]}{t}  \\
& \quad \to \tletrxx{x_1 = (\lambda x.s), \bchainXInd{2}{m},  \iEnv, y = C[(\lambda x.s)]}{t}   
\1.1ex]
(\rlcase)& C[(\tcase_T~\tletrx{\iEnv}{s}^S~\tof~alts)]  \\
         &\quad\to 
         C[\tletrx{\iEnv}{(\tcase_T~s~\tof~alts)}]
\1.1ex]
(\rlletin)& \tletrxx{\iEnv_1}{\tletrx{\iEnv_2}{s}^S} \to  \tletrxx{\iEnv_1,\iEnv_2}{s}
\1.1ex]
(\rseqc)& 
C[(\tseq~v^S~s)]   \to  C[s]  \hspace*{1cm}  \mbox{if } v  \mbox{ is a  value}
\1.1ex]
(\rseqe)& 
\tletrx{x_1 = v^S, \bchainXInd{2}{m}, \iEnv, y = C[(\tseq~x_m^V~s)]}{t} \\
& \quad \to  \tletrx{x_1 = v, \bchainXInd{2}{m}, \iEnv, y =C[s]}{t} \\
&  \mbox{if } v  \mbox{ is a {constructor application}}

\1.1ex]
(\rcasein)&\tletrec~x_1 = (c_{i}~\vect{s})^S, \bchainXInd{2}{m}, \iEnv~\\
          &\tin~C[\tcase_T~x_{m}^V~\tof\ldots((c_{i}~\vect{z}) \to t)\ldots]\\
                   &\quad\to\tletrec~  x_1 = (c_{i}~\vect{y}), \bchainN{y}{s}{n}, \bchainXInd{2}{m}, \iEnv \\ 
                   &\quad\phantom{\to\,\,}\tin~     C[\tletrx{\bchainN{z}{y}{\ari(c_{i})}}{t}]~\mbox{if } \ari(c_{i}) \ge  1 \mbox{ and where } y_i  \mbox{ are fresh}
\1.1ex]
(\rcasee)&\begin{array}[t]{@{}l@{}l}\tletrec~&x_1 = (c_{i}~\vect{s})^S, \bchainXInd{2}{m},\\
                                                   &u = C[\tcase_T~ x_{m}^V ~\tof\ldots ((c_{i}~\vect{z}) \to t)\ldots], \iEnv\\
                                          \multicolumn{2}{@{}l}{\tin~r}
                    \end{array}\\
     &\quad\to\begin{array}[t]{@{}l@{}l}
                 \tletrec~&x_1 = (c_{i}~\vect{y}), \bchainN{y}{s}{\ari(c_i)}, \bchainXInd{2}{m},\\
                          &u = C[\tletrx{\bchainN{z}{y}{\ari(c_i)}}{t}], \iEnv\\
                 \multicolumn{2}{@{}l}{\tin~r}
               \end{array}
\\
     & \mbox{if } \ari(c_{i}) \ge 1 \mbox{ and where } y_i  \mbox{ are fresh }
\\
(\rcasee)& \tletrec~ x_1 = c_{i}^S,  \bchainXInd{2}{m}, u = C[\tcase_T~ x_{m}^V ~ \ldots~ (c_{i} \to t) \ldots],  \iEnv 
                ~\tin~ r\\
                &\quad\to \tletrec~x_1 = c_{i}, \bchainXInd{2}{m}\ldots, u = C[t], \iEnv
                ~\tin~ r~\mbox{ if }  \ari(c_{i}) = 0 \\     
 \hline
\end{array}\begin{array}{|lll|}
\hline
&&\
\caption{Labeling algorithm for \label{figure:label-LLR}}
\end{figure*}
 

\begin{definition}[Normal Order Reduction of ] \label{def-no-reduction}
Let  be an expression. 
Then a single normal order reduction step  is defined as follows:
first the labeling algorithm in \FIGURE~\ref{figure:label-LLR} is applied to .  
If the labeling algorithm terminates successfully, then one of the rules 
in \FIGURE~\ref{figure-reductions-LLR} is applied, if possible, where the
labels   must match the labels in the expression  
(again  may have more labels).   
The {\em normal order redex} is defined as the left-hand side of the applied
reduction rule.
The notation for a normal-order reduction that applies the rule  is 
, \eg\  applies the rule . 
\end{definition}

The normal order reduction of  implements a call-by-need reduction with sharing
which avoids substitution of arbitrary expressions.
We describe the rules: 
The rule (\rlbeta) is a sharing variant of classical -reduction,
where the argument of an abstraction is shared by a new \tletrec-binding 
instead of substituting the argument in the body of an abstraction. 
The rules (\rcpin) and (\rcpe) allow to copy abstractions into needed positions. 
The rules (\rlapp), (\rlcase), and (\rlseq) allow moving \tletrec-expressions 
to the top of the term if they are inside a reduction position of an application,
a \tcase-expression, or a \tseq-expression. 
To flatten nested \tletrec-expressions, the rules (\rlletin) and (\rllete) are
added to the reduction.
Evaluation of -expressions is performed by the rules (\rseqc), (\rseqin),
and (\rseqe), where the first argument of  must be a value (rule \rseqc)
or it must be a variable which is bound in the outer -environment to
a constructor application.
Since normal order reduction avoids copying constructor applications, the rules
(\rseqin) and (\rseqe) are required.
Correspondingly, the evaluation of -expressions requires several variants: 
there are again three rules for the cases where the argument of  is 
already a constructor application (rule (\rcasec)) or where the argument is a
variable which is bound to a constructor application (perhaps by several 
indirections in the \tletrec-environment) which are covered by the rule 
(\rcasein) and (\rcasee). 
All three rules have two variants: one variant for the case when a constant
is scrutinized (and thus no arguments need to be shared by new -bindings)
and another variant for the case when arguments are present (and thus the arity of
the scrutinized constructor is strictly greater than 0). 
For the latter case the arguments of the constructor application are shared by
new \tletrec-bindings, such that the newly created variables can be used as 
references in the right hand side of the matching alternative.


\begin{definition}
A {\em reduction context}  is any context, such that its hole is 
labeled with  or  by the -labeling algorithm. 
\end{definition}
Of course, reduction contexts could also be defined recursively, as 
in \cite[Definition 1.5]{schmidt-schauss-schuetz-sabel:08}, but such a 
definition is very cumbersome due to a large number of special cases. 
The labeling algorithm provides a definition that, in our experience,
is easier to work with.
 
By induction on the term structure one can easily verify that the normal
order redex, as well as the normal order reduction, is unique. 
A {\em weak head normal form in  (-WHNF)} is either an
abstraction , a constructor application ,
or an expression  where  is a constructor application
or an abstraction, or an expression of the form 
, where . 
We distinguish abstraction-WHNF (AWHNF) and  constructor WHNF (CWHNF) based
on whether the value  is an abstraction or a constructor application, 
respectively.
The notions of convergence, divergence and contextual approximation are as
defined in Sect.~\ref{sec:common}.
If there is no normal order reduction originating at an expression  then
. 
This, in particular, means that expressions for which the labeling algorithm
fails to find a redex, or for which there is no matching constructor for a
subexpression (that is a WHNF) in a \tcase{} redex position, or expressions
with cyclic dependencies like , are diverging. 

\begin{example}
We consider the expression
.
The labeling algorithm applied to  yields
.
The reduction rule that matches this labeling is the reduction rule \mbox{(\rcpe)}, \ie\
.
The labeling of  is
, which makes the rule  \mbox{(\rlbeta)} applicable, \ie\
.
The labeling of   is
.
Thus an \mbox{(\rllete)}-reduction is applicable to , \ie\
.
Now  gets labeled as 
,
and a \mbox{(\rcpin)}-reduction is applicable, \ie\
.
The labeling algorithm applied to  yields
,
but no reduction is applicable to , since  is a WHNF.
\end{example}

Concluding, the calculus  is defined by the tuple 
 where
 are the -WHNFs, where we equate alpha-equivalent
expressions, contexts and answers. 

\vspace{1mm} 

In \cite{schmidt-schauss-schuetz-sabel:08} correctness of several program
transformations was shown: 
\begin{figure*}[t] 
-1.8ex]
\mbox{(gc)} & C[\tletrec~\{x_i = s_i\}_{i=1}^n~\tin~t] \to C[t],~~~\text{if }
\1.1ex]
\mbox{(lwas)} &C[(s~(\tletrec~\iEnv~\tin~t))] \to C[\tletrec~\iEnv~\tin~(s~t)]
\1.1ex]
\mbox{(lwas)} &C[(\tseq~s~(\tletrec~\iEnv~\tin~t))] \to C[\tletrec~\iEnv~\tin~\tseq~s~t]
\\\hline
\end{array}\begin{array} {|lll|}
\hline
&&\
\caption{Labeling algorithm for \label{fig:labeling-LNAME}}
\end{figure*}  

In \FIGURE~\ref{fig:labeling-LNAME} the rules of the labeling algorithm for  are given.
The algorithm uses the labels  and . For an expression  the labeling starts with .

An  reduction context  is any context where the hole is labeled  or 
by the labeling algorithm, or more formally they can be defined as follows:
\begin{definition}
{\em Reduction contexts}  are contexts of the form  where the context classes
 and  are defined by the following grammar, where  is any expression:


\end{definition}

Normal order reduction  of  is defined by the rules
shown in \FIGURE~\ref{figure-reductions-LNAME} where the labeling algorithm 
according to \FIGURE~\ref{fig:labeling-LNAME} must be applied first.
Note that the rules (\rseqc), (\rlapp), (\rlcase), and (\rlseq) are identical
to the rules for  (in \FIGURE~\ref{figure-reductions-LLR}), but the 
labeling algorithm is different.

\begin{figure}[t]
-1.8ex]
(\rbeta) & C[(\lambda x.s)^S~t] \to C[s[t/x]]
\1.1ex]
(\rlapp) & C[(\tletrx{\iEnv}{s}^S~t)]  \to   C[\tletrx{\iEnv}{(s~t)}]
\1.1ex]
(\rlseq) & C[(\tseq~\tletrx{\iEnv}{s}^S~t)]   \to   C[\tletrx{\iEnv}{(\tseq~s~t)}]
\1.1ex]
(\rcase) &C[(\tcase_T~(c~s_1 \dots s_{ar(c)})^S~\tof \ldots ((c~x_1 \dots x_{ar(c)}) \rightarrow t)\ldots)]\\
&\quad \to C[t[{s_1}/{x_1}, \dots, {s_{ar(c)}}/{x_{ar(c)}}]] 
\
\caption{Normal order reduction rules  of  \label{figure-reductions-LNAME}}
\end{figure}



Unlike , the normal order reduction of  allows substitution of arbitrary
expressions in (\rbeta), (\rcase), and (\rgcp) rules.
An additional simplification (compared to ) is that nested -expressions
are not flattened by reduction (\ie\ there is no (\rllet)-reduction in ).
As in  the normal order reduction of  has reduction rules (\rlapp),
(\rlcase), and (\rlseq) to move \tletrec-expressions out of an application, a
\tseq-expression, or a \tcase-expression.

\vspace*{1mm} 
Note that  is unique. 
An -WHNF is defined as an expression either of the form 
or of the form  where  is an  context. 
Let  be the set of -WHNFs, then the calculus 
is defined by the tuple 
 
(modulo -equivalence). 

\subsection{\texorpdfstring{The Extended Lazy Lambda Calculus }{The Extended Lazy Lambda Calculus Llcc}}
In this subsection we give a short description of the  lazy lambda 
calculus \cite{abramsky-lazy:90} extended by data constructors, 
\tcase-expressions and \tseq-expressions, denoted with . 
Unlike the calculi  and , this calculus has no 
-expressions.
The set  of -expressions is that of the usual (untyped)
lambda calculus extended by data constructors, , and : 


Contexts  are -expressions where a subexpression is
replaced by the hole .
The set  of {\em answers} (or also {\em values}) are the 
-abstractions and constructor applications. 
Reduction contexts  are defined by the following grammar, where
 is any -expression:


An -reduction is defined by the three rules shown 
in \FIGURE~\ref{figure-reductions-LLAZY}, and thus the calculus  is defined 
by the tuple 
(modulo -equivalence).


\begin{figure}[htpb]
\centering
\begin{tabular}{|ll|}
\hline
&\
 \begin{array}{rcl@{~~~\mbox{and}~~~~}rcl}
   \leb_{D,{\cal Q},0} &= &{\EXPRESSIONS}\times{\EXPRESSIONS} &\leb_{D,{\cal Q},i} &=&F_{D,{\cal Q}}(\leb_{D,{\cal Q},{i-1}}) \text{if }
  \end{array}
r \in \mathit{CE}_{\LCC} ::= \Omega~|~\lambda x. s~|~(c~r_1 \ldots r_{\ari(c)})
 \begin{array}{@{}rcl}
S,T,S_i,T_i \in\IEXPR &::=& x \syxor (S_1~S_2) \syxor (\lambda x. S) \syxor \tbot
\\
    &&\syxor (c~S_1 \ldots S_{\ari(c)})
    \syxor (\tseq~S_1~S_2)
    \syxor (\tcase_T~S~\tof~alts)
\end{array}
\begin{array}{@{\,}l@{~}c@{~}l@{~}l@{\,}}
\Ctxt[(s~t)\LABELCOMP_{\varepsilon}] & \mapsto &  @ \\
\Ctxt[({\tt case}_T~\ldots)\LABELCOMP_{\varepsilon}] & \mapsto & {\tt case}_T \\
\Ctxt[(c~x_1\ldots~x_n\to s)\LABELCOMP_{\varepsilon}] & \mapsto & (c~x_1~\ldots~x_n) \qquad \mbox{for a case-alternative}\\
\Ctxt[({\tt seq}~s~t)\LABELCOMP_{\varepsilon}] & \mapsto & {\tt seq} \\
\Ctxt[(c~s_1 \ldots s_n)\LABELCOMP_{\varepsilon}] & \mapsto & c \\
\Ctxt[(\lambda x.s)\LABELCOMP_{\varepsilon}] & \mapsto &  \lambda x \\
\Ctxt[x\LABELCOMP_{\varepsilon}] & \mapsto &  x \hspace*{.3cm} \mbox{if  is a free variable or a lambda-bound variable in } \\
\end{array}\begin{array}{ll@{\quad}c@{\quad}ll}
1. &\Ctxt[(\lambda x.s)\LABELCOMP_{1.p}] & \mapsto &  \Ctxt[\lambda x.(s\LABELCOMP_p)] \\
2. &\Ctxt[(s~t)\LABELCOMP_{1.p} ] & \mapsto &   \Ctxt[(s\LABELCOMP_p ~t)]\\
3. &\Ctxt[(s~t)\LABELCOMP_{2.p} ] & \mapsto &   \Ctxt[(s~t\LABELCOMP_p)]\\
4. &\Ctxt[(\tseq~s~t)\LABELCOMP_{1.p} ] & \mapsto &   \Ctxt[(\tseq~s\LABELCOMP_p~t)]\\
5. &\Ctxt[(\tseq~s~t)\LABELCOMP_{2.p} ] & \mapsto &   \Ctxt[(\tseq~s~t\LABELCOMP_p)]\\
6. &\Ctxt[(\tcase_T~s~{\tt of}~ \mathit{alt}_1 \ldots \mathit{alt}_n)\LABELCOMP_{1.p} ] & \mapsto &   \Ctxt[(\tcase_T ~ s\LABELCOMP_{p}~{\tt of} ~\mathit{alt}_1 \ldots \mathit{alt}_n)]\\
7. &\Ctxt[(\tcase_T ~s~{\tt of} ~\italt_1 \ldots \italt_n)\LABELCOMP_{(i + 1).p} ] & \mapsto &   \Ctxt[(\tcase_T ~s~{\tt of} \italt_1 \ldots {\italt_i}\LABELCOMP_{p} \ldots \italt_n)]\\
8. &\Ctxt[\ldots (c~x_1~\ldots~x_n \to s)\LABELCOMP_{1.p} \ldots ] & \mapsto &  \Ctxt[\ldots  (c~x_1~\ldots~x_n \to s\LABELCOMP_{p}) \ldots ] \\
9. &\Ctxt[(c~s_1 \ldots s_n)\LABELCOMP_{i.p} ] & \mapsto &   \Ctxt[(c ~s_1 \ldots s_i\LABELCOMP_{p} \ldots s_n)]\\
10.&\Ctxt[\tletrx{\iEnv}{s}\LABELCOMP_{p}]   & \mapsto &   \Ctxt[\tletrx{ \iEnv}{s\LABELCOMP_{p}}]  \\
11. &\Ctxt_1[\tletrx{x = s, \iEnv}{\Ctxt_2[x\LABELCOMP_p]}]  &\mapsto &  \Ctxt_1[\tletrx{x = s\LABELCOMP_p, \iEnv}{\Ctxt_2[x]}] \\
12. &\begin{array}{@{}l}\Ctxt_1[\tletrec~x = s, y = \Ctxt_2[x\LABELCOMP_p],\\ 
          \hspace*{1.5cm} \iEnv~\tin~t]  \end{array}
     & \mapsto   
  &  \begin{array}{@{}l} \Ctxt_1[\tletrec~x = s\LABELCOMP_p, y = \Ctxt_2[x], \\ \hspace*{1.5cm} \iEnv~\tin~t]  \end{array}\\ 
13. &\Ctxt_1[\tletrx{x = \Ctxt_2[x\LABELCOMP_p], \iEnv}{s}]  &\mapsto &  \Ctxt_1[\tletrx{x = \Ctxt_2[x]\LABELCOMP_p, \iEnv}{s}] \
}}
\caption{Infinite tree construction from positions for fixed }\label{figure-inftree}
\end{figure*}





\begin{example}
The expression 
   has the corresponding  tree  
 .
\end{example}

The set  of infinite tree contexts includes any infinite tree where a subtree is replaced by a hole .  
Reduction contexts on trees are defined as follows:

\begin{definition}
Call-by-name reduction contexts  of  are defined as follows, where the grammar is interpreted inductively
and  :

For an infinite tree, a {\em reduction position}  is any position such that  is defined and
there exists some  with  and 
\end{definition}
 

\begin{definition} An -answer (or an -WHNF) is any infinite -expression  which is an abstraction or constructor application,
\ie\  or  for some constructor .
The reduction rules on infinite expressions are allowed in any context and are as follows: 

If  for a  -context , and  for ,  
then we say  is a {\em normal order reduction} (-reduction) on infinite trees.
Here  is the {\em tree-redex} of the tree-reduction. 
We also use the convergence predicate  for infinite trees defined as:  iff  and
 is an -WHNF.
\end{definition}


Note that   and  only reduce a single redex, 
but may modify infinitely many positions, since there may be infinitely many positions of a replaced variable .  
\Eg, a \mbox{(,\rbetaTr)} of 

replaces the infinite number of occurrences of  by . 

Concluding, the calculus  is defined by the tuple 
where  are the -WHNFs.

  

In the following we  use a variant of infinite outside-in developments \cite{barendregt:84,kennaway-klop:97} as a reduction on trees 
that may reduce infinitely many redexes in one step.
The motivation is that the infinite trees corresponding to finite expressions may  
require the reduction of
infinitely many redexes of the trees for one - or -reduction, respectively. 



\begin{definition}\label{def:one-reduction} 
We define an infinite variant of Barendregt's 1-reduction:
Let  be an infinite  tree.  
Let  be a special label and  be a set of (perhaps infinitely many) positions of , which must be redexes
\wrt\ the same reduction .
Now exactly all  positions  of  are labeled with . 
By  we denote the (perhaps infinite) development top down, defined as follows:
\begin{itemize}
  \item  Let  and . 
  \item Iteratively compute  and  from  and  
for  as follows: \\
Let  be the length of the shortest position in , and  be the finite set of positions 
that are the shortest ones in . 

For every  construct an infinite tree  from  by iterating the following reduction
until the root of  is not labeled: remove the  label from the top of , then perform a labeled reduction inheriting all 
the labels. 
If this iteration does not terminate, because the root of   gets labeled in every step, then the result is 
  (unlabeled), otherwise a result  is computed after finitely many reductions. 

Now construct  by replacing every subtree at a position  in  by :
for the positions  of  that do not have a prefix that is in , we set  and
for  we set .
 

Let  be the set of positions in  which carry a label . 
The length of the shortest position is now at least . 
Then iterate again with .
\item  is defined as the result after (perhaps infinitely many) construction steps 
\end{itemize}
If the initial set  does not contain a reduction position then we write .
We write  (, resp.)
if there exists a set  such that  (, resp.). 
\end{definition}

\begin{example}\label{example:inf-tree-reductions-std} We give two examples of standard reduction and -reductions.\\
An -reduction on expressions corresponds to an -reduction on infinite trees
and perhaps corresponds to an infinite sequence of infinite -reductions.
Consider . The -reduction 
with a subsequent  reduction results in 
.  The corresponding infinite tree of  is
.
The -reduction-sequence is infinite.
let   be the infinite set of positions of all the applications in , \ie\ . Then in the (infinite) development described in  Def. \ref{def:one-reduction} all intermediate trees have a label at the top,
and thus we have . For a set  without , the result will be a value tree.  

  For the expression   the -reduction results in
the expression  which diverges. The corresponding infinite tree is
   , which has an infinite number of -reductions,
   at an infinite number of deeper and deeper positions. 
   Let  be the set consisting of all those positions.
Then . 
\end{example}


There may be  such that  as well as  for some sets  where  contains a reduction position, 
but  does not contain a reduction position. For example , where a single (\rbetaTr)-reduction   
at the top reproduces ,
as well as a single (\rbetaTr)-reduction of the  argument. 





\subsection{Standardization of Tree Reduction}\label{subsec-inf-proc-standardization}
Before considering the concrete calculi  and  and their correspondence to the calculus with infinite
trees, we show that for an arbitrary reduction sequence on infinite trees resulting
in an answer we can construct a -reduction sequence that results in an -WHNF.

\begin{lemma}\label{lemma:T-successful-nsr-base-case} Let  be an infinite expression.
 If   for some , where  is an answer, then  is also an answer.
 \end{lemma}
\begin{proof}
This follows since an answer cannot be generated by -reductions, since neither abstractions
nor constructor expressions can be generated at the  top  position.
\end{proof}


\begin{lemma}\label{lemma-R-forking} 
Any overlapping between a -reduction and a -reduction 
 can be closed as follows. The trivial case that both given reductions
are identical is omitted.  

\begin{tabular}{@{}lll@{}}
  \begin{minipage}{0.3\textwidth}
  
  \end{minipage}
&
  \begin{minipage}{0.3\textwidth}
  
  \end{minipage}
&
  \begin{minipage}{0.3\textwidth}
  
  \end{minipage}
 \end{tabular}

 \end{lemma}
 \begin{proof}
 This follows by checking the  overlaps of  with -reductions.   
The third diagram applies if the positions of  are removed by the -reduction.
The second diagram applies if the -redex is included in  and the first diagram is applicable
in all other cases.
 \end{proof}


 
 \begin{lemma}\label{lemma-R-star-forking}
Let  be an infinite  tree such that there is
a -reduction sequence of length  to a WHNF , and let  be an infinite tree with 
.
Then   has a -reduction sequence  of length  to a WHNF .  
 \end{lemma}
 \begin{proof}
This follows from Lemma \ref{lemma-R-forking} by induction on .
 \end{proof}

\begin{lemma}\label{lemma-red-triangle} 
Consider two  reductions   and   of the same type   (\rbetaTr), (\rcaseTr) or (\rseqTr). 
For all trees : if , 
and , and , then there is a set  of positions, such that  . 

\end{lemma}
\begin{proof} 
The argument is that the set  is computed by labeling the positions in  using , and then by performing the infinite development using
the set of redexes , where we assume that the -labels are inherited.
The set of positions of marked redexes in  that remain and are not reduced by   
 is exactly the set . \qedhere
\end{proof}

Consider a reduction  of type (\rbetaTr), (\rcaseTr) or (\rseqTr).
This reduction may include a redex of a normal order \TREE-reduction. Then the reduction can be split into , 
and splitting of the reduction can be iterated
as long as the remaining  has a \TREE-redex. 
It may happen that this process does not terminate. 

We consider this non-terminating case, \ie\ let  and we can assume that there exist infinitely many 
 and  such that for any :  and .
By induction we can show for every : 
 for a reduction context  and 
where  is the redex and  is the contractum of  and the normal order 
-redex of  labels  a subterm of .
This holds, since the infinite development for   is performed top down.

This implies that the infinite -reduction goes deeper and deeper along one path of the tree,
or at some point all remaining -reductions are performed at the same position.

\begin{lemma}\label{lemma:iteration-stops-maycon}
Let  such that  and  labels the normal order redex of .
Then there exists  and  such that .
\end{lemma}
\begin{proof}
Let ,  where  labels a normal order redex.

We have   where  is a reduction context, and  labels the hole of , 
which is the normal order redex. The normal order
reduction is . 
Let  be the path of the hole of , together with the 
constructors and symbols (\tcase, \tseq, constructors and ) on the path. 
Also let , (where  means disjoint union) where the labels 
of  are in , and the labels  are
in . 
Lemma \ref{lemma-red-triangle},  the structure of the expressions and the properties of the infinite top down developments
show  that the normal order redex can only stay or descend, \ie\
   implies that  is a prefix of . 
  
 
 Also, we have , where ,
 and .
 
 \noindent There are three cases: 
 \begin{itemize}
    \item The normal order reduction of  halts, \ie, there is a maximal . 
        Then obviously .
    \item There is some , such that  for all . In this case, 
    . The infinite development  will reduce infinitely
      often at the position of the hole, hence it
       will plug a  at position   of , and so .  But then  cannot converge,
         and so this case is not possible.
    \item The positions  of the reduction contexts  will grow indefinitely. Then there
     is an infinite path (together with the constructs and symbols)  
      such that   is a  prefix  of  for every .
      Moreover,  is a position of . 
      The sets  are an infinite ascending set \wrt\ , hence there is a limit tree
       with , which is exactly
      the limit of the contexts  for . 
      There is a  reduction   which is exactly .
      Hence  has the  path ,     
        and we see that the tree  cannot have a normal order redex, since the search for such a redex 
         goes along  and thus does not terminate. 
         This is a contradiction, and hence this case is not possible.\qedhere
 \end{itemize}
 \end{proof}

\begin{lemma}\label{lemma:commute-one-nsr-base} Let . 
Then the reduction can be commuted to  for some .
\end{lemma}
\begin{proof}
This follows since the -reduction cannot generate a new normal order -redex.
Hence, the normal order redex of  also exists in . The set  can be found by labeling  with , then performing
the -reduction where all labels of  are kept and inherited by the reduction, except for those positions which are
removed by the reduction.
\end{proof}




\begin{lemma}\label{lemma:commute:ntree-maycon}
 Let  and . Then .
\end{lemma}
\begin{proof}
 We show by induction on  that whenever   where  is an -WHNF,
 then .
The base case is  and it holds by Lemma~\ref{lemma:T-successful-nsr-base-case}.
For the induction step let .
We apply Lemma~\ref{lemma:commute-one-nsr-base} to 
and thus have  for some .

This situation can be depicted by the following diagram where the dashed reductions follow by Lemma~\ref{lemma:commute-one-nsr-base}:



If  does not contain a normal order redex, then the induction hypothesis shows that  and thus
also . 
Now assume that  contains a normal order redex. Then we apply Lemma~\ref{lemma:iteration-stops-maycon} to
 (note that  and hence the lemma is applicable).
This shows that :


Now we can apply the induction hypothesis
to  and have  which also shows .
\end{proof}

\begin{proposition}[Standardization]\label{prop:I-sequence-gives-maycon}
Let  be infinite trees such that 
,
where  is an -WHNF.
Then 
\end{proposition}
 \begin{proof}
We use induction on . If  then the claim obviously holds since  is already an -WHNF.
For the induction step assume that  
 and . Let .
If  contains a normal order redex, then we apply Lemma~\ref{lemma:iteration-stops-maycon} and have the following situation
              
where  is an -WHNF. We apply Lemma~\ref{lemma:commute:ntree-maycon} to 
which shows that  and thus also .

\noindent If  contains no normal order redex, we have
 
where  is an -WHNF. We apply Lemma~\ref{lemma:commute:ntree-maycon} to 
and have .
 \end{proof}



\subsection{\texorpdfstring{Equivalence of Tree-Convergence and -Convergence}{Equivalence of Tree-Convergence and LR-Convergence}}
In this section we will show that -convergence for finite expressions 
coincides with convergence for the corresponding infinite tree .

\begin{lemma}\label{lemma-cp-ll-inftreeeq} Let  be finite expressions and  by a rule (\rcp), or (\rlll).
Then . \qed
\end{lemma}


\begin{lemma}\label{lemma-red-base-case} Let  be a finite expression. If  is an -WHNF then   is an answer.
If    is an answer, then .
\end{lemma}
 \begin{proof}
If   is an -WHNF, then obviously,  is a answer.
If  is an answer, then the label computation of the infinite tree for the empty position using , \ie\ ,
must be  or  for some constructor. If we consider all the cases where the label computation for  ends
with such a label, we see that  must be of the form , where  is an -answer and the contexts  are constructed
according to the grammar:


We show by induction that every expression , where  is a value, can be reduced by normal order (\rcp)- and (\rllet)-reductions
to a WHNF in . We use the following induction measure  on :
 
The base case obviously holds, since  is already an -WHNF. For the induction step assume that , where  is 
an -WHNF for every  with . Let , and  be fixed, such that .
There are two cases:
\begin{itemize}
 \item . 
 If  is the empty context, then  is an -WHNF.
 Otherwise  is a -expression. Thus we can apply an -reduction to , where the measure  is 
 decreased by one. The induction hypothesis shows the claim.
\item .
If  is a -expression, then we can apply an -reduction to  and the measure  is
 decreased by 1. 
If  is the empty context, and there is some  such that  is not the empty context, then we can choose the largest number 
and apply an -reduction to . Then the measure  is strictly decreased and we can use the induction hypothesis.
If all the contexts  for  are empty contexts, then either  is an -WHNF (if  is a constructor application)
or we can apply an  reduction to obtain an -WHNF. \qedhere
\end{itemize}
\end{proof}

\begin{lemma}\label{lemma:single-red-inf}
Let  such that .  
If the reduction  is (\rcp) or (\rlll) then .  
If the reduction  is (\rlbeta), (\rcasec), (\rcasein), (\rcasee) or (\rseqc), (\rseqin),(\rseqc) then 
 for some , where  is (\rbetaTr), (\rcaseTr), or (\rseqTr), respectively, and the set 
 contains normal order redexes.
\end{lemma}
\begin{proof}
Only the latter needs a justification. Therefore, we label every redex in  that is derived from the redex  by .
This results in the set  for .
There will be at least one position in  that is a normal order redex of . 
\end{proof}
 

 


  
 \begin{proposition}\label{prop:maycon-expr-to-infexpr}
Let  such that . Then .
 \end{proposition}
 \begin{proof}
We assume that  , where  is a WHNF.
Using Lemma \ref{lemma:single-red-inf}, we see that there is
a finite sequence of reductions . 
Lemma~\ref{lemma-red-base-case} shows that  is an -WHNF.
Now Proposition~\ref{prop:I-sequence-gives-maycon} shows that .
 \end{proof}





We now consider the other direction and show that for every expression : if  converges, then  converges, too.
  



\begin{lemma}\label{lemma-partition-R-red} 
Let  be some reduction context, \st\ .
Then for 
there exist expressions  and an infinite tree  with .

 
\end{lemma}
\begin{proof}
Let  be the position of the hole of . We follow the label computation to  along  inside 
and show that the redex corresponding to  can be found in  after some  and  reductions. 
For applications, \tseq-expressions, and \tcase-expressions there is a one-to-one correspondence.
If the label computation shifts a position into a ``deep'' , \ie\ 
 where  is non-empty, 
then a sequence of normal order (lll)-reduction moves the environment  to the top of the expression, where
perhaps it is joined with a top-level environment of . Let 
Lemma~\ref{lemma-cp-ll-inftreeeq} shows that  and the label computation along  for  requires fewer steps than the computation for .
Hence this construction can be iterated and terminates. This yields a reduction sequence  such that
the label computation along  for  does not shift the label into deep s and where  (see Lemma~\ref{lemma-cp-ll-inftreeeq}).
Now there are two cases: Either the redex corresponding to  is also a normal order redex of , or  is of
the form . For the latter case an  reduction
is necessary before the corresponding reduction rule can be applied. Again Lemma~\ref{lemma-cp-ll-inftreeeq} assures that the infinite tree remains unchanged.
After applying the corresponding reduction rule, \ie\ , the normal order reduction may have changed
infinitely many positions of , while  does not change all these positions, but nevertheless
Lemma \ref{lemma:single-red-inf} shows that  there is a reduction , and Lemma~\ref{lemma-red-triangle} 
shows that also  for some . 
\end{proof} 

\begin{example}
An example for the proof of the last lemma is the expression  defined as  . Then
. The -reduction for  is
. On the other hand the normal order reduction of  reduces
to  and . To join the reductions we perform an -reduction
for  where all redexes are labeled in , which also results in .
\end{example}

 

\begin{proposition}\label{prop:tree-conv-impl-term-conv} Let  be an  expression such that . 
Then  .     
\end{proposition} 
\begin{proof} 
The precondition   implies
 that there is a -reduction sequence of   to an -WHNF.
The base case, where no -reductions are necessary, is treated in Lemma \ref{lemma-red-base-case}. 
In the general case, let  be a -reduction.
Lemma \ref{lemma-partition-R-red} shows that  there are expressions  with 
,  
and  .
Lemma \ref{lemma-R-star-forking} shows that  has a normal order -reduction to a WHNF 
where the number of -reductions is strictly smaller than the  number of -reductions of  to a WHNF.
Thus  we can use induction on this length and obtain a normal order -reduction of  to a WHNF.
\end{proof}
\noindent Propositions \ref{prop:maycon-expr-to-infexpr} and \ref{prop:tree-conv-impl-term-conv} imply the theorem
\begin{theorem}\label{thm:may-equivalence}
Let  be an -expression. Then  if and only if .  \qed
\end{theorem}
\subsection{\texorpdfstring{Equivalence of Infinite Tree Convergence and -convergence}{Equivalence of Infinite Tree Convergence and LNAME-convergence}}
It is easy to observe that several reductions of  do not change the infinite trees \wrt\ the 
translation :

\begin{lemma}\label{lemma:lapp-cp-it-identical}
Let . Then 
   for  implies .\qed
\end{lemma}

\begin{lemma}\label{lemma:name-beta-is-tree-beta}
For  it holds:

\noindent If  for , then  .
\end{lemma}
\begin{proof}
Let  where  is the redex of the -reduction
and  is an -reduction context. First one can observe that 
the redex  is mapped by  to a unique tree position within a tree reduction context in .  

We only consider the (\rbeta)-reduction, since for a (\rcase)- or a (\rseq)-reduction the reasoning is completely analogous.
So let us assume that . Then  transforms  into a subtree 
 where  is a substitution replacing variables by infinite trees.
The tree reduction replaces  by , 
hence the lemma holds.
\end{proof}


\begin{proposition}
 Let  be an expression with . Then .
\end{proposition}
\begin{proof}
This follows by induction on the length of a normal order reduction of . 
The base case holds since , where  is an -answer is always an -answer.
For the induction step we consider the first reduction of , say . The induction hypothesis
shows . If the reduction 
is  (,\rgcp), (,\rlapp), \mbox{(,\rlcase),} or (,\rlseq), then Lemma~\ref{lemma:lapp-cp-it-identical}
implies . If  for , 
then Lemma~\ref{lemma:name-beta-is-tree-beta} shows  and thus .
\end{proof}
\noindent Now we show the other direction: 


\begin{lemma}\label{lem:name-lapp-cp=gleich}
Let   such that , where  is a tree reduction context and  is a value or a redex.   
Then there are expressions   such that , ,  ,
, where  is a reduction context for some -context  and some -context ,
  may be an abstraction, a constructor application, or a  \rbeta-, \rcase- or \rseq-redex 
   iff  is an abstraction, a constructor application, or a  \rbetaTr-, \rcaseTr- or \rseqTr-redex, respectively,
and the position  of the hole in  is also 
the position of the hole in .
\end{lemma}
\begin{proof*}
The tree  may be an abstraction, a constructor application, an application, or a \rbetaTr-, \rcaseTr- or \rseqTr-redex in . 
Let  be the position of the hole of . 
We will show by induction on the label-computation for  in  that there is a  reduction 
, where  is as claimed in the lemma. \\
We consider the label-computation for  to explain the induction
measure, where we use the numbers of  the rules given in  \FIGURE~\ref{figure-inftree}.
Let  be such that the label computation for  is of the form  and  does not start with . 
The measure for induction is  a tuple , where  is the  
length of , and   is
 the maximal number with   .
The base case is : Then the label computation is of the form  and 
indicates that  is of the form  and satisfies the claim of the lemma.
For the induction step  we have to check several cases: 
\begin{enumerate}
\item The label computation starts with . 
 Then a normal-order (lapp), (lcase), or (lseq)
can be applied to  resulting in 
. The label-computation for  \wrt\  is of the same
  length, and only applications of (10)
  and  are interchanged, hence the second component of the measure is strictly decreased.
\item  The label computation starts with . 
Then a normal-order (\rgcp) can be applied to  resulting in 
. The length  is strictly decreased by 1, and perhaps one (12)-step is changed into a (11)-step. Hence the 
measure is strictly decreased.
\end{enumerate}
In every case the claim on the structure of the contexts and  can easily be verified.
\qedhere
\end{proof*}

\begin{lemma}\label{lemma:tree-reduction-can-be-simulated-by-name}
 Let  be an expression with . 
 Then there is some  with  and .
\end{lemma}
\begin{proof}
If , then  where  is a reduction context,
  a tree-redex with 
and . Let  be the position of the hole of  in . 
We  apply 
Lemma \ref {lem:name-lapp-cp=gleich}, which implies 
 that there is  a reduction , such that  and  
 where  is a reduction context and  is a beta-, case-, or seq-redex.
It is obvious that .
Now one can verify that  must hold.
\end{proof}


\begin{proposition}
 Let  be an expression with . Then .
\end{proposition}
\begin{proof}
We use induction on the length  of a tree reduction , where  is an -answer.
For the base case it is easy to verify that if  is an -answer, then  for 
some -context  and some -value . Hence we have .
The induction step follows by repeated application of Lemma~\ref{lemma:tree-reduction-can-be-simulated-by-name}.
\end{proof}




\begin{corollary}\label{cor:infinite-tree-conv=name-conv} For all -expressions : 
  if, and only if . \qed
\end{corollary}

\begin{theorem}\label{theo:leqneed-equals-leqname}
 .
\end{theorem}
\begin{proof}
In Corollary~\ref{cor:infinite-tree-conv=name-conv} we have shown that -convergence is equivalent to infinite tree convergence. 
In Theorem~\ref{thm:may-equivalence} we have shown that -convergence is equivalent to infinite tree convergence. Hence, 
-convergence and -convergence are equivalent, which further implies that both contextual preorders and also
the contextual equivalences are identical.
\end{proof}





\begin{corollary}\label{cor:W-fully-abs}
The translation  is convergence equivalent and fully abstract. \qed
\end{corollary}

Since  is the identity on expressions, this  implies:
\begin{corollary}\label{cor:W-iso}
 is an isomorphism according to Definition \ref{def:translation-compo-etal}.\qed
\end{corollary}

A further consequence of our results 
 is that the general copy rule (gcp) is a correct program transformation in .
This is a novel result, since in previous work only special cases were proved correct.
\begin{proposition}\label{prop-gcp-correct}
 The program transformation (gcp) is correct in  and .
\end{proposition}
\begin{proof}
Correctness of (gcp) in  holds, since for  with
  and for any context : . Hence
 Corollary~\ref{cor:infinite-tree-conv=name-conv} implies that
  and
thus . Theorem~\ref{theo:leqneed-equals-leqname} finally also shows .
\end{proof}
 





\section{\texorpdfstring{The Translation }{The Translation N}}\label{sec:NAME-to-LAZY}
We use multi-fixpoint combinators as defined in~\cite{goldberg:05} to translate
letrec-expressions  of the calculus  into equivalent ones without a \tletrec. The translated
expressions are  and belong to the calculus .

\begin{definition}\label{def:multifixpoint}
Given , a family of  fixpoint combinators  for  can be defined as follows: 

\end{definition}

The idea of the translation is to replace  
  by 
 where  
 and .

In this way the fixpoint combinators implement  the generalized fixpoint property: 
. However, our translation uses modified expressions, as shown below. 



Consider the expression \mbox{}. After expanding the notation for  we obtain the expression

where  can be expanded to .
If we reduce further then we get:



We take the latter expression as the definition of the
multi-fixpoint translation, where we avoid substitutions 
and instead generate (\rnbeta)-redexes
which ensures that contexts are mapped to contexts
\begin{definition}
The translation  is recursively defined as:
\begin{itemize}
\item
  \\
  \\begin{array}{rcl}
  \sigma &= & \{x_1 \mapsto U_1, \ldots x_n \mapsto U_n\}
 \\ 
   U_i   &=& (X'_i~X'_1~\ldots~X'_n),
\\
   X'_i  &=& \lam x_1 \ldots x_n. F_i (x_1~x_1~\ldots~x_n)~\ldots~(x_n~x_1~\ldots~x_n), 
\\
   F_i &=& \lambda x_1, \ldots, x_n . \transN(s_i).
\end{array}

\begin{array}{l}
\transN(s) = R'[\sigma(\transN((\lam x. s_1)~s_2))]
     = R'[(\lam x.\sigma(\transN(s_1)))~\sigma(\transN(s_2))]
\
\begin{figure}
1.1ex]
\text{(1)} &\text{(2)} &\text{(3)}
\end{array}
\1.1ex]
\text{(4)} &\text{(5)} &\text{(6)}&\text{(7)}
\end{array}
\end{array}

\begin{array}{l}
s = L[\tletrec~x_1=s_1,\ldots,x_n=s_n~\tin~R[x_1]]
\annRed{\NAME,\rgcp}
\\
t = L[\tletrec~x_1=s_1,\ldots,x_n=s_n~\tin~R[s_1]]
\end{array}
\begin{array}{ll}
\transN(s)  &= \sigma_L(\sigma_{\iEnv}(R'[\sigma_{R}(x_1)]))
      = \sigma_L(\sigma_{\iEnv}(R'))[\sigma_L(\sigma_{\iEnv}(\sigma_{R}(x_1)))]
\\
      &= \sigma_L(\sigma_{\iEnv}(R'))[\sigma_L(\sigma_{\iEnv}(x_1))]
  \end{array}\transN(t) = \sigma_L(\sigma_{\iEnv}(R'))[\sigma_L(\sigma_{\iEnv}(\transN(s_1)))]
\begin{array}{ll}
&(\lam x_1, \ldots, x_n. (F_1 (x_1 x_1 \ldots x_n) \ldots (x_n x_1 \ldots x_n)))~X'_1~\ldots~X'_n 
\\
\annRed{\rnbet,n}
&F_1~(X'_1 X'_1 \ldots X'_n)~\ldots~(X'_n X'_1 \ldots X'_n) 
\\
=&
(\lam x_1, \ldots, x_n. \sigma_L(\transN(s_1)))~(X'_1 X'_1 \ldots X'_n)~\ldots~(X'_n X'_1 \ldots X'_n)
\\
\annRed{\rnbet,n}
&
\sigma_L(\transN(s_1))[U_1/x_1, \ldots, U_n/x_n].
\end{array}

\begin{array}{@{\quad\qquad}l@{~}l@{}}
\transN(s) &= R'[\sigma(\transN(\tcase_T~(c~s_1 \ldots s_{\ari(c)}) \ldots ((c~x_1 \ldots x_{\ari(c)}) \to r) \ldots ))] 
\\
            &= R'[\tcase_T~(c~\sigma(\transN(s_1))) \ldots \sigma(\transN(s_{\ari(c)})) \ldots ((c~x_1 \ldots x_{\ari(c)}) \to \sigma(\transN(r))) \ldots]
\end{array}
\begin{array}{@{\quad\qquad}l@{~}l@{}}
\transN(t)  &= \transN(R[r[s_1/x_1, \ldots, s_{\ari(c)}/x_{\ari(c)} ]]) 
\\
 &=     R'[\sigma(\transN(r[s_1/x_1, \ldots, s_{\ari(c)}/x_{\ari(c)} ]))] 
\\
 &=     R'[\sigma(\transN(r))[\sigma(\transN(s_1))/x_1, \ldots, \sigma(\transN(s_{\ari(c)}))/x_{\ari(c)} ]]
\end{array}\qquad\qquad
\eqalign{
  \transN(R[(\tletrec~\iEnv~\in~s_1)~s_2]) 
&= R'[\sigma_R(\sigma_{Env}(\transN(s_1))~\transN(s_2))]\cr
&= R'[\sigma_R(\sigma_{\iEnv}(\transN(s_1~\transN(s_2))))]\cr
&= \transN(R[(\lr \iEnv \inn (s_1~s_2))])
}

\begin{array}{l}
\transN(s) = R'[\sigma(\transN(\tseq~v~s_1))]=R'[\tseq~\sigma(\transN(v))~\sigma(\transN(s_1))] 
\

By Lemma~\ref{lem:translate-values}~ is a value in  (which cannot be changed by the substitution )
and thus .
The diagram for this case is (7) in Figure~\ref{fig:N-diagrams}.
\end{itemize}



We inspect how WHNFs and values  of both calculi are related \wrt\ :


\begin{lemma}\label{lemma:irreduble-in-lname-non-whnf-implies-irreducible-non-whnf-in-lcc}
Let  be irreducible in , but not an -WHNF. 
Then  is irreducible in  and also not an -WHNF.
\end{lemma}
\begin{proof}
Assume that expression  is irreducible in  but not an -WHNF. There are three cases:
\begin{enumerate}
 \item Expression  is of the form  where  is a free variable in ,
then let  and thus .  Since  only substitutes bound variables, we get
 and thus  where  is free in . Hence  cannot be an -WHNF and it is irreducible in .
\item Expression  is of the form , but  is not of type .
Let . Then 
which shows that  is not an -WHNF and irreducible in .
\item Expression  is of the form . Then again  is not an -WHNF and irreducible. \qedhere
\end{enumerate}
\end{proof}
\begin{lemma}\label{lem:T-WHNF} 
Let . Then   is an -WHNF iff  is an -WHNF.
\end{lemma}
\begin{proof}
If  or  then  
or  respectively, both of which are
-WHNFs. 

For the other direction assume that  is an abstraction or a constructor application.
The analysis of the reduction correspondence in the previous paragraph
shows that  cannot have a normal order redex in , since otherwise  cannot be an -WHNF. 
Lemma \ref{lemma:irreduble-in-lname-non-whnf-implies-irreducible-non-whnf-in-lcc} shows that  cannot be irreducible in , but
not an -WHNF. Thus  must be an -WHNF.
\end{proof}


\subsubsection*{\texorpdfstring{Transferring -reductions into -reductions}{Transferring LCC-reductions into LNAME-reductions}}~\\
We will now analyze how normal order reductions for  can be transferred
into normal order reductions for  in .

Let  be an -expression and .
We split the argument into three cases based on whether or not a normal order reduction is applicable to :
\begin{itemize}
 \item If , then we can use the already developed diagrams, since normal-order reduction
in both calculi is unique.
 \item  is a WHNF. This case cannot happen, since then  would also be a WHNF (see Lemma~\ref{lem:T-WHNF}) and thus irreducible.
 \item  is irreducible but not a WHNF. Then Lemma~\ref{lemma:irreduble-in-lname-non-whnf-implies-irreducible-non-whnf-in-lcc} implies
that  is irreducible in  which contradicts the assumption . Thus this case is impossible.\medskip
\end{itemize}



\noindent We summarize the diagrams in the following lemma:
\begin{lemma}\label{lem:T-diagrams}
Normal-order reductions in  can be transferred into
reductions in , and vice versa, by the diagrams in Figure~\ref{fig:N-diagrams}. \qed
\end{lemma}



\begin{proposition}\label{prop:TY-conv-equiv-appendix}\label{prop:TY-conv-equiv}
  and  are convergence equivalent, \ie\ for all -expressions :  
 (
, resp.).
\end{proposition}
\begin{proof}
We first prove convergence equivalence of :
Suppose . Let  where  is a WHNF.
We show that there exists an -WHNF  such that  
by induction on . The base case follows from Lemma~\ref{lem:T-WHNF}. 
The induction step follows by applying a diagram from Lemma~\ref{lem:T-diagrams}
and then using the induction hypothesis.

For the other direction we assume that , \ie\ there exists a
WHNF  \st\ . 
By induction on  we show that there exists a
-WHNF  such that . The base case is covered by
Lemma~\ref{lem:T-WHNF}. The induction step uses the diagrams.
Here it is necessary to observe that the diagrams for the reductions (\rlapp), (\rlcase), and (\rlseq) cannot be applied
infinitely often without 
being interleaved with other reductions.
This holds, since let-shifting by (\rlapp), (\rlcase), and (\rlseq) moves \tletrec-symbols to the top of the expressions, and thus
 there are no infinite sequences of these reductions.

It remains to show convergence equivalence of : 
Let  then , since  is
convergence equivalent. Lemma~\ref{lemma:T-prime-sim-T} implies  
and thus  must hold.
For the other direction Lemma~\ref{lemma:T-prime-sim-T} shows that  implies 
. Using convergence equivalence of  yields
.
\end{proof}

 
\begin{lemma}\label{lemma:T-prime-comp}
The translation  is compositional, \ie\ for all expressions  and all contexts : .
\end{lemma}
\begin{proof}
This easily follows by  structural induction on the definition.
\end{proof}


\begin{proposition}\label{prop:T-adequ}
 For all  : , \ie\  is adequate.
\end{proposition}
\begin{proof}
Since  is convergence-equivalent (Proposition~\ref{prop:TY-conv-equiv}) 
and compositional by Lemma \ref{lemma:T-prime-comp}, 
we derive that  is adequate (see \cite{schmidt-schauss-niehren-schwinghammer-sabel-ifip-tcs:08} 
and Section \ref{sec:common}).
\end{proof}

 
\begin{lemma}\label{lemma:leq-transfers-from-name-to-lazy-for-letrec-free-expr}
 For -free expressions   the following holds: 
 .
\end{lemma}
\begin{proof}
Note that the claim only makes sense since clearly .
Let  be -free such that .
Let  be an -context such that , \ie\ .
By comparing the reduction strategies in  and , we obtain
that  (by the identical reduction sequence)
since  is -free. Thus,  and also , \ie\ there is a normal order reduction in  for  to a WHNF. 
Since  is -free, we can
perform the identical reduction in  and obtain .
\end{proof}


\noindent The language  is embedded into  (and also ) by .    

\begin{proposition}\label{proposition:s-Ns-neu}
 For all : . 
\end{proposition}
\begin{proof}
We first show that for all expressions : .
Since  is the identity mapping on -free expressions of  and  is -free,
we have
. 
Hence adequacy of  (Proposition~\ref{prop:T-adequ}) implies .
\end{proof}

\begin{proposition}\label{prop:missing-part:N-fully-abs}
 For all : .
\end{proposition}
\begin{proof}
For this proof it is necessary to observe that , thus we can  treat  expressions as  expressions.
Let  and . 
By  Proposition~\ref{proposition:s-Ns-neu}:
,  thus .
Since  and  are -free, we can apply Lemma~\ref{lemma:leq-transfers-from-name-to-lazy-for-letrec-free-expr}
and thus have .
\end{proof}


Now we put all parts together, where  means :
\begin{theorem}\label{theorem:N-fully-abstract}
 and  are fully-abstract, \ie\ for all expressions : \mbox{}.
\end{theorem}
\begin{proof}
Full-abstractness of  follows from Propositions~\ref{prop:T-adequ} and~\ref{prop:missing-part:N-fully-abs}.
Full-abstractness of  thus holds, since  is fully-abstract (Corollary~\ref{cor:W-fully-abs}).
\end{proof}


Since  is surjective, this and Corollary \ref{cor:N-iso} imply:
\begin{corollary}\label{cor:N-iso}
 and  are isomorphisms according to Definition \ref{def:translation-compo-etal}.\qed
\end{corollary}

The results also allow us to transfer the characterization of expressions in  into 
. With  we denote the set of -expressions  with the property that for all 
substitutions : if  is closed, then . 


\begin{proposition}\label{prop-classification-lr}
Let  be a closed -expression. 
Then there are three cases: ,  for some ,  

for some terms  and constructor . Moreover, the three cases are disjoint.   
For two closed -expressions  with : Either , or , 
 and  for all  for some terms 
   and constructor ,
or   and  for some expressions  with , or  
 and  
for some term , expressions  and constructor . 
\end{proposition} 
\begin{proof}
This follows by Proposition~\ref{prop-classification-lcc} and since  is surjective, compositional and fully abstract, and the identity on constructors.
\end{proof}


\section{\texorpdfstring{On Similarity  in  }{On Similarity in LR}}\label{sec-simulations}
In this section we will explain co-inductive and inductive (bi)similarity for .
Our results of the previous sections then enable us to show that these bisimilarities coincide  
with contextual equivalence in .


\subsection{\texorpdfstring{Overview of soundness and completeness proofs for similarities in }{Overview of soundness and completeness proofs for similarities in LR}}
Before we give details of the proof for lifting soundness and completeness of similarities from  to , 
we show an outline of the proof in \FIGURE~\ref{fig:proof-structure}.
The diagram shows fully abstract translations between the calculi , and  defined and studied in 
Sections~\ref{sec-translation-NEED-NAME} and~\ref{sec:NAME-to-LAZY}, where Corollary~\ref{cor:W-fully-abs} 
and Theorem~\ref{theorem:N-fully-abstract} show full abstractness for  and , respectively. 
These fully-abstract translations that are also surjective, and the identity on letrec-free expressions, allow us to 
prove that .  
By Theorem~\ref{thm:llc-Q-equivalence} in  ,
this is equivalent to  . 
 The proof is completed by using the translations by transferring the equations back and forth between  and 
in this section  in order to finally show that  in Theorem \ref{thm:maintheorem}.


\begin{figure}
\begin{tikzpicture}[yscale=0.6,xscale=1]
 \node (Lneedeq) at (0.5,-3) [] {\scalebox{1}{}};
 \draw [-,dotted] (Lneedeq) to node [] {} node [] {} (0.5,-.3);
 \node (LneedeqLRQce) at (-1.5,0) [] {\scalebox{1}{}};
 \node (Lneedbeq) at (0.5,3) [] {\scalebox{1}{}};
 \draw [-,dotted] (Lneedbeq) to node [] {} node [] {} (0.5,.3);
 \node (Lnameeq) at (5,-3) [] {\scalebox{1}{}};
 \draw [-,dotted] (Lnameeq) to node [] {} node [] {} (5,-.3);
 \node (Llazyeq) at (9.8,-3) [] {\scalebox{1}{}};
 \draw [-,dotted] (Llazyeq) to node [] {} node [] {} (10,-.3);
 \node (LlazyQbeq) at (9.8,3) [] {\scalebox{1}{}};   
 \draw [-,dotted] (LlazyQbeq) to node [] {} node [] {} (10,.3);
 \node (Lneedcircle) at (0.5,0) [line width=1pt,shape=ellipse,draw,fill=black!15!white] {\rule{0mm}{8mm}\rule{8mm}{0mm}};
 \node (Lneedtext) at (0.5,0) [] {\scalebox{1}{}};
 \node (Lnamecircle) at (5,0) [line width=1pt,shape=ellipse,draw,fill=black!10!white] {\rule{0mm}{8mm}\rule{8mm}{0mm}};
 \node (Lnametext) at (5,0) [] {\scalebox{1}{}};
 \node (Llazycircle) at (9.8,0) [line width=1pt,shape=ellipse,draw,fill=black!10!white] {\rule{0mm}{8mm}\rule{8mm}{0mm}};
 \node (Llazytext) at (9.8,0) [] {\scalebox{1}{}};
 \draw[->,line width=1pt] (Lneedcircle) to node [above] {} node [] {} (Lnamecircle);
 \draw[->,line width=1pt,bend left =30] (Lneedcircle) to node [above] {} node [] {} (Llazycircle);
 \draw[->,line width=1pt] (Lnamecircle) to node [above] {} node [] {} (Llazycircle);
 \draw[<->,double,double distance=1.2pt,line width=.5pt] (Lneedeq) to node [above=3pt] {Cor}  node [below=3pt] {\ref{cor:W-fully-abs}}(Lnameeq);
 \draw[<->,double,double distance=1.2pt,line width=.5pt] (Lnameeq) to node [above=3pt] {Thm} node [below=3pt] {\ref{theorem:N-fully-abstract}} (Llazyeq);
 \draw[<->,double,double distance=1.2pt,line width=.5pt, bend right=40] (Llazyeq) to node [right] {\parbox{1cm}{Thm\\\ref{theorem:bisim-alternatives}}} node [] {} (LlazyQbeq);
 \draw[<->,double,double distance=1.2pt,line width=.5pt, bend left=20] (Lneedeq) to node [left] {\parbox{1cm}{Prop\\\ref{prop:finite-simulation-LLR}}} node [] {} (LneedeqLRQce);
 \draw[<->,double,double distance=1.2pt,line width=.5pt, bend left=20] (LneedeqLRQce) to node [left] {\parbox{1cm}{Thm\\\ref{theo:closed-need-bisim-is-csim}}} node [] {} (Lneedbeq);
 \draw[<->,double,double distance=1.2pt,line width=.5pt] (LlazyQbeq) to node [above] {see Proof of Prop.  \ref{prop:finite-simulation-LLR}} node [] {} (Lneedbeq);
\end{tikzpicture}
\caption{The structure of the reasoning for the similarities in  for closed expressions.}\label{fig:proof-structure}
\end{figure}


\subsection{\texorpdfstring{Similarity in }{Similarity in LR}}\label{subsec:sim-lr-def}
The definition of -WHNFs implies that  they are of the form , where  is either 
an abstraction  or a constructor application ,
and where  is an {\em -AWHNF-context} according 
to the grammar  if  is an abstraction, 
 and    is an {\em -CWHNF-context} according 
to the grammar 
if  is a constructor application. Note that  -AWHNF-contexts and -CWHNF-contexts are
special -reduction contexts, also called {\em -WHNF-contexts}.
 
First we show that finite simulation (see \cite{schmidt-schauss-machkasova-rta:08}) is correct for : 



\begin{definition}
Let  be defined for  as instantiating 
the relation  in Definition~\ref{def:Q-simpl-preorder} with the closed subcalculus of the calculus  and the set 
with  from Definition~\ref{def:Q-Omega-expr-contexts}.

The relation  is -similarity
(Definition~\ref{def:Q-gfp-preorder}) instantiated for the calculus  with the set of contexts  (Definition~\ref{def:Q-Omega-expr-contexts}).
Its open extension is denoted with .
\end{definition}

\begin{proposition} \label{prop:finite-simulation-LLR}
Let   be closed -expressions. Then  iff .
\end{proposition}
\begin{proof} 
The  direction is trivial.
We show , the nontrivial part:
Assume that the inequation  holds.
Then , since for every  
and context 
with , we have , and also , since 
is convergence-equivalent and compositional, and the identity on -free expressions. 
Now Theorem \ref{theorem:bisim-alternatives} shows   , 
and then  Theorem \ref{theorem:N-fully-abstract} shows   .\qedhere
 \end{proof}
\noindent The following  lemma is helpful in applying Theorem \ref{thm:conv-admissibile-implies}.

\begin{lemma}\label{lem:w-condition-need}
 The closed part of the calculus   is convergence-admissible: 
 For all contexts , and closed -WHNFs :
   iff  and .
\end{lemma}
\begin{proof}
 ``'': First assume  is of the form  for closed .  
Let . There are two cases, which can be verified by induction on the length  of a reduction sequence :
 ,
 where , and the claim holds.
The other case is , where . In this case , and thus the claim is proven. 
The other cases where  is of the form  can be proven similarly.
\\
The ``''-direction can be proven using induction on the length of reduction sequences. 
\end{proof}





\begin{lemma}\label{lemma:LR-open-extension-ok}
In , the equation   holds.
\end{lemma}
\begin{proof}
If  are (open) -expressions with , then  
 for closed expressions ,
and then by correctness of reduction in , , and hence .

If for all closing -substitutions : , then using the fully abstract translations , we obtain
,
hence  by 
Theorem \ref{theorem:bisim-alternatives}. Again using fully abstractness of , we obtain .
\end{proof}



\begin{theorem}\label{theo:closed-need-bisim-is-csim}
In , for closed -expressions  and  the statements 
, 
 and 
 are all equivalent.
\end{theorem}
\begin{proof}
Lemma~\ref{lem:w-condition-need} shows that Theorem \ref{thm:conv-admissibile-implies} is applicable
for the testing contexts from  , i.e.  and
Proposition~\ref{prop:finite-simulation-LLR} shows 
\end{proof}


For open  -expressions, we can lift the properties from , which also follows from full abstraction of   and  
from Lemma \ref{prop:open-closed-case}.


The results above imply the following theorem: 

\begin{maintheorem}\label{thm:maintheorem}
 .
\end{maintheorem}
\begin{proof}
  Theorem \ref{theo:closed-need-bisim-is-csim} shows , 
  hence . Then  
  Lemma \ref{lemma:LR-open-extension-ok} shows .
\end{proof}

The Main Theorem \ref{thm:maintheorem} implies that our embedding of  into  the call-by-need letrec calculus  (modulo   )   
  is isomorphic \wrt\ the corresponding term models, \ie\:
\begin{theorem}\label{thm:isomorphism}
The identical embedding  is an isomorphism according to Definition \ref{def:translation-compo-etal}. \qed
\end{theorem}




\begin{remark}
Consider a polymorphically typed variant of ,
say , and a
corresponding type-indexed contextual preorder  which relates expressions of polymorphic type  
and where the testing contexts are restricted to well-typed contexts, \ie~for  of type  the inequality  holds
iff for all contexts  such that  and  are well-typed: .
Obviously for all expressions  of type  the inequality  implies , since
any test (context) performed for  is also included in the tests for  (there are more contexts).
Thus the main theorem implies that  is sound \wrt~the typed preorder .
Of course completeness does not hold, and requires another definition of similarity which respects the typing. 
\end{remark}

\subsection{\texorpdfstring{Similarity up to }{Similarity up to simcLR}}


A more comfortable tool to prove program equivalences in  is the following similarity definition which allows to 
 simplify intermediate expressions that are known to be equivalent.



\begin{definition}[Similarity up to ]
Let  be the greatest fixpoint of the following operator  on closed -expressions:

We define an operator  on binary relations  on closed -expressions:\\
   iff the following holds:
\begin{enumerate}
 \item If  then there are two possibilities: 
     (i)  if   then , or  
     (ii) if   then for all closed ;
 \item If  then  and  for all .
\end{enumerate}
\end{definition}



\begin{lemma}\label{lem:simc-implies-simbupto} 
\end{lemma}
\begin{proof}
We show that  is -dense, i.e. .


Let  and .
Since  either  or
 and . For the latter case we are finished.
For the former case  we have .
Since  is a precongruence, this implies  for all closed -expressions
. Thus we conclude .


Now let  and .
Then  by Proposition~\ref{prop-classification-lr}.
The contexts  where all other
right hand sides of \tcase-alternatives are , show that also  must hold,
since otherwise  cannot hold.
Thus also in this case  holds.
\end{proof}


\begin{lemma}\label{lemma:upto-from-lr-into-lc} .
\end{lemma}
\begin{proof}
 We show that  is -dense (see Definition \ref{def:lcc-sim-upto}), i.e. .
Let  for closed .      If , then also .
Now there are two cases: If  then  must hold.
Then also  and  and we are finished.
If  then for all closed -expressions :
  (by unfolding the fixpoint equation for ).
Since  is surjective, compositional and fully abstract, this also shows
 for all -expressions .

If , then also .
Now  shows that  such that for all : .
Hence  and also , since  is fully abstract.
\end{proof}





\begin{theorem}\label{theo:le_c-eq-bisim-uptop}
 
\end{theorem}
\begin{proof}
For the closed relations, one direction of the equation 
 is  Lemma~\ref{lem:simc-implies-simbupto},
the other direction follows from Lemma~\ref{lemma:upto-from-lr-into-lc}, 
since  implies 
which in turn implies  and finally, 
full-abstraction of  shows .

For the open extension the claimed equality holds, since  iff 
 for all closing substitutions : 
This holds, since for  the equation
 holds 
by correctness of the general copy rule (gcp) (Proposition~\ref{prop-gcp-correct}) and
of garbage collection (gc) (Theorem~\ref{theo:lr-trans-corr}).
\end{proof}
\noindent We demonstrate the use of similarity up to  in the following example:

\begin{example}
As an example we prove the list law  
where  is a closed expression and , , resp. contains the definition of , or  and , 
resp., i.e. the corresponding -expressions are:
1.2ex]
t := &\tletrec~
\\
&~~~~\mathit{repeat} = \lambda x.\tCons~x~(\mathit{repeat}~x),
\\
      &\tin~\mathit{repeat}~\ttrue 
\end{array}
\begin{array}{l@{~}l@{}}
v_1 = &\tletrec~
\\
        &~~~~\mathit{repeat} = \lambda x.\tCons~x~(\mathit{repeat}~ x),
\\
        &~~~~\mathit{map}    = \lambda f.\lambda xs.\tcase_{\mathit{List}}~xs~\tof~(\tnil \to \tnil)~(\tCons~y~ys \to \tCons~(f~y)~(\mathit{map}~f~ys))
\\
        &~~~~f_1 = (\lambda x.\ttrue),x_1 = t, xs_1 = \tCons~x_1'~x_2', x_1' = x_1, x_2' = (\mathit{repeat}~t), y_1 = x_1', ys_1 = x_2'
\\
        &\tin~\tCons~(f_1~y_1)~(\mathit{map}~f_1~ys_1)
\
Using correctness of garbage collection, copying of bindings (gcp), 
shifting constructors over \tletrec, and the other correct reduction rules
(see Theorem~\ref{theo:lr-trans-corr} and Proposition~\ref{prop-gcp-correct}),
we can simplify as follows: 
 and .
Now the proof is finished, since obviously  and
, .
\end{example}



\section{Conclusion}\label{sec:conclusion}
In this paper we have shown that co-inductive applicative bisimilarity, in the
style of Howe, and also the inductive variant, is equivalent to contextual 
equivalence in a deterministic call-by-need calculus with letrec, case, 
data constructors, and {\tt seq} which models the (untyped) core language of 
Haskell. This also shows soundness of untyped applicative bisimilarity for the
polymorphically typed variant of .  As a further work one may try to
establish a coincidence of the typed applicative bisimilarity and contextual
equivalence for a polymorphically typed core language of Haskell.



\section*{Acknowledgements}
The authors thank the anonymous reviewers for their valuable comments.
\newcommand{\etalchar}[1]{}
\begin{thebibliography}{KKSdV97}

\bibitem[AB97]{ariola-blom:97}
Zena~M. Ariola and Stefan Blom.
\newblock Cyclic lambda calculi.
\newblock In Mart\'{\i}n Abadi and Takayasu Ito, editors, {\em {TACS} 1997},
  volume 1281 of {\em Lecture Notes in Comput. Sci.}, pages 77--106. Springer,
  1997.

\bibitem[AB02]{ariola-blom:02}
Z.~M. Ariola and S.~Blom.
\newblock Skew confluence and the lambda calculus with letrec.
\newblock {\em Ann. Pure Appl. Logic}, 117:95--168, 2002.

\bibitem[Abr90]{abramsky-lazy:90}
S.~Abramsky.
\newblock The lazy lambda calculus.
\newblock In D.~A. Turner, editor, {\em Research {T}opics in {F}unctional
  {P}rogramming}, pages 65--116. Addison-Wesley, 1990.

\bibitem[AF97]{ariola:97}
Z.~M. Ariola and M~Felleisen.
\newblock The call-by-need lambda calculus.
\newblock {\em J. Funct. Programming}, 7(3):265--301, 1997.

\bibitem[AFM{\etalchar{+}}95]{ariola:95}
Z.~M. Ariola, M.~Felleisen, J.~Maraist, M.~Odersky, and P.~Wadler.
\newblock A call-by-need lambda calculus.
\newblock In {\em {POPL} 1995}, pages 233--246. ACM, 1995.

\bibitem[AK94]{ariola-klop-short:94}
Z.~M. Ariola and J.~W. Klop.
\newblock Cyclic {L}ambda {G}raph {R}ewriting.
\newblock In {\em {LICS} 1994}, pages 416--425. IEEE, 1994.

\bibitem[AO93]{abramsky-ong:93}
S.~Abramsky and C.-H.~L. Ong.
\newblock Full abstraction in the lazy lambda calculus.
\newblock {\em Inf. Comput.}, 105(2):159--267, 1993.

\bibitem[Bar84]{barendregt:84}
H.~P. Barendregt.
\newblock {\em The {L}ambda {C}alculus. {I}ts {S}yntax and {S}emantics}.
\newblock North-Holland, Amsterdam, New York, 1984.

\bibitem[DBG97]{Dennis-Bundy-Green:1997}
Louise~A. Dennis, Alan Bundy, and Ian Green.
\newblock Using a generalisation critic to find bisimulations for coinductive
  proofs.
\newblock In {\em CADE~1997}, volume 1249 of {\em Lecture Notes in Comput.
  Sci.}, pages 276--290, London, UK, UK, 1997. Springer-Verlag.

\bibitem[Fel91]{Felleisen:91}
M.~Felleisen.
\newblock On the expressive power of programming languages.
\newblock {\em Sci. Comput. Programming}, 17(1--3):35--75, 1991.

\bibitem[Gol05]{goldberg:05}
M.~Goldberg.
\newblock A variadic extension of {C}urry's fixed-point combinator.
\newblock {\em Higher-Order and Symbolic Computation}, 18(3-4):371--388, 2005.

\bibitem[Gor99]{Gordon:99}
A.~D. Gordon.
\newblock Bisimilarity as a theory of functional programming.
\newblock {\em Theoret. Comput. Sci.}, 228(1-2):5--47, 1999.

\bibitem[How89]{howe:89}
D.~Howe.
\newblock Equality in lazy computation systems.
\newblock In {\em {LICS} 1989}, pages 198--203. IEEE, 1989.

\bibitem[How96]{howe:96}
D.~Howe.
\newblock Proving congruence of bisimulation in functional programming
  languages.
\newblock {\em Inform. and Comput.}, 124(2):103--112, 1996.

\bibitem[Jef94]{jeffrey-short:94}
A.~Jeffrey.
\newblock A fully abstract semantics for concurrent graph reduction.
\newblock In {\em {LICS} 1994}, pages 82--91. IEEE, 1994.

\bibitem[JV06]{johann-voigtlaender:06}
P.~Johann and J.~Voigtl\"ander.
\newblock The impact of seq on free theorems-based program transformations.
\newblock {\em Fund. Inform.}, 69(1--2):63--102, 2006.

\bibitem[KKSdV97]{kennaway-klop:97}
R.~Kennaway, J.~W. Klop, M.~Ronan Sleep, and F.-J. de~Vries.
\newblock Infinitary lambda calculus.
\newblock {\em Theoret. Comput. Sci.}, 175(1):93--125, 1997.

\bibitem[KW06]{koutavas-wand:2006}
V.~Koutavas and M.~Wand.
\newblock Small bisimulations for reasoning about higher-order imperative
  programs.
\newblock In {\em POPL 2006}, pages 141--152. ACM, 2006.

\bibitem[Lau93]{launch:93}
J.~Launchbury.
\newblock A natural semantics for lazy evaluation.
\newblock In {\em POPL 1993}, pages 144--154. ACM, 1993.

\bibitem[Mil80]{Milner:80}
R.~Milner.
\newblock {\em A Calculus of Communicating Systems}, volume~92 of {\em Lecture
  Notes in Comput. Sci.}
\newblock Springer, 1980.

\bibitem[Mil99]{milner-pi-calc:99}
R.~Milner.
\newblock {\em Communicating and Mobile Systems: the -calculus}.
\newblock Cambridge university press, 1999.

\bibitem[Mor68]{morris:68}
J.H. Morris.
\newblock {\em Lambda-Calculus Models of Programming Languages}.
\newblock PhD thesis, MIT, 1968.

\bibitem[MOW98]{maraistoderskywadler:98}
J.~Maraist, M.~Odersky, and P.~Wadler.
\newblock The call-by-need lambda calculus.
\newblock {\em J. Funct. Programming}, 8:275--317, 1998.

\bibitem[MS99]{moran-sands:99}
A.~K.~D. Moran and D.~Sands.
\newblock Improvement in a lazy context: An operational theory for
  call-by-need.
\newblock In {\em {POPL} 1999}, pages 43--56. ACM, 1999.

\bibitem[MSS10]{mannmss:10}
M.~Mann and M.~Schmidt-Schau{\ss}.
\newblock Similarity implies equivalence in a class of non-deterministic
  call-by-need lambda calculi.
\newblock {\em Inform. and Comput.}, 208(3):276 -- 291, 2010.

\bibitem[NH09]{Nakata-hasegawa:2009:jfp}
K.~Nakata and M.~Hasegawa.
\newblock Small-step and big-step semantics for call-by-need.
\newblock {\em J. Funct. Program.}, 19:699--722, 2009.

\bibitem[{Pey}03]{peyton-jones-haskell-98:03}
S.~{Peyton Jones}.
\newblock {\em Haskell 98 language and libraries: the Revised Report}.
\newblock Cambridge University Press, 2003.
\newblock {\tt www.haskell.org}.

\bibitem[Pit97]{pitts:97}
A.~M. Pitts.
\newblock Operationally-based theories of program equivalence.
\newblock In {\em Semantics and {L}ogics of {C}omputation}. Cambridge
  University Press, 1997.

\bibitem[Pit11]{Pitts:2011}
A.~M. Pitts.
\newblock Howe's method for higher-order languages.
\newblock In D.~Sangiorgi and J.~Rutten, editors, {\em Advanced Topics in
  Bisimulation and Coinduction}, volume~52 of {\em Cambridge Tracts Theoret.
  Comput. Sci.}, chapter~5, pages 197--232. Cambridge University Press, 2011.

\bibitem[Plo75]{plotkin:75}
G.~D. Plotkin.
\newblock Call-by-name, call-by-value, and the lambda-calculus.
\newblock {\em Theoret. Comput. Sci.}, 1:125--159, 1975.

\bibitem[Ses97]{sestoft:97}
P.~Sestoft.
\newblock Deriving a lazy abstract machine.
\newblock {\em J. Funct. Programming}, 7(3):231--264, 1997.

\bibitem[SKS11]{Sangiorgi-Kobayashi-Sumii:2011}
D.~Sangiorgi, N.~Kobayashi, and E.~Sumii.
\newblock Environmental bisimulations for higher-order languages.
\newblock {\em ACM Trans. Program. Lang. Syst.}, 33(1):5, 2011.

\bibitem[SS07]{schmidt-schauss-copy-rta:07}
M.~Schmidt-Schau{\ss}.
\newblock Correctness of copy in calculi with letrec.
\newblock In {\em RTA 2007}, volume 4533 of {\em Lecture Notes in Comput.
  Sci.}, pages 329--343. Springer, 2007.

\bibitem[SSM08]{schmidt-schauss-machkasova-rta:08}
M.~Schmidt-Schau{\ss} and E.~Machkasova.
\newblock A finite simulation method in a non-deterministic call-by-need
  calculus with letrec, constructors and case.
\newblock In {\em RTA 2008}, number 5117 in Lecture Notes in Comput. Sci.,
  pages 321--335. Springer-Verlag, 2008.

\bibitem[SSMS13]{schmidt-schauss-machkasova-sabel:rta:2013}
M.~Schmidt-Schau{\ss}, E.~Machkasova, and D.~Sabel.
\newblock Extending {A}bramsky's lazy lambda calculus: (non)-conservativity of
  embeddings.
\newblock In {\em RTA 2013}, volume~21 of {\em LIPIcs}, pages 239--254,
  Dagstuhl, Germany, 2013. Schloss Dagstuhl.

\bibitem[SSNSS08]{schmidt-schauss-niehren-schwinghammer-sabel-ifip-tcs:08}
M.~Schmidt-Schau{\ss}, J.~Niehren, J.~Schwinghammer, and D.~Sabel.
\newblock Adequacy of compositional translations for observational semantics.
\newblock In {\em 5th IFIP TCS 2008}, volume 273 of {\em IFIP}, pages 521--535.
  Springer, 2008.

\bibitem[SSNSS09]{schmidt-schauss-niehren-schwinghammer-sabel-frank-33:09}
M.~Schmidt-Schau{\ss}, J.~Niehren, J.~Schwinghammer, and D.~Sabel.
\newblock Adequacy of compositional translations for observational semantics.
\newblock Frank report~33, Inst. f. Informatik, Goethe-University, Frankfurt,
  2009.
\newblock \url{http://www.ki.informatik.uni-frankfurt.de/papers/frank/}.

\bibitem[SSS11]{sabel-schmidt-schauss-PPDP:2011}
D.~Sabel and M.~Schmidt-Schau{\ss}.
\newblock A contextual semantics for {Concurrent} {Haskell} with futures.
\newblock In {\em PPDP 2011}, pages 101--112, New York, NY, USA, 2011. ACM.

\bibitem[SSS12]{sabel-schmidt-schauss:12:LICS}
David Sabel and Manfred Schmidt-Schau{\ss}.
\newblock Conservative concurrency in {H}askell.
\newblock In Nachum Dershowitz, editor, {\em {LICS} 2012}, pages 561--570.
  IEEE, 2012.

\bibitem[SSSM10]{schmidt-schauss-sabel-machkasova-rta:10}
M.~Schmidt-Schau{\ss}, D.~Sabel, and E.~Machkasova.
\newblock Simulation in the call-by-need lambda-calculus with letrec.
\newblock In {\em RTA 2010}, volume~6 of {\em LIPIcs}, pages 295--310. Schloss
  Dagstuhl, 2010.

\bibitem[SSSM11]{schmidt-schauss-sabel-machkasova-IPL:11}
M.~Schmidt-Schau{\ss}, D.~Sabel, and E.~Machkasova.
\newblock Counterexamples to applicative simulation and extensionality in
  non-deterministic call-by-need lambda-calculi with letrec.
\newblock {\em Inf. Process. Lett.}, 111(14):711--716, 2011.

\bibitem[SSSS08]{schmidt-schauss-schuetz-sabel:08}
M.~Schmidt-Schau{\ss}, M.~Sch\"utz, and D.~Sabel.
\newblock Safety of {N}\"ocker's strictness analysis.
\newblock {\em J. Funct. Programming}, 18(04):503--551, 2008.

\bibitem[SW01]{sangiorgi-walker:01}
D.~Sangiorgi and D.~Walker.
\newblock {\em The -calculus: a theory of mobile processes}.
\newblock Cambridge university press, 2001.

\bibitem[VJ07]{voigtlaender-johann:07}
J.~Voigtl\"ander and P.~Johann.
\newblock Selective strictness and parametricity in structural operational
  semantics, inequationally.
\newblock {\em Theor. Comput. Sci}, 388(1--3):290--318, 2007.

\end{thebibliography}
\end{document} 
