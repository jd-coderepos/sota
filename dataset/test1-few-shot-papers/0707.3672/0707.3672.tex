\documentclass[11pt,titlepage]{article}
\usepackage{amsfonts,amssymb,amstext,amsthm,amsmath,amsbsy,amsopn,amsgen}

\setlength{\textwidth}{16cm}
\setlength{\oddsidemargin}{0.26cm}
\setlength{\evensidemargin}{-0.26cm}
\setlength{\textheight}{22.5cm}
\setlength{\topmargin}{-1.4cm}
\setlength {\parindent}{0ex}




\newcommand{\ls}[1]
   {\dimen0=\fontdimen6\the\font
    \lineskip=#1\dimen0
    \advance\lineskip.5\fontdimen5\the\font
    \advance\lineskip-\dimen0
    \lineskiplimit=.9\lineskip
    \baselineskip=\lineskip
    \advance\baselineskip\dimen0
    \normallineskip\lineskip
    \normallineskiplimit\lineskiplimit
    \normalbaselineskip\baselineskip
    \ignorespaces
   }


\def\geq{\geqslant}
\def\leq{\leqslant}




\def\Blackboardfont{\mathbb}
\def\P{{\Blackboardfont P}}
\def\Q{{\Blackboardfont Q}}
\def\Z{{\Blackboardfont Z}}
\def\M{{\Blackboardfont M}}
\def\N{{\Blackboardfont N}}
\def\R{{\Blackboardfont R}}
\def\1{1\kern-0.30em 1}
\def\NN{I\kern-0.25em N}
\def\Im{{\rm Im}}
\def\pp{\P}


\def\sq{\hbox{\rlap{}}}
\def\qed{\ifmmode\sq\else{\unskip\nobreak\hfil
\penalty50\hskip1em\null\nobreak\hfil\sq
\parfillskip=0pt\finalhyphendemerits=0\endgraf}\fi}


\newenvironment{compactenum}{\setlength{\leftmargini}{3mm}\setlength{\parskip}{5mm}
\begin{enumerate}
\setlength{\labelsep}{1mm}
\setlength{\itemsep}{0mm}}{\end{enumerate}}
\newenvironment{compactitem}{\setlength{\leftmargini}{3mm}\setlength{\parskip}{5mm}
\begin{itemize}
\setlength{\labelsep}{1mm}
\setlength{\itemsep}{0mm}}{\end{itemize}}



\newcommand{\myline}{\newline\underline{\hskip\textwidth}}
\newcommand{\done}{\hspace*{\fill}\rule{1.8mm}{1.8mm} \\ }
\def\cc{{\c c}}


\def\calA{{\cal A}}\def\cala{{\cal A}}
\def\calI{{\cal I}}
\def\calE{{\cal E}}
\def\calC{{\cal C}}
\def\calL{{\cal L}}
\def\calB{{\cal B}}
\def\calT{{\cal T}}
\def\calD{{\cal D}}
\def\calF{{\cal F}}\def\FF{{\cal F}}
\def\calR{{\cal R}}\def\calr{{\cal R}}
\def\calP{{\cal P}}
\def\calS{{\cal S}}
\def\calH{{\cal H}}
\def\dg{{\cal D}}
\def\rg{{\cal R}}

\def\eref#1{(\ref{#1})}
\def\un{\vec{1}}
\def\im{{\rm Im}}
\def\nopr#1{|#1|_{{\cal P}}}
\def\ov#1{\overline{#1}}
\def\uv#1{\underline{#1}}
\def\NEWDEF#1{{\em #1}}
\def\imply{\Rightarrow}
\def\matrix#1#2{\left[\begin{array}{#1}#2\end{array}\right]}
\def\iff{\Leftrightarrow}
\newcommand{\parag}{\medskip\noindent}
\newcommand{\eps}{\varepsilon}
\newcommand{\separe}{\newline\underline{\hskip\textwidth}}
\newcommand{\cqfd}{\hspace*{\fill}\rule{1.8mm}{1.8mm} \\ }
\def\dep{\mrm{---}} \def\DEPSYMBOL{\dep}\def\mrm#1{\text{\rm #1}}
\newcommand{\intmin}[2]{\mbox{}}
\def\proj{\pi}
\DeclareMathAlphabet{\eus}{U}{eus}{m}{n}
\def\eulerT{{\calT}}
\def\eulerD{{\calD}}
\DeclareSymbolFont{cmrmn}{OT1}{cmr}{m}{n}
\DeclareMathAlphabet{\eurm}{U}{eur}{m}{n}
\def\morphism{{\cal M}}
\def\mua{\morphism_{\calA}}
\def\muar{\morphism_{\calA\calR}}
\def\mura{\calI}
\def\mur{\morphism_{\calR}}
\def\xa{x_{\calA}}
\def\xr{x_{\calR}}
\def\DR{D}\def\DEP{D}\def\trace{{\M}}
\def\emptyword{e}\def\eref#1{(\ref{#1})}
\def\iff{\Leftrightarrow}
\def\<#1,#2>{\langle#1,#2\rangle}
\newcommand{\alphabet}{\rm{alph}}
\def\nsup#1{\|#1\|}
\def\rmax{{\R}_{\max}}
\def\rmaxb{\overline{\R}_{\max}}
\def\Nmax{{\N}_{\max}}
\def\zero{\varepsilon}
\def\un{e}
\def\Id{\rm{I}}
\def\cf#1{\rm{nf}(#1)}
\def\lcf#1{\ell(#1)}
\def\set#1#2{\{#1\mid\; #2\}}\def\char{\rm{char}}
\def\lser{{\langle\!\langle}}
\def\rser{{\rangle\!\rangle}}
\def\implies{\Rightarrow}
\def\matrix#1#2{\left[\begin{array}{#1}#2\end{array}\right]}

\def\cA{{\cal A}}
\def\cI{{\cal I}}
\def\cT{{\cal T}}
\def\cJ{{\cal J}}
\def\cD{{\cal D}}
\def\cB{{\cal B}}
\def\cF{{\cal F}}
\def\cE{{\cal E}}
\def\cG{{\cal G}}
\def\cR{{\cal R}}
\def\cP{{\cal P}}
\def\cS{{\cal S}}
\def\cH{{\cal H}}
\def\cC{{\cal C}}
\def\cM{{\cal M}}
\def\cL{{\cal L}}
\def\eE{{\cal E}}
\def\eL{{\cal L}}
\def\eN{{\cal N}}
\def\eR{{\cal R}}
\def\calm{{\cal M}}
\def\cK{{\cal K}}


\newcommand{\bydef}{\stackrel{\rm{def}}{=}}

\newtheorem{theo}{Theorem }[section]
\newtheorem{lemm}[theo]{Lemma }
\newtheorem{prop}[theo]{Proposition }
\newtheorem{defi}[theo]{Definition }
\newtheorem{defif}[theo]{D\'efinition }
\newtheorem{conj}[theo]{Conjecture }
\newtheorem{coro}[theo]{Corollary}
\newtheorem{example}[theo]{Example }
\newtheorem{prob}{Problem }
\newenvironment{exam}{\begin{example}\rm}{\end{example}}
\newtheorem{remarkf}[theo]{Remarque }
\newenvironment{remaf}{\begin{remarkf}\rm}{\end{remarkf}}
\newtheorem{remark}[theo]{Remark }
\newenvironment{rema}{\begin{remark}\rm}{\end{remark}}
\newtheorem{coun}[theo]{Counter-example }
\newtheorem{step}{Step }
\newtheorem{stag}{Stage }
\newtheorem{stage}{Stage }
\newtheorem{game}{Game}

\ls{1.15}

\title{Products of Irreducible Random Matrices in the (max,+)
Algebra\thanks{Supported by  
 the European Grant BRA-QMIPS of CEC
DG XIII.}}
\author{ Jean Mairesse\thanks{Research supported by the Direction des
Recherches 
Etudes et Techniques (DRET) under contract  91 815.}
(mairesse@sophia.inria.fr)  \\ 
INRIA Sophia-Antipolis \\ B.P.\ 93, 06902 Sophia Antipolis Cedex,
France \\ \\ 
{\it To appear in {\rm Advances in Applied Probability}, June 1997}}

\date{July 1995}

\begin{document}
\maketitle

\noindent
\begin{abstract}
We consider the recursive equation ``''
where  and  are 
-valued vectors and  is an irreducible
random
matrix of size . The matrix-vector multiplication in the
(max,+) algebra is defined by . This type of equation can be used to
represent the evolution of Stochastic Event Graphs which include cyclic
Jackson Networks, some manufacturing models and 
models with general
blocking (such as Kanban). Let us assume that the sequence  is i.i.d or more 
generally stationary and ergodic. The main result of the paper states that the
system couples  
in finite time with a unique stationary regime if and only
if there exists a set of matrices  such that 
and the matrices  have a unique periodic regime.
\end{abstract} 


\section{Introduction}
\label{se-intro}
Let us consider the following recursive equation:
 
The sequences  are given (exogenous data).
The process we want 
to
study is the sequence of  vectors . 
The vector  is the initial condition. 

Because of the generality of Equation (\ref{eq-eq1}), it appears
in many different types of applications. In fact, this
equation appears in statistical mechanics in the study of crystal structures,
see Griffiths \cite{grif}.
It is also common under one form or another in economic and control
literature, see Yakovenko \& Kontorer \cite{YaKo}. In fact, it is the basic
Bellman equation of 
dynamic 
optimization in discrete time, for a finite state space. 
Recently, this kind of
equation has become very popular in the study of Discrete Events Dynamic
Systems (DEDS), see for example the recent textbooks of Baccelli, Cohen,
Olsder \& Quadrat \cite{BCOQ} and Glasserman \& Yao \cite{GlYa}. Let us
insist on 
the last point. 

\parag
A large class of computer or communication networks accepts a description as 
DEDS. Different approaches have been proposed to model DEDS. Petri Nets is
one of the most common formalism. 
More precisely, a sub-class of Petri Nets, Event Graphs, appears to be very
efficient in describing models with synchronization, blocking and/or fork-join
properties. We can mention Job-Shop models (see Cohen, Dubois, Quadrat \& Viot
\cite{CDQV85} or \cite{BCOQ}), cyclic
Jackson 
Networks (see Section \ref{sse:cjn}) or asymmetric exclusion
models as 
examples. On the other hand, Event 
Graphs cannot be used to model systems with routings.\\
We can describe the evolution of an Event Graph by the daters associated with
the 
transitions (nodes) of the graph.  It is well known, see for example
\cite{BCOQ},  that the
evolution of the daters of an Event Graph can be represented in
the form of Equation (\ref{eq-eq1}).\\
Generalized Semi-Markov Processes (GSMP) are another common formalism for
DEDS. It is 
shown in \cite{GlYa} that a GSMP with convex and homogeneous structural
properties 
admits a representation of the form (\ref{eq-eq1}).
In order to give a flavor of the modeling power
of Equation 
(\ref{eq-eq1}) and in order to motivate the practical interest of this work, 
we will present two different models in Section
\ref{se:tmm}. \\
\hspace*{1cm}  The first model appears in the modeling and the
analysis of parallel programs and architectures. It is a task graph with `and'
synchronizations also known as PERT Network.

\parag

\hspace*{1cm}  
The second model is a closed cyclic Jackson
Network. We will consider both infinite and finite buffers with various
blocking modes.


\parag
It is very fruitful to use a matrix-vector notation for Equation
\eref{eq-eq1}. We define the following ``(max,+)'' notations:
 
We define also the  matrix 
and the column vector .
With these notations,  the basic
Equation (\ref{eq-eq1}) takes a very simple and convenient form.
In fact, it can be rewritten as:

The matrix-vector product is defined in a natural way just by 
replacing   and
 by  and , i.e. . 

\parag

Historically, the first approach has been
to consider deterministic 
systems where .

It is natural to consider a stochastic extension
where  is a
sequence of random matrices.
As a consequence, here is an equivalent way of introducing our subject: it is
a counterpart of the classical theory of products of random matrices (see
Furstenberg \& Kesten \cite{FuKe} or Bougerol \& Lacroix~\cite{BoLa}) but in
another algebraic structure, the (max,+) algebra.

\parag
For systems described by Equation (\ref{eq-eqmat}), we will consider
two kinds of asymptotic results.

\parag

\hspace*{1cm}  First order limits, on ratios:
 
\hspace*{1cm}  Second order limits, on differences:
 

A first order limit is a cycle time or equivalently the inverse of a
throughput.
Second order limits
are related to waiting and idle 
times, queue length and frequency of occupation.
More insights on the relations between these limits and quantities of interest
for the system will be provided in Section \ref{se:tmm}. Our 
goal is to find 
stationary regimes for second order limits. Multiple
stationary regimes will mean multiple possible regimes for waiting
times or queue lengths, depending on the initial condition.

\parag
Among the systems modeled by Equation (\ref{eq-eqmat}), we can distinguish
two classes: the open (or non-autonomous) systems and the closed (or
autonomous) ones. Open systems have been exhaustively treated by  
Baccelli~\cite{bacc92}~\cite{BCOQ} (for both first and second order
limits).  
Problems of existence and uniqueness of first order limits for closed systems
have been 
solved by Cohen~\cite{cohe} (see also \cite{bacc92}). These results are
recalled in \S \ref{sse:rfbacc}. 
This paper deals with the open question of existence and uniqueness of second
order limits  for
closed systems. These problems were considered
in several earlier
papers (Resing, de Vries, Hooghiemstra, Keane \& Olsder \cite{Ral90} and
\cite{Oal90}, Baccelli \cite{bacc92}) but only sufficient 
conditions of
uniqueness were known. 
The approach we use is new
and exploits completely the common hidden algebraic structure of the
different models we consider. It enables us to obtain necessary and
sufficient conditions for stability (in some cases) together with simple proofs.

\parag

The conditions we give
are based on the structure of
deterministic matrices chosen in the support of the random matrix
. One of the main results states that the
system couples  
in finite time with a unique stationary regime if and only
if there exists a set of matrices  such that 
and the matrices  have a unique periodic regime.
The proof makes use of Borovkov's theory of renovating events, see Borovkov \&
Foss \cite{BoFo92}~\cite{BoFo94}.
This theory 
appears to be much more tractable than classical Harris regeneration
due to the specific form of our recursive equations. 

\parag

The paper is organized as follows. We introduce two models
in Section
\ref{se:tmm}, cyclic Jackson
Networks and task graphs with random precedences.  Sections \ref{se:m+a},
\ref{se:dst} and 
\ref{se:bret} are presenting the tools that we are using in the paper. They 
can be skipped by people knowing the subject. Section \ref{se:m+a} is devoted
to the (max,+) algebra, Section \ref{se:dst} to the spectral 
theory in this algebra and Section \ref{se:bret} to Borovkov's theory of
renovating 
events. Section \ref{se:prr} presents the main results. In \ref{sse:rfbacc},
we recall some results from \cite{bacc92} and \cite{cohe}.
In \ref{sse:prr}, we state
some 
preliminary results. In \ref{sse:sdm} and \ref{sse:sgm}, we give 
sufficient 
conditions for the stability of discrete and general models respectively.
In Section \ref{se:ct}, we establish the converses of the results of
the
previous section. In Section \ref{se:wi}, we weaken the assumptions under
which some of our results apply.
Finally, for convenience,
some of the proofs are given in 
Appendix.



\section{Two Motivating Models}
\label{se:tmm}

\subsection{Task graphs}
\label{sse:tg}
We consider a parallel program executed on several identical 
processors. We model it
by its precedence graph . If we consider a system of  processors, 
the graph  has a set of nodes which is . The node  
represents the -th task to be executed at processor . The arcs
between nodes represent 
the synchronization constraints. There
is an arc between
the node  and the node  (notation~: ) 
if the -th task at processor  has to be
completed in order for the -th task at processor  to be enabled.
The execution of a task begins as soon as all the tasks 
of its incoming arcs are
completed. 
Each task has a
duration which may depend on the processor. 


\parag
Let us consider a task graph with synchronizations only between consecutive
levels  (i.e.
nodes ) and . 
We assume that the synchronizations depend on .
We denote by  the set of nodes 
such 
that .
We suppose that for all , there exists a probability law  
on the
subsets of  such that  with
probability . 
We denote by  the
date of completion of task  at processor , and by  the
duration 
of the synchronization constraint between nodes  and  (it
may include a transmission time as well as the execution time at processor
). 
We adopt the convention that 
 if  . 
It is easy to check that such a model,
we could call it a task graph with random precedences, verifies Equation
(\ref{eq-eqmat}). \\

A Queuing Network model studied by Baccelli \& Liu \cite{BaLi92a}
corresponds
to this 
model. The task resource models studied in \cite{BrVi} or \cite{GaMa95} 
also have this kind of structure.


\subsection{Cyclic Jackson network}
\label{sse:cjn}
We consider a closed Jackson Network. The study of such closed networks can be
traced
back to Gordon and Newell, \cite{GoNe}. In their original model,
there is 
a given number of
indistinguishable customers. The routing of  the customers leaving a given
queue 
is provided by a sequence of i.i.d. Bernouilli random variables. All the
service times are exponential.
They prove the existence of an explicit product form for the
unique stationary distribution. 

\parag
A natural generalization of the basic model is to consider
i.i.d. (resp. stationary and ergodic) sequences of service
times with general distributions, i.e. to replace  servers by
 (resp. ) servers. Finding the minimal assumptions
leading to a unique 
stationary regime for this generalized closed Jackson Network is still an open
problem. 

\parag 
We consider a restriction of the previous model. There are  queues and all
customers have the same cyclic route ,  see Figure
\ref{fi:jak}. 
We will
denote this model by CJN for Cyclic Jackson Network, following the terminology
of \cite{KaMa92}.

\begin{figure}[htb]
\centerline{\begin{picture}(0,0)\special{psfile=jak.pstex}\end{picture}\setlength{\unitlength}{0.00087500in}\begingroup\makeatletter\ifx\SetFigFont\undefined
\def\x#1#2#3#4#5#6#7\relax{\def\x{#1#2#3#4#5#6}}\expandafter\x\fmtname xxxxxx\relax \def\y{splain}\ifx\x\y   \gdef\SetFigFont#1#2#3{\ifnum #1<17\tiny\else \ifnum #1<20\small\else
  \ifnum #1<24\normalsize\else \ifnum #1<29\large\else
  \ifnum #1<34\Large\else \ifnum #1<41\LARGE\else
     \huge\fi\fi\fi\fi\fi\fi
  \csname #3\endcsname}\else
\gdef\SetFigFont#1#2#3{\begingroup
  \count@#1\relax \ifnum 25<\count@\count@25\fi
  \def\x{\endgroup\@setsize\SetFigFont{#2pt}}\expandafter\x
    \csname \romannumeral\the\count@ pt\expandafter\endcsname
    \csname @\romannumeral\the\count@ pt\endcsname
  \csname #3\endcsname}\fi
\fi\endgroup
\begin{picture}(3553,2247)(1553,-3391)
\put(2236,-1996){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}Queue 1}}}
\put(4141,-1996){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}Queue 2}}}
\put(2056,-1336){\makebox(0,0)[lb]{\smash{\SetFigFont{8}{9.6}{rm} FIFO}}}
\put(3826,-1336){\makebox(0,0)[lb]{\smash{\SetFigFont{8}{9.6}{rm} FIFO}}}
\put(2221,-2611){\makebox(0,0)[lb]{\smash{\SetFigFont{8}{9.6}{rm} FIFO}}}
\put(2416,-3361){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}Queue }}}
\end{picture}
 }
\caption{\sf A Cyclic Jackson Network consisting of  queues.
\myline}
\label{fi:jak}
\end{figure}
In the following, the numbering of
queues has to be understood modulo , for example queue  is queue 2.
We denote by , the sequence of service times at queue
. 
Instead of describing the system by the workload or the queue length process,
as is usually done, we propose to study this model by introducing the
following variables. With 
each queue , we associate a dater . The variable
 represents the date of completion of the th service at queue
. All variables of interest for the network can be derived from
these 
daters and from the  sequences of service times.
More 
precisely, we have:
\begin{itemize}
\item Asymptotic throughput at queue :

\item Idle time of queue  before the arrival of the -th customer to visit
queue . 

\item Workload at queue  at the instant of the arrival of the -th
customer to visit queue . This customer comes from queue . We suppose
that it was the -th customer to visit queue .

\end{itemize}
The variables () which are obtained as ratios of daters will be
called first order 
variables. The ones () which are obtained as differences of daters
will be called 
second order variables. We are concerned with the problem of deriving
necessary and sufficient conditions under which there is a unique stationary
regime for both first and second order variables. In such a case, we say
that our model is {\it stable}.

\parag
Suppose for the moment that there are exactly
 customers. We suppose also that there is initially one customer in each
queue.  These assumptions together with the FIFO service discipline at each
queue yields the following property. The -th customer to visit queue 
will be, at the next step of its route,  the -th customer to visit queue
. 
As a consequence, we have

Using the (max,+) notation, this can be
rewritten as:

The initial condition is , where   is the remaining
service time of the customer being served at queue  at time 0.

\parag
When the service times are
deterministic, it is possible to obtain many asymptotic behaviors, depending
on the initial condition . In fact, initial delays between customers
might never vanish. Therefore, it is possible to
have several 
stable regimes 
for second order quantities () including periodic ones. For
stochastic systems, when the service times are random variables, it is still
possible to have several stationary regimes if the system is not ``stochastic
enough''.  As an application of the results
presented in this paper, we obtain the necessary and sufficient conditions
for the existence of a unique stationary regime for this CJN.
This model will be used as an illustration of the
results throughout the paper (Examples \ref{ex:jak1}, \ref{ex:jak2},
\ref{ex:jak3}, \ref{ex:jak4}).

\parag
When there are less than  customers in the network,
the system can be represented in the same way as previously. The only
difference is that the structure of matrices  is more complicated.
When there are more than  customers, the trick consists in splitting
queues. Each
queue which has originally  customers in its buffer is transformed into
 queues with one customer per buffer. This
is done by creating  fictive queues with service times identically
equal to zero. By doing this, one gets back to the previous case. The
main difference is that we have represented our model by a (max,+) linear
system of dimension greater than the original number of queues. For more
details on these transformations, see \cite{mair95e}. 

\parag

We can 
also model CJN with 
finite buffers (the  case).
Finite buffers imply the blocking of some customers. There are different
possible types of blocking.
\begin{enumerate}
\item Blocking before service. The service begins
at queue  only when the buffer at queue  is not full.
\item Blocking after service (of communication type). Service at queue 
begins as soon as a customer is available. After completion of the service,
if the buffer of queue  is full, the customer starts another service at
 queue .
\item Blocking after service (of manufacturing type). Service at queue 
begins as soon as a customer is available. After completion of the service,
the customer has to wait in queue  if the buffer of queue  is full.
It prevents another customer from being served at queue .
\item Blocking after service (of Kanban type). The mechanism is the same as
previously but there exists a finite intermediate buffer between queue  and
. A 
customer completing its service at queue  enters this intermediate buffer
if 
the buffer of queue  is full and the intermediate buffer is not. 
It enables to serve a new 
customer at queue .
\end{enumerate}
Excepting the blocking after service of communication type, all these types of
blocking can be considered. We can even consider different types of blocking
for the different queues of the network. In all cases, we obtain 
a (max,+) 
linear representation for the network.

\parag
In the case of a CJN with i.i.d. general
service 
times (./GI/1 servers), the classical method for studying the
network is to
consider the Markov chain formed by queue lengths and
remaining service times and to apply Harris regeneration techniques. 
This method was first introduced for closed
acyclic Jackson Networks by Borovkov \cite{boro86}, \cite{boro88}. For closed
Cyclic Jackson Networks, it is used by
Bambos \cite{bamb} and 
Kaspi  Mandelbaum \cite{KaMa92}~\cite{KaMa94}.
The method provides sufficient conditions of stability.
Our approach is completely different and provides
necessary and sufficient
conditions of
stability for CJN.

\parag

For a much more complete description of the systems modeled by 
Equation (\ref{eq-eqmat}), the
reader is referred to 
the textbook of Baccelli, Cohen, Olsder and Quadrat \cite{BCOQ}.


\section{(max,+) Algebra}
\label{se:m+a}
\begin{defi}[(max,+) algebra]
We consider the semiring .
The law  is ``max'' and  is the usual addition.
We set 
 and .
The element  is neutral for the operation  and absorbing for
. 
The element  is neutral for . The law  is idempotent, i.e.
.  is an idempotent semiring,
called 
a dioid. It is usually referred to as the
(max,+) algebra.
We shall denote it by . 
\end{defi}

We define the product spaces . We
define the product of a vector by a scalar: . \\
Matrix product is defined in a natural way, replacing + and  by
 and  respectively.
Let ,

Matrix-vector product is defined in a similar way, see Section \ref{se-intro}.
In the rest of the paper, the notations ``+,'' will stand for
the usual addition and multiplication.
Nevertheless, we will write  for  whenever there is no
possible confusion. For example, for .

\parag


Let us recall some definitions adapted to the  algebra.

\begin{defi}
The graph of a square matrix  is a directed graph having a number of
nodes equal to the size of . This graph contains an arc from  to  iff
. The valuation of this arc is . 
\label{de:comgr}
\end {defi}

\begin{defi}
A square matrix  is
irreducible if:  
 (or equivalently
if its graph is strongly connected). 
\end {defi}

\begin{defi}
\label{ape}
A square matrix  is aperiodic if:  .
\end {defi}

\begin{defi}
Let  be a
probability space. 
A stochastic matrix  has a fixed structure
if  
 or .
\label{struc}
\end {defi}

\begin{defi}[]
The projective space  is defined as the quotient of 
by the parallelism relation: 

Let  be the canonical projection of  into .
\label{de:pi}
\end{defi}
For example  and  are in the same parallelism
class, i.e. are two 
representatives of the same element of . 
We define in the same way ,  and
. 
We use the same notation  for the different canonical projections.
We define a norm and a distance on  which we call 
the projective norm and 
distance. 
\begin{defi}
Let  and  be a representative of , i.e. .
We define:

Let  and  be two representatives of  and 
respectively.
We define:

We write either
 or  with some abuse of notation.
\label{dist}
\end{defi}

The space  is an Euclidean space. 
In particular, it is complete.
The norm  corresponds to
the  norm\footnote{It is worth
mentioning that  is the  analogue of a 
distance used in classical Perron-Frobenius 
theory, which is called the Hilbert's projective metric and is defined by ``''.} on the projective
space .  

\begin{prop}
Let  be an irreducible matrix. Let  be two
vectors of . We have: 

\label{decd}
\end{prop}

\begin {proof}
By definition, we have:

We define  such that . Note that  depends on  and . We
have: 

We obtain
 i.e. . 
\end {proof} 


There is no simple criterion to get a strict inequality. This monotonicity 
has to be 
interpreted as a synchronization property.

\begin{defi}
We consider . We set 

We call  the projective diameter of .
\label{D}
\end{defi}
It is easy to prove that  is finite if and only if
. 
A matrix  can be considered as a ``linear'' (in the (max,+) sense)
operator
from
 into . It is a bounded operator if the (decreasing) sequence
 
has a finite limit, i.e. if  is aperiodic (Def. \ref{ape}).

\section{Deterministic Spectral Theory}
\label{se:dst}
We recall some results of the deterministic spectral theory in the
 
algebra. Theorem \ref{lyap} is due to
Cuninghame-Green~\cite{cuni62}. Versions of Theorem
\ref{vectprop} were proved in~\cite{roma}~\cite{cuni79} and
\cite{GoMi77}. Under 
the form proposed here, the result is  
from \cite{CDQV85}.
Theorem \ref{thcyc} is due to Cohen, Dubois, Quadrat and
Viot~\cite{CDQV83} and \cite{CDQV85}. A complete
treatment of the spectral theory can be found in \cite{BCOQ}.


\parag
We want to find non trivial solutions to the equation:

where  is an irreducible matrix,  is a column vector
(the 
``eigenvector'') and  is a real constant (the ``eigenvalue''). We
define also periodic regimes for the eigenvalue 
problem. A periodic regime of period
  is a set of vectors  of
 verifying  and . 

\begin{defi}
For each path , we define its
average 
weight by:

(here the division is the conventional one).
\end{defi}

\begin{theo}
There is a unique (non ) eigenvalue, . It satisfies the relation

where  covers all the circuits of (the graph of) .
We call also  the Lyapunov exponent or the cycle time of .
\label{lyap}
\end{theo}

There might be several eigenvectors. A linear combination (in ) of
eigenvectors is an eigenvector. An eigenvector has all its coordinates different from
 (due to the irreducibility assumption). 

\begin{defi}
For a matrix , we define:
\begin{description}
\item [Critical circuit] A circuit  of  is said to be critical if its
average weight is maximal, i.e. if .
\item[Critical graph] It consists of the nodes and arcs of  belonging to the
critical circuit(s).
\end{description} 
For a general graph, we define :
\begin{description} 
\item [Cyclicity] The cyclicity of a strongly connected graph 
is the greatest common divisor of the lengths of all the circuits. The
cyclicity of 
a connected graph is the least common multiple of the cyclicities of its
maximal strongly connected 
subgraphs (s.c.s.).
\end{description}
\label{3def}
\end{defi}

We normalize a matrix by subtracting (in the
conventional algebra) the eigenvalue to all the coordinates. 
The eigenvalue of a
normalized matrix is .
For a normalized matrix  of size , we define:

We check that .
\begin{theo}
Let  be a normalized matrix. 
\begin{enumerate}
\item[a.] Critical columns ,  belonging to the critical graph,
are eigenvectors.
\item[b.] For  belonging to the critical graph,  and
 are different iff  
they belong to two different s.c.s. of the critical graph.
\item[c.] Every eigenvector of  writes as a linear
combination (in ) of critical columns
.
\end{enumerate}
\label{vectprop}
\end{theo}

In , every irreducible matrix is cyclic in the sense of the following
theorem.
\begin{theo}
For an irreducible matrix  of size  and whose eigenvalue is ,
there 
exists integers  and  such that:

furthermore the smallest  verifying the property is equal to the cyclicity
of the 
critical graph of . We call it the {\bf cyclicity} of . \\
\label{thcyc}
\end{theo}

A cyclicity greater than one will provide periodic regimes of period greater than
one for the eigenvalue problem.

\begin{prop}
An irreducible matrix has a unique eigenvector and no periodic regimes of period greater than
one for the eigenvalue problem, if and only if its critical graph has a unique s.c.s. and its cyclicity is one. Such a matrix will be called a
{\bf scs1-cyc1} matrix.
\label{pr:scscyc}\index{scs1-cyc1}
\end{prop}

The proof follows from Theorems \ref{vectprop} and \ref{thcyc}. 


\begin{defi}[rank]
\label{de:rank1}
By analogy with 
classical linear algebra, we define 
the ``rank'' of a matrix  as the number of additively
independent columns (resp. lines) of . More precisely, 
let   denote the -th column  of .
Matrix  is of rank  if there exists 
such that  and  and
, such that

\end{defi}

Let  be a {\bf rank 1} matrix. Then  is a {\bf scs1-cyc1} matrix and
verifies  ( is the eigenvalue of ).
The other way round, let  be a {\bf scs1-cyc1} matrix and  
be defined as in Equation \eref{eq-cyc}. One can
check that  is a matrix of {\bf rank 1}.


\begin{exam}[Cyclic Jackson Network 1] 
\label{ex:jak1}
Let us consider a basic Cyclic Jackson Network as presented in Section
\ref{sse:cjn}. We suppose that the service times are deterministic, i.e
. We suppose also that the number of customers,
, is 
equal to the number of queues. Then we can consider the (max,+) matrix
associated with the network, see Equation (\ref{eq-cjn}). 
The graph associated with this matrix is constituted by the
circuit  and the recycling loops  to . 
Let us define . There are two possible
cases.
\begin{itemize}
\item If the cardinal , then the critical graph of the matrix consists of the nodes  and the arcs . It implies
that the matrix is scs-cyc1.
\item If  then the graph and the critical graph of the matrix
coincide. It implies that the matrix is scs1-cyc1.
\end{itemize}
We conclude that the matrix is scs1-cyc1 if and only if  or . 
\end{exam}

\section{Borovkov's Renovating Events Theory}
\label{se:bret}
Borovkov's theory deals with the problem of regeneration in so-called
``Stochastic Recursive 
Sequences''. For a complete treatment, the reader is referred to Borovkov
\cite{boro84}, Borovkov \& Foss \cite{BoFo92,BoFo94}
or Brandt, Franken \& Lisek \cite{BFLi}. Let  be a probability space. Let  be a measurable map from
 into itself such that  is -invariant and
-ergodic. Let  and  be two Polish spaces 
(complete, separable metric spaces) equipped with their respective Borel 
-algebra. 

\begin{defi}
We call Stochastic Recursive
Sequence (SRS), a sequence  of -valued random variables
defined by  

where   is an exogenous sequence of -valued random variables,
stationary with respect to
the shift . The function  is a measurable function from
 into 
. The vector  is the initial condition. In order to stress the
value of the initial condition, 
we will sometimes denote the SRS by .
We talk of an i.i.d. SRS when the sequence  is i.i.d. (an i.i.d.
SRS is a Markov 
Chain and the converse is true).
\label{srs}
\end{defi}

\begin{defi}
We consider a SRS . We denote by  the
-algebra  . 
The sequence of events  is said to be a renovating sequence of length 
and of associated function  
 if:

A sequence 
of renovating events of same length and associated function is said to be
stationary if 
.
\end{defi}

We need the following notions of convergence:

\begin{defi}
We say that there is coupling convergence in finite time (or, merely,
coupling) of a sequence   	
to a stationary sequence  if

\end{defi}
It is easy to show that this notion of coupling convergence implies total
variation convergence 
( in total variation if ).       
                          
\begin{defi}
We say that there is strong coupling convergence in finite time (or, merely,
strong coupling) of a sequence 
to a stationary sequence  if:

\label{scoup}
\end{defi}
{\bf Remark } Strong coupling implies coupling but the converse is not true.

\begin{theo}[Borovkov's renovating events]
\label{thbo1}
We consider a SRS
 defined by:

If the random process  admits a stationary sequence of
renovating events  
 such that , then there exists a finite random variable  such that:

and  converges with strong coupling in finite time to . 
\end{theo} 




In the previous theorem, we have considered a SRS defined with a unique
initial condition, . In the rest of 
the paper, we will be interested in having results that hold uniformly over
the initial 
conditions. We will then use the 
following generalization of Borovkov's theorem.

\begin{theo}
\label{thbo2}
We consider a subset  of  ( is in particular possible).
We suppose that  there exists a stationary sequence of 
events  verifying  and which is renovating
for the SRS ,  
. 
Then, for all (possibly random) initial condition 
 such that , the sequence  
converges with strong coupling to a unique stationary 
regime.
\end{theo}

\begin{theo}[converse of Th. \ref{thbo1} and \ref{thbo2}]
\label{thbo2c}
The conditions of Theorem \ref{thbo1} are  necessary and sufficient for strong
coupling 
convergence. Let  be a compact subset of . The conditions of
Theorem \ref{thbo2} are  necessary and sufficient for strong coupling
convergence 
uniformly
over initial conditions in .
\end{theo}

Next theorem was proved
by Anantharam and Konstantopoulos in \cite{AnKo}.

\begin{theo}
\label{anko}
Let  be a probability space. We assume that  is
a Polish space equipped with its Borel -algebra.
We consider a SRS ``'' defined on .
Suppose that,
for some , the sequence 
is tight\footnote{Tightness on  means that for any , there is a compact  of  such that , for all .} on .
Then there is a stationary distribution for the SRS.
\end{theo}
The stationary
distribution is defined on  with an  marginal 
equal to . It
provides only a {\it weak
stationary regime} ({\it wsr}) for the SRS, 
see \cite{AnKo} or \cite{BFLi} for details. 
All we need to know about {\it wsr} is that
stationary regimes are {\it wsr}. Hence, the uniqueness of
stationary regimes implies the uniqueness of {\it wsr}. 

\parag
It is proved in \cite{BoFo92}, that for an i.i.d. SRS (i.e. Markov chain), 
the conditions of Th. \ref{thbo1}
are equivalent 
to the ones ensuring
Harris ergodicity. 
In Harris' framework, the conditions are on
the state 
space. In Borovkov's framework, the conditions are on the exogenous driving
sequence. This second approach is better suited for our problem.  On the one
hand, a direct analysis on the state
space appears to be almost inextricable. 
On the other hand, the 
renovating events will take a very convenient form because a
product 
of matrices is still a matrix (see Theorems \ref{th1}, \ref{th2}).

\paragraph{-coupling}
Coupling and strong coupling, introduced 
above, are related to total variation convergence. 
We define now the notion of -coupling. It is related to weak 
convergence.

\begin{defi}[-coupling]
We consider a metric space . We consider two sequences  and  defined on . We say that there 
is -coupling\footnote{The classical terminology is
-coupling. We change it to -coupling to
avoid confusions with the notation  of the  algebra.}
of  
these two sequences if for each , one 
can find versions of  and  defined on a common probability
space and an a.s. finite random time  such that 

\label{eps} 
\end{defi}
The following proposition is shown in Asmussen \cite{asmu92}.

\begin{prop} 
We consider a sequence  and a stationary sequence
 defined on the metric space .
Let  be the invariant distribution of . If there is -coupling of the two sequences, then  converges
weakly to .
\label{asmu}
\end{prop}

\section{Presentation of the Results}
\label{se:prr}
Let us consider a probability space . The
probability  is stationary and ergodic with respect to the shift .
We are interested in systems of the type: 

where  and  () are finite, respectively 
and 
-valued, random variables. 
We are sometimes going to use the notation
 to 
emphasize the value of the initial condition. We will
consider models where the sequences  are respectively {\bf
i.i.d}  or
{\bf stationary and ergodic} (i.e ).

\parag

We recall that we have defined first and second order
limits in Section \ref{se-intro}, Equations \eref{eq-1ord} and \eref{eq-2ord}.

We are going to recall results on first and second order limits for open
systems and first order limits for closed systems before
completing the picture by solving the problem of second order limits for
closed systems. 

\subsection{Results from Baccelli \protect\cite{bacc92} and Cohen
\protect\cite{cohe}} 
\label{sse:rfbacc}
For  and , we use
the notation  and . 


\subsubsection{First order limits for closed systems}

\begin{theo}[Cohen \protect\cite{cohe}]
Let  be a stationary and ergodic sequence of 
matrices. We suppose that the matrix  has a fixed structure (see
Definition \ref{struc}), is
irreducible and verifies  or
. 
There exists a constant  such
that, for all initial condition  and for all :

The constant  is called the Lyapunov exponent of the stochastic
matrix . 
\label{first}
\end{theo} 

The basic idea is to use the inequality  in order to apply 
Kingman subadditive ergodic theorem. \\

This definition of a  Lyapunov exponent is coherent with the one
of Theorem 
\ref{lyap}. Indeed, by Theorem \ref{thcyc}, for every irreducible and
deterministic matrix , there 
exists  and  such that , where  is the eigenvalue of .
It implies that .

\subsubsection{First order limits for open systems}

We suppose that matrices  have a fixed structure.
We decompose the graph of  
into its maximal strongly connected
subgraphs (s.c.s.). If we replace each s.c.s. by one node, we obtain an associated
reduced graph which is acyclic. We associate with each node  of the
reduced 
graph a constant  which is the Lyapunov exponent of the
corresponding s.c.s. in isolation, see Theorem \ref{first}. We denote
by  the
set of predecessors of  (including ) in the reduced
graph. We have :

\begin{theo}[Baccelli \protect\cite{bacc92}]
Let  be a stationary and ergodic sequence of 
matrices. We suppose that  has a fixed structure. We suppose also that
 or .  Let us
consider ,  belongs to the s.c.s. .

\label{first2}
\end{theo}

Intuitively, 
the dynamic of the system is imposed by the s.c.s.
having 
the smallest throughput (largest cycle time ).

\subsubsection{Second order limits for open systems}
Matrices  
have a fixed structure. In order to simplify the presentation of the
results, let us assume that the structure consists of two s.c.s. The general
case is completely similar. Up to a permutation of the coordinates, we have~:

The block  is a square matrix of size , irreducible. It
is interpreted as the input 
of our system. The block  is a square matrix of size  , irreducible. The block  is the matrix of the
communications between the sources () and 
(). We suppose that the block 
 in isolation has a unique stationary regime.
We have the following theorem.

\begin{theo}[Baccelli \protect\cite{bacc92}]
Let  and  be the Lyapunov exponents of  and 
respectively (see Theorem \ref{first}). If , 
there is a unique stationary regime 
for the SRS , regardless of the initial condition. Convergence to
the stationary regime occurs with strong coupling.
If , then the differences of the form

tend to , , for all finite initial condition.
\label{bacc}
\end{theo}

If , the sources which
are slower impose their pace. If , 
everything happens asymptotically as if  were in isolation.
 
\parag

{\bf Remark } In the previous theorem, we need the assumption that
 
in isolation has a 
unique stationary regime. Knowing if  has a
unique stationary regime is precisely the problem which is going to be  
addressed in the following.
Then, to determine if there is a unique stationary regime for , we
have to use the results of Section \ref{sse:sgm} (applied to
) together with  
the comparison of Lyapunov exponents (of
 and ).

\parag

{\bf Remark } 
In the results above (Theorems \ref{first}, \ref{first2} and \ref{bacc}), the
assumption that a 
matrix 
 has a fixed structure and is irreducible can be weakened and replaced
by: 




\subsection{Preliminary results}
\label{sse:prr}

From now on, we concentrate on second order limits in the closed (i.e  is
-a.s. irreducible) case. 
The 
limits
are expected to be random variables. We are interested in determining whether
the limiting distribution is unique.
Furthermore, we want to investigate the type 
of convergence to the limit.

\parag

We recall that  is the canonical projection  (Def. \ref{de:pi}). It is clear
that the  
recursive 
equation  defines a SRS (Def. \ref{srs}). It implies that
 is also a SRS. Indeed, let us
consider  and  such that . We define
 and 
. It is straightforward that .
We write with some abuse of 
notation that  verifies
the recursive equation ``''\footnote{It
would be more rigorous to use different notations  and  for
the canonical projections in  and  respectively. Then we would define more formally .}.


\begin{lemm}[Reising \& al~\cite{Ral90}]
For , we define . 
We have , where  is an absolutely 
continuous function.
\end{lemm} 

The sequence  being stationary by hypothesis,
it implies the following corollary. 

\begin{coro}
A sufficient condition for  to
converge weakly (resp. in total variation) to a unique
invariant 
distribution, uniformly over initial conditions in , is that
 
has the same property.
\label{co:co}
\end{coro}

This sufficient condition is not necessary as  demonstrated by the
following 
deterministic example.
\begin{exam}
\label{ex:det}
Let us consider 

We have , so  and  are eigenvectors of . 
The set  

is the set of eigenvectors
of , see Theorem \ref{vectprop}. There is a continuum of stationary regimes
for 
. For example, it is easy to check that for an initial condition
, we have:  

But on the other hand, we have a unique stationary regime for . As a direct consequence of the equality , we have
. \\
We can also easily build stochastic counter-examples of the same kind.
\end{exam}

{\bf Remark } The variables  depend only on the sequence
.
Therefore,
all the results on 
 
would still be true under the weaker assumption that 
only the sequence  is stationary and ergodic. But, on the other
hand, the variables  depend on the sequence  and not only
on . Corollary \ref{co:co} would not be true under
the assumption that  is stationary and ergodic.
 
\parag

In the rest of the paper, 
we investigate the existence of a stationary regime for the SRS
, i.e. the existence of a finite r.v. 
  such that\footnote{We will write
 with some abuse of notations.} 

We are interested by conditions
ensuring the uniqueness of the stationary regime and the convergence
of  toward it, for all . In such cases, we say
that the model is {\it stable}. Two types of
convergence will appear, convergence with -coupling and convergence with
coupling. They imply, respectively, weak convergence and total
variation convergence as recalled in \S \ref{se:bret}. 

\subsection{Stability of discrete models}
\label{sse:sdm}
Let  or , be
a finite or countable collection of irreducible 
matrices of size . We suppose that there 
exists a 
discrete probability law \{\} such that  with
probability .  

\begin{defi}[pattern, 1]  \\
\label{de:patt}
A matrix  is called a pattern of the random sequence  if: 
\begin{enumerate}
\item  with
 (or ).
\item .
\end{enumerate}
If the sequence  is i.i.d. then the second condition is always
verified. 
\end{defi}

\begin{theo}
\label{th1}
The sequence of matrices  is i.i.d. 
If there exists a pattern of  whose critical graph has a unique
s.c.s. and whose cyclicity is 1 ({\bf scs1-cyc1} matrix), then 
 converges with strong coupling 
to a unique stationary regime. It implies total variation
convergence of  to its stationary distribution.
\end{theo}


\begin {proof}
Let  
be a scs1-cyc1 pattern. We have,
using the cyclicity 1 
assumption  (Th. \ref{thcyc}), 

where  is the Lyapunov exponent of .
We conclude that for all initial condition , . It means that  is an eigenvector of . By the
assumption on the 
critical graph of , there is a unique eigenvector (up to a constant)
denoted  (Th. \ref{vectprop}).  We have
, or equivalently
. We define  

From the {\bf i.i.d.} assumption, it follows
that P( 0. On , and for all initial condition ,
we have:
 
We check that the sequence  is compatible
with the shift, i.e. . We conclude that
 is a stationary renovating 
event 
sequence for the SRS . We apply Borovkov's Theorem
(version 
\ref{thbo2} for the set , 
as we have obtained a sequence of renovating
events independent 
of the initial condition) and the uniqueness of
the stationary regime follows. 
\end {proof} 


\begin{exam}[Cyclic Jackson Network 2] 
We consider a basic Cyclic Jackson Network with  queues and  customers.
Such a 
network can be represented by the (max,+) matrix given in \S \ref{sse:cjn},
Equation (\ref{eq-cjn}).
We suppose that the sequence of  service times
 is i.i.d.  
However the random variables
 need not be independent for a given . 
We suppose also that the service times have a discrete support, i.e. can only
take a countable number of values. We are in the framework of Theorem
\ref{th1}. 
We conclude that a sufficient condition of stability is to find a scs1-cyc1
matrix among the (max,+) matrices corresponding to this network.
As a direct application of the result stated in Example
\ref{ex:jak1}, we obtain that a condition of stability is:

\label{ex:jak2}
\end{exam}

\parag
We now give a version of Theorem \ref{th1} in the stationary and
ergodic case. 

\begin{theo}
\label{th2}
The sequence  is stationary and ergodic. We suppose that
there 
exists a finite pattern 
 which is 
scs1-cyc1 and of rank 1 (see Def. \ref{de:rank1}). 
We suppose that  is of strictly positive probability.
Then  converges with
strong coupling to a unique stationary regime.
\end{theo}

\begin {proof}
The proof resembles the one of Theorem
\ref{th1}. As  is of rank 1, we
have (see 
Def. \ref{de:rank1}): , where  is the Lyapunov
exponent 
of . We conclude that:

It implies that  is an eigenvector of . As matrix  is scs1, it has a
unique eigenvector , up to a constant. On , 
we have 

We check that the sequence  is compatible with the shift and we
apply Borovkov's Theorem \ref{thbo2}. 
\end {proof} 

{\bf Remark} If the dependence between matrices is markovian, a
sufficient 
condition to get  0 is that 
, where  is the
markovian 
transition kernel.

\parag
{\bf Remark} The conditions of this theorem are, of course, weaker than the
i.i.d. 
assumption of Theorem \ref{th1}. However we made an
additional assumption, namely that the pattern  is of rank 1. This
assumption cannot be relaxed, as
shown by the
counter-example \ref{ex:erg1}.

\begin{exam}
\label{ex:erg1}
Let  be the probability space,
P=\{, \} the 
probability law, and  the stationary and ergodic shift defined by:
 and .
We consider


Both matrices  and  are scs1-cyc1 patterns of length 1. But
patterns which are scs1-cyc1 {\bf and} of rank 1 are for example  or  for
. We have for any , . Hence the conditions of Theorem \ref{th2}
are not verified. In fact, there is a continuum of
possible periodic limits. Consider  with
. Then the limit regime of  has a
state space which is either 
 (with probability ), or  (with probability ).
\end{exam}

\subsection{Stability of general models}
\label{sse:sgm}
In this section, we consider a general model where the coordinates of our
matrices have a support which can be discrete, 
absolutely continuous with respect to Lebesgue measure or a mixture of these
two cases.

\parag
We need the following definition, extending the notion of pattern we have
been using for finite models. 
Let  be a 
deterministic matrix and . We denote
by  the open ball of center  and of radius  for the supremum norm of . We have  iff
\index{ (ball)}


\begin{defi}[pattern, 2]
\label{de:pattern}\index{pattern}
Let  be a random matrix. We say that  is a pattern of  if
 is a deterministic 
matrix verifying
 
Equivalently, we can say that  belongs to the support
of the random matrix . It includes the cases where 
 is an accumulation point (discrete case) or a boundary point
(continuous case) of the support.
\end{defi}

\begin{defi}[pattern, 3]
\label{de:pattern2}\index{pattern}\index{pattern!asymptotic}
Let  be a sequence of random matrices. We say that the
deterministic matrix
 is a pattern of the sequence  if 

Equivalently, we can say that
 is a pattern (Def. \ref{de:pattern}) of the random matrix
. We say that  is an
asymptotic pattern of  if 


\end{defi}
{\bf Remark } This definition is coherent with the one given in Definition
\ref{de:patt} for a discrete model. Note that, for convenience reasons, 
asymptotic patterns are defined in the projective space . 

\begin{theo}
\label{th3}
The matrices  are i.i.d. (resp. stationary and ergodic). 
We suppose that
there exists a 
matrix  which is a pattern of 
 (see Def. \ref{de:pattern2}) and which is
scs1-cyc1 (resp. of rank 1).
Then the SRS  has a unique stationary regime .  The convergence occurs with coupling. It 
implies weak convergence of  to its unique 
stationary distribution.
\end{theo}
\begin{proof}
We prove directly Theorem
\ref{conv3}, a stronger version of the result. 
It is done in Appendix, \S \ref{app:conv3}. 
\end{proof}

\begin{theo}
The sequence of matrices  is  i.i.d. or stationary and ergodic.
We assume that
there exists a set  of matrices such that~:
\begin{enumerate}
\item ,  is a matrix of rank 1.
\item ,  is a pattern of .
\item .
\end{enumerate}
Then  converges with strong coupling to a unique stationary
regime. 
\label{th4}
\end{theo}
The conditions of Theorem \ref{th4} are stronger than the ones of 
Theorem \ref{th3} as we require the patterns of rank 1 to be of
positive probability. On the other hand, we obtain a stronger type of 
convergence.
\begin{proof}
Let us define
 and . Using that the matrices  are of rank 1, we
obtain that, on the event ,  is 
independent of the value of . It implies that 
 is a stationary sequence of renovating events. 
The result follows. 
\end{proof}


{\bf Remark } Theorems \ref{th1} to \ref{th4} do not require any aperiodicity
(Def. 
\ref{ape}) assumption on matrices . 
However, the pattern  whose existence is essential in all of these theorems
is 
aperiodic. The condition ``scs1-cyc1'' implies 
aperiodicity.  

\begin{exam}[Cyclic Jackson Network 3]
\label{ex:jak3}
We consider the same i.i.d. model as in Example \ref{ex:jak2}. 
However, the
distributions of the service times are now general. 
We obtain, by using Theorems
\ref{th3} and \ref{th4}, the stability under the condition:\\
The support of the random vector  contains at least one point such that:

If the previous condition occurs with strictly positive probability,
we obtain total variation convergence. Otherwise, we obtain weak 
convergence. 
Here  is a case with only weak convergence. We consider an i.i.d. CJN
with three queues and three customers. We assume that  and  is uniformly distributed over . 
\end{exam}



\section{Converse Theorems}
\label{se:ct}
We are going to prove converses of Theorems \ref{th1}, \ref{th2}, \ref{th3} and \ref{th4}. We
will consider successively finite 
and general models of type:
``'' where the matrices are of size  and are
 irreducible. We will, moreover, always suppose that there 
exists a pattern whose projective diameter (Def. \ref{D}) is
finite,  i.e.

It implies ,
see the proof of Lemma \ref{le:loyn}.
This condition is very weak. In the i.i.d. case, it is enough
that there exists a pattern which is irreducible and
aperiodic. We comment further on this condition in Section \ref{se:wi}.


\subsection{Finite models in }
We consider a finite model: ``'',
with . We assume that the matrices 
are irreducible. We assume also that the matrices 
belong to , i.e. that their coordinates are
rational. 

\begin{theo}
The sequence of matrices  is  i.i.d. or stationary and ergodic.
When there is
a unique stationary regime, convergence to this regime
occurs with strong coupling. A
necessary and sufficient condition for the 
model to have a unique stationary regime is that there exists a matrix 
verifying 
\begin{enumerate}
\item  is a matrix of rank 1
(Def. \ref{de:rank1}).
\item  is a pattern of  (Def. \ref{de:pattern2}).
\end{enumerate}
\label{conv}
\end{theo}

\begin{proof} 
It is given
in Appendix, \S \ref{app:conv}. 
\end{proof} 

Theorem \ref{conv} is not true in general when the matrices  
belong to , see the following 
counter-example.

\begin{exam}\label{ex-irra}
We consider the matrices 

where  and ,  are not co-rational,
i.e. . 

\parag
Let  , we set . 
We identify  and  using the function .
The matrices  and  are scs1-cyc1. Their respective and unique 
eigenvectors are  and . For a 
vector  such that 
, we have


We consider a Markov chain defined on the set 
. The transition
probabilities are
\begin{itemize}
\item For  such that  
.
\item For  such that 
.
\item For  such that  
.
\end{itemize}
The behaviour of the Markov chain is illustrated in Figure \ref{fi-markov}.

\begin{figure}[hb]
\centerline{\begin{picture}(0,0)\special{psfile=markov.pstex}\end{picture}\setlength{\unitlength}{0.00087500in}\begingroup\makeatletter\ifx\SetFigFont\undefined
\def\x#1#2#3#4#5#6#7\relax{\def\x{#1#2#3#4#5#6}}\expandafter\x\fmtname xxxxxx\relax \def\y{splain}\ifx\x\y   \gdef\SetFigFont#1#2#3{\ifnum #1<17\tiny\else \ifnum #1<20\small\else
  \ifnum #1<24\normalsize\else \ifnum #1<29\large\else
  \ifnum #1<34\Large\else \ifnum #1<41\LARGE\else
     \huge\fi\fi\fi\fi\fi\fi
  \csname #3\endcsname}\else
\gdef\SetFigFont#1#2#3{\begingroup
  \count@#1\relax \ifnum 25<\count@\count@25\fi
  \def\x{\endgroup\@setsize\SetFigFont{#2pt}}\expandafter\x
    \csname \romannumeral\the\count@ pt\expandafter\endcsname
    \csname @\romannumeral\the\count@ pt\endcsname
  \csname #3\endcsname}\fi
\fi\endgroup
\begin{picture}(4891,641)(4223,-3748)
\put(6688,-3248){\makebox(0,0)[lb]{\smash{\SetFigFont{9}{10.8}{rm}}}}
\put(5390,-3248){\makebox(0,0)[lb]{\smash{\SetFigFont{9}{10.8}{rm}}}}
\put(6253,-3203){\makebox(0,0)[lb]{\smash{\SetFigFont{9}{10.8}{rm}}}}
\put(5300,-3721){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}}}}
\put(7377,-3711){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}}}}
\put(8705,-3706){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}}}}
\put(7528,-3203){\makebox(0,0)[lb]{\smash{\SetFigFont{9}{10.8}{rm}}}}
\end{picture}
 }
\caption{\sf Markov chain  on .}
\label{fi-markov}
\end{figure}

Let  be a realization of the Markov chain.
It is easy to check that this Markov chain is aperiodic.
Under the assumption , one can prove using
classical arguments that the set  is -a.s. 
dense in . It implies that the Markov chain is
-irreducible where
 is the Lebesgue measure on . 
Hence there exists a unique 
stationary distribution   for the Markov chain.
It verifies  for all event  such that . 
For a complete treatment of Markov chains on continuous state spaces,
see Meyn \& Tweedie \cite{MeTw}.

Let us consider a 
stationary realization  of the Markov chain (i.e. 
). 
We define

As  is stationary, it follows that  is a 
stationary and ergodic sequence. 

\parag
Let us consider the stationary-ergodic finite model ``''
and . Note that  is not 
a Markov chain anymore. 


Let us consider a pattern  of , i.e.
. Let  be
a corresponding path for the Markov chain , i.e.

Let us denote by  and  the 
minimal distances 
between  and the extremal points of .
We have
 and 
.

It follows from \eref{eq-effAB} that 

where 
. 
From the definition of the Markov chain , it follows that
. We conclude that  is not a 
rank 1 matrix. There exists no finite pattern of rank 1 for . 

\parag
On the other hand,  let us prove that there exists  asymptotic
patterns of rank 1 for . We define
 and 
. 
As  is dense in , we obtain that
 and . 
Using
\eref{eq-imag}, we obtain that
 -a.s.
We conclude following the lines of Theorem \ref{conv3}, \S \ref{app:conv3}. 
There is a unique 
stationary regime for the model. For an arbitrary 
initial condition,  we have -coupling (weak convergence) with this
stationary regime.

\parag
To summarize, we have exhibited a finite model with a unique 
stationary regime and no coupling convergence. 
This type of behaviour is closely related to the 
non-finiteness of the projective semigroup , see Def. \ref{de-semi}.
\end{exam}

\subsection{General models}
We consider  a general model of type ``''.
Stability no longer implies coupling in finite time.
It was illustrated by Example \ref{ex-irra}. Here is another example, for
an i.i.d. model.
\begin{exam}
\label{ex:erg2}

where  are i.i.d. random variables of uniform distribution over
. There is a unique stationary 
regime for  which is . We denote by  the
projective distance. For an initial condition  with 
, we have .
Thus convergence to  occurs only asymptotically. 
There is no coupling but only 
-coupling with the unique stationary regime.
\end{exam}

We can show the following results.

\begin{theo}
The sequence of matrices  is  i.i.d. or stationary and ergodic. The
necessary and sufficient condition for the 
model to converge with -coupling to 
a unique stationary regime is the existence of
an asymptotic pattern  of 
 of rank 1 (Def. \ref{de:pattern2}).
\label{conv3}
\end{theo}
\begin{proof} It is given in Appendix, \S \ref{app:conv3}.
\end{proof}

\begin{theo}
The sequence of matrices  is  i.i.d. or stationary and ergodic. The
necessary and sufficient conditions for the 
model to converge with coupling to 
a unique stationary regime are~:\\
There exists a set  of matrices such that~:
\begin{enumerate}
\item ,  is a matrix of rank 1.
\item ,  is a pattern of .
\item .
\end{enumerate}
We can say equivalently that we must have patterns of rank 1
but with 
strictly positive probability. 
\label{conv2}
\end{theo}

\begin{proof} We have already proved the sufficient part (Th. \ref{th4}).
We prove the necessary part of the theorem in Appendix, 
\S \ref{app:conv2}.
\end{proof} 

Convergence with coupling appears as a limiting case of
coupling in finite time. 
In a discrete model,
we will have only 
-coupling when the set  of  scs1-cyc1 patterns is non empty
but is of 
probability 0. It means that the scs1-cyc1 patterns are only accumulation
points of the 
support. In a general model, we will 
have only  
-coupling when the scs1-cyc1 patterns are isolated points
of the support 
(which implies that they 
are boundary 
points of the support). 

\begin{exam}
\label{ex:erg3}
To illustrate the previous remark, let us continue the analysis of Example
\ref{ex:erg2}. 
There is only one matrix
(in the projective space )
verifying the first two conditions of Theorem 
\ref{conv2}. It is the matrix 
  
But condition 3. of Th. \ref{conv2} is not verified as . \\
Let us consider a slightly modified sequence of matrices 
where the 
diagonal elements are two random variables  and  defined 
on  and such that
  
Now, we have scs1-cyc1 patterns with strictly positive probability and there is
coupling in 
finite time with the unique stationary regime. 
\end{exam}



\begin{exam}[Cyclic Jackson Network 4] 
\label{ex:jak4}
We consider the model of Example \ref{ex:jak3}. The condition

is necessary
and sufficient for strong coupling convergence to a
unique stationary regime.
For i.i.d. Cyclic Jackson Networks,
the sufficient condition 
 
was obtained in
\cite{KaMa92}. The method of proof was completely
different, 
see the remarks at the end of Section \ref{sse:cjn}.
\end{exam}


\section{Without Irreducibility}
\label{se:wi}
We have supposed from the beginning that the matrices  were
irreducibles. 
The relaxation of the
irreducibility assumption is very important in terms of modeling power.
It enables us to 
consider, for example, the task graphs with random precedences introduced in
Section \ref{sse:tg}.

\parag

The irreducibility assumption
is used in 
Prop. \ref{decd}. But the only point we need to prove this
proposition is: 
``'', i.e. if  has only non-
coordinates then  has the same property. So the only 
assumption we 
need on the matrices  is:\\

\hspace*{1cm} {\bf I}  \\

The
irreducibility is also essential for the  spectral theory of Section
\ref{se:dst}.  
A reducible matrix  may
have several eigenvalues. Definition \ref{3def} and Theorem \ref{vectprop}
have to be reinterpreted by replacing the unique eigenvalue 
by the maximal 
eigenvalue. 
Theorem \ref{thcyc} is not true anymore.
But as far as the direct theorems
(\ref{th1}, \ref{th2}, \ref{th3} and \ref{th4}) are concerned, we use results of
the  spectral theory only for the pattern  whose 
existence is critical for the proofs. These theorems are still valid if we state
that condition {\bf I} is verified and that there exists a 
pattern  
which is scs1-cyc1
{\bf and} irreducible.
 
\parag
Dropping the irreducibility assumption does not influence the converse results.
More precisely, the proofs of 
Theorems \ref{conv}, \ref{conv3} and \ref{conv2} are still valid. 
Only two conditions
need to
be verified: \\

\hspace*{1cm} {\bf I}  \\
\hspace*{1cm} {\bf II}  . \\

Irreducibility  is not necessary to 
ensure that these conditions hold. We conclude that we can state our converse
results under the previous two minimal assumptions.

\parag


A counter-example shows that without condition {\bf II},
the uniqueness
of the stationary regime does not imply the existence of a
rank 1 pattern.

\begin{exam}
\label{ex:cond2}
Let  be the probability space, 
 the
probability law, and  the ergodic shift defined by:  and .
We consider


All patterns have an infinite projective diameter. Therefore,
condition {\bf II} is not verified. Nevertheless,
there is coupling in finite 
time with a unique periodic regime. More precisely, 
there is coupling of 
to the periodic regime  
and coupling occurs for . 
We conclude that there is coupling in finite time to a
unique stationary regime but no rank 1 pattern. 
Without condition {\bf II}, Theorem \ref{conv} is
not true anymore. 
\end{exam}

Another class of systems where condition {\bf II} is not verified is the class
of open systems studied by Baccelli in 
\cite{bacc92}. The results for this type of systems have been recalled in \S
\ref{sse:rfbacc}. In this case also, Theorem \ref{conv} fails to
be true. In such models, there are no  patterns which are scs1-cyc1 and
irreducible (matrices are non-irreducible with probability 1 !).
The good criterion to decide
the uniqueness of the stationary regime is the comparison between Lyapunov 
exponents, see Theorem \ref{bacc}. The computation of such exponents involves
the whole structure of 
the stochastic matrices , and not only an extracted 
pattern. 


\parag
Condition {\bf II} is weak and will be verified in most cases.
For a discrete  i.i.d. model, for example, it is sufficient to have one pattern of finite length
 which is irreducible and aperiodic to verify it. For a general  i.i.d. model, it is sufficient to have
 irreducible and aperiodic. In a stationary and ergodic framework, condition {\bf II} is a little bit
stronger, as shown by Example \ref{ex:cond2} where  irreducible and aperiodic and where
condition {\bf II} is not verified.

\parag

{\bf Remark }
For a general model which does not verify condition {\bf II}, we decompose the
model into its maximal sub-models verifying it. Then the complete analysis of
the system boils down to an analysis of the sub-models (using the results of
Section \ref{sse:sgm}) and of their interactions (using Theorem \ref{bacc} and
its generalizations, see \cite{bacc92}).

\section{Appendix}
\label{se:app}
\subsection{Loynes scheme}\index{Loynes scheme}\label{sse:ls}
Lemma \ref{le:loyn} is going to be used in several of the 
forthcoming proofs. Under an assumption of -coupling of the
trajectories, we build a stationary regime using a Loynes' type 
construction. 

\begin{lemm}
\label{le:loyn}
We consider a general model ``''
(see \S \ref{sse:sgm}). The sequence  is 
stationary and ergodic. We assume that there exists  such that 

We assume also that  a.s. (-coupling of the
trajectories). Then there exists a r.v. 
 verifying
.
The sequence  is the unique
stationary regime of the model.
\end{lemm}

\begin{proof}
We are going to show that the sequence
, ,
has a simple limit in . 
The argument is an analog of the famous backward scheme proposed by 
Loynes in \cite{loyn} for G/G/1 queues. 


We want to show that
.
It is easy to see that the event 

is invariant by the translation shift.
Then by the ergodic Lemma, it is of probability 
0 or 1. We have made the assumption that , hence 
.

Using the stationarity of the sequence , we have that  such that

Then we can define the projective image of  which is a bounded subset of  and that we denote by .
The boundedness implies that

where . Let us define the vectors

It is
immediate that  is included in the convex hull of these vectors, i.e.

In the (max,+) algebra, we have the following property, 
for all . It implies
\begin {equation}
\label{eq-semil}
\forall x \in \Pi, \; \pi (Ax) \in \left\{\pi(\alpha_1 \otimes Ac_1 \oplus 
\cdots \oplus \alpha_k
\otimes Ac_k),\;\alpha_i \in \R\right\}\:.
\end {equation} 




We fix . Using the coupling assumption, we have that the random
variable  is  
finite, where  is defined by:


As both  and  are  finite, we have

As a direct consequence of  \eref{eq-semil}, we have
on the event ~:

We deduce, using the stationarity of , that
 

It implies that the random variables  converge
in probability to 0. But as  is pathwise decreasing, the convergence occurs also
 

\parag

We have in particular, for all , 
 It implies that  is a Cauchy sequence which converges. 
The limit does not depend on . We denote it by . We have~:


The sequence  is a stationary regime. Let us prove 
it is the unique one. 
We want to prove that

As  is  finite, for all , there exists a compact
 such that . We
proceed as above (Equation \eref{eq-bip}) in order to
define vectors  such that 

We have

Using the coupling of trajectories, we also have

We conclude easily that
there is coupling of  and . 
We can apply Proposition
\ref{asmu}. There is weak convergence of  to
the distribution of  and relation (\ref{eq-eq}) establishes the a.s. 
convergence of  to . 
As a direct consequence, 
 is the unique stationary regime.
\end{proof}

\subsection{Proof of Theorem \protect\ref{conv} } 
\label{app:conv}
We are going to prove that the existence of a unique stationary regime
implies the existence of a pattern of rank 1 (Def. \ref{de:patt}). 
Using Theorem \ref{th2}, the proof will then be complete.

We need the following definition.
\begin{defi}
\label{de-semi}
Let us consider .
We denote by , the semigroup generated by these matrices 
and by  its projection. We have

\end{defi}

We consider the Euclidean space 
as introduced in Definition \ref{dist}. 
Next proposition was proved by Gaubert in \cite{gaub94b}.

\begin{prop}
\label{pr-gaub}
Let . 
For all compact set  of , we have
 is finite. 
\end{prop}

Let us prove a lemma first.
\begin{lemm}
\label{le:boug}
We consider a finite model ``''
with  and .
We suppose that there is a
unique stationary regime. It implies

Equivalently, it implies -coupling of the trajectories
corresponding to different initial conditions.
\end{lemm}

\begin{proof}
We assume that Equation \eref{eq-eta} is not verified. It implies,
using Proposition \ref{decd}, that there exists  and 
such that

Let  be the projective semigroup generated 
by the matrices of the model (Def. \ref{de-semi}).
For , we define . 
We have that  is finite for all compact 
of , Proposition \ref{pr-gaub}. 
It implies that  is finite for
all compact  of . We conclude that  has no accumulation point
and verifies , where  is the closure of 
in . 

\parag
We want to apply Theorem \ref{anko}. It is required that the probability
space be a Polish space. 
In order to fulfill this,
we consider 
the canonical probability space 
consisting of one-sided infinite sequences of matrices , 
i.e.

We recall 
that we made the assumption \eref{eq-ass}, which implies

It implies that for all , there exists  
and , a compact set of  such that

There exists a compact  (which depends on )
of  such that 

We conclude that the sequence
 is tight in . 
It implies that it is tight in . 
We can view  as
a SRS defined on  only. 
Applying Theorem \ref{anko}, we obtain that,
for all , there exists a
stationary distribution  defined on .

\parag
Let us consider the initial conditions  and  as defined in
\eref{eq-boug}. It is a-priori possible to have . As a consequence, one cannot 
rule out that . 
We are going to prove that there exists
 such that . 
It will provide
two stationary
distributions , which contradicts the 
uniqueness of the stationary regime. 

\parag


We work on the event , see \eref{eq-boug}. We have  for all . 
Let  be two different points. Then there exists an
open interval  such that


The proof is straightforward.
We consider
the (random) intervals 
 defined as above for
the couples
of points .
For any 
and , we have . As a
consequence, the sequence  
is decreasing. Let  and  be 
the limits of  and .
On
the event , we have  
(see \eref{eq-boug}).

\parag
We define the sets


Let  be three different points. It is immediate to
prove that there exists a unique  such that 
.
As a consequence, the sets  are countable and  is countable. 
It implies that 
the set
 is non-empty on .
For all , 
we have,
by definition of , that . The conclusion follows.
\end{proof}

{\bf Remark } The proof does not work 
when matrices  belong to . 
In this 
case, it is possible to have .  
In the model detailed in Example \ref{ex-irra},
all the sets  are dense in the interval 
(as a classical consequence of the assumption ). 
It implies that .
The stationary distributions  are all defined on the same set, ,
which prevents the previous proof from working. 

\parag

We want to prove the existence of a rank 1 pattern of  
(Def. \ref{de:patt}).
There exists a r.v.  such that 
 (consequence
of Equation \eref{eq-ass}). 

It follows from the ergodic Lemma, that the set

is infinite, -a.s. Let  be the strictly increasing
function such that . We define the 
subsequence . 
The matrices  can be written under the 
form  for . We have

for some indices   belonging to the argmax in .
We also have

We consider the Euclidean space  where 
is the norm introduced in Definition \ref{dist}. It follows from \eref{eq-cest1} and \eref{eq-cest2} that

It implies that the sequence  belongs to a compact 
of . Hence there exists a strictly increasing
function  such that 
is converging. Let  be a representative (in )
of the limit. 
By 
continuity of the projective distance, we have that . Therefore  is a 
rank 1 matrix. 

\parag
As the products  
can only take a finite number of values in compact sets
(Proposition \ref{pr-gaub}),
it implies  that 
the limit matrix 
is attained in finite time. More precisely, there exists  such that

The matrix  is a rank 1 pattern
for . It concludes the proof.
\cqfd










\subsection{Proof of Theorem \protect\ref{conv3} } 
\label{app:conv3}
We first prove the necessary part of the Theorem, i.e. coupling
with a unique stationary regime implies the existence of an 
asymptotic pattern.

Let  be the unique stationary regime. We have for all
,



We have assumed that 
 such that , see 
Equation \eref{eq-ass}, Section \S \ref{se:ct}. 
Let  be such that . 
It implies that there exists  such that
. 
Let us denote 

It follows from the stationary-ergodic assumption, that there exists 
a minimal  such that

We define in the same way an increasing sequence  and
a decreasing sequence of events  verifying 

On the event , we have 

The proof is exactly similar 
to the one proposed in the proof of Theorem 
\ref{conv} (\S \ref{app:conv}, Equation \eref{eq-cI} and after). 
\index{ (projective ball)}
Let  denote the open ball of  of
center  and of radius . 
For all , we
choose a deterministic matrix  belonging to 
and verifying 

As the matrices  belong to a compact, there exists a
subsequence  which converges to a limit . 
We have (see the proof of Lemma \ref{le:loyn}) that
. We conclude that
 is a rank 1 matrix. 

We fix . Let  be such that , we have
. For , we have
. It implies

It means precisely that  is an asymptotic
pattern of , see Definition \ref{de:pattern2}.



\parag

Let us prove the sufficient part of the theorem. We assume that there exists
a deterministic 
matrix  which is a rank 1 asymptotic pattern of .
We want to prove the -coupling convergence of  to a 
unique stationary regime. 

We fix . Let  be such that 

Using the ergodic Lemma, we have

Let  be the unique eigenvector of the rank 1 matrix 
and 
 the ball of center  and radius  in . 
We have
that for all ,

In particular, it implies that  and  large enough,

We deduce that
. We conclude by using 
Lemma \ref{le:loyn} (the existence of  such that  comes from Equation \eref{eq-triv}).

\cqfd

\subsection{Proof of Theorem \protect\ref{conv2}}
\label{app:conv2}
We want to prove that the conditions given in Theorem \ref{conv2} are
necessary. We suppose that our model couples in finite time with a unique
stationary regime, uniformly over initial
conditions in . 
Let us prove a lemma first.

\begin{lemm}
If there is a unique stationary regime 
for , coupling in finite time uniformly over
initial conditions in  implies strong coupling in finite time uniformly
over initial conditions in .
\end{lemm}

\begin{proof} Let  be the unique stationary regime with
which the SRS  couples.
We consider the event:

The assumption of coupling in
finite time, uniformly over , may be written~:

Here we implicitly use the assumption that the projective image of
 is asymptotically bounded (see 
Equation \eref{eq-ass}).
Let us consider  and  an integer
, we have:

The passage from \eref{eq-st1} to \eref{eq-st2} uses
the fact that coupling occurs uniformly over
initial conditions. We have:

and

This is exactly the definition of strong coupling (Def. \ref{scoup}).
\end{proof} 

We can now use the converse Theorem \ref{thbo2c}. There exists a stationary
sequence of 
events  which is renovating for the SRS , and verifies . Let  be
the common length and  the common function of these renovating events.
We have, on :

But we also have:

We conclude that, on ,  is independent of . It implies 
that  is a 
matrix of rank 1. \cqfd


\parag
\parag

{\bf Acknowledgment } I would like to thank Fran\c{c}ois Baccelli who
introduced me to this problem. 
F. Baccelli gave me also many ideas and suggestions which appear in this
paper. I am also grateful to Serguei Foss, St\'ephane Gaubert 
and Philippe Bougerol for 
several fruitful talks on the topic. At last, the careful comments of an
anonymous referee have greatly helped improving the presentation of this paper.

\begin{thebibliography}{10}

\bibitem{AnKo}
V.~Anantharam and T.~Konstantopoulos.
\newblock Stationary solutions of stochastic recursions describing discrete
  event systems.
\newblock In {\em Proc. 33rd Conf. on Decision and Control}, volume~2, pages
  1481--1486, Lake Buena Vista, FL, 1994.

\bibitem{asmu92}
S.~Asmussen.
\newblock On coupling and weak convergence to stationarity.
\newblock {\em Annals of Applied Probability}, 2(3):739--751, 1992.

\bibitem{bacc92}
F.~Baccelli.
\newblock Ergodic theory of stochastic {P}etri networks.
\newblock {\em Annals of Probability}, 20(1):375--396, 1992.

\bibitem{BCOQ}
F.~Baccelli, G.~Cohen, G.J. Olsder, and J.P. Quadrat.
\newblock {\em Synchronization and Linearity}.
\newblock John Wiley \& Sons, New York, 1992.

\bibitem{BaLi92a}
F.~Baccelli and Z.~Liu.
\newblock On a class of stochastic recursive equations arising in queueing
  theory.
\newblock {\em Annals of Probability}, 21(1):350--374, 1992.

\bibitem{bamb}
N.~Bambos.
\newblock On closed ring queueing networks.
\newblock {\em J. Appl. Prob.}, 29:979--995, 1992.

\bibitem{boro84}
A.~Borovkov.
\newblock {\em Asymptotic Methods in Queueing Theory}.
\newblock John Wiley \& Sons, New York, 1984.

\bibitem{boro86}
A.~Borovkov.
\newblock Limit theorems for queueing networks. {I}.
\newblock {\em Theory Prob. Appl.}, 31:413--427, 1986.

\bibitem{boro88}
A.~Borovkov.
\newblock Limit theorems for queueing networks. {II}.
\newblock {\em Theory Prob. Appl.}, 32:257--272, 1988.

\bibitem{BoFo92}
A.~Borovkov and S.~Foss.
\newblock Stochastically recursive sequences and their generalizations.
\newblock {\em Siberian Adv. in Math.}, 2:16--81, 1992.

\bibitem{BoFo94}
A.~Borovkov and S.~Foss.
\newblock Two ergodicity criteria for stochastically recursive sequences.
\newblock {\em Acta Applicandae Mathematicae}, 34:125--134, 1994.

\bibitem{BoLa}
P.~Bougerol and J.~Lacroix.
\newblock {\em Products of Random Matrices with Applications to {S}chr\"odinger
  Operators}.
\newblock Progress in Probability and Statistics. Birk\"auser, 1985.

\bibitem{BFLi}
A.~Brandt, P.~Franken, and B.~Lisek.
\newblock {\em Stationary Stochastic Models}.
\newblock Prob. and Math. Stat. Wiley, New York, 1990.

\bibitem{BrVi}
M.~Brilman and J.M. Vincent.
\newblock Synchronisation by resources sharing : a performance analysis.
\newblock Technical report, MAI-IMAG, Grenoble, France, 1995.

\bibitem{CDQV83}
G.~Cohen, D.~Dubois, J.P. Quadrat, and M.~Viot.
\newblock Analyse du comportement p\'{e}riodique des syst\`{e}mes de production
  par la th\'{e}orie des dio\"\i des.
\newblock Technical Report 191, INRIA, 1983.

\bibitem{CDQV85}
G.~Cohen, D.~Dubois, J.P. Quadrat, and M.~Viot.
\newblock A linear system-theoretic view of discrete-event processes and its
  use for performance evaluation in manufacturing.
\newblock {\em IEEE Trans. Automatic Control}, AC-30:210--220, 1985.

\bibitem{cohe}
J.~Cohen.
\newblock Subadditivity, generalized product of random matrices and operations
  research.
\newblock {\em SIAM Review}, 30(1):69--86, 1988.

\bibitem{cuni62}
R.~Cuninghame-Green.
\newblock Describing industrial processes with interference and approximating
  their steady-state behaviour.
\newblock {\em Oper. Res. Quat.}, 13(1):95--100, 1962.

\bibitem{cuni79}
R.~Cuninghame-Green.
\newblock {\em Minimax Algebra}, volume 166 of {\em Lecture Notes in Economics
  and Mathematical Systems}.
\newblock Springer-Verlag, Berlin, 1979.

\bibitem{FuKe}
H.~Furstenberg and H.~Kesten.
\newblock Products of random matrices.
\newblock {\em Ann. Math. Statist.}, 31:457--469, 1960.

\bibitem{gaub94b}
S.~Gaubert.
\newblock On semigroups of matrices in the  algebra.
\newblock Technical Report 2172, INRIA, 1994.

\bibitem{GaMa95}
S.~Gaubert and J.~Mairesse.
\newblock Task resource models and (max,+) automata.
\newblock In J.~Gunawardena, editor, {\em Idempotency}. Cambridge University
  Press, 1995.

\bibitem{GlYa}
P.~Glasserman and D.~Yao.
\newblock {\em Monotone Structure in Discrete-Event Systems}.
\newblock John Wiley \& Sons, 1994.

\bibitem{GoMi77}
M.~Gondran and M.~Minoux.
\newblock Valeurs propres et vecteurs propres dans les dio\"\i des et leur
  interpr\'etation en th\'eorie des graphes.
\newblock {\em EDF, Bulletin de la Direction des Etudes et Recherches, Serie C,
  Math\'ematiques Informatique}, 2:25--41, 1977.

\bibitem{GoNe}
W.~Gordon and G.~Newell.
\newblock Closed queuing systems with exponential servers.
\newblock {\em Oper. Res.}, 15:254--265, 1967.

\bibitem{grif}
R.~Griffiths.
\newblock Frenkel-{K}ontorova models of commensurate-incommensurate phase
  transitions.
\newblock In H.~van Beijeren, editor, {\em Fundamental problems in statistical
  mechanics VII}. Elsevier Science Publishers, 1990.

\bibitem{KaMa92}
H.~Kaspi and A.~Mandelbaum.
\newblock Regenerative closed queueing networks.
\newblock {\em Stoch. and Stoch. Reports}, 39:239--258, 1992.

\bibitem{KaMa94}
H.~Kaspi and A.~Mandelbaum.
\newblock On {H}arris recurrence in continuous time.
\newblock {\em Math. Oper. Research (to appear)}, 1994.

\bibitem{loyn}
R.~Loynes.
\newblock The stability of a queue with non-independent interarrival and
  service times.
\newblock {\em Proc. Camb. Philos. Soc.}, 58:497--520, 1962.

\bibitem{mair95e}
J.~Mairesse.
\newblock {\em Stabilit\'e des syst\`emes \`a \'ev\'enements discrets
  stochastiques. Approche alg\'ebrique}.
\newblock PhD thesis, Ecole Polytechnique, Paris, 1995.
\newblock In english.

\bibitem{MeTw}
S.~Meyn and R.~Tweedie.
\newblock {\em Markov Chains and Stochastic Stability}.
\newblock Springer-Verlag, Berlin, 1993.

\bibitem{Oal90}
G.J. Olsder, J.~Resing, R.~de~Vries, M.~Keane, and G.~Hooghiemstra.
\newblock Discrete event systems with stochastic processing times.
\newblock {\em IEEE Trans. on Automatic Control}, 35(3):299--302, 1990.

\bibitem{Ral90}
J.~Resing, R.~de~Vries, G.~Hooghiemstra, M.~Keane, and G.J. Olsder.
\newblock Asymptotic behavior of random discrete event systems.
\newblock {\em Stoch. Proc. and Applications}, 36:195--216, 1990.

\bibitem{roma}
I.V. Romanovski\u\i.
\newblock Optimization and stationary control of discrete deterministic process
  in dynamic programming.
\newblock {\em Cybernetics}, 3:66--78, 1967.

\bibitem{YaKo}
S.~Yakovenko and L.~Kontorer.
\newblock Nonlinear semigroups and infinite horizon optimization.
\newblock In V.~Maslov and S.~Samborski\u\i, editors, {\em Idempotent
  analysis}, volume~13 of {\em Adv. in Sov. Math.} AMS, 1992.

\end{thebibliography}




\end{document}
