\pdfoutput = 1
\documentclass[8pt]{article}


\usepackage{times}
\usepackage[comma,authoryear]{natbib}
\usepackage[english]{babel}
\usepackage{blindtext}
\usepackage{graphicx}
\usepackage{amsmath, amsthm, amssymb, bbm, bm}
\usepackage{enumerate}
\usepackage{float}      \usepackage{subcaption}  \usepackage{wrapfig}
\usepackage[margin=0cm]{caption}
\usepackage[titletoc, toc]{appendix}
\usepackage{tabularx}

\usepackage{multirow}
\usepackage{makecell}


\usepackage[x11names, usenames, dvipsnames, svgnames, table]{xcolor}
\definecolor{firebrick}{rgb}{.698,.133,.133}

\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{url}            \usepackage{booktabs, colortbl}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      

\usepackage{csquotes}
\usepackage{latexsym}

\usepackage[boxruled, vlined, linesnumbered]{algorithm2e}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\usepackage{algorithmic}
\algsetup{linenosize=\tiny}

\let\oldnl\nl \newcommand{\nonl}{\renewcommand{\nl}{\let\nl\oldnl}}

\usepackage{paralist}
\newcommand{\quoteit}[1]{``#1''}
\usepackage{xspace}
\usepackage{soul}
\usepackage{dsfont}
\usepackage{stmaryrd}
\usepackage[textwidth=15mm]{todonotes}
\usepackage{dirtytalk}
\usepackage{pbox}
\usepackage{paralist}
\usepackage{cprotect}


\usepackage{verbatim}
\usepackage{textcomp}
\usepackage[normalem]{ulem}

\usepackage{mathtools}
\usepackage{etextools}
\usepackage[inline]{enumitem}


\usepackage[colorlinks=true,allcolors=firebrick,bookmarks=false]{hyperref}
\renewcommand{\qed}{\hfill \mbox{\raggedright \rule{0.1in}{0.1in}}}



\newcommand{\reals}{\mathbb{R}}
\newcommand{\naturals}{\mathbb{N}}
\newcommand{\complex}{\mathbb{C}}

\newcommand{\R}{\mathbb{R} \xspace}


\newcommand{\abs}[1]{\ensuremath \left| #1 \right|}
\newcommand{\norm}[1]{\ensuremath \lVert#1\rVert}
\newcommand{\given}{\, \vert \,}
\providecommand{\cal}[1]{\ensuremath \mathcal{#1}}
\newcommand{\ag}[1]{\ensuremath \left\langle#1\right\rangle}
\providecommand{\OO}{\mathcal{O}}
\newcommand{\indep}{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{}\mkern2mu{#1#2}}}
\newcommand{\trace}{\trm{tr}}
\newcommand{\kron}{\otimes}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}

\newcommand{\aeq}[1]{}
\newcommand{\aeqs}[1]{}
\newcommand{\beq}[1]{}
\newcommand{\beqs}[1]{}

\newcommand{\trm}[1]{\mathrm{#1}}
\newcommand{\enum}[2][(a)]{\begin{enumerate}[#1]{#2}\end{enumerate}}
\newcommand{\clist}[1]{\begin{itemize}\setlength{\itemsep}{0pt}
\setlength{\parsep}{0pt}
{#1}\end{itemize}}
\newcommand{\ilist}[1]{\begin{itemize}{#1}\end{itemize}}
\newcommand{\bmat}[1]{\begin{bmatrix}#1\end{bmatrix}}
\newcommand{\mpage}[2]{\begin{center}
\begin{minipage}{#1}#2\end{minipage}\end{center}}
\newcommand{\la}{\ \leftarrow\ }
\newcommand{\ra}{\rightarrow}
\providecommand\f[2]{\ensuremath \frac{#1}{#2}}


\newcommand{\deriv}[1]{\f{d}{d #1}\ }
\newcommand{\pderiv}[1]{\f{\partial}{\partial #1}\ }

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{problem}[theorem]{Problem}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{note}[theorem]{Note}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{assumption}[theorem]{Assumption}

\renewcommand{\P}{\trm{P}}
\newcommand{\E}{\mathop{\mathbb{E} \xspace}}
\newcommand{\corr}{\textrm{cross-corr}\ }
\providecommand{\ones}{\mathbbm{1}}
\providecommand{\ind}{{\bf 1}}
\providecommand{\nnot}[1]{\overline{#1}}
\providecommand{\oor}{\vee}
\providecommand{\aand}{\wedge}
\renewcommand{\implies}{\Rightarrow}
\newcommand{\convp}{\overset{P}{\to}}
\newcommand{\convd}{\overset{\DD}{\to}}

\newcommand{\s}{\sigma}
\newcommand{\w}{\omega}
\renewcommand{\r}{\rho}
\renewcommand{\t}{\tau}
\renewcommand{\th}{\theta}
\renewcommand{\a}{\alpha}
\newcommand{\p}{\phi}
\newcommand{\e}{\epsilon}
\renewcommand{\b}{\beta}
\newcommand{\g}{\gamma}
\renewcommand{\d}{\delta}
\newcommand{\D}{\Delta}
\newcommand{\z}{\zeta}
\renewcommand{\L}{\Lambda}
\renewcommand{\l}{\lambda}
\newcommand{\G}{\Gamma}
\renewcommand{\S}{\Sigma}
\newcommand{\Th}{\Theta}

\def \XX {\mathcal{X}}
\def \LL {\mathcal{L}}
\def \DD {\mathcal{D}}
\def \FF {\mathcal{F}}
\def \OO {\mathcal{O}}
\def \tOO {\widetilde{\mathcal{O}}}
\def \BB {\mathcal{B}}
\def \PP {\mathcal{P}}

\newcommand{\bR}{\mathbb{R}}
\newcommand{\bN}{\mathbb{N}}
\newcommand{\bZ}{\mathbb{Z}}

\def \rmF {\trm{F}}

\newcommand{\var}{\trm{var}}
\newcommand{\stddev}{\trm{stddev}}
\newcommand{\covar}{\trm{covar}}

\newcommand{\Poissondist}{\trm{Poisson}}
\newcommand{\Berdist}{\trm{Ber}}
\newcommand{\Geomdist}{\trm{Geom}}
\newcommand{\Betadist}{\trm{Beta}}
\newcommand{\Bindist}{\trm{Bin}}
\newcommand{\Gammadist}{\trm{Gamma}}
\newcommand{\InvGammadist}{\trm{InvGamma}}
\newcommand{\Expdist}{\trm{Exp}}



\newcommand{\data}{\trm{input}}
\newcommand{\convolution}{\trm{conv}}
\newcommand{\maxpool}{\textrm{max-pool}}
\newcommand{\meanpool}{\trm{meanpool}}
\newcommand{\relu}{\trm{relu}}
\newcommand{\dropout}{\trm{dropout}}
\newcommand{\linear}{\trm{linear}}
\newcommand{\softmax}{\trm{softmax}}
\newcommand{\batchnorm}{\trm{batchnorm}}
\newcommand{\block}{\trm{block}}

\DeclarePairedDelimiterX{\divx}[2]{(}{)}{#1\;\delimsize\|\;#2}
\newcommand{\divg}{D\divx}


\DeclarePairedDelimiter{\normdiv}{\lVert}{\rVert}


\providecommand\rbrac[1]{\ensuremath \left(#1\right)}
 \providecommand\sqbrac[1]{\ensuremath \left[#1\right]}
 \providecommand\cbrac[1]{\ensuremath \left\{#1\right\}}


\newcommand*{\eg}{\emph{e.g.}\@\xspace}
\newcommand*{\ie}{\emph{i.e.}\@\xspace}

\newcommand{\before}{\prec \xspace}
\DeclareMathOperator{\dom}{\textbf{dom}}  \DeclareMathOperator{\ran}{\textbf{ran}}   \usepackage{style}


\linespread{1.05}





\newcommand\red[1]{{\color{red}#1}}
\newcommand{\entropysgd}{\mathrm{Entropy}\textrm{-}\mathrm{SGD}}
\newcommand{\entropyadam}{\mathrm{Entropy}\textrm{-}\mathrm{Adam}}
\newcommand{\minibatch}[1]{\Xi^{#1}}
\newcommand{\mnistfc}{\textrm{mnistfc}}
\newcommand{\smallmnistfc}{\textrm{small-mnistfc}}
\newcommand{\charlstm}{\textrm{char-LSTM}}
\newcommand{\ptblstm}{\textrm{PTB-LSTM}}
\newcommand{\lenet}{\textrm{LeNet}}
\newcommand{\allcnn}{\textrm{All-CNN-BN}}





\title{Non-parametric Uni-modality Constraints \\ for Deep Ordinal Classification
\thanks{Code:~\href{https://github.com/sbelharbi/Deep-Ordinal-Classification-with-Inequality-Constraints}{https://github.com/sbelharbi/Deep-Ordinal-Classification-with-Inequality-Constraints}}}

\renewcommand\footnotemark{}




\renewcommand\footnotemark{}

\author{Soufiane Belharbi, Ismail Ben Ayed, Luke McCaffrey, Eric Granger\0.03in]
{\footnotesize
\hspace{8.5mm} \href{mailto:eric.granger@etsmtl.ca}{eric.granger@etsmtl.ca}
}}

\setlength{\marginparwidth}{1in}
\newcommand{\nt}[2]{
{\color{ForestGreen}#1}\marginpar{\tiny\noindent{\raggedright{\color{Sienna}[NOTE]} \color{Sienna}{#2} \par}}
}
\renewcommand{\ss}[2]{{\color{cyan}#1}\marginpar{\tiny\noindent{\raggedright{\color{BurntOrange}[SS]}\color{BurntOrange}{#2} \par}}}
\newcommand{\ac}[2]{{\color{magenta}#1}\marginpar{\tiny\noindent{\raggedright{\color{magenta}[AC]}\color{magenta}{#2} \par}}}

\newcommand{\status}[2]{{\color{red}#1}\marginpar{\tiny\noindent{\raggedright{\color{red}#2}}}}

\newcommand{\todoit}[1]{{\color{gray}#1}\marginpar{\tiny\noindent{\raggedright{\color{blue}[TODO]}}}}
\newcommand{\fix}[2]{{\color{blue}#1}\marginpar{\tiny\noindent{\raggedright{\color{blue}[FIX]}\color{blue}{#2} \par}}}
\newcommand{\ignore}[1]{}
\newcommand{\mref}{{\color{BurntOrange}\&ref\& \xspace}}
\newcommand{\sota}{state-of-the-art\xspace}




\begin{document}

\maketitle

\begin{abstract}
We propose a new constrained-optimization formulation for deep ordinal classification, in which uni-modality of the label distribution is enforced implicitly via a set of inequality constraints over all the pairs of adjacent labels. Based on  constraints for  labels, our model is {\em non-parametric} and, therefore, more flexible than the existing deep ordinal classification techniques. Unlike these, it does not restrict the learned representation to a single and specific parametric model (or penalty) imposed over all the labels. Therefore, it enables the training to explore larger solution spaces, while removing the need for {\em ad hoc} choices, and scaling up to large numbers of labels. Our formulation can be employed in conjunction with any standard classification loss and deep architecture.
To address this challenging optimization problem, we solve a sequence of unconstrained losses based on a powerful extension of the log-barrier method. This effectively handles competing constraints and accommodates standard SGD for deep networks, while avoiding computationally expensive Lagrangian dual steps and substantially  outperforming penalty methods. Furthermore, we propose a new Sides Order Index (SOI) performance metric for ordinal classification, as a proxy to measure distribution uni-modality. We report comprehensive set of evaluations and comparisons with state-of-the-art methods on benchmark public datasets for several ordinal classification tasks, showing the merits of our approach in terms of label consistency, classification accuracy and scalability. Importantly, enforcing label consistency with our model does not incur higher classification errors, unlike many existing ordinal classification methods.
\end{abstract}


\section{Introduction}
\label{sec:introduction}

Different research has suggested using a set of surrogate losses for OC training \citep{pedregosa2017consistency,rennie2005loss}. However, cross-entropy and/or mean squared error remain a primary choice for deep models due to their differentiability, simplicity, and capability to deal with many classes. Such standard classification losses, e.g., cross-entropy, do not impose any prior on the structure of the labels. Designed to penalize the error between predicted and true labels for each data sample, they do not account for the semantic relationships that might exist between the labels. However, in a wide range of classification tasks, the set of labels exhibits a natural structure, for instance, in the form of a specific order. A typical example is classifying biopsy samples, with the labels encoding cancer-aggressiveness levels (or grades), which are ordered. Ordinal classification (OC) attempts to leverage such natural order of the labels, and is useful in a breadth of applications, such as movies rating \citep{crammer2002pranking,Koren2011}, market bonds rating \citep{moody1994architecture}, age estimation \citep{liu2017ordinal,pan2018mean,zhu2019ordinal}, emotion estimation \citep{jia2019facial,XiongLiuZhongFu2019,zhou2015emotion}, cancer grading \citep{gentry2015penalized}, diabetic retinopathy grading \citep{beckham2017unimodal}, photographs dating \citep{palermo2012datingdataset}, among many others.


\begin{figure}[h!]
  \centering
  \includegraphics[scale=0.5]{order}
  \caption{An example of two different posterior distributions of the same input sample with the same probability of the predicted label  and the same cross-entropy loss:  corresponds to paradoxical predictions, ranking grade  right after predicted grade , despite their significant semantic difference, whereas  corresponds to consistent (ordered) predictions.}
  \label{fig:fig-0}
\end{figure}


Fig.\ref{fig:fig-0} depicts a typical OC task, which consists of grading cancer (8 classes, for illustration). It shows two different posterior distributions (PDs) of class predictions for the same input. While the two PDs have exactly the same cross-entropy loss,  corresponds to a {\em uni-modal} distribution of the posteriors as it
concentrates its probability mass around predicted label  and, as we move away from the latter, it decreases {\em monotonically}. In contrast,  distributes its mass over labels that are far away from each other, yielding inconsistent class predictions. Therefore,  corresponds to predictions that are semantically paradoxical. The model gave the second highest posterior probability to grade , ranking it right after predicted grade , despite the significant semantic difference between the two grades. In practice, such inconsistent distributions may raise serious interpretability issues, and impede the deployment of the models, more so when important actions are associated with the predictions. As an example, consider  with the following ordered actions for the top-3 labels . This order of top-3 actions is confusing, and may not be considered due to its discordance.


Several recent deep learning works addressed ordinal classification by imposing a uni-modality prior on the predicted posterior distributions following some {\em parametric} model. This is often done by enforcing uni-modality either on the label distributions \citep{beckham2016simple,cheng2008neural,gao2017deep,geng2016label,geng2013facial,huo2016deep,pan2018mean} or on the network outputs
\citep{beckham2017unimodal,da2005classification}. While both type of approaches yield consistent predictions, they
constrain  the  output  distribution  to  have  a  specific form, following the choice of a parametric uni-modal prior, e.g., Poisson \citep{beckham2017unimodal} or Gaussian \citep{gao2017deep,geng2016label,geng2013facial,huo2016deep}, imposed as a {\em single} penalty on all the labels . Therefore, in general, they require
several task-dependent choices, including tuning carefully the hyper-parameters that control the form (or shape) of the parametric model and complex network-architecture design. They might also lead to models that do not scale well for large numbers of labels, as is the case of \citep{beckham2017unimodal}\footnote{The experiments in \citep{beckham2017unimodal} were limited to 8 labels}, which limits their applicability.
We argue that restricting the posterior distribution to a single parametric model of a specific form is not necessary for ensuring uni-modality and order consistency, and propose a non-parametric,  constrained-optimization solution for deep ordinal classification.

{\bf Contributions:} We propose a novel constrained-optimization formulation for deep ordinal classification. Our model enforces uni-modality and label-order consistency via a set of inequality constraints over all pairs of adjacent labels, which can be imposed on any standard classification loss and integrated with any deep architecture. Based on  constraints for  labels, our model is {\em non-parametric} and, therefore, more flexible than the existing deep ordinal classification techniques. Unlike these, it does not restrict the learned representation to a single and specific parametric model (or penalty) imposed on all the labels. Therefore, it enables the training to explore larger spaces of solutions, while removing the need for {\em ad hoc} choices and scaling up to large numbers of labels.

To tackle the ensuing challenging optimization problem, we solve a sequence of unconstrained losses based on a powerful extension of the log-barrier method.
This handles effectively competing constraints and accommodates standard SGD for deep networks, while avoiding computationally expensive Lagrangian dual steps and outperforming substantially penalty methods. Furthermore, we introduce a new performance metric for OC, as a proxy to measure distribution uni-modality, referred to as the Sides Order Index (SOI). We report comprehensive evaluations and comparisons to state-of-the-art methods on benchmark public datasets for several OC tasks (breast cancer grading, age estimation, and historical color image dating). The results indicate that our approach outperforms substantially several state-of-the-art ordinal classification methods in terms of label consistency, while scaling up to large numbers of labels. Importantly, enforcing label consistency with our model does not incur higher classification errors, unlike many existing ordinal classification methods.




\section{Related work}
\label{sec:related-work}


Several recent work converted the hard target label into a prior distribution \citep{gao2017deep,geng2016label,geng2013facial,huo2016deep}.
One way to impose such a prior distribution over the labels is, for instance, to optimize a divergence loss, such as Kullback–Leibler (KL), for training the network \citep{geng2016label}. A typical choice in the literature is to use a parametric uni-modal Gaussian to model label distribution, with the mean of the Gaussian encoding the true label, while the variance is set through validation or through prior knowledge. The main motivation behind this class of label-distribution methods is to deal with the ambiguity and uncertainty of discrete labels, in tasks such as age estimation, head pose estimation, and semantic segmentation. Using prior distributions over the labels is also related to the well-known label-smoothing regularization for improving the training of deep networks \citep{szegedy2016rethinking}. Such a regularization perturbs the hard label with a uniform distribution, embedding uncertainty in the ground truth. In \citep{cheng2008neural}, the prior order of the labels is encoded using a step function. Instead of a standard one-hot encoding, a binary-vector encoding the labels is used as a target for network training. Another class of methods in literature penalize directly the deviations of the softmax predictions of the network from a uni-modal Gaussian, which is constrained to have the same mean as the true label and minimal variance \citep{beckham2016simple,pan2018mean}. These methods do not impose specific prior knowledge on the variance, but attempt to push it towards zero. In \citep{beckham2017unimodal,da2005classification} specific parametric distributions are directly encoded within the network output, e.g., binomial or Poisson distributions. The network output is a single scalar used to model the output distribution and to infer the probability of each label. Other methods \citep{liu2018constrained,xia2007recursive} seek to reinforce the order between samples of adjacent labels within the feature space, not in the output space. However, such methods require considerable changes to the network architecture \citep{liu2018constrained}.

 While the above mentioned techniques enforce the prior order and uni-modality of the output distributions, they have several shortcomings. The techniques in \citep{gao2017deep,geng2016label,geng2013facial,huo2016deep} constrain the output distribution to have a specific form (or shape), following the choice of a parametric uni-modal model, e.g., Gaussian. This requires {\em ad hoc} (manual) setting of model parameters, e.g., the variance of a Gaussian, which might have a direct but unclear impact on the results. The models in \citep{beckham2016simple,pan2018mean} learn such variance parameter by pushing it towards zero, yielding a sharp Gaussian that approaches a Dirac function. Choosing a sharp or flat Gaussian has a direct impact on the labels and their order, but it is not clear how to make such a choice. In general, the choices that one has to make as to the form of the parametric model are task-dependent. Directly encoding a specific parametric distribution within the network output, as in \citep{beckham2017unimodal}, also requires several choices, including complex network architecture design and setting {\em ad hoc} parameters. In particular, the performance of the method in \citep{beckham2017unimodal} seems to depend strongly on a hyper-parameter that controls the variance of the distribution. Such a hyper-parameter should be set empirically with some care since its value changes the distribution shape from uniform to Gaussian.  The method in \citep{beckham2017unimodal} was evaluated on only two ordinal datasets that have very few classes (5 and 8). The authors of \citep{beckham2017unimodal} stated that the method does not scale well to large numbers of labels, in particular, with the Poisson distribution, due to the nature of the latter. With this distribution choice, the label probabilities have a stair-like shape with a \emph{constant} (deterministic) variation in each step.

 As detailed in the next section, our approach circumvents the need to pre-define a parametric uni-modal model for network outputs, and to set its parameters. We enforce uni-modality and a consistent order between the labels, but without constraining the learned representation to any specific parametric model, allowing the training to explore a larger space of solutions. To this end, we describe the uni-modality property through ordering adjacent labels, thereby ensuring decreasing monotonicity of the probabilities on both sides of the target label. Such an order is represented using a set of inequality constraints on all pairs of adjacent labels. The competing constraints are optimized with a powerful extension of the log-barrier method \citep{boyd2004convex,kervadec2019log}, which is well-known in the context of interior-point methods in convex optimization. Unlike \citep{beckham2017unimodal}, our method scales up to a very large number of labels. Furthermore, we provide a new metric, as a proxy, to asses the uni-modality of a distribution by measuring the order between adjacent labels.





\section{Uni-modality via pairwise inequality constraints}
\label{sec:proposed-method}

Let us consider a set of training samples  where  is an input sample, a realization of the discrete random variable  with support set ;  is the sample label, a realization of the discrete random variable  with support set  that exhibits an \emph{overall order} between the labels,

where  means that the event described by the label  \emph{is ordered before} the event described by the label . In this work, we propose to use pairwise inequality constraints to enforce implicitly the uni-modality of the posterior probability, with the latter decreasing monotonically as we move further away from the target label. For notation simplicity and clarity in this section, we omit sample index  and the expected value of losses over all the samples. We define   as the posterior probability estimated by a neural-based model (function) .  denotes the logit scores\footnote{For generality, we assume that such scores are unbounded.} obtained by the model , where the posterior probability is computed using standard \verb+softmax+ function, . Let  and  denote the domain and range of function , respectively.


We describe the uni-modality of a function with respect to a target point (or label) as a decreasing monotonicity of the function above and below the point, according to some pre-defined order. To ensure such decreasing monotonicity in a non-parametric way, we embed hard pairwise constraints on the order between every two adjacent points, within each of two sets of points, one including those below the target and the other including those above. Instead of ordering probabilities, we consider ordering scores.
For a sample , and its score vector , we formulate adjacent ordering as a constrained-optimization problem using the following set of hard pairwise inequality constraints:

where  is a standard classification loss such as the cross-entropy (CE):
.
The cross-entropy will be used in our experiments, but our constrained optimization can be integrated with any other classification loss in a straightforward manner.


Our constrained optimization problem in Eq.\eqref{eq:eq-2} is very challenging for modern deep networks involving large numbers of trainable parameters \citep{kervadec2019constrained,kervadec2019log,marquez2017imposing,pathak2015constrained,ravi2018constrained}. In the context of deep networks, hard constraints are typically addressed with basic penalty methods \citep{he2016learning,jia2017constrained,kervadec2019constrained}  as they accommodate SGD optimization, avoiding explicit primal-dual steps and projections. However, for a large set of constraints, penalty methods might have difficulty guaranteeing
constraint satisfaction as they require careful and manual tuning of the weight of each constraint. In principle, standard Lagrangian-dual optimization seeks automatically the optimal weight of the constraints, and have well-established advantages over penalty methods, in the general context of convex optimization \citep{boyd2004convex}. However, as shown and discussed in several recent deep learning works \citep{marquez2017imposing,pathak2015constrained,ravi2018constrained,kervadec2019constrained,kervadec2019log}, in problems other than ordinal classification, those advantages do not materialize in practice for deep networks due mainly to the interplay between the dual steps and SGD optimization, causing instability, and to the incurred computational complexity. To solve our problem in Eq.\eqref{eq:eq-2}, we consider two alternatives to explicit Lagrangian-dual optimization: a penalty-based method and a powerful extension of the log-barrier method, which is well-known in the context of interior-point methods \citep{boyd2004convex,kervadec2019log}. In particular, the log-barrier method is well-suited to our problem. It approximates Lagrangian optimization via implicit dual variables, handling effectively large numbers of constraints, while accommodating standard SGD and avoiding explicit Lagrangian-dual steps and projections.

\textbf{Penalty-based optimization:}  in Eq.\ref{eq:eq-2} is augmented by converting each inequality constraint into a penalty term  that increases when the corresponding constraint is violated \citep{bertsekas1995athena}. To impose the inequality constraint , a quadratic penalty is used,

where , , and  is a slack constant to avoid the equality case. In this case, our problem in Eq.\eqref{eq:eq-2} becomes,

where , and  is a model hyper-parameter, which balances the contribution of all the penalties encouraging constraint satisfaction in Eq. \eqref{eq:eq-quad-pen}; and determined using a validation set. This method is referred to as PN (Eq.\ref{eq:eq-quad-pen}).

\textbf{Log-barrier optimization:}
While PN-based methods are simple and straightforward, they do not guarantee constraints satisfaction and require an empirical tuning of the importance coefficient(s) \citep{fletcher1987practical,gill1981practical}. Moreover, once a constraint is satisfied, the penalty is zero. Consequently, constraints that are satisfied in one iteration may not be satisfied in the next one since the penalty does not play a role of a barrier at the feasible set of solutions. This can be problematic when dealing with a large number of constraints at once. To avoid such well known issues with PN methods, we consider log-barrier methods (LB) as an alternative. LB-methods belong to interior-point methods (IP) \citep{boyd2004convex}, which aim to approximate Lagrangian optimization with a sequence of unconstrained problems and implicit dual variable, avoiding dual steps and projections \citep{boyd2004convex}.  Eq.\eqref{eq:eq-2} can be re-written in a standard form of a LB method:

LB methods are widely used for inequality constrained problems \citep{boyd2004convex}. The main aim of LB methods is to convert a constrained problem of the form in \eqref{eq:eq-5}) into an unconstrained one via an indicator function  that has zero penalty when the constraint is satisfied, and a penalty of  otherwise. Instead of using , LB methods employ an approximate, , using the logarithmic function, where the penalty decreases the further we get away from violating the inequality, forming a barrier between feasible and infeasible solutions. To solve Eq.\eqref{eq:eq-5}, a strictly feasible set of parameters  are required as a starting point. Such a set is found through Lagrangian minimization of inequality constraints (\emph{phase I} \citep{boyd2004convex}), which turns out to be a problem of similar difficulty as the constrained optimization in Eq.\eqref{eq:eq-5} \citep{boyd2004convex}. Such strategy makes standard LB methods impractical for constraining deep models. We use an extension of the standard log-barrier based on a different approximation of the indicator function \citep{kervadec2019log}. The main advantage is that this algorithm does not require starting from a feasible solution -- i.e.,  is no longer restricted to feasible points of . A direct consequence is that stochastic optimization techniques such as SGD can be directly applied without the need for a feasible starting point. We replace problem Eq.\eqref{eq:eq-5} by the following sequence of unconstrained problems, parameterized by a temperature :

where  is a log-barrier extension, which is convex, continuous, and twice differentiable \citep{kervadec2019log}:

One can show that optimizing log-barrier extensions approximate Lagrangian optimization of the original constrained problem with implicit dual variables, with a duality gap upper bounded by a factor of ; see Proposition 2 in \citep{kervadec2019log}.
Therefore, in practice, we use a varying parameter  and optimize a sequence of losses of the form \eqref{eq:eq-elb}, increasing gradually the value of  by a constant factor. The network parameters evaluated at the current  and epoch are used as a starting point for the next  and epoch.
In our experiments, we refer to this LB method as the \emph{extended log-barrier} (ELB) (Eq.\ref{eq:eq-elb}).




\section{Experiments}
\label{sec:experiments}

\noindent \textbf{Performance metrics:}
We denote  as the label predicted by the model,  as the expectation value, and  as an evaluation dataset. For our evaluation, we report performances using two metrics:
1) The mean absolute error, which is often used in OC setups: ; and
2) We propose a new metric that measures how well labels are ordered, above and below the true or predicted label.
Following the \emph{non-monotonic index} defined in \citep{ben1995monotonicity,gutierrez2016current}, we propose the \emph{Side-Order Index} (SOI) that counts the number of satisfactions (non-violations) of the order constraints over adjacent labels above and below a reference label ,

This metric can be seen as a proxy to describe how well a distribution is uni-modal with respect to a reference label .
    Furthermore, it is appropriate for evaluating the performance of a constrained-optimization method for our problem
    in \eqref{eq:eq-2} as it evaluates constraint satisfaction. We compute the expected value over a normalized measure so that the metric is independent of the total number of labels, hence, independent of the number of pairs of  adjacent labels. Consequently, the range of the measure is in , where  indicates that all the adjacent labels are un-ordered, and  indicates a perfect order.   In our experiments, we consider the case where the reference label  is the predicted label. It is noted . In this case, we measure the consistency of the model's predictions with respect to the predicted label and \emph{independently} from the true label. This measure is the most important as it assesses the model's consistency when it is evaluated in a real scenario, where the true label is unknown.



\noindent  \textbf{Datasets and training protocol:}
We consider datasets that naturally exhibit order between the labels.  We target datasets that have large number of labels. Applying OC over datasets with very small number of labels is unlikely to show the power and limitation of different methods. We consider 3 different applications: breast cancer grading, photographs dating, and age estimation using public benchmarks.
(1) \emph{Breast cancer grading}: This task consists in classifying histology images of breast biopsy into different grades that are ordered with respect to the cancer aggressivity. We use the dataset BACH (Part A) Breast cancer \citep{aresta2018bach} referred to here as ICIAR. The dataset contains a total of 400 images, and 4 classes: normal, benign, in Situ, and invasive (in this order). Following the protocol described in \citep{belharbi2019wsolentropy,rony2019weak-loc-histo-survey}, we perform two splits of the dataset where in each split we take 50\% of samples per class for test, and perform 5-fold cross-validation to build the train/validation sets.
(2) \emph{Photographs dating}: This task consists of predicting in which decade a color image was taken. We consider the dataset Historical Color Image dataset (for classification by decade)\footnote{\url{http://graphics.cs.cmu.edu/projects/historicalColor/}} \citep{palermo2012datingdataset}, referred to here as HCI, along with the experimental protocol in \citep{palermo2012datingdataset}. The dataset contains 5 decades from 1930s to 1970s, each containing 265 images, for a total of 1325 images. We took 50 random images per decade to form a test set, with the rest of the data used for training and validation sets using 10-fold cross-validation. This process is repeated 10 times.
(3) \emph{Age estimation}: This task consists of estimating someone's age based on their picture. We consider three datasets:
(q) FG-NET dataset\footnote{\url{https://yanweifu.github.io/FG\_NET\_data/index.html}} \citep{panis2016overview}, referred to here as FGNET: It is a very early database used for age estimation, which contains 1,002 face images from 82 individuals, with ages ranging from 0 to 69 (70 classes);
(b) Asian Face Age Dataset (AFAD)\footnote{\url{http://afad-dataset.github.io/}} \citep{niu2016ordinal} light (AFAD-Lite), with a total of 59,344 samples, and age ranges from 15 to 39, and a total number of classes of 22; and
(c) AFAD-Full \citep{niu2016ordinal}, with a total of 165,501 samples, an age ranges from 15 to 72, and a total number of classes of 58. The same protocol is conducted over the three datasets. Following the experimental setup in \citep{chang2011ordinal,chen2013cumulative,niu2016ordinal,wang2015deeply}, we randomly select 20\% of the entire dataset for testing, and perform 5-fold cross-validation to build train and validation sets. This process is repeated 10 times. All the splits are done randomly using a deterministic code that we provide publicly along with the splits. We report the mean and standard deviation of each metric.


For a fair comparison, all the methods use exactly the same training setup including the shuffling, the order of processing samples, and the experimental environment (device and code). We use a pre-trained Resnet18 \citep{heZRS16} as a model ,  with WILDCAT \citep{durand2017wildcat} pooling layer and  hyper-parameters . Randomly cropped patches of size  are used for training. We train for 1000 epochs using SGD with a learning rate of ,\footnote{Except for HCI dataset, where we use a learning rate of .}  which is decayed every  epochs by , with an allowed minimum value of , a batch size of , a  momentum of  and weight decay of . For PN (Eq.\ref{eq:eq-quad-pen}),  is selected using validation from the set , and set to ; . For LB methods,  is initialized to , and iteratively increased after each epoch by a factor of , with an allowed maximum value of . Due to the large size of AFAD-Lite-Full datasets, training is done using a batch size of 64 for 100 epochs.\footnote{For AFAD-Full, PN and ELB are trained only for 80 epochs due to time constraint.} For AFAD-Full,  is initialized to  and increased by a factor of . For the case of age estimation task, we do not use any face detector, face cropping, nor face alignment. We feed the network the raw image. For efficient computation and scalability, we implement the difference  (Eq.\ref{eq:eq-quad-pen}, \ref{eq:eq-5}) using 1D convolution with fixed weights  as a differentiator from left to right. The difference in the other direction is the same as the one from left to right but with sign .









\section{Results and discussion}
\label{sec:results}
\begin{table*}[ht!]
  \caption{Evaluation of different methods over the test sets of ICIAR and HCI datasets (classification datasets).}
  \label{tab:iciar-hci}
  \centering
  \small
  \resizebox{0.9\linewidth}{!}{
  \begin{tabular}{l|l|l||l|l}
\hline
    Method &  \multicolumn{2}{c||}{ICIAR} &  \multicolumn{2}{c}{HCI}\\
\cmidrule{2-5}
                      &     &  (\%)    &       &  (\%) \\
    \midrule
    CE       &  &     &    &  \\
    \hline
    REN \citep{cheng2008neural}           &   &   &     &  \\
    LD \citep{geng2016label}             &  &     &      &  \\
    MV \citep{pan2018mean}               &   &    &    &  \\
    PO \citep{beckham2017unimodal}        &   &    &    &  \\
    \hline
    PN (ours)   &   &    &    &   \\
    ELB (ours)   &    &    &   &  \\
    \hline
  \end{tabular}
  }
\end{table*}


\begin{table*}[ht!]
  \caption{Evaluation of different methods over the test sets of AFAD-Lite, AFAD-Full, and FGNET datasets.  indicates that the method does not scale to a large number of classes.
}
  \label{tab:afad-fgnet}
  \centering
  \small
  \resizebox{1.\linewidth}{!}{
  \begin{tabular}{l|l|l||l|l||l|l}
\hline
    Method &  \multicolumn{2}{c||}{AFAD-Lite} & \multicolumn{2}{c||}{AFAD-Full} & \multicolumn{2}{c}{FGNET}\\
\cmidrule{2-7}
                      &   &  (\%)
                      &   &  (\%)
                      &   &  (\%)  \\
    \midrule
    CE          &   &   &  &  &    &   \\
    \hline
    REN \citep{cheng2008neural}          &     &   &    &    &    &  \\
    LD \citep{geng2016label}             &     &   &    &     &    &   \\
    MV \citep{pan2018mean}               &     &   &    &     &   &  \\
    PO \citep{beckham2017unimodal}       &     &   &    &   &   &  \\
     \hline
     PN (ours) &  &   &  &  &    &  \\
     ELB (ours) &  &   &  &  &    &    \\
    \hline
  \end{tabular}
  }
\end{table*}

The quantitative results obtained with the different methods over the different test sets are presented in Tabs.\ref{tab:iciar-hci}- Tab.\ref{tab:afad-fgnet}. We recall the notation of the different methods --
CE:  cross-entropy method;
 REN \citep{cheng2008neural}: re-encode the hard target into a vector of binary values and use the mean squared error as a loss. The threshold is set to ;
 LD \citep{gao2017deep,geng2016label,geng2013facial,huo2016deep}: label distribution learning with Bayes rule prediction. The variance is set to ;
 MV \citep{pan2018mean}: mean-variance loss combined with softmax where the predicted label is the round function of the expected value of the labels. Following \citep{pan2018mean}, we set ;
 PO \citep{beckham2017unimodal}: Hard-wire Poisson distribution at the network output, and use cross-entropy for learning.  is fixed and set to 1 as in the paper \citep{beckham2017unimodal}, and the prediction is based on the expected value of the labels;
 PN (Eq.\ref{eq:eq-quad-pen}): penalty-based method;
 ELB (Eq.\ref{eq:eq-elb}): extended log-barrier method.
All the methods have the same exact model capacity (i.e., ResNet18 \citep{heZRS16}), except PO \citep{beckham2017unimodal} where we add a dense layer that maps from  (number of classes) into one (positive score). Based on the obtained results, we note the following.
\textbf{(1) In term of}  \textbf{consistency}, we observe that ELB method yields the best results, achieving almost perfect ordering  over all datasets.
 Then, comes second the PN method, but with a large gap of  in comparison to ELB, and a slightly  better performance than CE (). We note that the gap between PN and ELB increases with the number of classes:  on ICIAR and HCI with  and  classes, respectively;  on AFAD-Lite with  classes, and AFAD-Full with  classes, respectively; and  on FGNET with  classes. This is expected, since the PN method does not cope well with the interplay between different constraints, more so when the number of constraints is large unlike LB methods which approximate Lagrangian optimization. \hspace{2mm} The different methods REN, LD, MV, and PO yield a  not far from the CE method. LD achieves good results over ICIAR and HCI with  of  and  ranking in the second place after ELB. However, its performance drops to  over AFAD-Lite -Full, and to  over FGNET suggesting that it does not handle well large number of classes. Compared to LD, MV performs better on large number of classes achieving  over AFAD-Lite -Full, and FGNET, respectively. REN performance is usually worse than CE. The case of PO is particular. It is expected to obtain  but since the predicted label is the expected value of the label (and not the  of the scores), it achieves a low level of performance. When PO uses , it does not represent a fair comparison to other methods since the order in PO is \emph{hardwired}, while the order is \emph{learned} with all other methods. PO \citep{beckham2017unimodal} does not scale up to large numbers of classes, and, in \citep{beckham2017unimodal}, it was evaluated only on two datasets, with 5 and 8 classes. \hspace{2mm}  These results show the amount of disorder with a CE prediction in an OC setup, which confirms its inadequacy to such context. Furthermore, we observe the power of LB methods compared to PN method, with the former achieving much better constraint satisfaction than the latter. This shows the effectiveness of LB methods and, in particular, its extension \citep{kervadec2019log}, for optimizing with inequality constraints
 on a model output (Fig.\ref{fig:curves-valid-others-main}).
\textbf{(2) In term of} , in all the datasets, we observe that combining CE with inequality constraints always helps improving the performance. Over ICIAR and HCI datasets, ELB obtained the best performance with , respectively. Over AFAD-Lite, the MV method yields , while REN obtains a state-of-the-art error over AFAD-Full with , compared to   reported in \citep{niu2016ordinal}. In both datasets, ELB ranks third with , respectively. All our experiments are repeated 10 times, while \citep{niu2016ordinal} repeats experiments for 100 times.
On the FGNET dataset, which has 70 labels, ELB obtained the best performance of ,  followed by REN, and MV with , respectively. Combining the inequality constraints with the CE to promote a consistent output prediction helps always to improve the  performance.
\begin{figure*}[ht!]
  \centering
  \includegraphics[width=.45\linewidth]{afad-full-valid-metrics}
  \includegraphics[width=.45\linewidth]{fgnet-valid-metrics}
  \includegraphics[width=.45\linewidth]{afad-lite-valid-metrics}
  \includegraphics[width=.45\linewidth]{bach-part-a-2018-valid-metrics}
  \caption{Moving average of  and  metrics over the \textbf{validation set (one run over fold-0, split-0)} of AFAD-Full (top-left), FGNET (top-right), AFAD-Lite (bottom-left), and ICIAR (bottom-right) for CE, PN and ELB. (Best visualized in color.)}
  \label{fig:curves-valid-others-main}
\end{figure*}
\textbf{(3) Training time}: PN and LB methods do not add a significant computation overhead compared to CE. \textbf{(4) Which method to choose in practice?}: this is an important question and the answer depends mostly on the specific application.  Based on the above empirical evidence we suggest that: (\emph{a}) for critical applications where an agent is used who expects an explanation for the model’s decision (e.g., in the medical domain, where model interpretability/consistency is a priority),  our method is a better choice; (\emph{b}) For applications where the  performance is a priority (e.g., control and automatic applications) without agent, other methods can be a good choice. However, our method can be considered as well since it yields competitive . (\emph{c}) for applications where both metrics are crucial, our method is a reasonable choice. \hspace{2mm} Independently from the chosen method, the proposed  metric provides a helpful tool for the agent to quickly and reliably assess the prediction’s consistency along with the PD visualization.





\section{Conclusion}
\label{sec:conclusion}

We presented a new constrained-optimization formulation for ordinal classification, with uni-modality of the label distribution imposed implicitly via a set of inequality constraints over pairs of adjacent labels.
To tackle the ensuing challenging optimization problem, we solve a sequence of unconstrained losses based on a powerful extension of the log-barrier method, which is well-known in the context of interior-point methods. This accommodates standard SGD, and avoids computationally expensive Lagrangian dual steps and projections, while outperforming substantially standard penalty methods. Our non-parametric model is more flexible than the existing ordinal classification techniques: it does not restrict the learned representation to a specific parametric model, allowing the training to explore larger spaces of solutions and removing the need for {\em ad hoc} choices, while scaling up to large numbers of labels. It can be used in conjunction with any standard classification loss and any deep architecture. We also propose a new performance metric for ordinal classification, as a proxy to measure a distribution uni-modality, referred to as the Sides Order Index (SOI). We report comprehensive evaluations and comparisons to state-of-the-art methods on benchmark public datasets for several ordinal classification tasks, showing the merits of our approach in terms of label consistency and scalability.


\medskip

\small


\bibliographystyle{apalike}
\bibliography{bibliography}

\end{document}
